diff --git a/source/_includes/custom/category_feed.xml b/source/_includes/custom/category_feed.xml
index 0b3b968..1e65f32 100644
--- a/source/_includes/custom/category_feed.xml
+++ b/source/_includes/custom/category_feed.xml
@@ -15,13 +15,16 @@ layout: nil
   </author>
   <generator uri="http://octopress.org/">Octopress</generator>
 
-  {% for post in site.categories[page.category] limit: 5 %}
+  {\% for post in site.categories[page.category] limit: 5 %\}
+  {% for post in site.posts limit: 20 %}
   <entry>
-    <title type="html"><![CDATA[{{ post.title | cdata_escape }}]]></title>
-    <link href="{{ site.url }}{{ post.url }}"/>
-    <updated>{{ post.date | date_to_xmlschema }}</updated>
-    <id>{{ site.url }}{{ post.id }}</id>
-    <content type="html"><![CDATA[{{ post.content | expand_urls: site.url | cdata_escape }}]]></content>
+{{post.categories}}
+
+
+{% if post.categories contains "startup" %}
+TARAS
+   {{ post.content}}
+  {% endif %}
   </entry>
   {% endfor %}
 </feed>
diff --git a/source/_posts/2006-12-05-static-analysis.markdown b/source/_posts/2006-12-05-static-analysis.markdown
deleted file mode 100644
index 4441a4f..0000000
--- a/source/_posts/2006-12-05-static-analysis.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2006-12-05 09:50:38
-layout: post
-slug: static-analysis
-title: Static Analysis
-wordpress_id: 3
-categories:
-- mozilla
-- DeCOMtamination
-- squash
----
-
-**Introduction**  
-  
-My name is Taras Glek. I have been tasked with working on static analysis tools to automate [deCOMtamination](http://wiki.mozilla.org/Gecko:DeCOMtamination), verify code, etc.  
-  
-**Progress**  
-  
-C++ is a hard language to parse and no static analysis can be done before Mozilla source code be represented as an abstract syntax tree. My first step was to get the Mozilla trunk parsing with [Elsa](http://www.cs.berkeley.edu/~smcpeak/elkhound/). With a small fix, Elsa now parses all files needed to build Firefox with -DNS_DISABLE_LITERAL_TEMPLATE (Elsa's template support is incomplete).  
-  
-Now that code parses we can move to the next step of writing tools that can analyze the Mozilla AST. These would prove certain parts of code correct or do source-to-source transformations such as the planned [patch tool](http://weblogs.mozillazine.org/roadmap/archives/2006/11/oinkbased_patch_generation.html). More applications of static analysis [here](http://wiki.mozilla.org/Static_Analysis). DeCOMtamination of the Gecko core is a time consuming task and is the main candidate for static analysis. I started formalizing the broad tasks collectively referred to as DeCOMtamination into an [algorithm](http://wiki.mozilla.org/Gecko:DeCOMtamination_Algorithm) that could be implemented. I am prototyping the analysis in O'Caml using the [Olmar](http://www.cs.ru.nl/~tews/olmar/) binding to Elsa. O'Caml is a great language to this task because it has a lot of [features](http://flint.cs.yale.edu/cs421/case-for-ml.html) for writing compilers and it allows me to load and traverse parts of the AST in an interactive console which greatly speeds up development. I am currently able to process class declarations, graph the class hierarchy into a giant pseudo-UML class diagram and am working on an ability to move class members up from the implementation class into the interface class while adding forward declarations, etc.  
-  
-Additionally I am involved in garbage collection related analysis that prevents unsafe uses of the garbage collection API and improving LXR precision and functionality via feeding it data from Elsa/Olmar.  
-  
-**Update:** This mini-[presentation](http://glek.net:8080/~taras/presentation.pdf) should clarify some of the reasons why we are doing deCOMtamination.
diff --git a/source/_posts/2006-12-21-oink-meet-squash.markdown b/source/_posts/2006-12-21-oink-meet-squash.markdown
deleted file mode 100644
index adb515d..0000000
--- a/source/_posts/2006-12-21-oink-meet-squash.markdown
+++ /dev/null
@@ -1,64 +0,0 @@
----
-comments: true
-date: 2006-12-21 15:55:25
-layout: post
-slug: oink-meet-squash
-title: Oink, Meet Squash
-wordpress_id: 4
-categories:
-- mozilla
-- DeCOMtamination
----
-
-Progress  
-  
-I spent some time proving to myself that it is possible to automate DeCOMtamination. The result is squash - a tool that aims to accomplish the first step of DeCOMtamination. My near term goals are to be able to squash together a real life XPCOM interface and implementation such that: 
-
-  1. The resulting code compiles
-  2. Firefox runs correctly
-  3. Simple functions using out parameters are converted to use return values instead
-Currently I am approximately halfway through with first requirement. In its current form squash lives as a patch to the [oink suite](http://www.cubewano.org/oink) of tools.  
-  
-Usage 
-
-  * Pick a simple XPCOM implementation class to squash. I like 
-```
-CSSLoaderImpl
-```
-.
-  * Produce a .i file because Oink/Elsa do not have an integrated preprocessor yet.
-```
- make CXX="gcc -E" nsCSSLoader.o; mv nsCSSLoader.o nsCSSLoader.i
-```
-
-  * Squash it: 
-```
-./squash -o-lang GNU_Cplusplus -sq-implementation CSSLoaderImpl  nsCSSLoader.i  -sq-exclude-include string/nsTString.h -sq-include "nsString.h" > /tmp/cssloader.patch > cssloader.patch
-```
-
-  * Apply the patch: 
-```
-patch -p0 < cssloader.patch
-```
-
-  * Run make, deduce the problem with the patch and start over
-Current functionality at the header level: 
-  * Class member merging 
-    * virtual interface members are replaced with non-virtual ones from implementation
-    * Class members and their parameters are renamed: eg s/CSSLoaderImpl/nsICSSLoader/
-  * Additional members from the implementation are added to the interface
-  * Extra class/struct definitions used by the implementation members are moved up into the header as needed
-  * Header and forward declaration inference 
-    * The resulting class will usually not compile because more headers are needed. Squash computes the set difference of class definitions as used by the implementation and the interface. Part of the list ends up as forwad declarations, the other part is translated futher into #include statements.
-    * The above is trickly algorithm to fully implement fully, so in the meantime there are also manual overrides with -sq-include and -sq-exclude-include
-At the source level squash renames the class part of function definitions along with their arguments.  
-  
-**Results**  
-  
-[Sample patch output](http://glek.net:8080/~taras/cssloader.patch.gz).  
-  
-[Oink patch](http://glek.net:8080/~taras/oink.patch.gz).  
-  
-**Challenges and Limitations**  
-  
-I am really grateful for Elsa's ability to parse C++ as used in Mozilla. I think this opens a lot of doors to automation, optimizations and new features that would be too laborious to even consider implementing otherwise. However Elsa still has some maturing to do. We loose typedef information, pretty-printing is still spotty and looks too different from parsed C++, but the biggest challenge is the lack of an "end-of-ASTNode" position information. All these will be addressed in the future, but in the meantime I have to make unfortunate choices of either getting distracted and working on Elsa/Oink internals or do work-around and continue with writing tools. My short term goal is to finish step 1 and to get squash into the oink SVN.
diff --git a/source/_posts/2007-01-03-squashed-and-compiled.markdown b/source/_posts/2007-01-03-squashed-and-compiled.markdown
deleted file mode 100644
index a2853d4..0000000
--- a/source/_posts/2007-01-03-squashed-and-compiled.markdown
+++ /dev/null
@@ -1,49 +0,0 @@
----
-comments: true
-date: 2007-01-03 11:22:25
-layout: post
-slug: squashed-and-compiled
-title: Squashed and Compiled
-wordpress_id: 5
-categories:
-- mozilla
-- DeCOMtamination
-- squash
----
-
-**Squash Milestone Reached** Squash can now produce a patch that squashes my testcase class nsCSSLoaderImpl into the nsICSSLoader interface such that the resulting code compiles, links and runs!  
-  
-**Gory Details** Patching function bodies turned out easier than expected. Since the last post, I've added the ability to rewrite variable declarations, casts and static method calls. This was enough to get nsCSSLoader.cpp compiling.  
-  
-I also ran into an issue where some methods need to remain virtual such that they can be referenced from other modules. I added a -sq-virtual flag to specify method names which need to stay virtual.  
-  
-I discovered that the implementation class can be used from other source files so now squash can work on multiple files. Unfortunately, this made me run into another Elsa misfeature: memory allocation. Elsa data structures do not attempt to clean up in their destructors. Once an AST is produced, it will remain in memory for the duration of execution. This is an issue, because merely parsing all of the .i files in layout/style/ takes over 600M of memory even though squash is strictly sequential and processes a single file at a time. Hopefully, converting Elsa to use auto_ptr is feasible and I wont have to resort to funny fork() tricks to reclaim memory.  
-  
-**ML vs C++ for Compilers: Rant** I wonder why people insist on using C++ for symbolic manipulations instead of an *ml like O'Caml and either give up or, more frequently, reinvent features such as the ml type system, list processing, garbage collection or pattern matching. Isn't it more productive to not have to deal with segfaults, slow compilation times and have a tenfold reduction in code size?  
-  
-**Squash Usage** First I grep the build directory for usage of CSSLoaderImpl. This imprecise and will eventually be handled by squash itself, but first the memory deallocation issue has to be addressed or an index of the whole sourcetree needs to be built.  
-  
-find -name \*.o | xargs grep CSSLoaderImpl  
-  
-This returned nsCSSLoader.o and nsLayoutStatics.o . Now .i files are produced by running make in their respective directories  
-  
-make nsCSSLoader.i make nsLayoutStatics.i  
-  
-For convenience I gather the .i files in a moz directory and run squash.  
-  
-./squash -o-lang GNU_Cplusplus -sq-exclude-include string/nsTString.h -sq-include nsString.h -sq-include nsCOMArray.h -sq-virtual LoadSheetSync -sq-virtual LoadSheet -sq-implementation CSSLoaderImpl moz/nsCSSLoader.i moz/nsLayoutStatics.i > cssloader.patch  
-  
-Turns out pretty printing C++ is hard and Oink/Elsa's pretty printer still needs a lot of work. By producing patches and only rewriting part of the code squash rewrites only the code that needs changing. This avoids pretty printer bugs, and maximally preserves comments and the original code structure. The wackyness of the pretty printed code is apparent in the [cssloader.patch](http://glek.net:8080/~taras/cssloader.patch), especially in the function bodies.  
-  
-**Future Work** I am happy to see that patching is viable even without precise source coordinates or preprocessor support in Elsa. My near term goals for squash are: 
-
-  * Push squash upstream
-  * Add the ability to translate out-parameters to return values where possible
-  * Get a list of candidates for DeCOMtamination and improve squash enough to process all of them
-  * Work on a source code indexer. This would be useful to both squash as a semantic grep database and could be used to improve lxr.
-In the longer term, I would also like to see some Elsa changes: 
-  * Figure out a memory de-allocation strategy
-  * Resolve the pain that is caused by Elsa having own "string" class which makes using STL an exercise in namespace verbosity. If Elsa were to switch to C++ strings, the above de-allocation job would be simplified too.
-  * Elsa is lossy when it comes to C++ extensions: may need to extend the Elsa AST a little
-  * It would be nice to improve Elsa memory consumption further. This would be hard.
-  * It would be great to make Elsa's C++ [const-correct](http://www.parashift.com/c++-faq-lite/const-correctness.html)
diff --git a/source/_posts/2007-01-11-squash-progress-and-plans.markdown b/source/_posts/2007-01-11-squash-progress-and-plans.markdown
deleted file mode 100644
index a7a9a38..0000000
--- a/source/_posts/2007-01-11-squash-progress-and-plans.markdown
+++ /dev/null
@@ -1,55 +0,0 @@
----
-comments: true
-date: 2007-01-11 14:34:59
-layout: post
-slug: squash-progress-and-plans
-title: Squash Progress and Plans
-wordpress_id: 6
-categories:
-- mozilla
-- DeCOMtamination
-- squash
----
-
-**Out-param Rewriting Work**  
-  
-Since the last post I worked on rewriting functions that use out-parameters to use return values instead. I got as far as rewriting method definitions and simple call sites, but decided to hold off further work until the rest of squash is more complete.  
-  
-**Squash Development Roadmap** [Robert O'Callahan](http://weblogs.mozillazine.org/roc/) helped me devise a near term roadmap. I am going to focus getting squash to be production quality for member renames and to produce commit-quality patches. An example query would be to rename sIFrame::GetPresContext to nsIFrame::PresContext. This involves a couple of big details: 
-
-  * Produce aesthetically pleasing code via text substitution instead of oink pretty printing. The advantage of this is that the original coding style, comments and indentation will all be preserved. This involves reparsing the resulting code to verify correctness (doubles-memory usage & processing time).
-  * To produce a complete patch squash needs to process all of the relevant source code. This increases memory usage and processing time linearly. I'll use grep to narrow down candidates for processing and in the future will use a AST database of mozilla to figure out exactly what needs changing.
-  * It is useful to be able to process all interesting source code in one invocation but just processing the layout/generic directory sequentially uses over 2GB of RAM (Elsa's AST does not support deallocation) and takes 3 minutes on a quad Opteron. So in order to reduce RAM usage and be a trendy multi-core developer I'll fork() a process for every file and use that for both parallelism and memory cleanup purposes.
-  * Develop a web frontend that maintains an up-to-date mozilla source tree and has squash setup on it where one would be able to enter their rename operation and have patch emailed back to them. Rob even had a cool idea to have the user enter a bugzilla id and have the patch automatically attached to that. This will be useful so I don't have to work so hard on packaging squash and users will get instant gratification. Plus people without quad Opterons will be able to test squash too :)
-All that is Milestone 1. After that I'll work on infrastructure like AST-node-location info, cleaning up pretty printing and defining the exact goal for the next milestone.  
-  
-**Current Status**  
-  
-Over the past 3 days I refactored squash to be able to do renames without having to go through class squashing, etc. I added the ability to rename class members and now it can produce ugly patches for that.  
-  
-The current workflow to rename nsIFrame::GetPresContext to nsIFrame::PresContext is: 
-
-  1. Identify possible targets 
-```
-find ~/work/ff-build -name \*.o |xargs grep nsIFrame > /tmp/output.sh
-```
-
-  2. My sed is rusty so I used regexps in [Kate](http://kate-editor.org/) to convert resulting lines into something like 
-```
-make -C ./layout/generic/ nsSpacerFrame.i
-make -C ./layout/generic/ nsFrameSetFrame.i
-make -C ./layout/generic/ nsBlockFrame.i
-```
-
-  3. Run the script to produce the needed .i files 
-```
-. /tmp/output.sh
-```
-
-  4. Grand-finale: 
-```
-find ~/work/ff-build/ -name \*.i |time xargs  ./squash -o-lang GNU_Cplusplus  -sq-implementation nsIFrame  -sq-no-squash -sq-rename-member GetPresContext PresContext > [nsiframe.diff](http://glek.net:8080/~taras/nsiframe.diff)
-
-```
-Note that find outputs absolutely filenames which is essensial for squash to resolve relative include files.
-The setup and squashing itself is a bit laborious and RAM/CPU intensive and is the reason for a web frontend. I am going to be ecstatic once this all works.
diff --git a/source/_posts/2007-01-24-will-rename-class-members-for-food.markdown b/source/_posts/2007-01-24-will-rename-class-members-for-food.markdown
deleted file mode 100644
index 34110a3..0000000
--- a/source/_posts/2007-01-24-will-rename-class-members-for-food.markdown
+++ /dev/null
@@ -1,54 +0,0 @@
----
-comments: true
-date: 2007-01-24 18:04:39
-layout: post
-slug: will-rename-class-members-for-food
-title: Will Rename Class Members for Food
-wordpress_id: 8
-categories:
-- mozilla
-- DeCOMtamination
-- squash
----
-
-  
-  
-Squash may now be ready as a class member renaming tool for early adopters. I would like people to use me as a frontend to squash. Email me your requests for renames and I will reply with giant patches. This way squash can be immediately useful. Plus I can fix bugs in squash and figure out actual usecase while I get the frontend set up.Progress  
-  
-Squash can now produce a good looking [92K patch](http://glek.net:8080/~taras/nsiframe.diff) for renaming nsIFrame::GetPresContext. This means that squash can now correctly traverse 167 files and produce a patch that affects 103 of them. I am going to work on the web frontend next.  
-  
-Some issues below.  
-  
-**Tool Explosion**  
-  
-I wrote a creatively named frontend: run_squash. It prevents squash from running out of address space by running squash unit-at-a-time and combining patch output from multiple runs. It runs squash in parallel similar to make -j. This decreases runtime proportionally with the number of cores. I would be curious to see how Sun's Rock-based systems fare for this. For example on the 4way Opteron a 20 minute squash run takes around 5 minutes. Having lots of CPU cores will become important down the road once multiple users are running multiple analysis tasks on a single machine through a web frontend.  
-  
-There is another temporarly named tool, prepare.py, which greps .cpp files looking for candidates for renaming, produces matching .i files, figures out number of cpus and then invokes run_squash.  
-  
-More special purpose tools will need to be written. For example roc mentioned that it would be nice to check when generated interface files are being modified and to have the corresponding IDL updated instead while refusing to modify frozen IDL interfaces. Classes with IIDs would need to have them changed too.  
-  
-_Tool Rant_ I am trying to decide how to manage the tool growth such that things evolve sanely. Should squash be a giant swiss-army-knife binary capable of doing everything but incredibly hard to modify? Or should it be broken up into a dozen of separate programs & scripts that work together in an ad-hoc way? The latter would be what some people describe as UNIX way, whatever that means. In the 90s, the former would've been done by making everything a COM component and still just as hard to modify. Alternatively, I could use some strong ROPE and SOAP to tie everything together with SOA. Kidding aside, it would be nice to have a strategy to deal with this so people could run squash on their own machines too without spending a week setting up dependencies.  
-  
-**CPP – To Invert or Not to Invert**  
-  
-A large part of squash is hacks and workarounds for preprocessor-induced pain. Recently, I ran into two interesting cases where blind string substitution fails.  
-  
-_Multiline macro parameters_  
-  
-
-```
-if (NS_SUCCEEDED(
-nsSVGUtils::GetReferencedFrame(&nextPattern, targetURI,
-mContent,
-GetPresContext()->PresShell()))) {
-
-```
-Squash works on an AST produced from .i files. When cpp expands this macro, everything ends up on the same line as the if keyword. That's a problem because when squash wants to replace GetPresContext() the parser gives it the wrong line. Initially I was tempted to remove the newline in a few cases from the original source, but then I realized that this analogous to looking for the closing } in class declarations when end-of-AST-node info isn't available. Now if a string substitution fails squash will go to the next line until a match is found or one of ;{} characters is encountered. Yes, that's also an emoticon of me looking at yet another CPP-induced problem.  
-  
-_Replacing Code Within a Macro Definition. _Mozilla has whole functions defined within macros. Squash can not deal with that. Is it worth it to do a limited preprocessor inversion to fix these or to fail and let a developer do it by hand? For example one could mark up the .i file with metadata on which sections came from a macro expansion and which sections were passed into macros as parameters. Then an intelligent rewrite decision could be made. This would solve most of the CPP-induced problems I can think of, but would require hacking a good C preprocessor. This is probably not worth the pain, but apparently someone bolted on a bsd-licensed preprocessor onto Elsa. If that's true, the patch may get me most of the way to a macro-aware squash.  
-  
-**Quick Analyses**  
-  
-There are hundreds of useful analyses that can be done on Elsa's AST of Mozilla. However using C++ is too verbose and error prone do many of the simpler tasks. It would be nice to make a first-class binding to Oink/Elsa that easily extract all interesting info from the AST. Olmar is one way of doing that, but converting Elsa-style OO into ML datatypes produces incredibly verbose data structures and requires careful conversion of code such that information isn't lost.  
-  
-A language that can query the C++ AST in the way that the author's intended it, may be an easier way to go. ES4 JavaScript would be interesting for that because the script could traverse the cast-happy Elsa-AST, extract information of interested and present that as a structured type which could then be manipulated using type-safe pattern matching.
diff --git a/source/_posts/2007-02-01-lossy-ast-traversals-for-good-code-health.markdown b/source/_posts/2007-02-01-lossy-ast-traversals-for-good-code-health.markdown
deleted file mode 100644
index 2b4c19c..0000000
--- a/source/_posts/2007-02-01-lossy-ast-traversals-for-good-code-health.markdown
+++ /dev/null
@@ -1,48 +0,0 @@
----
-comments: true
-date: 2007-02-01 18:34:28
-layout: post
-slug: lossy-ast-traversals-for-good-code-health
-title: Lossy AST Traversals for Good Code Health
-wordpress_id: 9
-categories:
-- mozilla
-- dehydra
----
-
-Two weeks ago I finally listened to [Graydon](http://blog.mozilla.org/graydon) and spent some quality time playing with [UNO](http://spinroot.com/uno/) and reading the [paper](http://spinroot.com/uno/uno_long.pdf) on it. UNO provides a simple DSL language to traverse interesting parts of the C abstract syntax tree. It simplifies the AST down to the bare minimum of variable and function call info and iterates user-defined scripts over that.  
-  
-Since I was looking for a way to get away from C++ for code analysis I was very excited and decided to implement the ideas in UNO in my own tool which goes by a temporarily name of "dos". There limitations in UNO: it has no hope of parsing C++ without switching parsers and the DSL is rather limited. Thus, dos is built on the incredible [Elsa/Oink](http://www.cubewano.org/oink/) C/C++ parser and uses SpiderMonkey to provide JavaScript as a scripting language.  
-  
-**Status**
-
-  * dos builds a Control Flow Graph from the Elsa AST. It isn't finished and while for/while loops, break/continue/return and if statements are supported (as opposed to the trinary operator or goto), but the CFG isn't quite right yet. However, it's good enough for proof of concept purposes.
-  * Dos does not do DFS traversal when iterating the script like UNO, but instead iterates through statements sequentially because I did not feel like writing my own traversal of the massive Elsa AST.
-  * I mostly implemented an UNO-compatibility JS lib in [system.js](http://people.mozilla.com/~tglek/system.js) which should allow for easy ports of UNO analyses like [malloc.js](http://people.mozilla.com/~tglek/malloc.js). It's missing the negation conditions from UNO, but those should be quick to implement.
-**Instructions**
-
-  1. Download my oink [tarball](http://people.mozilla.com/~tglek/dos_and_squash-0.0.tar.gz) with the squash & dos additions.
-  2. Install ossp spidermonkey distribution: cd dos_and_squash-0.0/js-1.6.20060820 ; configure --prefix=/usr (or use /usr/include) && make install
-  3. Build the oink suite: cd ../oink ; ./configure && make
-  4. I ported a simple UNO analysis which checks that malloc() is always paired with a corresponding free() statement. To run it: ./dos -dos-javascript malloc.js simple.cpp Now modify line 12 of simple.cpp by putting ; after the while statement. The error will be detected: func:test Error at simple.cpp:13: malloc without free
-**Writing Scripts**  
-  
-Take a look at [simple.js](http://people.mozilla.com/~tglek/simple.js) for a barebone analysis. There should be at least 2 functions in every script _uno_check(vars, state)_ and _path_end(state)_. _uno_check()_ is called for every statement in a control flow path. _vars_ is an array of interesting variables and function calls in the current AST statement and _state_ is where the script should store all state info. _state_ gets copied on CFG block transitions with an optionally user-provided _clone()_ function (see system.js for an example). _path_end()_ is called when the end of the CFG path is reached.  
-  
-./dos -dos-javascript simple.js simple.cpp # this runs the user script  
-  
-**UNO-compatibility**  
-  
-UNO and the corresponding paper on it is currently the best documentation for dos. Thus I also assign _vars_ and _state_ to the global object to achieve UNO-like scripting feel. See malloc.js and system.js for details.  
-  
-**Goals**
-
-  * My foremost goal is to find a better name for dos. I'm open to suggestions that are both humorous and somehow related to source analysis.
-  * Easy: finish UNO compatibility functions. I'll do that as I port more scripts, but I wont mind if anyone does it for me.
-  * Improve the CFG, do some value analysis to reduce the graph and provide more info to the scripts
-  * Easy: Add types to the variable info, should get dos closer to doing the [GC safety-analysis](http://wiki.mozilla.org/GC_SafetySpec).
-  * Reuse the JS parser to build a JS CFG to allow the same kind of analyses for JavaScript. This would be great for verifying API usage in extensions. For bonus points one can allow the user to tie the JS and C/C++ analysis together for cross-language analyses.
-  * UNO has a fairly complicated global variable analyses that is not very scriptable and thus boring. I would be interested in scripting intra-procedural analyses to figure out call-graphs, do some sort of behavior inference (ie figure out indirect malloc calls, certain other heap modifying behaviors and propagate them as attributes to function calls), etc.
-**Update: New name for dos -> DeHydra**  
-  
-The tool is now named DeHydra since it is supposed identify bugs in the multi-headed Control Flow Graph monster.
diff --git a/source/_posts/2007-02-07-dotting-pretty-graphs.markdown b/source/_posts/2007-02-07-dotting-pretty-graphs.markdown
deleted file mode 100644
index 826e52e..0000000
--- a/source/_posts/2007-02-07-dotting-pretty-graphs.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2007-02-07 14:36:23
-layout: post
-slug: dotting-pretty-graphs
-title: Dotting Pretty Graphs
-wordpress_id: 10
-categories:
-- mozilla
-- dehydra
----
-
-It is difficult to follow error messages from control-flow analyzing tools. After struggling to visualize what I was debugging, I added a a native JavaScript function to graph the CFG and display the current path through it.  
-  
-Now debugging control flow errors is as easy as looking at a (sometimes giant) [picture](http://people.mozilla.com/~tglek/cfg.png) of [this function](http://lxr.mozilla.org/mozilla/source/js/src/jsarray.c#492). The red represents the current flow and gray indicates flows that the script deemed correct.  
-  
-**Recipe**  
-  
-In this example I am checking that control flows through a particular point in the code (from line 1128 into line 1200). Since dos only deals with variables I added variables that it can match to the AST.  
-  
-I added DFLOW_START to line 1127, DFLOW_STOP to line 1200 and produced my .i files with make CC="gcc -DFLOW_START='{int __flow_start;}' -DFLOW_STOP='{int __flow_start=1;}'" jsarray.i  
-  
-Then I ran dos with the tiny analysis script: ./dos -dos-javascript [ensure_out.js](http://people.mozilla.com/~tglek/ensure_out.js) -o-lang GNU_C ~/work/ff-build/js/src/jsarray.i  
-  
-**Future Work** This should allow function-local dead code detection. Once dos is mature enough for function-local CFG traversals it will be interesting(but challenging) to try to expand this to detect dead functions or classes in Mozilla.
diff --git a/source/_posts/2007-02-28-websquash.markdown b/source/_posts/2007-02-28-websquash.markdown
deleted file mode 100644
index 10438f6..0000000
--- a/source/_posts/2007-02-28-websquash.markdown
+++ /dev/null
@@ -1,59 +0,0 @@
----
-comments: true
-date: 2007-02-28 13:20:15
-layout: post
-slug: websquash
-title: WebSquash
-wordpress_id: 11
-categories:
-- mozilla
-- DeCOMtamination
-- squash
----
-
-**Looking for developers to test the web frontend for squash** I got the web frontend to squash working. Right now I'm looking for people to test it on my test server before I open it to the wild web. It ended up in a further frontend script explosion, but all of the pieces seem to make sense. As it stands right now there are 5 pieces: 
-
-  1. JavaScript client-side provides progress notification
-  2. A PHP frontend to communicate with the stateful server
-  3. Python server that handles command queuing, progress reporting and error handling
-  4. Python library to build a list of possible candidates for squashing, produce the necessary .i files and an invocation command from squash
-  5. Squash: the friendly neighborhood class member renamer
-**Passion of CPP: Macros are Considered Painful **  
-  
-In the process of testing the web frontend I updated the Mozilla sourcecode only to notice that Elsa can no longer parse files for tasks that worked before. At first I got a little discouraged thinking that I'll have to teach Elkhound about yet another obscure C++ feature that wasn't handled correctly before. However, turned out that in one case I was feeding squash a file that didn't even compile and in the other 2 cases CPP was messing with my head.  
-  
-The first case was the magic of CPP leading to unintentional code duplication and squash confusion: 
-```
-PR_MAX(GetPresContext()->PointsToAppUnits(0.5f), onePixel)
-```
-gets expanded and parsed as 
-```
-GetPresContext()->PointsToAppUnits(0.5f) ? GetPresContext()->PointsToAppUnits(0.5f) : onePixel
-```
-  
-  
-I ended up putting in a special case teaching squash to not get upset if it can only find one of the two instances of class member to replace when PR_MAX is involved.  
-  
-The second case was exciting. In my innocent perception of CPP wonder I thought that running g++ on a .cpp or a .i file produced from the said .cpp would result in pretty similar behavior. Not so.  
-  
-
-```
-PR_LOG(gLog, PR_LOG_DEBUG,
-("xul: %.5d. %s    %s=%s",
--1, // XXX pass in line number
-NS_ConvertUTF16toUTF8(extraWhiteSpace).get(),
-NS_ConvertUTF16toUTF8(qnameC).get(),
-NS_ConvertUTF16toUTF8(valueC).get()));
-
-```
-yields  
-  
-
-```
-do { if (((gLog)->level >= (PR_LOG_DEBUG))) { PR_LogPrint ("xul: %.5d. %s    %s=%s", -1, // XXX pass in line number NS_ConvertUTF16toUTF8(extraWhiteSpace).get(), NS_ConvertUTF16toUTF8(qnameC).get(), NS_ConvertUTF16toUTF8(valueC).get()); } } while (0);
-```
-  
-  
-Here the // comment ends up being promoted to being inside a line due to PR_LOG contracting and the resulting line won't parse since half of it is commented out.  
-  
-This kind of CPP mischief leads me to believe that something has got to give. If we are to embrace automated tools to aid in verification and development either CPP use has to be reduced considerably or Elsa needs to get a builtin preprocessor. I suspect the solution to this will involve a mixture of the two approaches.
diff --git a/source/_posts/2007-03-02-uno-dos-dehydra.markdown b/source/_posts/2007-03-02-uno-dos-dehydra.markdown
deleted file mode 100644
index a9a728f..0000000
--- a/source/_posts/2007-03-02-uno-dos-dehydra.markdown
+++ /dev/null
@@ -1,40 +0,0 @@
----
-comments: true
-date: 2007-03-02 10:52:59
-layout: post
-slug: uno-dos...-dehydra
-title: Uno, dos... DeHydra!
-wordpress_id: 12
-categories:
-- mozilla
-- DeCOMtamination
-- dehydra
----
-
-**A Creature so Fierce...**  
-  
-I've been wrestling with control flow graphs [like this](http://people.mozilla.org/~tglek/hydra.png). I eliminated those pesky "empty" nodes found in the previous incarnations, improved branching to track conditions and realized that what I'm really doing is developing a tool to bite off the excessive necks and heads (otherwise known as edges and basic blocks) of the Hydra monster that is represented by the bloody graph. Thus, say hello to DeHydra which was once known as [dos](http://taras.glek.net/blog/2007/02/01/lossy-ast-traversals-for-good-code-health).  
-  
-**DeHydra Plans**  
-  
-I am quite happy with how dehydra is turning out. JavaScript is a nice language to pattern match code in a flow sensitive fashion and the uno-style api seems appropriate for the task.  
-  
-In the near term I really need some value-awareness through abstract interpretation. For example, [this graph](http://people.mozilla.org/~tglek/hydra-unfeasible.png) of a [simple function](http://people.mozilla.org/~tglek/hydra-unfeasible.c) demonstrates several things that dehydra will need to notice: 
-
-  1. There is a path from hydra-unfeasable.c:6 to hydra-unfeasable.c:10 and that those blocks are part of only a single control flow, not 4.
-  2. hydra-unfeasable.c:12 requires a contradiction in the condition in order to have flow through it and should be dropped or even reported as dead code.
-I pondered a number of approaches ranging from value analysis, using a theorem prover and reversing conditions via prolog code. A simple C++ symbolic expression interpreter in C++ seems like the most productive thing at this point. So I will focus on that in the next short while.  
-  
-While I was reviewing my options I found a paper on [null pointer analysis for Java](http://www.cs.umd.edu/~jspacco/marmoset/papers/hovemeyer-paste2005.pdf) to be a useful stating point for references to other relevant literature.  
-  
-**Longer Term DeHydra Plans**  
-  
-There is literature on how source-to-source transformation (like squash but also like the future C++ to ES4 tool) is assisted by flow sensitive static analysis tools (like dehydra) which I will have to absorb. DeHydra will gain whole-program analysis capability by: 
-
-  1. _Inlining control flow graphs_ into the main() function
-  2. Supporting user-defined function attributes and using some sort of _attribute inference _(like in ML) to propagate them. This method would have higher performance, but less precision.
-For the above to work will also need support for a user-correctable/suggestable callgraph to compensate for function pointers and dynamic module loading. This should also be enough to do dead code and module detection. Oh and I want dehydra to support JavaScript for doing cross-language analysis.  
-  
-There is also [Whaley's paper](http://www.stanford.edu/~jwhaley/papers/pldi04.pdf) which uses prolog as a concise and expressive query engine for the source code. I would really like to see dehydra evolve such capabilities.  
-  
-All this will take more than a little time on my own, but this stuff is too exciting for other impatient people to idly observe.
diff --git a/source/_posts/2007-03-07-dehydra-01.markdown b/source/_posts/2007-03-07-dehydra-01.markdown
deleted file mode 100644
index 31da839..0000000
--- a/source/_posts/2007-03-07-dehydra-01.markdown
+++ /dev/null
@@ -1,17 +0,0 @@
----
-comments: true
-date: 2007-03-07 15:38:08
-layout: post
-slug: dehydra-0.1
-title: Dehydra 0.1
-wordpress_id: 13
-categories:
-- mozilla
-- dehydra
----
-
-Dehydra does a form of basic symbolic execution now. It's enough to avoid the _[unfeasable](http://taras.glek.net/blog/2007/03/02/uno-dos...-dehydra) _branches. It enabled me to add known_zero() and known_notzero() so dehydra supports all of the functions documented in the [UNO paper](http://www.spinroot.com/uno/uno_long.pdf).  
-  
-I believe dehydra can now match all of the features of uno's DSL. Download it [here](http://spinroot.com/uno/). See malloc.js for an example of how to port UNO scripts. There is no documentation, except for this blog, but the docs on the [UNO website](http://spinroot.com/uno/) should work too.  
-  
-This is the first release so there are bugs, but the tool should be able to find some API-misuse issues, etc. I need some early adopters to help direct the evolution of this tool.
diff --git a/source/_posts/2007-04-02-automated-code-refactoring.markdown b/source/_posts/2007-04-02-automated-code-refactoring.markdown
deleted file mode 100644
index f12bb95..0000000
--- a/source/_posts/2007-04-02-automated-code-refactoring.markdown
+++ /dev/null
@@ -1,27 +0,0 @@
----
-comments: true
-date: 2007-04-02 11:29:12
-layout: post
-slug: automated-code-refactoring
-title: Automated Code Refactoring
-wordpress_id: 14
-categories:
-- mozilla
-- DeCOMtamination
-- dehydra
-- squash
----
-
-**Squash **  
-  
-If you are working on any C++ refactoring, especially if it involves function calls, spans multiple files or feels like you need a compiler in your head to help you, drop me a note to see if [squash](http://wiki.mozilla.org/Squash) can help. Squash provides a great deal of control over the refactoring process because it is not tied to a particular IDE and can be customized to accommodate for special cases.  
-  
-On Friday, two squash-produced patches landed: 
-
-  1. A [212K patch](https://bugzilla.mozilla.org/show_bug.cgi?id=376042) to rename nsIFrame::GetPresContext to PresContext. It took a couple of minutes to produce a patch for mac & linux, and then some manual labour to complete it so it builds on Windows too. Unfortunately, Microsoft C++ is not yet supported by Oink. Windows-specific code will require magnitudes more of human labour until such support is contributed.
-  2. A much simpler patch to calls to [remove uses of the deprecated ::Recycle()](https://bugzilla.mozilla.org/show_bug.cgi?id=375878). This took a few minutes once I added support for renaming global functions to squash.
-**Dehydra**  
-  
-C++ support in dehydra is coming along splendidly. I started working on cross-function analysis support. Currently my goal is to allow the user to build callgraphs of Mozilla. The first application of that is going to be dead code detection.  
-  
-In the meantime, contact me if you are looking for patterns in the code that grep wont help with : control flow-sensitive code, type & syntax-aware matching, API misuse, etc. Dehydra can probably help.
diff --git a/source/_posts/2007-04-04-what-about-javascript-in-dehydra.markdown b/source/_posts/2007-04-04-what-about-javascript-in-dehydra.markdown
deleted file mode 100644
index 4fb7ecb..0000000
--- a/source/_posts/2007-04-04-what-about-javascript-in-dehydra.markdown
+++ /dev/null
@@ -1,19 +0,0 @@
----
-comments: true
-date: 2007-04-04 16:44:04
-layout: post
-slug: what-about-javascript-in-dehydra
-title: What About JavaScript In Dehydra?
-wordpress_id: 15
-categories:
-- mozilla
-- dehydra
----
-
-Most static analysis tools don't let you script them. Oink is an example of that. Adding a new analysis requires extending an existing tool with a feature which may not fit in smoothly or writing a new tool in C++ with the corresponding boilerplate to handle command-line arguments, etc.  
-  
-At the other extreme lives UNO which has a DSL that is designed strictly for solving control-flow programs.  
-  
-I chose JavaScript for Dehydra to get the power of a full-blown (and memory safe) programming language while keeping JS's view of the code under analysis as simple as possible. I think I got the C++/JS mix just right, the C++ codebase is growing slowly, yet I add JS scripts for any little task.  
-  
-Additionally JS came in handy for publishing the data on the web. I wrote a [script](http://people.mozilla.org/~tglek/inheritance.js) to determine the class inheritance graph. Then I added a little prefix to the [file produced](http://people.mozilla.org/~tglek/graph/examples/inheritance.js), combined it with [jsviz](http://www.kylescholz.com/blog/projects/jsviz/) and ended up with a really slow and unusable, but somewhat pretty [class browser](http://people.mozilla.org/~tglek/graph/examples/classes.html). This could evolve to be a rather neat way to supplement LXR.
diff --git a/source/_posts/2007-04-23-mozilla-class-browser.markdown b/source/_posts/2007-04-23-mozilla-class-browser.markdown
deleted file mode 100644
index 0a5fafa..0000000
--- a/source/_posts/2007-04-23-mozilla-class-browser.markdown
+++ /dev/null
@@ -1,17 +0,0 @@
----
-comments: true
-date: 2007-04-23 14:12:11
-layout: post
-slug: mozilla-class-browser
-title: Mozilla Class Browser
-wordpress_id: 16
-categories:
-- mozilla
-- dehydra
----
-
-My last attempt at visualizing the Mozilla class hierarchy ended up being way too slow to be useful. So I based my second attempt on using a different [tree layout](http://www.codeproject.com/jscript/graphic_javascript_tree.asp). After quite a few scalability optimizations, the graphing performance is now bearable.  
-  
-This [class browser](http://people.mozilla.org/~tglek/classbrowser/classbrowser.html) uses the canvas tag to draw the pretty boxes & lines and links back into lxr. The class browser consumes a JSON file produced by running DeHydra on the layout/ directory. I am happy that I am finally able to examine gigantic code graphs interactively thanks to the <canvas> tag.  
-  
-In the near future I hope to produce a few different kinds of complete graphs of the entire Firefox codebase. The idea is to have them generated nightly. Then that if someone has a general question about the Firefox codebase, it could be expressed as JavaScript within an interactive console in the browser. The answer would be either be graphed or returned as a JSON object.
diff --git a/source/_posts/2007-05-01-status-report.markdown b/source/_posts/2007-05-01-status-report.markdown
deleted file mode 100644
index 1333f8c..0000000
--- a/source/_posts/2007-05-01-status-report.markdown
+++ /dev/null
@@ -1,41 +0,0 @@
----
-comments: true
-date: 2007-05-01 14:13:01
-layout: post
-slug: status-report
-title: Status Report
-wordpress_id: 17
-categories:
-- mozilla
-- DeCOMtamination
-- dehydra
-- squash
----
-
-**Automated Analyses and Rewrites**  
-  
-Dehydra and Squash are now mature enough to assist with mundane tasks like renames and various kinds of tedious code inspection. If you ever suspect that part of the Mozilla hacking you are doing could be done by a tool, contact me to see if I have a suitable tool for you.  
-  
-Also, these tools are in no way limited to working with Mozilla source code. I would be happy to see people use them for other projects too.  
-  
-**Short-term Plans**  
-  
-For the next week or two I plan to focus on out-parameter rewriting and the Mozilla-wide C++ callgraph.  
-  
-**Mozilla-wide Callgraph** This is proving to be a little painful. Things work for basic test-cases, but I am running into scalability issues with Mozilla (as expected). My current approach of serializing everything into a giant JSON graph blows the 32bit address space after a few hundred files. Even doing a Mozilla-wide inheritance graph causes out of memory errors, but that runs almost to competition. The best solution to this will be to break up the graph into as many smaller JSON files as possible and only load ones that are absolutely required into memory.  
-  
-The callgraph will be a useful starting point for many other useful analyses (dead code one is going to be lots of fun) and it's a good test of dehydra's scalability, but I have suspended work on it for a few days to focus on more productive tasks.  
-  
-**Out-parameter Rewriting**  
-  
-Due to XPCOM, Mozilla getters typically return an error code and a value via an out parameter. This requires checking the error code and likely propagating it at the callsite.  
-  
-For many places in the code there are performance and aesthetical reasons to stop using error codes. Brendan talks discusses some reasons [here](http://weblogs.mozillazine.org/roadmap/archives/2006/10/mozilla_2.html). This would be cool stuff, but switching to exceptions isn't going to happen right away. However, I can already start working on my tools to assist with simpler cases (like [nsBidiPresUtils::GetBidiEngine](http://www.google.com/codesearch?hl=en&q=+nsBidiPresUtils::GetBidiEngine+show:kW5gzhxHJvU:iRn_dfI9xJY:Y5Gdp6b4NgE&sa=N&cd=1&ct=rc&cs_p=http://ftp.mozilla.org/pub/mozilla.org/mozilla/releases/mozilla1.7a/src/mozilla-source-1.7a.tar.bz2&cs_f=mozilla/layout/base/src/nsBidiPresUtils.cpp#a0)?). I'm focusing on getters that return NS_OK/(some error) and a value and rewriting them to return NULL on error and non-NULL on success. This could be ready in time for Firefox 3. Once I'm done with the tool, I'll just need someone to help me figure which functions are ok to simplify like that.  
-  
-I suspended work on out-param rewriting [some time ago](http://taras.glek.net/blog/2007/01/11/squash-progress-and-plans/). It was proving to be too complicated to do within squash. Now that I can use dehydra to verify the control flow graph, things are a lot simpler. Current plan is to have the [dehydra script](http://people.mozilla.org/~tglek/outparams.js) produce a list of candidates for out-param surgery and have squash consume that list and produce the appropriate patches. Currently, the script works for some very simple cases and I am working on the squash side.  
-  
-**Smaller Tasks**
-
-  * Sayrer's uninitialized member analysis: added more complete constructor support to dehyra, wrote a [sample script](http://people.mozilla.org/~tglek/member-init.js) to get sayrer started. Fixed dehydra's 64bit support. [Bug 378763](https://bugzilla.mozilla.org/show_bug.cgi?id=378763)
-  * Made some squash-generated patches for bz, helped me find a bug in squash. [Bug 378780](https://bugzilla.mozilla.org/show_bug.cgi?id=378780)
-  * Pushing squash upstream into oink. This is time consuming because it is a combination of legal and many minor technical issues. Dehydra will follow later.
diff --git a/source/_posts/2007-05-07-status-update-outparam-work.markdown b/source/_posts/2007-05-07-status-update-outparam-work.markdown
deleted file mode 100644
index c070a29..0000000
--- a/source/_posts/2007-05-07-status-update-outparam-work.markdown
+++ /dev/null
@@ -1,60 +0,0 @@
----
-comments: true
-date: 2007-05-07 09:58:43
-layout: post
-slug: status-update-outparam-work
-title: 'Status Update: Outparam work'
-wordpress_id: 18
-categories:
-- mozilla
-- squash
----
-
-**Squash Outparams**  
-  
-The following took me a few days to achieve.  
-  
-
-```
-./squash -sq-rewrite-outparams out2.txt -sq-implementation nsBidiPresUtils  -sq-no-squash -o-lang GNU_Cplusplus ~/work/ff-build/dom/src/base/nsFocusController.i
-```
-  
-  
-where out2.txt contains instructions on which functions to modify  
-  
-
-```
-nsFocusController::GetFocusedElement,0=mCurrentElement,
-```
-  
-  
-produces  
-  
-
-```
---- /Users/tarasglek/work/mozilla/dom/src/base/nsFocusController.h
-+++ /Users/tarasglek/work/mozilla/dom/src/base/nsFocusController.h
-@@ -72,1 +72,1 @@
--  NS_IMETHOD GetFocusedElement(nsIDOMElement** aResult);
-+  nsIDOMElement* GetFocusedElement();
-
-```
-  
-  
-This still doesn't add the already_AddRefed or other important attributes, but that should be easy. The result looks simple, but getting squash from working with a testcase to an actual source file was a little on the painful side.  
-  
-After my experience with renaming I have realized that squash should avoid the C++ pretty printer for now. Thus the result is produced in a verbose AST-sensitive regexp-like way. However figuring out where things start and end is incredibly painful due to the presence of the preprocessor.  
-  
-My plan is to get squash rewriting some basic Mozilla code the painful way and then I use what I learned to integrate [mcpp](http://mcpp.sourceforge.net/) along with the much coveted end-of-ast-node info into elsa.  
-  
-**JavaScript is an AST's Best Friend **  
-  
-  
-  
-Until recently I have been doing a lot of work with dehydra. Now that it is feature-complete I am back to working on squash fulltime and I miss JavaScript already. JS is much better suited for messing about with Abstract Syntax Trees. It is so nice to be able to print out any data structure, create new ones without modifying a billion files and the lack of C++ compile/linking delay is nice too. It's amazing how much simpler it is to analyze functions for out-param rewriting in JS compared to checking for simpler patterns in C++. I am seriously excited about Tamarin/ES4 and the productivity boost that it will provide.  
-  
-I wonder whether a complete JS binding for Elsa would be a good idea.  
-  
-**Emacs**  
-  
-Switching to a Mac finally made me switch to Emacs. I could not find any other editors that would be support the workflow I was used to with SciTE or Kate. Other than absolutely hating the majoring of Emacs shortcuts (who's idea was Ctrl-^ and the crazy undo/redo) I love the editor for the amazing term mode. It's a little buggy in the current version, but the CVS version is good enough to comfortably run vim in it for quick edits :). It's so nice to keep all of my terminals and code in the same window. I am dreaming of the day when Emacs will undergo the Mozilla->Firefox-like modernization.
diff --git a/source/_posts/2007-05-10-nicely-rewriting-outparams.markdown b/source/_posts/2007-05-10-nicely-rewriting-outparams.markdown
deleted file mode 100644
index 9fd5378..0000000
--- a/source/_posts/2007-05-10-nicely-rewriting-outparams.markdown
+++ /dev/null
@@ -1,23 +0,0 @@
----
-comments: true
-date: 2007-05-10 14:52:07
-layout: post
-slug: nicely-rewriting-outparams
-title: Nicely rewriting outparams
-wordpress_id: 19
-categories:
-- mozilla
-- squash
----
-
-Automatic code rewriting business can be a little depressing sometimes. I tend to run into funny issues caused by CPP, oink limitations or just unpleasant-to-rewrite parts of C++. After banging my head against the wall due to all these issues I finally arrived at a workable approach for the easy part of the outparam rewrite.  
-  
-  
-  
-Currently I have a dehydra script that finds all non-virtual getters that return either NS_OK or *NS_SOMETHING_IS_WRONG*. The script then outputs data for squash to base the rewrites on. Then squash takes over.  
-  
-In order to preserve sanity, pretty-printing is not used at all for rewriting the getter functions. This way one doesn't have to worry about oink generating invalid C++ and the output is much more aesthetically pleasing. Instead, squash finds interesting expressions in the .i file. Then it extracts the corresponding strings from .h/.cpp files. The strings are used to fudge the position information obtained from the .i file to vaguely correspond to the original source files. After various C++ string-foo, squash produces a promising looking patch like [this](http://people.mozilla.org/~tglek/outparams.May10.diff).  
-  
-This also relies on a fair amount of semantic information provided by elsa/oink. For example when removing a parameter, squash inserts a local variable with the same name and then removes all of the derefences of the old parameter. Since there could be multiple variables with the same name, squash relies on elsa's variable resolution.  
-  
-I think squash is now 50% feature complete with respect to outparam stuff. The other 50% is the hard part of rewriting all of the call-sites. I'm not counting easy parts like wrapping the return type in already_AddRefed<>, eliminating redundant assignments in the getter or removing the error variable once it is no longer needed.
diff --git a/source/_posts/2007-05-11-cpp-strikes-back.markdown b/source/_posts/2007-05-11-cpp-strikes-back.markdown
deleted file mode 100644
index e22f156..0000000
--- a/source/_posts/2007-05-11-cpp-strikes-back.markdown
+++ /dev/null
@@ -1,36 +0,0 @@
----
-comments: true
-date: 2007-05-11 16:07:26
-layout: post
-slug: cpp-strikes-back
-title: CPP Strikes Back
-wordpress_id: 20
-categories:
-- mozilla
-- squash
----
-
-I have gotten used to dodging CPP-expansion issues by fudging column & line information until the position info in squash mostly matches the source positions in the original source code. That sufficed for rewriting declarations, but I have finally hit a brick wall.  
-  
-**CPP Fun**  
-  
-I got as far with call-site outparam rewriting as [this patch](http://people.mozilla.org/~tglek/outparams.May11.diff). It demonstrates an interesting flaw. 
-```
-@@ -8297,1 +8297,1 @@
--  GetInsertionPoint(parentFrame, nsnull, &insertionPoint, &multiple);
-+  insertionPoint = GetInsertionPoint(parentFrame, &insertionPoint, &multiple);
-@@ -8346,1 +8346,1 @@
--          GetInsertionPoint(parentFrame, child, &insertionPoint);
-+          insertionPoint = GetInsertionPoint(parentFrame, child);
-```
-  
-  
-Due to macro expansion, nsnull contracts to 0 such that the .i file has &insertionpoint positioned right in the middle of nsnull (in the .cpp file). So when squash trims the param including the surrounding commas, it ends up removing the wrong parameter.  
-  
-**Elsa Limitation**  
-  
-I have mentioned lack of end-of-ast-node position information in Elsa. It also lacks start-of-ast-node information for most expressions. This makes selectively rewriting source code rather difficult.  
-  
-**Plan**  
-  
-Instead of fighting an uphill fudging battle against CPP, I am going to have to suspend outparam rewriting yet again to work on better position information and integrating a preprocessor into elsa. This is unfortunate because I was looking forward to finally doing something more sophisticated than renames. Now my elsa fork is going to grow even bigger before I get commit access.
diff --git a/source/_posts/2007-05-17-undoing-cpp-deep-in-enemy-territory.markdown b/source/_posts/2007-05-17-undoing-cpp-deep-in-enemy-territory.markdown
deleted file mode 100644
index d165c1e..0000000
--- a/source/_posts/2007-05-17-undoing-cpp-deep-in-enemy-territory.markdown
+++ /dev/null
@@ -1,66 +0,0 @@
----
-comments: true
-date: 2007-05-17 15:30:43
-layout: post
-slug: undoing-cpp-deep-in-enemy-territory
-title: Undoing CPP - Deep in Enemy Territory
-wordpress_id: 22
-categories:
-- mozilla
----
-
-**Positive**  
-  
-Since the last blog post, I have been investigating on how to teach elsa about the C preprocessor. Overall, I am really happy that [MCPP](http://mcpp.sourceforge.net/) exists and is actively maintained. Preprocessed source code may not be invertible into the original form, but at least it can be undone enough for refactoring purposes.  
-  
-Looks like I should be able to preprocess the source code, and while at it record macro expansion information and then have elsa fed with a somewhat xml-escue data structure.  
-  
-The way I see it, a line of code like  
-  
-
-```
-foo = PR_MAX(boo(), nsnull)
-```
-  
-  
-which expands into  
-  
-
-```
-foo =  boo() > 0 ? boo() : 0;
-```
-  
-  
-will get fed to elsa as something like  
-  
-
-```
-<fragment>foo = <macro id=somemacro_instance>PR_MAX(boo(), nsnull)</macro>;</fragment>
-
-```
-where somemacro_instance is defined as  
-  
-
-```
-<fragment><fragment ref=some_fragment/> > 0 ? <fragment ref=some_fragment/> : <macro id=some_staticmacro>0</macro></fragment>
-
-```
-where some_staticmacro is defined as  
-  
-
-```
-<fragment>0</fragment>
-```
-  
-  
-I think this is a cute scheme because fragments are basically regions of source-code. This is exciting because once a macro is used in the code, the text fragment that defines the macro can be parsed as C++ and rewritten accordingly. Obviously, this wouldn't be the default behavior.  
-  
-If you see a fatal flow in the above model, let me know.  
-  
-**Negative**  
-  
-My main reason for adding preprocessor support to elsa is to obtain precise source locations from elsa. Ironically, MCPP "compresses" whitespace, so column information is basically thrown out of the window. Means I'll have to do some extensive culling of the compression code (which is everywhere).  
-  
-Another fun issue is that the general structure of MCPP encourages the "lots of global variables and defines" mode of programming. It also uses strings-as-a-data-structure pattern which may make me give up on the fancy onion-peel model I described above and instead have mcpp generate preprocessed code along with an "undo" type log.  
-  
-MCPP is also a bit on the slow side compared to GCC, but I'll trade a second or two slowdown per file for never having to cry due to CPP again.
diff --git a/source/_posts/2007-05-29-cpp-integration-progress.markdown b/source/_posts/2007-05-29-cpp-integration-progress.markdown
deleted file mode 100644
index 3b0dd1d..0000000
--- a/source/_posts/2007-05-29-cpp-integration-progress.markdown
+++ /dev/null
@@ -1,81 +0,0 @@
----
-comments: true
-date: 2007-05-29 10:36:26
-layout: post
-slug: cpp-integration-progress
-title: CPP Integration Progress
-wordpress_id: 23
-categories:
-- mozilla
----
-
-**Existing Work**  
-  
-All of existing work is based on basic C parsers so it can't be directly applied to C++.  
-  
-I found out that someone did a PhD on refactoring C code resulting in the [CRefactory](https://netfiles.uiuc.edu/garrido/www/CRefactory.html)(down atm) project. Looks like reversing the C preprocessor was by far the hardest task to address. Languages consisting of stacked lexical syntaxes (like OCaml & camlp4) or preprocessorless ones like Java don't even have this problem.  
-  
-A way to tackle the problem is to violently shove the some of the preprocessor markup into the C AST. Unfortunately this is an incredibly hard task because CPP is purely lexical and works at the token level, whereas the C compilers works with higher level AST syntax trees. Combining the two can result in an ambiguous grammar which is useless for refactoring.  
-  
-CRefactory integrates CPP into the AST where possible, it even handles some CPP conditionals. The author's argument is that every CPP conditional represents a separate configuration and processing one configuration at a time will result in a combinatorial explosion of configurations to process thus conditionals must be integrated into the AST.  
-  
-However, CPP-in-AST solution is error prone and has issues scaling to large projects. Besides I think processing every configuration within the AST is still potentially a combinatorial explosion, the major benefit being that one can eliminate unfeasible conditionals if they cause syntax errors. This conditional elimination would be incredibly slow for C++. I also don't believe that this would be enough to solve Mozilla's conditionals since most of the troublesome macros are platform specific and would have dependencies on the system headers. Having said that, I appreciate seeing people prove that with enough effort even seemingly impossible tasks can be accomplished.  
-  
-A [paper](http://www.cs.berkeley.edu/~billm/astec-fse.pdf) on ASTEC presents another solution which involves translating [lexical] CPP constructs into a CPP-like AST-based language. This works great in theory, but the translation process is only semi-automatic and requires a lot of hand-holding. I have mixed feeling about this approach. A simpler intermediate language is an excellent thing but as soon as it becomes "CPP sux, so I invented this better language: use it" the world gains yet another troublesome programming language.  
-  
-**My Approach**  
-  
-  
-  
-It took me a few weeks to figure out how to tackle the CPP problem in squash. I think I have a solution that will work real soon(TM).  
-  
-I like to avoid solving unsolvable problems and stick with works-for-me approach. Thus I probably wont make squash aware of CPP conditionals. My existing approach of combining output of running squash on Mac/Linux(and Windows in the future) should take care of 99% of cases in Mozilla. The rest will be flagged by a compiler and will be trivial to fix by hand.  
-  
-**Macro Expansion**  
-  
-I also don't see the benefit of a partially integrated CPP within the C++ AST. Instead I am modifying MCPP to log the macro expansions with special markup enclosed in comments. Afterwards I plan to modify elsa to parse the macro-expansion log and modify the position tags on AST nodes accordingly. Then I'll be able to do cool things like "cut out the piece of code that was parsed as 0" which will reference the source locations, figure out that 0 was a result of macro expansion and return "NULL". Or when I try to rewrite a member in PR_MAX(something->GetPresContext()->foo, 0), the code will know that the the two GetPresContext() calls in the AST correspond to the same code fragment.  
-  
-Besides, isn't this marked-up code pretty? 
-```
-
-/*m__CONCAT,"testcase3.c",2,*/
-/*m__MATHDECL_1,"testcase3.c",5,*/
-/*m__MATH_PRECNAME,"testcase3.c",8,*/
-# 10 "testcase3.c"
-/*!0x2adfbaa6e010 _*/
-/*!0x2adfbaa6e015 b*/
-# 10 "testcase3.c"
-/*<__CONCAT*/__boo/*>*/
-/*!0x2adfbaa6e010 _*/
-/*!0x2adfbaa6e029 _*/
-# 11 "testcase3.c"
-# 11 "testcase3.c"
-# 11 "testcase3.c"
-testcase3.c:11: error: Not a valid preprocessing token "//"
-macro "__CONCAT" defined as: #define __CONCAT(x,y) x ## y   /* testcase3.c:*
-/
-macro "__MATHDECL_1" defined as: #define __MATHDECL_1(function,suffix) __CON
-CAT(function,suffix)    /* testcase3.c:5        */
-from testcase3.c: 11:    int __MATHDECL_1( __CONCAT(__, lgamma),_r);
-int  /*<__MATHDECL_1*/ /*<__CONCAT*//*<0x2adfbaa6e010*/ /*<__CONCAT*/__lgamma/*>
-*//*>*// *<0x2adfbaa6e029*/_r/*>*//*>*/ /*>*/ ;
-
-```
-This is the original testcase: 
-```
-
-#define __CONCAT(x,y)   x ## y
-```
-  
-  
-#define __MATHDECL_1(function,suffix) \ __CONCAT(function,suffix)  
-  
-#define __MATH_PRECNAME(name,r) __CONCAT(name,r)  
-  
-__CONCAT(__, boo) int __MATHDECL_1( __CONCAT(__, lgamma),_r); **Code**  
-  
-The MCPP maintainer is absolutely awesome work with. MCPP needs to be modified to preserve horizontal whitespace(which preprocessors don't do) and to provide the above expansion info. He volunteered to do a lot of the MCPP modifications for me and has been a lot of help in guiding me through his code.  
-  
-At this point looks like we'll be able to integrate this work into the MCPP trunk. This is great news because to the best of my knowledge all of the other C refactoring tools either use a bitrotting fork of some C preprocessor or reimplement a yet another buggy version of CPP resulting in a lot of collectively wasted effort.  
-  
-I hope to have this working in squash within two weeks so I can finish the outparam rewrite and hopefully rid squash of a large portion of code that details with the non-deterministic source positions due to macro expansion.
diff --git a/source/_posts/2007-06-12-undoing-cpp-expansion-in-3-simple-steps-say-hello-to-easier-c-rewriting.markdown b/source/_posts/2007-06-12-undoing-cpp-expansion-in-3-simple-steps-say-hello-to-easier-c-rewriting.markdown
deleted file mode 100644
index 1564563..0000000
--- a/source/_posts/2007-06-12-undoing-cpp-expansion-in-3-simple-steps-say-hello-to-easier-c-rewriting.markdown
+++ /dev/null
@@ -1,56 +0,0 @@
----
-comments: true
-date: 2007-06-12 10:26:01
-layout: post
-slug: undoing-cpp-expansion-in-3-simple-steps-say-hello-to-easier-c-rewriting
-title: Undoing CPP Expansion in 3 simple steps. Say "Hello" to easier C++ rewriting.
-wordpress_id: 21
-categories:
-- mozilla
-- squash
----
-
-This is incredibly exciting: I believe that I finally solved the messy and mind-numbingly boring CPP/C++ integration problem! Having code displaced or generated due to CPP-expansion should no longer be a fatal problem for [Squash](http://wiki.mozilla.org/Squash). I believe macro-expansion is (or was) the single biggest problem between me and large-scale automated refactoring of the Mozilla codebase.  
-  
-What's even more exciting is that I think my solution is both incredibly simple to implement and more general than prior work. Most other tools combine the CPP expansion & C parsing into a single step and then integrate (or should I say violently shove?) CPP constructs into the AST. This results in complete lack of separation between preprocessing and program analysis. For example, due to this tight coupling existing solutions were useless to me because the fancy CPP logic could not be separated from the C parser. I would also have a hard time submitting a more convoluted C++ parser upstream to the Elsa maintainer.  
-  
-**Design**  
-  
-There are three parts to my solution: 
-
-  1. _Critical component_. A CPP expansion undo-log injected during CPP-expansion by a modified C preprocessor (upcoming version of MCPP). The statements are wrapped in C comments such that the preprocessed result can be parsed by any C/C++/etc parser or compiler. Implementation-wise this is the hardest part since MCPP(as most other C proprocessors) was never designed it keep track of macro expansion info.
-  2. A small modification to the Elsa lexer to parse the undo-log and set it aside in a separate data structure.
-  3. _Tricky_. A function that utilizes the cpp undo-log to map the preprocessed source locations to the unpreprocessed ones. This is a a ridiculously simple solution to a tricky design problem of how to efficiently advertise the fact that every AST node has at least 2 different source positions (pre expansion, post expansion & a stack of positions resulting from expanding nested macros).
-The MCPP maintainer is almost done with 1. I have a prototype implementation of 2 & 3 weighing in at less than 500lines. Now that the design phase is complete, the amount of changes to Elsa is trivial, so I should be done with those real soon now.  
-  
-**Looking Ahead**  
-  
-Now I need to modify Elsa to retain more precise source locations. This includes adding end-of-ast-node-location and adding positions to nodes(such as expressions) that don't even have a start position at the moment. This combined with cpp-undo-log enhanced precise positions should allow for code rewrites to retain as much original source code as possible. This reduces the amount of ugly machine-generated code and results in better correctness (existing code is likely to work).  
-  
-**CPP Undo-log Example**  
-  
-The undo-log took a couple of tries to get right. Now macro-parameters have a notion of scope and sensible names. The following example features macro-induced column displacement and macro-expansion causing line shrinkage. 
-```
-
-#define NULL 0L
-#define FOO(a, b) a + b
-int i = NULL; int j;
-int k = FOO(
-FOO(NULL , 1),
-2);
-
-```
-Preprocessed version 
-```
-
-# 1 "testcase4.c"
-/*mNULL 1:8-1:15*/
-/*mFOO 2:8-2:23*/
-```
-  
-  
-int i = /*<NULL 3:8-3:12*/0L/*>*/; # 3 "testcase4.c" int j; int k = /*<FOO 4:8-6:3*//*!FOO#0-0 5:0-5:13*//*!FOO#0-1 6:1-6:2*//*<FOO#0-0*//*<FOO*//*!FOO#1-0*//*!FOO#1-1*//*<FOO#1-0*//*<NULL*/0L/*>*//*>*/ + /*<FOO#1-1*/1/*>*//*>*//*>*/ + /*<FOO#0-1*/2/*>*//*>*/;  
-  
-**Conclusion**  
-  
-It took a lot to arrive at such a simple solution. I expect that all of my work is likely to end up upstream in BSD-licensed projects: MCPP & and Elsa/Oink. I sincerely hope that other people will be able to build on it for their CPP-infested analysis needs and avoid the unbearable mind-numbing discomfort associated with making CPP play along.
diff --git a/source/_posts/2007-06-19-it-works.markdown b/source/_posts/2007-06-19-it-works.markdown
deleted file mode 100644
index 2d454c4..0000000
--- a/source/_posts/2007-06-19-it-works.markdown
+++ /dev/null
@@ -1,30 +0,0 @@
----
-comments: true
-date: 2007-06-19 12:51:23
-layout: post
-slug: it-works
-title: It works!
-wordpress_id: 24
-categories:
-- mozilla
----
-
-**Back to Real Life**  
-  
-Just over a month ago I ran into [this problem](http://taras.glek.net/blog/2007/05/11/cpp-strikes-back/). Before last month I hoped to never have to work on the C preprocessor or a parser generator. So much for that plan. Now my head is full of CPP-expansion-related trivia.  
-  
-After a month of design and implementing changes to mcpp, elsa, elkhound and oink I can finally move on. During the last week all of the pieces of the puzzle finally came together ( without any nasty surprises other than bugs). Now I can go back to solving real problems.  
-  
-**Upcoming Features**  
-  
-Benefits of having CPP support don't stop at actually being able to rewrite code. Now that the Oink C++ parser is aware of the C preprocessor, it should be possible to refactor C++ almost as easily as Java. Here are some cool things that are possible now: 
-
-  * Nicer UI. Exact source position info allows for eclipse-style context menus for renaming & other refactorings in lxr (or other online code browsers).
-  * Richer type system. It should be possible to detect macro constants. Tools will be able to tell the difference between a prnull and 0. Should also be able to detect and maintain NSRESULT and other macros used for declarations.
-  * Macro refactoring. Now it's possible to write a tool to automate the process of converting function-like macro calls to actual function calls. For example, PR_MAX could be converted into std::max calls with all of the accompanying casts to ensure that the resulting C++ is correct.
-  * Other nasty tricks like rewriting code within macro declarations.
-I'm not sure how much of these features I will work on, but they are relatively easy to implement now.  
-  
-I plan to write a minimalistic successor to squash and develop more aggressive refactorings than renames.  
-  
-Additionally, I will continue pushing above changes upstream and trying to facilitate a more open oink development community.
diff --git a/source/_posts/2007-06-26-status-report-recent-work.markdown b/source/_posts/2007-06-26-status-report-recent-work.markdown
deleted file mode 100644
index 47ea96c..0000000
--- a/source/_posts/2007-06-26-status-report-recent-work.markdown
+++ /dev/null
@@ -1,59 +0,0 @@
----
-comments: true
-date: 2007-06-26 11:08:52
-layout: post
-slug: status-report-recent-work
-title: 'Status Report: Recent Work'
-wordpress_id: 25
-categories:
-- mozilla
-- prbool
----
-
-**New Tool: Prcheck - PRBool's best friend **  
-  
-Mozilla has a number boolean types and most of them are a form of an int. People expect them to behave like a bool, but since they can be assigned more than 1 value for true, this assumption can lead to bugs. Prcheck will mandate that prbools can only be assigned 1 or 0. Typically static checkers output errors, but prcheck outputs errors & fixes for them in diff format so they can be fixed automatically. See [this bug](https://bugzilla.mozilla.org/show_bug.cgi?id=266048) for more info. I think the tool is almost complete. Hopefully, once the MCPP issues described below are addressed, I'll have one giant patch to eliminate this problem.  
-  
-**MCPP Teething Troubles**  
-  
-Even in the open-source world there are some problems with vendor monoculture. For example we a single vendor providing the C++ compiler and one C preprocessor that is widely used. Even though MCPP is a portable preprocessor that can plug into multiple compilers, it still chokes on some GCCisms. Things are slowly changing and new open source compilers are on the horizon: I can't wait.  
-  
-Additionally, since Mozilla is one of the largest projects to be preprocessed with MCPP, we found some scalability bugs in MCPP. The MCPP maintainer addressed those.  
-  
-**Elsa Backend Source Location Work - Works Well?**  
-  
-I am amazed, but hack & slash approach to adding end-of-ast-node info to elkhound still seems to work correctly! It mostly required consulting wikipedia on LR & GLR parsing algorithms to understand how to modify the data structures used in elkhound. I love the combination of Wikipedia and pretty & easy to modify source code.  
-  
-The preprocessor undo-log appears to function exactly as intended too. That combined with the end-of-ast-node info means that I finally have the ability to easily cut'n'paste code to move it around programmatically. It basically makes the C/C++ pretty printer in oink obsolete for my purposes. This is cool because now I can output prettier source code AND rely on less oink C++ code to do so (ie no need to call the pretty printer[s]), so more refactoring tools could be written in higher level languages such as OCaml or JavaScript in the future.  
-  
-**Publishing My Oink Mods**  
-  
-I have been sending people tarballs on request, due to not being able to integrate my changes into the upstream svn repository. I tried a few svn2hg tools, but they didn't work very well. [hgsvn](http://cheeseshop.python.org/pypi/hgsvn/) is good enough to work for OpenJDK, so it might work for me. I'll try to publish an hg repository of my work within the next week or two.  
-  
-I'm sorry for not doing this earlier, but it's extremely time consuming to switch gears from coding oink stuff to trying to package it, especially due to all of the politics involved. Hopefully once the repository is easier to work with I'll have more people sharing the oink worldload with me. Now that dust settled and the major missing pieces are either implemented or decided upon, a lot of exciting possibilities opened up.  
-  
-**libgcc**  
-  
-Another day, another piece of preprocessor trivia. Turned out there was an alternative to MCPP that I could have used: gcc's libcpp. It is common knowledge that gcc uses an integrated preprocessor. It is not so well known that the preprocessor is factored out into what appears to be a mostly standalone library inside of gcc called libgcc. Google barely knows about it and there are no docs or other webpages pointing to it, so i missed it in my search.  
-  
-This could be a useful project, take libcpp turn it back into a standalone preprocessor and add the cpp undo log comments to it. The only downside of libgcc is that it is GPL which would normally be a pain for BSD-licensed projects, but by turning it back into a standalone tool there is no linking to to worry about.  
-  
-So if anyone finds implementing the macro-undo log with libgcc interesting, please feel free to do so :)  
-  
-**Random Rant on Parallels vs VMWare Fusion vs BootCamp vs 64bit Linux**  
-  
-  
-  
-I installed 64bit ubuntu on my MBP. Compilers & other tools are ridiculously fast when running linux natively on core2duo. Due to some performance bugs that I can't track down (shark isn't working for and recently OSX's gdb stopped working too) oink runs much faster on the linux side of the MBP. If any mac people want to profile oink on OSX, that'd be awesome. However OSX has some nice things (such as a display driver that works well and good battery life). I wish ati wasn't such a pain with releasing specs for their cards so linux could support them properly. I hope the recent reverse engineered driver work stabilizes soon. So I figured it would be nice to access & work on the linux partition from within OSX.  
-  
-I was pretty excited when I heard that Parallels 3 supports BootCamp. Problem was that nothing could see the bootcamp linux install. Turned the problem was caused because I used fdisk + refit to do the partitioning and turned on the bootable flag. To fix this I turned off the bootable flag on the linux partition using parted(which can sync the gpt partition table!) .  
-  
-Then I realized that Parallels has very slow disk access AND doesn't do 64bit and doesn't appear to support SMP.  
-  
-VMWare Fusion on the other hand supports bootcamp & 64bit & smp and appears to have much faster IO. However it lacks UI for accessing a linux bootcamp install or documentation. So here is the secret recipe to save time for others in my situation:  
-  
-1) Create a vmware disk for the bootcamp partition using vmware-rawdiskCreator in /Library/Application Support/VMware Fusion.  
-  
-2) Create a new machine, point at the file created in 1.  
-  
-Fusion's performance is remarkable. Oink runs almost as fast as it does natively. Plus VMWare support the VMI interface in Linux which combined with a tickless kernel should make the virtualizing overhead minimal. Too bad Linux doesn't have these features yet for amd64.
diff --git a/source/_posts/2007-07-13-dehydra-prcheck-squash-in-mercurial.markdown b/source/_posts/2007-07-13-dehydra-prcheck-squash-in-mercurial.markdown
deleted file mode 100644
index f0e5e68..0000000
--- a/source/_posts/2007-07-13-dehydra-prcheck-squash-in-mercurial.markdown
+++ /dev/null
@@ -1,48 +0,0 @@
----
-comments: true
-date: 2007-07-13 08:54:08
-layout: post
-slug: dehydra-prcheck-squash-in-mercurial
-title: Dehydra, prcheck, squash - in mercurial
-wordpress_id: 28
-categories:
-- mozilla
-- dehydra
-- squash
----
-
-**New Repository**  
-  
-Since I do not yet have write access to oink svn, I have been doing all of my development in ad-hoc repositories within the svn checkout. This made it rather hard to collaborate with others. I finally got sick of the situation (and stumbled upon [hgsvn](http://cheeseshop.python.org/pypi/hgsvn/)) and converted all 11 svn repositories to mercurial. To my surprise, mercurial even let me merge my repositories while preserving history (hg has yet to fail me!).  
-  
-oink uses svn-externals to aggregate the repositories into a single checkout. hg doesn't have anything similar, so to checkout all 11 repositories use a script:  
-  
-
-```
-[checkout.sh](http://people.mozilla.org/~tglek/checkout.sh) http://hg.mozilla.org
-
-```
-**Released Differences from Oink Mainline **
-
-  * New oink tool - [prcheck](http://taras.glek.net/blog/2007/06/26/status-report-recent-work/): ensures that bool-like integer typedefs behave like bools
-  * New oink tool - [dehydra](http://wiki.mozilla.org/DeHydra): source query tool with queries specified in JavaScript
-  * New oink tool - [squash](http://wiki.mozilla.org/Squash): source refactoring tool. This is now deprecated since most of the code in it dealt with working around elsa limitations to do with macro expansion & lack of precise locations. The patching engine used in squash lives on to provide a simple refactoring API for use in other tools (like prcheck).
-  * Minor grammar changes to parse more of Mozilla
-  * Compilation fixes for OSX
-  * Elsa fixes to parse OSX headers
-  * make -j support for elsa
-  * end-of-ast-node location support for elkhound & elsa
-  * preprocessor expansion markup support for elsa
-**Coming Soon**
-
-  * Amazing new version of [MCPP](http://mcpp.sourceforge.net/) capable of preprocessing mozilla while outputting refactoring-friendly annotations.
-  * Web front-end for squash which will likely be refactored to be tool-agnostic.
-  * Front-end to run patch-producing tools in parallel for multi-core machines
-**Near Future**
-
-  * squash will be split up into a library with each major feature ripped out into a standalone tool. Two tools coming soon:outparam rewriter & class member renamer.
-  * RAD for static analysis: oink tool templates to make it trivial to write custom new tools with minimal amount of boilerplate
-**Some time in the Future**
-
-  * Collaboration with the author of [Olmar](http://www.cs.ru.nl/~tews/olmar/) to provide an OCaml API for Elsa. If everything goes as expected it will be possible to write analyses that are more powerful and more concise than DeHydra ones except they will perform at C/C++ speeds. Plus it should be possible to perform them from a native interactive OCaml toplevel. Most of this work already exists in bits and pieces. It's a matter of adding some AST transformations, fixing a few issues and tying it all together.
-  * MapReduce inspired front-end: generic framework for executing transformations/analyses in-parallel and Mozilla-wide without blowing the 32bit address space (as it typical when static analysis tools meet Mozilla).
diff --git a/source/_posts/2007-07-13-pondering-prepost-conditions-to-enforce-software-correctness.markdown b/source/_posts/2007-07-13-pondering-prepost-conditions-to-enforce-software-correctness.markdown
deleted file mode 100644
index 99b170a..0000000
--- a/source/_posts/2007-07-13-pondering-prepost-conditions-to-enforce-software-correctness.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2007-07-13 09:12:55
-layout: post
-slug: pondering-prepost-conditions-to-enforce-software-correctness
-title: Pondering Pre/Post Conditions to Enforce Software Correctness
-wordpress_id: 29
-categories:
-- mozilla
----
-
-That other software company has a some brilliant people working on verifying their source code. Their approach is hardcore and seems quite good. Their recipe to robust C# (applying this to C is research-in-progress, C++ isn't yet considered) code is: 
-
-  * sprinkle pre/post-conditions for functions. Reduce annotation labour by additional rule inference
-  * dataflow analysis to verify type-system stuff like not-null annotations
-  * Abstract interpretation + model checker to enforce pre/post-conditions
-  * [BoogiePL](http://research.microsoft.com/research/pubs/view.aspx?type=Technical%20Report&id=923) intermediate language. Anything can be accomplished by an awesomely named intermediate language!
-Resulting code runs fast has a lot fewer bugs than code without all this fancy machinery. Unfortunately, the benefits can only be reaped if a whole program gets annotated. Otherwise, the model checker gets frustrated. Essentially the language being checked is turned into another much safer (more boogie!) language. I'm looking forward to the day (that will never come) when all new C code is written this way.  
-  
-If adding these to source code makes you rewrite the whole program, wouldn't it be easier to invent another low-level language that comes with safety by default?  
-  
-I am guessing that the dehydra method of checking for a relatively small number of application specific bugs is the most practical approach available and it will get us 60% towards Boogieing. Now that elsa has support for preprocessor macros it should be possible to specify non-formal pre/post-conditions to check for common errors. It's merely a complicated question of defining what should be checked for.  
-  
-I don't have the motivation to write/buy/adopt/integrate a formal tool like a model checker, but it seems that it's possible to write application specific checks in JavaScript that can run circles around what most model checkers can do.  
-  
-That other company isn't the only vendor working on this stuff. There [brilliant people](http://www.cs.princeton.edu/~appel/cminor/) taking a somewhat different (and open source) approach.
diff --git a/source/_posts/2007-07-18-cpp-aware-c-rewriting-can-be-fun.markdown b/source/_posts/2007-07-18-cpp-aware-c-rewriting-can-be-fun.markdown
deleted file mode 100644
index 7daeade..0000000
--- a/source/_posts/2007-07-18-cpp-aware-c-rewriting-can-be-fun.markdown
+++ /dev/null
@@ -1,39 +0,0 @@
----
-comments: true
-date: 2007-07-18 14:29:16
-layout: post
-slug: cpp-aware-c-rewriting-can-be-fun
-title: CPP-Aware C++ Rewriting Can Be Fun
-wordpress_id: 30
-categories:
-- mozilla
----
-
-Recently MCPP started working well enough to process all of Mozilla with the special macro-expansion undoing markup. Below is the most exciting patch line I have produced so far. A few months ago, I didn't think was possible to rewrite macro parameters with elsa. 
-```
-
--    ENCODE_SIMPLE_ARRAY(PRBool, Bool, (PRUint16) values[i]);
-+    ENCODE_SIMPLE_ARRAY(PRBool, Bool, 0 != ((PRUint16) values[i]));
-
-```
-To produce this: 
-
-  1. Elsa consumed the expanded .ii file
-  2. Boolean checker found the problematic subexpression
-  3. Original source position was calculated from the expansion log
-  4. Then prcheck figured out that only the macro parameter needs to be rewritten.
-  5. Original source was read in and enclosed within 0 != ()
-**Integrating Static Checks - PRBool check **  
-  
-[This bug](https://bugzilla.mozilla.org/show_bug.cgi?id=266048) contains the rest of the rewriting results. Prcheck checks every assignment to a prbool and outputs a patch if the expression may evaluate to anything other than 0/1. A message is produced if a patch can not be generated because the expression is within a macro.  
-  
-The goal is to have prcheck run on every commit(or every day) and send out an email or another form of a complaint when a new prbool violation is introduced. Since the current prbool misuses aren't going to be fixed overnight, there should be a db kept somewhere with the old misuses to prevent the new ones from being introduced and old ones from being annoying. I'm thinking of associating misuse counts with a filename, so when the number goes up an error gets mailed out. Anyone get a better idea?  
-  
-**Latest Recipe to Running Oink Tools **
-
-  1. If you want to rewrite sources either wait for the next mcpp release or use my [tarball](http://people.mozilla.org/~tglek/mcpp-post2.6.4.tar.gz).
-  2. Install gcc 3.4.x. If using mcpp, configure mcpp with --enable-replace-system so it replaces the gcc preprocessor
-  3. [Checkout](http://taras.glek.net/blog/2007/07/13/dehydra-prcheck-squash-in-mercurial/) and build my oink version.
-  4. Build mozilla with -save-temps gcc option. If using mcpp set environment variables CC="gcc -Wp,-K -Wp,-W0 -save-temps " and CXX="g++ -Wp,-K -Wp,-W0 -save-temps " and do make -f client.mk build as usual. The extra gcc parameters tell it to save intermediate files to pass -K and -W0 to enable macro expansion annotation and silence warnings.
-  5. Run tools individual files
-  6. Produce a global patch with ./pork-barrel 4 /path/to/prcheck /tmp/input.txt where input.txt is a list of absolute filenames of all of the .i and .ii files produced by the build process
diff --git a/source/_posts/2007-07-27-superity-complex-static-analysis.markdown b/source/_posts/2007-07-27-superity-complex-static-analysis.markdown
deleted file mode 100644
index 08c26d4..0000000
--- a/source/_posts/2007-07-27-superity-complex-static-analysis.markdown
+++ /dev/null
@@ -1,41 +0,0 @@
----
-comments: true
-date: 2007-07-27 14:57:23
-layout: post
-slug: superity-complex-static-analysis
-title: Superity Complex & Static Analysis
-wordpress_id: 32
-categories:
-- mozilla
-- prbool
----
-
-It is always frustrating to see a compiler complain about something trivial. It is especially annoying since most of the trivial complaints are trivial to fix automatically (eg. superfluous semicolon).  
-  
-I think this is a bigger problem in the static analysis industry. Vendors/researchers ship their tools with a superiority complex built-in. Most of the error messages produced by error checking tools can be paraphrased as "Gee look, I found some trivial to fix bugs in your code, but I ain't gonna do nothing about them! Neeener! Go worker-human!"  
-  
-My policy is to make my tools more polite than that. Starting from prcheck, all of my tools will point out simple errors by suggesting patches (when possible). It is impossible to produce a correct patch every time, but I am not worried about that since developers are quite good at disregarding stupid suggestions.  
-  
-**Automatic Whining**  
-  
-Now I have a few extra scripts that lay the foundation for regular code inspection via static analysis. PRBool checks are my first step. Here is a sample email: 
-```
-
-```
-
-    
-    
-    Subject: Prbool violation in nsPlainTextSerializer.cpp
-    
-    vidur@netscape.com introduced a new PRBool problem in revision 1.1 of nsPlainTextSerializer.cpp.
-    
-    Commit message: branches:  1.1.2;  
-      
-    Error: /content/base/src/nsPlainTextSerializer.cpp: 614:
-    
-    -          PRInt32 semiOffset = style.Find("ch", widthOffset+6);
-    +          PRInt32 semiOffset = style.Find("ch", 0 != (widthOffset+6));
-
-[http://bonsai.mozilla.org/cvsblame.cgi?file=mozilla/content/base/src/nsPlainTextSerializer.cpp&rev=&cvsroot=/cvsroot#614](http://bonsai.mozilla.org/cvsblame.cgi?file=mozilla/content/base/src/nsPlainTextSerializer.cpp&rev=&cvsroot=/cvsroot#614)  
-  
-This an example of an incorrect suggestion. The actual problem is due to the incorrect method overload being chosen.
diff --git a/source/_posts/2007-08-06-outparams-take-2.markdown b/source/_posts/2007-08-06-outparams-take-2.markdown
deleted file mode 100644
index 8e8f77e..0000000
--- a/source/_posts/2007-08-06-outparams-take-2.markdown
+++ /dev/null
@@ -1,84 +0,0 @@
----
-comments: true
-date: 2007-08-06 16:02:10
-layout: post
-slug: outparams-take-2
-title: 'Outparams: Take 2'
-wordpress_id: 33
-categories:
-- mozilla
-- DeCOMtamination
-- outparamdel
----
-
-**Will Rid Code of Outparams!**  
-  
-I resumed my outparam rewriting work last week. Having fixed the [CPP induced](http://taras.glek.net/blog/2007/05/11/cpp-strikes-back/) architectural limitation that I ran into, it was quite straight-forward to factor out squash's rewriting code into a new tool. Unlike squash, outparamdel (creatively named new tool), can rewrite code precisely and reliably. I still don't have end-of-ast-node information in every Elsa AST member, but I think I have added position info to enough AST nodes to be able to do most of the Mozilla 2 rewrites.  
-  
-Last time I was working on this, I was a little unhappy with the amount of code that had to be changed in the callee. I also wasn't sure how to handle the complexity of callsites where control flow depends on the error code returned by the callee. This time I chose the path of least resistance.  
-  
-In the callee two variables replace the out-parameter. The first holds the return value and the second points at the first and is declared in the same way as the out-parameter.  
-  
-
-```
-@@ -2358,6 +2358,5 @@
--nsresult
--nsCSSFrameConstructor::CreateHTMLImageFrame(nsIContent* aContent,
--                                            nsStyleContext* aStyleContext,
--                                            ImageFrameCreatorFunc aFunc,
--                                            nsIFrame** aFrame)
--{
-+nsIFrame*
-+nsCSSFrameConstructor::CreateHTMLImageFrame(nsIContent* aContent,
-+                                            nsStyleContext* aStyleContext,
-+                                            ImageFrameCreatorFunc aFunc)
-+{
-@@ -2364,1 +2364,3 @@
--  *aFrame = nsnull;
-+  nsIFrame* __aFrame = 0;
-+  nsIFrame** aFrame = &__aFrame;
-+  *aFrame = nsnull;
-@@ -2371,1 +2371,1 @@
--      return NS_ERROR_OUT_OF_MEMORY;
-+      return nsnull;
-@@ -2374,1 +2374,1 @@
--  return NS_OK;
-+  return __aFrame;
-
-```
-With a little more work one can get of one or even both local variables, but that will require more heuristics.  
-  
-I also simplified call-site rewriting by wrapping the call to the callee function into a ternary expression when the error code is evaluated.  
-  
-@@ -5290,2 +5290,1 @@ 
-```
--    rv = CreateHTMLImageFrame(aContent, aStyleContext, NS_NewImageFrame,
--                              &newFrame);
-+    rv = ((newFrame = CreateHTMLImageFrame(aContent, aStyleContext, NS_NewImageFrame)) ? NS_OK : NS_ERROR_OUT_OF_MEMORY);
-
-```
-Obviously this could be improved upon by getting rid of rv altogether, but the trick works in all cases and can be improved-upon incrementally.  
-  
-**Problems & Limitations**
-
-  * Code within macros is detected, but not modified. Since macros are something that is easier to modify manually than with a tool, this isn't a problem.
-  * Indentation isn't updated. I think this is solvable with a few more heuristics in the patcher.
-  * Expression rewriting doesn't work on Mac or Windows source-code. Mac is going to be relatively straight-forward to support. MCPP doesn't understand all of the Mac strangeness yet and needs a loving and affectionate mac user to teach it the ways of Darwin. Windows is more work as it will require both updating the mingw Mozilla port and porting MCPP.
-**Coolness**  
-  
-
-```
-nsCSSFrameConstructor.cpp:10383: nsCSSFrameConstructor::CreateContinuingTableFrame,6=newFrame,
-nsCSSFrameConstructor.cpp:10993: nsCSSFrameConstructor::GetInsertionPoint,2=aParentFrame,
-nsCSSFrameConstructor.cpp:2374: nsCSSFrameConstructor::CreateHTMLImageFrame,3=aFunc,
-nsCSSFrameConstructor.cpp:4080: nsCSSFrameConstructor::ConstructDocElementTableFrame,2=childList,
-nsCSSFrameConstructor.cpp:4477: nsCSSFrameConstructor::ConstructRootFrame,1=viewportFrame,
-nsCSSFrameConstructor.cpp:4720: nsCSSFrameConstructor::ConstructRadioControlFrame,0=NS_NewGfxRadioControlFrame,
-nsCSSFrameConstructor.cpp:4741: nsCSSFrameConstructor::ConstructCheckboxControlFrame,0=NS_NewGfxCheckboxControlFrame,
-
-```
-I wrote outparamdel and tested it on a convoluted manual testcase. Then I ran outparamdel mozilla-wide with the above input and the resulting code compiled! This was never the case prior to MCPP work since I found find new and exciting preprocessor madness to work-around and special case with every new rewrite.  
-  
-**Future**  
-  
-Going to make this a little more challenging by rewriting QueryInterface to return result by a return value which should affect the majority of functions in Mozilla.
diff --git a/source/_posts/2007-08-30-pork-the-brave-new-world.markdown b/source/_posts/2007-08-30-pork-the-brave-new-world.markdown
deleted file mode 100644
index c271e13..0000000
--- a/source/_posts/2007-08-30-pork-the-brave-new-world.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2007-08-30 15:31:43
-layout: post
-slug: pork-the-brave-new-world
-title: 'Pork: The Brave New World'
-wordpress_id: 34
-categories:
-- mozilla
-- DeCOMtamination
-- dehydra
-- outparamdel
----
-
-It doesn't look like my oink patches are going to reach upstream anytime soon. In fact, in the past year no patches have landed in the oink tree. I think this is unfortunate, but I have my own repository at [http://hg.mozilla.org](http://hg.mozilla.org) and will continue working on my fork. So allow me to introduce Pork, the Oink fork. So if anyone has any exciting source location, pretty printing or other elsa improvements, I hope to eventually see those land in pork.  
-  
-Note, pork is just an informal name for the fork, I am not currently planning to do any source renaming or repository renaming.  
-  
-**Pork: Now in a VMware flavour**  
-  
-bsmedberg pointed out that oink seems a bit intimidating to setup and it would be nice if it came in virtual machine. So I have oink/mcpp/etc packaged up in a virtual machine that can build Mozilla with gcc3.4, run dehydra analyses and produce automated patches. If you want to play with that, post a comment and I'll reply with a download link.  
-  
-A couple of people asked me about some simple code-scans to see for problems and optimization opportunities. Next week I am going to post few simple dehydra recipes on how to look for patterns in the code. It's dead simple with JavaScript and some minimal shell knowledge to aggregate the results. The VM should provide a good way to get started.  
-  
-**Outparams: QueryInterface Rewrite Milestone Reached ** I finally got Mozilla to compile with the outparam-less qi call. The outparamdel part of that was surprisingly easy and straightforward. I   also learned all kinds of fun details about multiple inheritance and fun ways to construct functions out of macro segments. The next step is to get the code to run. I'll also have to look into a few minor MCPP issues that the rewrite uncovered. See QI [bug](https://bugzilla.mozilla.org/show_bug.cgi?id=391275) for the gory details.
diff --git a/source/_posts/2007-09-10-automatic-decomtamination-roadmap-for-automated-refactorings.markdown b/source/_posts/2007-09-10-automatic-decomtamination-roadmap-for-automated-refactorings.markdown
deleted file mode 100644
index 5efc1c3..0000000
--- a/source/_posts/2007-09-10-automatic-decomtamination-roadmap-for-automated-refactorings.markdown
+++ /dev/null
@@ -1,70 +0,0 @@
----
-comments: true
-date: 2007-09-10 18:26:36
-layout: post
-slug: automatic-decomtamination-roadmap-for-automated-refactorings
-title: 'Automatic DeCOMtamination: Roadmap For Automated Refactorings'
-wordpress_id: 35
-categories:
-- mozilla
-- DeCOMtamination
-- outparamdel
----
-
-This is an update on the ongoing [deCOMtamination](http://wiki.mozilla.org/Gecko:DeCOMtamination) work from the automated rewriting perspective. I think it's pretty exciting that Mozilla is the first large-scale C++ project to attempt automated large scale source code cleanups and optimizations. I think the tools are finally getting mature enough for the job.  
-  
-The downside is that there isn't a published roadmap of what we are planning to achieve with deCOMtamination as we are still in the planning stages. The upside is that there is still time for any interested parties to think up the next great improvement on how things are done, [checkout](http://taras.glek.net/blog/2007/07/13/dehydra-prcheck-squash-in-mercurial/) the refactoring toolchain and either extend an existing tool or implement a new one.  
-  
-Below is a list of things that I plan to have working in the near future. The idea is to try to implement various optimizations that would be impractical(or impossible?) to do manually and see if they yield the expected performance and code quality benefits.  
-  
-**Step 1: Outparam Elimination**  
-  
-QueryInterface() and other ok/fail methods have a redundant nsresult value which can be eliminated without changing any logic in the code. The QueryInterface() rewrite is my first serious tree-wide refactoring attempt. QueryInterface() is probably the most well known and frequently-used method within Mozilla. It also one of the most CPP-encumbered methods in the tree, so it made for a good test of my CPP-aware elsa work.  
-  
-The [getting code to compile](https://bugzilla.mozilla.org/show_bug.cgi?id=391275) phase is over. Currently Benjamin is working on getting the modified code to run which requires XPConnect changes, debugging the manually-rewritten macros and verifying that the generated patch is correct.  
-  
-The next step will be to eliminate local nsresult variables in the callees when they are used to store & check return values of QueryInteface(). This is basically a make-resulting-source-look-prettier optimization.  
-  
-I hope to measure a speed-up and slight footprint decrease with the new QueryInterface call.  
-  
-**Step 2: Try Mozilla Without Reference Counting?**  
-  
-In my mind the most exciting part of Moz2 is Tamarin. Few things are cooler than an elegant JIT VM.  
-  
-Tamarin comes with a modern [garbage collector](http://developer.mozilla.org/en/docs/MMgc).  
-  
-The goal of this rewrite is to aid [Jason](http://blog.mozilla.org/jorendorff/) and [Benjamin](http://benjamin.smedbergs.us/) with switching XPCOM from reference counting to garbage collection. This might end up in gigantic patches to rid the stack of nsCOMPtr objects. This might be hard as it will be affecting a lot of code and might reveal more shortcomings in [my version](http://taras.glek.net/blog/2007/08/30/pork-the-brave-new-world/) of elsa and MCPP. [Details](http://wiki.mozilla.org/XPCOMGC) are in the wiki.  
-  
-**Step 3: Try C++ Exceptions**  
-  
-This is the most ambitious rewrite I know of for Mozilla 2. It's similar to step 1 in that the goal is to eliminate outparameters and nsresult error codes, except in this case it would happen for all functions. Brendan [mentioned](http://weblogs.mozillazine.org/roadmap/archives/2006/02/fresh_xpcom_thinking.html) this is in his blog.  
-  
-The idea is that exceptions in Mozilla happen in exceptional circumstances, thus most of the time the return value will be NS_OK and the outparameter will have something valid in it. So we should rewrite all methods that return nsresult to return the outparameter value through the return value and have the errors thrown as exceptions.  
-  
-In the simplest case this would involve rewriting return statements into throw statements and rewrite callers to use try/catch. Instead of  
-  
-rv = bla(&outparam)...if(rv == foo) .. else if(rv == boo) return rv  
-  
-the code would be  
-  
-try{ outparam=bla() } catch(foo) {...} catch(boo) {throw boo}  
-  
-Note this is still inefficient since the code would be manually unrolling the stack instead of letting the exceptions do that. So the next iteration of the rewrite would get rid of the  
-  
-catch(boo) {throw boo}  
-  
-code to streamline the execution path. Ideally this would provide a significant reduction of footprint (due to getting rid of the error propagation code) and provide a speed boost.  
-  
-However, there are a lot of issues that need to be solved. How to ensure that the C++ code is exception-safe (everything has destructors to do appropriate cleanup)? How to deal with the case of the stack being a mix of platform C, C++, JavaScript, Python, etc? Most runtimes are not aware of C++ exceptions.  
-  
-**Infrastructure Work**  
-  
-Unfortunately, not all of the automated refactoring work is about exciting rewrites. Elsa is still tied to the stone-age gcc 3.4 as it can't yet process C++ headers from the newer gcc releases due to template complexity.  
-  
-There is also work that needs to be done to get OSX supported as well as Linux by elsa & mcpp. I think very little work remains there.  
-  
-Another big issue is getting elsa/mcpp to work on Windows. This may involve teaching elsa about the Microsoft windows flavour of C++ or getting Mozilla to reliably build with mingw and merely teaching elsa about mingw's flavour of windows C++.  
-  
-There is also an issue of maturity. Mozilla is probably the biggest codebase to make use of elsa and mcpp, so there are teething issues to solve. Having said that, the current version of MCPP in svn should be able to compile Mozilla. Elsa can process all of Mozilla with a small patch to two files attached in the QueryInterface() bug.  
-  
-Overall I'm doing less and less infrastructure work as time goes by, hopefully the tools will mostly just work from now on.
diff --git a/source/_posts/2007-09-12-garburator-another-day-another-rewrite-tool.markdown b/source/_posts/2007-09-12-garburator-another-day-another-rewrite-tool.markdown
deleted file mode 100644
index c273219..0000000
--- a/source/_posts/2007-09-12-garburator-another-day-another-rewrite-tool.markdown
+++ /dev/null
@@ -1,14 +0,0 @@
----
-comments: true
-date: 2007-09-12 12:54:45
-layout: post
-slug: garburator-another-day-another-rewrite-tool
-title: 'Garburator: Another day, Another rewrite tool'
-wordpress_id: 36
-categories:
-- mozilla
----
-
-I'm going to be on vacation until September 25th. I started the day by planning out how to do the rewriting tool to implement Benjamin's [spec.](http://wiki.mozilla.org/XPCOMGC/Stack_Pointers) I'll have to add more position information to elsa to do things properly and that might take a week or two. However, I'm into instant gratification so I wrote up a hacky prototype that results in a patch [like this.](http://people.mozilla.org/~tglek/garburator.diff)  
-  
-Say hi to garburator, a tool that will assist with the reference counting -> MMgc transition. The tool is less than 100 lines long, so someone could finish the hacky version while I am away. Either that or one could teach elsa to keep detailed position information in declarations and identifier names and clean up the postvisitS_decl() method in garburator.
diff --git a/source/_posts/2007-10-04-multiple-degrees-of-correctness.markdown b/source/_posts/2007-10-04-multiple-degrees-of-correctness.markdown
deleted file mode 100644
index 1d12da5..0000000
--- a/source/_posts/2007-10-04-multiple-degrees-of-correctness.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2007-10-04 17:05:05
-layout: post
-slug: multiple-degrees-of-correctness
-title: Multiple Degrees of Correctness
-wordpress_id: 37
-categories:
-- mozilla
-- prbool
----
-
-**Prcheck**  
-  
-The trouble with prcheck and the automated [prbool validation](http://taras.glek.net/blog/2007/06/26/status-report-recent-work/) is that one can't attach the giant patch it produces to bugzilla and expect it to get committed. So I am spending this week combing through prcheck output  and patch-bombing bugzilla with per-module patches.  
-  
-I find going through the errors manually to be a lot of fun than I expected. I am finding types of errors that I was not considering when I was writing prcheck. For example, I expected the biggest gains to come at runtime from making all prbool values 0/1, but it seems that most of the cool errors are due to PRBool & PRInt32 resolving to the same type. That results in code mayhem ranging from wrong method overloads being called to method signatures claiming to return PRBool where method bodies act like the function returns nsresults.  
-  
-The prbool check is just an incredibly minor restriction of the C++ system, yet it resulted in hundreds of errors(almost all of which are typos). In my mind this reinforces the importance of static typing (which C++ doesn't do enough of).  
-  
-The main lesson I learned today is that [code](https://bugzilla.mozilla.org/show_bug.cgi?id=398624) doesn't have to be correct in order to work correctly.  
-  
-**Mobile**  
-  
-While on vacation in Ukraine I finally got to try out GPRS Internet through my cellphone. Sure EDGE is slow, but the convenience of having internet everywhere I go while traveling is unparalleled. It's just too bad that I had to go to a developing country to be able to afford mobile internet. In Canada I would've paid over $750 for the $10 worth of Internet in Ukraine. So I am very excited that governments are starting to regulate mobile pricing. Looks like [EU is first](http://news.yahoo.com/s/afp/20071004/bs_afp/eutelecommobilesectorregulateconsumer). I hope the [local](http://telus.ca) [cellular](http://www.rogers.com) [oligopoly](http://bell.ca/home/) gets a kick to the head soon.
diff --git a/source/_posts/2007-10-12-rewriting-tools-for-mozilla-2-moving-forward-as-planned.markdown b/source/_posts/2007-10-12-rewriting-tools-for-mozilla-2-moving-forward-as-planned.markdown
deleted file mode 100644
index ebeac77..0000000
--- a/source/_posts/2007-10-12-rewriting-tools-for-mozilla-2-moving-forward-as-planned.markdown
+++ /dev/null
@@ -1,31 +0,0 @@
----
-comments: true
-date: 2007-10-12 15:31:35
-layout: post
-slug: rewriting-tools-for-mozilla-2-moving-forward-as-planned
-title: 'Rewriting Tools for Mozilla 2: Moving Forward as Planned'
-wordpress_id: 38
-categories:
-- mozilla
-- DeCOMtamination
-- dehydra
-- garburator
----
-
-**In the Beginning There Was a Void**  
-  
-Approximately a year ago, Brendan discussed with me the crazy possibility of rewriting most of the Mozilla code automatically to modernize the codebase. The benefits were huge. Gecko would use the C++ standard library to improve code readability and reducing size, XPCOM would be ripped out of the core to improve performance and decrease footprint, etc.  
-  
-It seemed like a good idea, but in reality no other giant C++ project has attempted this before so we were not sure of how realistic it was. I spent a year in a [lonely corner](http://benjamin.smedbergs.us/blog/2007-10-11/dehydra-ftw/) of Mozilla trying to materialize the idea.  
-  
-Brendan & Graydon pointed me to [elsa](http://www.cs.berkeley.edu/~smcpeak/elkhound/sources/elsa/), the C++ parser that supposedly could parse Mozilla. However, it turned out that it was only able to parse an old version of Mozilla and rejected the new source. One of the elsa maintainers even tried to convince us to it was not designed for source-to-source transformations and wouldn't work that way.  
-  
-After I patched up elsa and started devising ways to use it for source rewriting I ran into more pain. After a few false starts, I realized that C++ in Mozilla is actually a mix of CPP and C++ and one can not rewrite C++ without dealing with the [mess that is macro expansion](http://taras.glek.net/blog/2007/05/11/cpp-strikes-back/). [MCPP](http://mcpp.sourceforge.net/) was pointed out to me as a good starting point for hacking on a preprocessor. So I [designed](http://taras.glek.net/blog/2007/06/12/undoing-cpp-expansion-in-3-simple-steps.-say-hello-to-easier-c-rewriting./) an inline log for macro expansion. To my surprise the maintainer of MCPP, Kiyoshi MATSUI, volunteered to implement the spec and thus saved me from a world of pain. (For which I am eternally grateful as I can't imagine a more depressing pastime than working on the root of all evil: the C preprocessor).  
-  
-In parallel with Kiyoshi's work I modified [elkhound](http://www.cs.berkeley.edu/~smcpeak/elkhound/) & elsa to make the C++ parser a lot more suitable for source transformations. I learned about LR & GLR parsing and confirmed my suspicion that I don't want to write parser generators for a living.  
-  
-**Happy Conclusion **  
-  
-All this work finally got us what we discussed last September: a framework for doing lots of [boring code rewrites](http://wiki.mozilla.org/XPCOMGC/Stack_Pointers).  
-  
-The first big Moz2 task is [switching](http://wiki.mozilla.org/XPCOMGC) from reference counting to garbage collection. Today, [garburator](http://taras.glek.net/blog/2007/09/12/garburator-another-day-another-rewrite-tool/) produced a [gigantic patch](http://people.mozilla.org/~tglek/garburator/nsgenerichtmlelement.diff) for subset of the content/ module and all of the affected files compiled. Hopefully next week I'll have a multi-megabyte patch for the whole of Mozilla that compiles and possibly runs.
diff --git a/source/_posts/2007-10-24-rewriting-javascript.markdown b/source/_posts/2007-10-24-rewriting-javascript.markdown
deleted file mode 100644
index 6e21c0e..0000000
--- a/source/_posts/2007-10-24-rewriting-javascript.markdown
+++ /dev/null
@@ -1,18 +0,0 @@
----
-comments: true
-date: 2007-10-24 15:36:00
-layout: post
-slug: rewriting-javascript
-title: Rewriting JavaScript
-wordpress_id: 39
-categories:
-- mozilla
----
-
-I'm having a very painful time rewriting Mozilla source code to switch it to garbage collection. So I took a little break to think about Myk's [JavaScript rewriting idea](http://www.melez.com/mykzilla/2007/10/automated-js-code-rewriting.html).Then I found excellent info on [parsing JS](http://siliconforks.com/doc/parsing-javascript-with-spidermonkey/) with [SpiderMonkey](http://www.mozilla.org/js/spidermonkey/). The downside to SpiderMonkey is that it is in C and thus hard to reuse, the upside is that will be able to parse all valid JavaScript.  
-  
-I think I shall find some free time to prototype a little tool to take a .js file and produce a JSON representation of it such that one could write transformation passes in JavaScript. This will be useful as it will complete DeHydra by enabling it to process JS in addition to C++ and it will save a lot of time for various JavaScript refactorings.  
-  
-I expect developing a JS refactoring tool to be relatively trivial compared to refactoring C++ as there is no source-code mangling going on due to lack of preprocessing (but JS is dynamic and can be embedded in various document types, so that could complicate things). Perhaps it would even be of use to mozpad people.  
-  
-Looking forward to playing more with this idea.
diff --git a/source/_posts/2007-11-02-garburator-works.markdown b/source/_posts/2007-11-02-garburator-works.markdown
deleted file mode 100644
index e08eb0d..0000000
--- a/source/_posts/2007-11-02-garburator-works.markdown
+++ /dev/null
@@ -1,19 +0,0 @@
----
-comments: true
-date: 2007-11-02 16:02:15
-layout: post
-slug: garburator-works
-title: Garburator works!
-wordpress_id: 40
-categories:
-- mozilla
-- garburator
----
-
-A [few weeks](http://taras.glek.net/blog/2007/10/12/rewriting-tools-for-mozilla-2-moving-forward-as-planned/) ago I convinced myself that is possible to rewrite Mozilla to avoid COMPtrs on the stack. Since then I've changed my mind a few times and felt like I may not be able to get this rewrite working. However, after three or four false starts, I finally managed to work out a metal model of the stack nsCOMPtr usage. With a combination of automatic blacklisting of tricky code, manual demacroing and lots of help from [Benjamin](http://benjamin.smedbergs.us/) I got the generated 3.2MB patch to compile.  
-  
-I am sure that there are lots of bugs to be found still, but at least we've discovered the pattern that the code follows. I am also sure that there are lots of unpleasant surprises to be discovered and dealt with in the near future.  
-  
-The bright side is that the result of these rewrites we should get a less buggy codebase that is easier to work on, more efficient and compiles to smaller binaries. My other big wish is to significantly reduce the amount of C++ magic in the codebase.  
-  
-I am happy that garburator works as it means I can go back to playing [outparamdel](http://taras.glek.net/blog/category/outparamdel/). Hopefully, once garburator+outparamdel are applied on all possible methods we'll end up with relatively nice looking C++ code and a healthy performance boost.
diff --git a/source/_posts/2007-11-12-cleaning-up-my-act.markdown b/source/_posts/2007-11-12-cleaning-up-my-act.markdown
deleted file mode 100644
index dd4bf4c..0000000
--- a/source/_posts/2007-11-12-cleaning-up-my-act.markdown
+++ /dev/null
@@ -1,18 +0,0 @@
----
-comments: true
-date: 2007-11-12 13:10:19
-layout: post
-slug: cleaning-up-my-act
-title: Cleaning up my act
-wordpress_id: 42
-categories:
-- mozilla
----
-
-I added an "ongoing work" and "tools" sections to the [Mozilla 2](http://wiki.mozilla.org/Mozilla_2) page.  
-  
-The pork suite now has a [wiki page](http://wiki.mozilla.org/Pork).  
-  
-#mercurial regulars kindly educated me about hg branches. Turned out hgimportsvn tries to map some subversion concepts onto hg branches which causes problems for people checking out pork using never versions of hg. For people googling for this issue: do "hg up trunk ; hg branch -f default; hg commit" to produce a magic empty revision to fix this problem.  
-  
-If you have tried to compile pork before and gave up in despair, please try again using the [pork wiki page](http://wiki.mozilla.org/Pork) for instructions.
diff --git a/source/_posts/2007-11-26-mozilla-2-outparamdel.markdown b/source/_posts/2007-11-26-mozilla-2-outparamdel.markdown
deleted file mode 100644
index c2b3831..0000000
--- a/source/_posts/2007-11-26-mozilla-2-outparamdel.markdown
+++ /dev/null
@@ -1,102 +0,0 @@
----
-comments: true
-date: 2007-11-26 15:26:17
-layout: post
-slug: mozilla-2-outparamdel
-title: 'Mozilla 2: Outparamdel'
-wordpress_id: 44
-categories:
-- mozilla
-- dehydra
-- outparamdel
----
-
-There will be a lot of under-the-hood code changes in Mozilla 2. Our goal is to end up with a simpler, safer and faster codebase.  
-  
-This is my perspective on the work ahead with respect to outparamdel.  
-  
-**Outparamdel**  
-  
-In the presence of a garbage collector we will be getting rid of stack nsCOMPtr<> usage (using raw pointers instead), but the getter_Addrefs() will still be needed to pass references to heap-allocated nsCOMPtr so they can be assigned to. Eliminating as many outparams as possible will eliminate much getter_Addrefs() footprint/perf/code bloat.  
-  
-Within the next week I hope to attempt to rewrite all of the auto-detectable outparamdel candidates.  
-  
-**Determining What To Rewrite**  
-  
-outparams.js is a dehydra script for flagging code that can be rewritten to use outparameters. It turned out a bit trickier than I initially expected. Here are the checks required 
-
-  1. Check that a function only ever returns 1 failure error code (NS_OK and something else). This enough if a function is not virtual.
-  2. Ensure that either a) This is the only implementation of a particular virtual function or b) All other implementations of this function satisfy 1 Currently I only do a).
-  3. Also check that all overloads of this function have the same outparameter type. This is required since C++ (thankfully) doesn't not allow function overloading by varying the return type.
-  4. Checks 1-3 ensure that the function can be rewritten, however one also needs to determine if the return type should be wrapped in getter_Addrefs<>. This can not be deterministically done from looking at the getter. So one has to scan the code for usage of the function to see if the outparam is ever passed getter_Addrefs.
-  5. Check that none of the callers are within macros to minimize non-automatic rewriting.
-Checks 2 and 3 require the complete class hierachy of Mozilla so I finally made a few more dehydra scripts to produce that. This was on my TODO list for a while and should make a few other interesting analyses possible (my favourite one is finding interfaces which only have 1 implementation to get rid of excessive virtual functions).  
-  
-Checks 4 and 5 were easiest to implement as warnings in outparamdel.  
-  
-One should keep in mind transitivity. Once the first outparamdel candidates are rewritten, some of their callers should become flagged for rewriting in the same manner.  
-  
-**Rewriting Code **  
-  
-Here is an example of how code will be simplified.  
-  
-given a function: 
-```
-
-nsresult getFoo(nsIFoo **out);
-
-```
-And usage like: 
-```
-
-nsCOMPtr<nsIFoo> bla;
-nsresult rv = getFoo(getter_Addrefs(bla));
-```
-  
-  
-
-```
-if ((NS_SUCCEEDED(rv) && bla) {
-...
-} else {
-return rv;
-}
-nsCOMPtr<nsIFoo> bla2;
-return getFoo(getter_Addrefs(bla2));
-
-```
-The function definition will become:  
-  
-
-```
-nsIFoo* getFoo();
-
-```
-Before this can be done, several issues come up 
-
-  1. It is not clear if the original getFoo() is allowed to always override the value passed to it. This is hard to determine automatically, so we make the assumption that in the general case it is ok.
-  2. It isn't obvious if getFoo() is returns null in the outparam to indicate some non-error condition. This is rare so the parameter shall be annotated. Currently, the plan is to annotate with a NULLABLE_OUTPARAM() macro which would be detectable by dehydra and serve as documentation for the function behavior.
-
-```
-nsCOMPtr<nsIFoo> bla = getFoo(); //after XPCOMGC rewrite the left side will become nsIFoo* bla
-if (bla) { // could even merge the above declaration into the if condition
-...
-} else {
-return NS_ERROR;// or NULL if this is another outparamdel candidate
-}
-nsCOMPtr<nsIFoo> bla2 = getFoo();
-return bla2 ? NS_OK : NS_ERROR_SOMETHING; // I'm not sure if outparamdel should use an explicit ternary operator or an inline function to convert new style errors into nsresult
-
-```
-Currently the code is being rewritten in a much uglier way. So this cleaner version will likely be implemented as an optimization pass (probably with a new tool outparamdel-opt?). There several tricks here: 
-
-  1. Connect the declaration with initialization of bla and bla2
-  2. Detect the error check and replace it with "bla"(or !bla for NS_FAILED).Then realize that bla && bla contains a redundant statement and take it out.
-  3. Do something similar to return statements.
-**Result**  
-  
-This should result in prettier code that compiles quicker and to a smaller, more efficient binary. It will also be more GC-friendly.  
-  
-**C++ Exceptions**  
-  
-Right now outparamdel does rewrites that are useful even if C++ exceptions will not be introduced. There are further code reduction gains possible if above error checks were converted into C++ exceptions, but I am not clear on performance characteristics of exceptions. We would also need to change tamarin exceptions to match C++ ones before any experimentation can be done.
diff --git a/source/_posts/2007-11-28-volume-of-refactoring-ahead.markdown b/source/_posts/2007-11-28-volume-of-refactoring-ahead.markdown
deleted file mode 100644
index e0d2e04..0000000
--- a/source/_posts/2007-11-28-volume-of-refactoring-ahead.markdown
+++ /dev/null
@@ -1,22 +0,0 @@
----
-comments: true
-date: 2007-11-28 17:53:42
-layout: post
-slug: volume-of-refactoring-ahead
-title: Volume of Refactoring Ahead
-wordpress_id: 45
-categories:
-- mozilla
-- dehydra
-- outparamdel
----
-
-In the previous post, I described the simple rewriting case that I am working on at the moment. Someone was quick to point out that the approach wouldn't work for all methods (XPIDL Arrays were the example). Indeed, anything more complicated than simple getters can't be rewritten to "Succeeded/Failed" pattern without switching to C++ exceptions. However, in the codebase the size of Mozilla there are several megabytes worth outparam getters to be rewritten.  
-  
-Currently my wimpy little [outparams.js](http://hg.mozilla.org/oink/?file/0ab46e97549e/dehydra_scripts/outparams.js) script identifies 100 methods that can be rewritten by outparamdel without any manual intervention. However doing a search for ::Get with a ** parameter yields over 2700 candidates, of which most look like they can be rewritten. Reason for the laughable detection rate is that the detection script currently refuses to flag methods that are defined in XPIDL interface or are implemented by more than one class. Soon the script will make heavier use of the class hierarchy and we will probably change XPIDL to support more efficient getters.  
-  
-**Complete Class Hierarchy**  
-  
-I finally managed to convince Dehydra to serialize the Mozilla class hierarchy into JSON files without running out of virtual memory. This will generate lots of input for refactoring and analysis tools. All kinds of [interesting stats](https://bugzilla.mozilla.org/show_bug.cgi?id=405855) can be produced with [simple scripts](http://hg.mozilla.org/oink/?file/0ab46e97549e/dehydra_scripts/find_single_impl.js). Generating the index is relatively [straightforward](http://wiki.mozilla.org/index.php?title=DeHydra#Capturing_the_Moz_Class_Hierarchy). It would be awesome if someone could figure out how to expose this data as a web app. Since there is so much being loaded incrementally, I don't see how one can keep things simple but use an asynchronous API.  
-  
-In the coming months, I am looking forward to extending this to be a complete callgraph to find dead code and other fun data.
diff --git a/source/_posts/2007-11-29-gcc-plugins-under-my-xmas-tree.markdown b/source/_posts/2007-11-29-gcc-plugins-under-my-xmas-tree.markdown
deleted file mode 100644
index 65f8e25..0000000
--- a/source/_posts/2007-11-29-gcc-plugins-under-my-xmas-tree.markdown
+++ /dev/null
@@ -1,27 +0,0 @@
----
-comments: true
-date: 2007-11-29 21:59:41
-layout: post
-slug: gcc-plugins-under-my-xmas-tree
-title: GCC Plugins under my xmas tree?
-wordpress_id: 41
-categories:
-- mozilla
-- dehydra
----
-
-Over at LWN there is an article on [GCC plugins](http://lwn.net/Articles/258700/). It touches onto how it would be useful to implement static analysis tools as GCC plugins.  
-  
-It does not mention that certain optimizations are not feasible without interfacing with the compiler and that there could be a very significant decrease in errors if we the compiler were pluggable with API-specific checks. Wouldn't it be nice if less developer time had to be spent hunting for common bugs and more implementing awesome new features?  
-  
-Typically safety is accomplished by executing code in a Virtual Machine that does extra runtime checks with Just In Time compilation to make up for performance losses. This approach has many known performance and footprint disadvantages. It is used by languages like Java and Scheme.  
-  
-Applications in these languages are slow and/or ship with a JIT compiler to optimize them during their runtime. C++ is compiled ahead of run time and has a reputation for running faster than these dynamic languages. However it also makes it a lot easier to make mistakes such as leak memory and buffer overflows. One can use the C++ OO system to perform extra-runtime checks to avoid some of these issues but that tends to cancel out any performance advantages of writing code in C++.  
-  
-Another approach is to enforce various safety-related properties through the compiler. Awesome existing languages such as [OCaml](http://en.wikipedia.org/wiki/OCaml) come with a strict type system that ensures that once code compiles it will run fast and have a lower bug percentages than comparable code in other languages. EcmaScript4 will feature a rocking type system similar to OCaml.  
-  
-C++ does not have such an awesome typesystem. However, there are many C++ errors that occur frequently and should be detected by the compiler, however long as there is no way to specify Mozilla-specific type system restrictions the compiler has no way of getting that information. Such plugins provide a certain piece of mind that once code complies with whatever rules we set for it, it is more likely to run correctly. Furthermore, some optimizations that we have in mind for Mozilla 2 (such as incremental garbage collection) will be much easier to work with if the compiler flags memory misuse at compile time.  
-  
-Currently we can use dehydra to scan the codebase, but it would be much more efficient to be able to plug such verification abilities into every developer's GCC. I sincerely hope that whoever is in charge of the plugin decision at GCC will realize the massive advantage this would give to GCC over other compilers.  
-  
-ps. Another use for plugins is to enable more aggressive optimizations. Small changes in the sourcecode can affect how conservative the generated code this. A clever plugin could warn whenever gcc cancels an optimization due to misbehaving source.
diff --git a/source/_posts/2007-12-05-exceptional-circumstances.markdown b/source/_posts/2007-12-05-exceptional-circumstances.markdown
deleted file mode 100644
index b12503b..0000000
--- a/source/_posts/2007-12-05-exceptional-circumstances.markdown
+++ /dev/null
@@ -1,43 +0,0 @@
----
-comments: true
-date: 2007-12-05 14:23:38
-layout: post
-slug: exceptional-circumstances
-title: Exceptional Circumstances
-wordpress_id: 46
-categories:
-- mozilla
-- DeCOMtamination
-- outparamdel
-- thrower
----
-
-My previous post on outparam rewriting [described](http://taras.glek.net/blog/2007/11/28/volume-of-refactoring-ahead/) the wealth of functions that can be rewritten. Unfortunately, most functions in Mozilla are declared in XPIDL interfaces.  
-  
-I have been convinced that my plan to rewrite xpidlgen to avoid outparameters wont be possible because most XPIDLinterfaces can be implemented by JavaScript in a few different ways. That is problematic because in addition to return values, JavaScript can also have an exception thrown at any point and have that converted to an nsresult error code by XPConnect. That means that the getters implemented in JavaScript are not in the set of functions that only return NS_OK+outparam/someerror. I wouldn't be at all disappointed if someone proved me wrong here.  
-  
-**nsexception**  
-  
-There is one other way to rid the code of outparameters (including getter_AddRefs and friends). Time to face my greatest reluctance: rewriting Mozilla to use exceptions. Brendan has been talking about it for a long time, but I have been skeptical until now, mostly due to the complexity of rewriting that much code. However, I have more confidence in rewriting huge amounts of code now since the XPCOMGC rewrite which touched most functions in Mozilla without too much trouble (in relative terms).  
-  
-**Motivation**  
-  
-There are some obvious benefits to be gained from switching to exceptions other than a reduction in code-size (and footprint?) and having code that looks more like common C++.  
-  
-We would like to modify tamarin to use C++ exceptions such that an exception thrown from JavaScript would unroll the mixed C++/JS stack. This would simplify and enable significant optimizations for XPConnect.  
-  
-I am dreaming of JITed marshaling code for C++->JS calls and having a low level FFI interface(ie being able to call most C/C++ methods [directly](http://starkravingfinkle.org/blog/2007/09/hello-js-ctypes-goodbye-binary-components/)) on the JavaScript side such that tracing JIT could automatically optimize common XPConnect calls. This an exciting area and there are lots of details to be worked out, so I'd love to see some feedback (or better yet proof of concept code!) on this.  
-  
-**The Plan** - Rewriting  
-  
-I have started implementing thrower (I am not a great namer), a tool for converting various code patterns involving nsresult into something that uses an nsexception wrapper.  
-  
-Since this rewrite requires a lot more scanning for code patterns I added an elsa feature to allow pattern matching on AST nodes in C++ (also using exceptions). Since there are lot of patterns to transform, for documentation I will be writing many minimal testcases documenting(and testing) exactly what gets rewritten. Any interested parties are welcome to contribute Mozilla error handling patterns as testcases.  
-  
-**Verifying the Result **  
-  
-Just like in the XPCOMGC rewrite, code will have to be scanned to verify that it fits in the "new world order". Unlike XPCOMGC, there are additional flow-sensitive issues to scan for to ensure that the code is thread-safe. The scans are at a lower level than dehydra currently works at, so it's a perfect opportunity to either extend dehydra or write the new tool.  
-  
-It would be especially cool to implement the code analysis tool as a [gcc plugin](http://taras.glek.net/blog/2007/11/29/gcc-plugins-under-my-xmas-tree/).  Sean Callanan's "Extending GCC with Modular GIMPLE Optimizations" paper in the [GCC summit proceedings](http://ols2006.108.redhat.com/2007/GCC-Reprints/GCC2007-Proceedings.pdf) should be an excellent starting point.  
-  
-This is an exciting experiment. I look forward to reducing speculation on the risks/benefits of switching the codebase to use exceptions with some concrete data.
diff --git a/source/_posts/2007-12-11-switching-to-exceptions-makes-head-spin.markdown b/source/_posts/2007-12-11-switching-to-exceptions-makes-head-spin.markdown
deleted file mode 100644
index e99ea8a..0000000
--- a/source/_posts/2007-12-11-switching-to-exceptions-makes-head-spin.markdown
+++ /dev/null
@@ -1,33 +0,0 @@
----
-comments: true
-date: 2007-12-11 12:10:19
-layout: post
-slug: switching-to-exceptions-makes-head-spin
-title: 'Switching to Exceptions: Makes Head Spin'
-wordpress_id: 47
-categories:
-- mozilla
-- DeCOMtamination
-- thrower
----
-
-**Typical**  
-  
-It seems that there are 3 stages to doing a rewrite in Moz: 
-
-  1. Start a new tool. Make sure that it can rewrite some trivial testcases. Add lots of asserts for cases you are unsure about.
-  2. Run tool on Mozilla and fix crashes caused by above asserts. Get 80% of the code rewriting correctly.
-  3. Get the other 20% rewriting. This often involves major overhauls to rewriting logic due to patterns that weren't expected when the spec was written
-Usually stage 3 is a few times harder than 2. For garburator rewriting got really hard in stage 3. 90% of my time ended up being spent in stage 3 due to fun issues like figuring out what to do with [unforeseen](http://benjamin.smedbergs.us/blog/2007-11-08/perils-in-rewriting/)(in spec) combination of references and nsCOMPtr<>s.  
-  
-**Exceptions**  
-  
-With exceptions step 2 is already getting hard. So far I've had to extend elsa to support pattern matching,  and reworked the code patcher to support recursive rewriting.  
-  
-Now looks like I'll need to do some flow-sensitive analysis to rewrite cases like [nsMemoryImpl::FlushMemory](http://lxr.mozilla.org/seamonkey/source/xpcom/base/nsMemoryImpl.cpp#217). I'm not sure if it is possible to automatically deal with functions like [nsExceptionService::DoGetExceptionFromProvider](http://lxr.mozilla.org/seamonkey/source/xpcom/base/nsExceptionService.cpp#290).  
-  
-Also, I'm not yet rewriting code to be bugfree, just trying to get it to compile. Once exceptioned code compiles, step two will be to statically check code to verify that it is exception-safe and convert it to RAII or something.  
-  
-Here is an [current patch](http://people.mozilla.org/~tglek/xpcom.diff) for xpcom/ produced by thrower. At the moment there are still a lot of pattern matches to be added. It mostly handles rv = foo(); if (NS_FAILED(rv)) and a few other simple [cases](http://hg.mozilla.org/oink/?file/fbbcc3e9056b/thrower_tests/).  
-  
-This is exciting stuff, but really hard, so if anyone has exciting problem solving ideas feel free to ping me.
diff --git a/source/_posts/2007-12-19-exceptions.markdown b/source/_posts/2007-12-19-exceptions.markdown
deleted file mode 100644
index 4ee19ee..0000000
--- a/source/_posts/2007-12-19-exceptions.markdown
+++ /dev/null
@@ -1,42 +0,0 @@
----
-comments: true
-date: 2007-12-19 15:26:30
-layout: post
-slug: exceptions
-title: Exceptions
-wordpress_id: 48
-categories:
-- mozilla
-- garburator
-- outparamdel
-- thrower
----
-
-Often there are two ways to write code. One way is to design an API and have code patterns adhere to how the API is supposed to be used. Another way is to rely on language features to accomplish the same thing. Typically API-pattern approaches are chosen because compilers are too immature or just don't provide the necessary features. Sometimes compilers do catch up and the possibility of utilizing newer language features appears.  
-  
-In the case of the exception rewrite the task is to rewrite code from a pattern-based (compiler in your head) approach to a more strict C++ construct-based exception paradigm. Unfortunately APIs don't enforce their usage as much as a compiler (in part because we don't have [app-spefic compiler plugins](http://taras.glek.net/blog/2007/11/29/gcc-plugins-under-my-xmas-tree/)) so transforming that into a strict compiler-friendly form automatically isn't always realistic ([example](http://lxr.mozilla.org/seamonkey/source/xpcom/glue/nsIInterfaceRequestorUtils.cpp#43)). See my previous post for more examples.  
-  
-Having done more work on the exception conversion I believe that it is possible to switch Mozilla to exceptions to the point of getting it to compile. Unfortunately, I don't think that it's possible to do this in the Mozilla2 timeframe due to the large amount of manual labour required.  
-  
-Due to various use cases that don't fit the exception model there is a need for an nsresult-lint tool to detect funny (see above) nsresult patterns so code can be manually fixed to enable thrower to transform code correctly.  
-  
-I expect conversion to exceptions to consist of the following large steps:  
-  
-XPCOMGC -> nsresult-lint -> thrower automatic conversion -> nsexception-lint -> outparamdel 
-
-  1. XPCOMGC needs to land first to simplify memory management. Otherwise there will be a lot more nsCOMPtr<>s already_AddRefed<>s and friends.
-  2. nsresult-lint would flag code for clean up to assist with the multitude of special cases in the code preventing it from transformation
-  3. thrower needs to do some reasonably sophisticated static analysis (sensitive to control flow) to ensure that code is rewritten correctly. The analysis step isn't ridiculously hard, but it is considerably more complex than what is done in existing tools.
-  4. nsexception-lint tool will flag exception-unsafe code. I expect this to highlight a fair amount of code that needs to be converted to RAII. It will take more manual labour to fix flagged code here than in than step2.
-  5. Once exceptions are used the return value is freed up for outparamdel to utilize. This will be a nice optimization and code clean up.
-I think the best bet with exceptions would be to start working on them during the moz2 development cycle to have them land early in post-moz2.  
-  
-Or as an alternative we could try to do just the OOM exceptions which are less frequent which would look like:  
-  
-XPCOMGC -> thrower automatic conversion(OOM cases are easier) -> nsexception-lint  
-  
-In this case the only significant piece of work is nsexception-lint which would be needed later for a full-blown exception rewrite. It wouldn't be so bad to convert code to RAII even before that is required for the full exception rewrite.  
-  
-For now I'm going let thrower rest in the pork hg repository while I try to make a [static checker plugin](http://wiki.mozilla.org/XPCOMGC/Static_Checker) for gcc. Feel free to ask for clarification. I'm dealing with after-effects of insomnia so this may not be completely clear.  
-  
-**Update**: Reasonable [description of RAII](http://www.hackcraft.net/raii/).
diff --git a/source/_posts/2007-12-28-recent-progress.markdown b/source/_posts/2007-12-28-recent-progress.markdown
deleted file mode 100644
index 388c026..0000000
--- a/source/_posts/2007-12-28-recent-progress.markdown
+++ /dev/null
@@ -1,21 +0,0 @@
----
-comments: true
-date: 2007-12-28 13:39:45
-layout: post
-slug: recent-progress
-title: Recent Progress
-wordpress_id: 49
-categories:
-- mozilla
-- DeCOMtamination
-- dehydra
-- garburator
----
-
-Looks like [pork](http://wiki.mozilla.org/Pork) is slowly going to get merged back into oink. This makes me happy as it will result in decreased merging headaches and gives more visibility to my work outside of Mozilla. My elkhound changes are already in!  
-  
-Recently I added support for retaining gnu attributes to elsa and corresponding features dehydra and garburator. Now dehydra can verify things based on attributes and  garburator gained a way to rewrite special cases like classes that are always [allocated on the stack](https://bugzilla.mozilla.org/show_bug.cgi?id=409088). Elsa still drops most attributes, but at least classes, methods and variable declarations are covered.  
-  
-I also spent a couple of days investigating gcc plugins. Turns out modifying gcc to support plugins is dead easy, but getting anything useful done in GCC requires a steep learning curve. I tried to find how to enumerate all of the toplevel declarations in the source, but I couldn't find the correct global variable that corresponds to the toplevel scope(aka the Translation Unit?). I have a few more ideas of what to try next. Once I do that, it shouldn't take much work to make a basic gcc-hosted version of dehydra. There is also a gcc plugin branch hosted in the gcc svn, but I can't find any example code for it. It isn't a big deal since none of the plugins I've seen mentioned venture outside of intra-function analyses.  
-  
-I am still pondering on how to tackle rewriting Mozilla to use exceptions. It is the key to improving overall readability/perf of Moz C++, but the logistics of writing the corresponding analyses+rewrites followed by a parallel manual correction step are still making my head spin. All I'm sure about is that the first step to exceptions would be to enable the OOM exceptions and do the corresponding exception safe analysis+rewrite.
diff --git a/source/_posts/2008-01-08-dehydra-as-a-gcc-plugin.markdown b/source/_posts/2008-01-08-dehydra-as-a-gcc-plugin.markdown
deleted file mode 100644
index bd43bce..0000000
--- a/source/_posts/2008-01-08-dehydra-as-a-gcc-plugin.markdown
+++ /dev/null
@@ -1,33 +0,0 @@
----
-comments: true
-date: 2008-01-08 12:56:48
-layout: post
-slug: dehydra-as-a-gcc-plugin
-title: Dehydra as a GCC plugin
-wordpress_id: 50
-categories:
-- mozilla
-- dehydra
----
-
-Thanks to the 2-fold increase in manpower working on pork, we finally have an opportunity to work on the nice-to-have things.  
-  
-**Progress**  
-  
-Recently I have been working on a GCC plugin to do Mozilla-specific analyses with GCC.  
-  
-Unfortunately, I didn't notice that GCC had a[ plugin branch ](http://gcc.gnu.org/svn.html)so I reinvented the wheel there. Fortunately that part was rather easy and turned out that the plugin branch isn't very useful to work with as it is in SVN, doesn't link GCC with -rdynamic nor does it install the hooks I need in the C++ frontend. Overall the plugin shim is relatively trivial and it will be pretty easy to merge with other similar efforts.  
-  
-My first and only plugin is a C reimplementation of Dehydra. GCC sources are currently fairly hostile to C++, so I elected to not make my head spin by mixing in C++ in addition to C and JavaScript. I think the C Dehydra has reached the hello world state, to take it for a spin see the [wiki page](http://wiki.mozilla.org/Dehydra_GCC).  
-  
-**GCC Thoughts**  
-  
-Integrating with GCC is pretty awesome. So far I regret not jumping in earlier. I was reluctant to do so as everyone I've talked to (other than [Tom Tromey](http://tromey.com/blog/)) claimed that GCC is ridiculously complicated and impossible to do stuff with. In fact academic people are so scared of GCC that they tend to opt to go with commercial frontends that have ridiculus licensing terms and make it impossible to release their work to general public.  
-  
-GCC internals are pretty crazy since everything is done with macros and the AST is dynamically typed so it's fairly painful to figure out seemingly simple things like "what AST nodes does this AST node contain". Additionally, GCC loves rewriting AST nodes inplace as the compilation progresses which sucks when one wants to analyze the AST while it looks as close as possible to the source. GCC parser also sucks to work with as it is implemented as a C code hodge-podge (technical term which applies to much code in GCC). Luckily, I am mainly concerned with poking at data that's already in GCC.  
-  
-The upside is that GCC is a well-tested production compiler that most source compiles with. Integrating with GCC means that the AST is correct (Elsa is a frontend so there is no way of knowing if AST has mistakes in it) . Integration also means that the user doesn't have to worry about making preprocessed files and maintain obsolete versions of GCC or old GCC headers. Unlike Elsa, GCC already has useful features like typedef tracking and doesn't implement location tracking with a stupid programming trick. Additionally, I hope to reuse computations from from middle-end GCC passes to build my control flow graph, do value numbering and other useful, but tricky to implement stuff.  
-  
-GCC isn't scary at all, it's just another way of implementing a compiler. Some people elect to have more pain in life by electing to [reinvent ML in C++](http://www.cs.berkeley.edu/~smcpeak/cpp/cplusplus.html) instead of using ML for compiler writing,  others get their pain dosage from working on a C compiler originally generated from LISP sources.  
-  
-Lastly, I'd like to thank patient gcc hackers in #gcc without whom I wouldn't stand a chance in figuring out how to get this far.
diff --git a/source/_posts/2008-01-17-gcc-spidermonkey-gcc-dehydra.markdown b/source/_posts/2008-01-17-gcc-spidermonkey-gcc-dehydra.markdown
deleted file mode 100644
index f1e1093..0000000
--- a/source/_posts/2008-01-17-gcc-spidermonkey-gcc-dehydra.markdown
+++ /dev/null
@@ -1,37 +0,0 @@
----
-comments: true
-date: 2008-01-17 16:16:07
-layout: post
-slug: gcc-spidermonkey-gcc-dehydra
-title: GCC + SpiderMonkey = GCC Dehydra
-wordpress_id: 51
-categories:
-- mozilla
-- dehydra
----
-
-**Analysis**  
-  
-[GCC Dehydra](http://wiki.mozilla.org/Dehydra_GCC) is starting to work. I encourage people try it out for their code scanning needs. The main missing feature is control-flow-sensitive traversal, which means that currently function bodies are traversed represented in a sequential fashion. It is the most complicated part of [Dehydra](http://wiki.mozilla.org/DeHydra), but most of the time this feature is not needed.  
-  
-So far I got Benjamin's [stack-nsCOMPtr finding script](http://hg.mozilla.org/users/bsmedberg_mozilla.com/xpcomgc-patches/?file/de1d37e87cf4/find-stack-comptrs.js) to do stuff, which indicates that most of the features are working.  
-  
-My vision is to switch to the GCC backend for all of our code analysis needs since it is well tested, fairly feature complete works with new versions of GCC (by definition).  
-  
-Not everything is perfect in GCC land. There are some frustrating typedef issues to [solve](http://gcc.gnu.org/ml/gcc/2008-01/msg00280.html).  
-  
-**Source Re-factoring**  
-  
-Elsa still holds its own when it comes to refactoring code because it has a much cleaner lexer/parser and rarely opts to "optimize away" original AST structure. We should stick with Elsa's arcane requirement of having to preprocess files with gcc <= 3.4 until either GCC becomes viable as a platform for refactoring or [clang](http://clang.llvm.org/) matures.  
-  
-GCC is not suitable for refactoring work because it: 
-
-  1. Starts simplifying the AST  too early
-  2. The parser is handwritten and therefore would be hard to modify to maintain end-of-AST-node location info.
-  3. GCC reuses many AST nodes which means their locations point at the declaration rather than usage-point.
-  4. Handwritten nature of GCC makes any of these above improvements time-consuming to implement and the political issues are something I'd rather not deal with.
-Most of these wouldn't have been an issue if GCC was written in [ML](http://en.wikipedia.org/wiki/ML_programming_language) :) **What's Next?**  
-  
-Time to start using GCC Dehydra to enforce GC-safety and lots of fun exception-rewrite preparation work.  
-  
-Stay tuned for more exciting developments regarding regaining control over source code here and on [Dave Mandelin's blog](http://blog.mozilla.org/dmandelin/2008/01/15/hello-world/).
diff --git a/source/_posts/2008-01-25-dehydra-progress.markdown b/source/_posts/2008-01-25-dehydra-progress.markdown
deleted file mode 100644
index 5b1591a..0000000
--- a/source/_posts/2008-01-25-dehydra-progress.markdown
+++ /dev/null
@@ -1,35 +0,0 @@
----
-comments: true
-date: 2008-01-25 17:39:30
-layout: post
-slug: dehydra-progress
-title: Dehydra progress
-wordpress_id: 52
-categories:
-- mozilla
-- dehydra
----
-
-[GCC Dehydra](http://wiki.mozilla.org/Dehydra_GCC) is evolving much faster than the Elsa version did and it is easier to use. Once I implemented virtual methods correctly, Joshua was able to [do his thing](http://quetzalcoatal.blogspot.com/2008/01/more-fun-and-games.html) in no time at all. All it takes is a custom GCC (I'd love to see it packaged) and specifying plugin parameters in CXXFLAGS.  
-  
-Dehydra has some new tricks now like a tree representation of types (instead of a string) with full typedef support. Lisp remnants in GCC are getting a new life as JavaScript objects.  
-  
-I'm current working on exposing the full GCC tree structure in JavaScript so one could do any analysis they wanted in pure JS. Dynamically typed GCC tree nodes are great for that. I'm starting with middle-end GIMPLE representation so in theory one will be able to analyze anything gcc can compile (Java, C++, C, ObjC, ObjC++, FORTRAN?). Eventually this will be expanded to support frontend specific tree nodes to be able to look at code closer to the way it was written. Oh and I expect people will be able to script large parts of C++ -> JavaScript rewrites with Dehydra.  
-  
-In theory, one could make tree node conversion two way which would enable writing optimization passes in JS, but that would be silly.  
-  
-**What's the point?**  
-  
-I want to be able to do [Exception-safety analysis](http://wiki.mozilla.org/Exceptions) in pure JS. I want to enable [unit checking ](https://bugzilla.mozilla.org/show_bug.cgi?id=265084)(thought typedefs and inline conversion functions) in pure JS.  
-  
-Additionally, Dehydra should be awesome for generating bindings. For example, I'll be able use Dehydra to import GCC's autogenerated enums to get string names for nodes.  
-  
-Also it will become easy to extract callgraphs and various other stats out of the code if they are accessible in JS. Eventually we'll be switching Dehydra to Tamarin to do all of the above really really fast.  
-  
-**GCC Plugins**  
-  
-While I am messing with the GCC AST, Dave is working on utilizing GCC's [control flow graphs](http://blog.mozilla.org/dmandelin/) with a separate plugin. Eventually we'll merge our work, but for now it's nice to not step on each others toes while adding features to the compiler. Given how easy life is with plugins I am amazed that people chose to go uphill bothways and not collaborate on a plugin interface for their crazy GCC extensions. Yes, I'm looking at you: [mygcc](http://mygcc.free.fr/) and [gccxml](http://www.gccxml.org/HTML/Index.html).  
-  
-Aren't there [IDEs](http://www.eclipse.org/cdt/) interested in making use of GCC internals too or is everybody interested in maintaining [yet another crappy C parser](http://git.kernel.org/?p=devel/sparse/sparse.git;a=blob;f=expression.c;h=289927ac7c88eb5bffbbb450915a7b829394d5a0;hb=a02aeb329d5a8f9047c0b75b7e7f64ee2db3ffcf) like Linux's Sparse tool?  
-  
-I'm looking forward to exploring the many ways we can reuse what's in the compiler to empower developers for Mozilla 2.
diff --git a/source/_posts/2008-02-06-gcc4-elsa-together-at-last.markdown b/source/_posts/2008-02-06-gcc4-elsa-together-at-last.markdown
deleted file mode 100644
index ef70da1..0000000
--- a/source/_posts/2008-02-06-gcc4-elsa-together-at-last.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2008-02-06 13:26:44
-layout: post
-slug: gcc4-elsa-together-at-last
-title: GCC4 + Elsa, Together at Last?
-wordpress_id: 53
-categories:
-- mozilla
----
-
-David Mandelin has been going through [Pork](http://wiki.mozilla.org/Pork) fixing bugs and now it is almost working with GCC4. Prior to Dave's involvement people would run into Elsa's scary template bugs and switch back to GCC3.4 while trembling with fear. I asked Dave to fix a few easily work-aroundable (in Moz, not in Elsa) crashes in Elsa caused by Mozilla source and he did. Recently, I accidentally ran Elsa on a Mozilla .ii file produced by GCC4 and magically it processed! Turns out that the 3-4 bugs that Dave fixed also fixed 90% of the failures caused by GCC4 headers. The good news is that soon people won't have to worry about that pesky GCC3.4 dependancy and run rewriting tools easier.  
-  
-[**GCC Dehydra**](http://wiki.mozilla.org/Dehydra_GCC)  
-  
-I feel like I'm nearing the feature-complete milestone. I plan to have Dehydra generate conversion code from GCC tree structures to JavaScript objects so we'll be able to easily hook into any GCC middle-end pass in pure JS.  Dynamic, GCed, introspective nature of JavaScript should allow for very rapid development of code police/extraction/grep tools. This should result in a consistent codebase for Mozilla 2.
diff --git a/source/_posts/2008-03-03-random-news-in-the-dehydra-corner.markdown b/source/_posts/2008-03-03-random-news-in-the-dehydra-corner.markdown
deleted file mode 100644
index 1d85b10..0000000
--- a/source/_posts/2008-03-03-random-news-in-the-dehydra-corner.markdown
+++ /dev/null
@@ -1,20 +0,0 @@
----
-comments: true
-date: 2008-03-03 18:05:31
-layout: post
-slug: random-news-in-the-dehydra-corner
-title: Random News in the Dehydra Corner
-wordpress_id: 54
-categories:
-- mozilla
----
-
-I have not blogged recently because I have been busy working on a rather fancy new mode for [Dehydra](http://wiki.mozilla.org/Dehydra_GCC). Turned out it is indeed possible to use JavaScript to walk and generate code to automagically convert thousands of recursive C structures into corresponding JS Objects. Now dehydra will have two modes: a simple pattern matcher that is easy to get started with and a hardcore mode for compiler geeks capable of advanced analyses. More on this later, for now subscribe to [static analysis](https://lists.mozilla.org/listinfo/dev-static-analysis) mailing list for more information.  
-  
-Turns out that I'm not the first person to [embed](https://sourceforge.net/forum/forum.php?thread_id=1685933&forum_id=624529) SpiderMonkey into GCC.  
-  
-I have gotten in touch with two different GCC plugin projects. Seems that other projects are more academic in nature and still in the early design/development stages.  
-  
-In constrast, Dehydra efforts are driven by existing unmet needs. In two months we went from having a crazy idea about using GCC for static analysis to having Benjamin [integrate](https://bugzilla.mozilla.org/show_bug.cgi?id=419622) support for Dehydra checks into the moz 2 development repository to be run in a tinderbox.  
-  
-I am also excited to see that people are discovering that Dehydra can be used to explore the codebase. We are not quite at the stage where one can interactively query the codebase from an ajax UI, but we are making [steps](http://blog.mozilla.org/dmandelin/2008/02/14/dtrace-c-mysteries-solved/) in the right direction. As part of this trend, dehydra documentation is starting to migrate to MDC.
diff --git a/source/_posts/2008-03-11-dehydra-as-pesticide.markdown b/source/_posts/2008-03-11-dehydra-as-pesticide.markdown
deleted file mode 100644
index 6aa5511..0000000
--- a/source/_posts/2008-03-11-dehydra-as-pesticide.markdown
+++ /dev/null
@@ -1,22 +0,0 @@
----
-comments: true
-date: 2008-03-11 22:13:23
-layout: post
-slug: dehydra-as-pesticide
-title: Dehydra as Pesticide?
-wordpress_id: 55
-categories:
-- mozilla
----
-
-[Joshua](http://quetzalcoatal.blogspot.com/), pointed me at a [fabulous article](http://www.economist.com/printedition/displaystory.cfm?story_id=10789417) over at the Economist. The brave souls went to great deal of effort to compare, contrast static and dynamic analyses in an easy to understand fashion. My favourite part of the article: 
-
-> Seth Hallem, the co-founder of Coverity, which makes a static-analysis tool, expects greater integration between programming and testing tools in future.
-
-I suspect in the future, there will be awesome tools that even [integrate](http://wiki.mozilla.org/Dehydra_GCC) into one's compiler. Egads!  
-  
-**Treehydra**  
-  
-I spent a few days chasing my own tail looking for bugs in the C->JS conversion code. Turns it out it wasn't bug, but a manifestation of GCC having slightly more AST mutation than I expected*. Bugs in the mental model hurt most :) The upside is that this forced me to switched the conversion process from eager to lazy which also gave a big performance boost. I hope to finally have something capable of doing initial analyses by the end of the week.  
-  
-* In a perfect world compilers are written in functional languages where AST are transformed instead of mutated.
diff --git a/source/_posts/2008-03-12-recipe-how-many-classes-are-instantiated-in-mozilla.markdown b/source/_posts/2008-03-12-recipe-how-many-classes-are-instantiated-in-mozilla.markdown
deleted file mode 100644
index e27460f..0000000
--- a/source/_posts/2008-03-12-recipe-how-many-classes-are-instantiated-in-mozilla.markdown
+++ /dev/null
@@ -1,64 +0,0 @@
----
-comments: true
-date: 2008-03-12 10:59:27
-layout: post
-slug: recipe-how-many-classes-are-instantiated-in-mozilla
-title: 'Recipe: How many classes are instantiated in Mozilla?'
-wordpress_id: 56
-categories:
-- mozilla
-- dehydra
----
-
-I got this question in the mail today.  
-  
-Seems like a simple enough question, but grep won't provide that answer :) It also happens to be an excellent usecase for [Dehydra](http://wiki.mozilla.org/Dehydra_GCC).  
-  
-My script: 
-```
-
-var classes = []
-function process_type (c) {
-if (!/class|struct/(c.kind)) return
-classes.push (c.name)
-}
-```
-
-```
-
-function input_end() {
-var f = this.aux_base_name + ".counter"
-print(f)
-write_file (f, classes.join ("\n"))
-}
-
-```
-process_type is called every time GCC hits a class declaration or a template is instantiated(also for enums and unions, but those get ignored with the .kind check). Then input_end is called when GCC is done processing the file. this.aux_base_name is the input filename.  
-  
-I hooked up this script to the mozilla build by adding the following to .mozconfig: 
-```
-
-export CXX=$HOME/gcc/bin/g++
-export CXXFLAGS="-fplugin=$HOME/work/gccplugin/gcc_dehydra.so -fplugin-arg=$HOME/work/gccplugin/test/count_classes.js"
-
-```
-Then I built: 
-```
-
-make -f client.mk build WARNINGS_AS_ERRORS=
-
-```
-Count: 
-```
-
-find -name \*.counter|xargs cat |sort |uniq > /tmp/classes.txt
-wc /tmp/classes.txt
-
-```
-  
-  
-Answer: 15001  
-  
-There are a million other trivial queries that could be accomplished in a similar manner that weren't easy or possible before.  
-  
-**Update**: Fixed typo, had an extra zero in the answer
diff --git a/source/_posts/2008-03-17-dehydra-world-tour.markdown b/source/_posts/2008-03-17-dehydra-world-tour.markdown
deleted file mode 100644
index 9e0a84f..0000000
--- a/source/_posts/2008-03-17-dehydra-world-tour.markdown
+++ /dev/null
@@ -1,31 +0,0 @@
----
-comments: true
-date: 2008-03-17 13:57:35
-layout: post
-slug: dehydra-world-tour
-title: Dehydra World Tour
-wordpress_id: 57
-categories:
-- mozilla
-- dehydra
----
-
-After a few weeks of mindnumbing work on treehydra gutts, I finally have something exciting to talk about!  
-  
-We will be presenting  [Dehydra](http://wiki.mozilla.org/Dehydra_GCC) at the [GCC Developer's Summit](http://www.gccsummit.org/2008/) in lovely Ottawa. The GCC version of Dehydra exceeded all of my expectations, so it will be exciting to meet awesome GCC hackers who lay the groundwork to make this possible. Got suggestions for other venues to present Dehydra?  
-  
-**Packaging Help Needed**  
-  
-I feel that the Dehydra concept is getting mature enough for a 1.0 release. Recently baked GCC 4.3 means I'll be able to distribute a 4.3-specific [plugin patch](http://hg.mozilla.org/users/tglek_mozilla.com/gcc-moz-plugin-mq/)(currently it's against trunk, aka 4.4to-be). Now I need README, LICENSE, configure files, etc.  
-  
-I will need help with packaging dehydra + patched gcc into .dpkg and .rpm files. Leave a comment, email me/[static analysis list](https://lists.mozilla.org/listinfo/dev-static-analysis) or poke me in #mmgc on irc.mozilla.org if you can help with packaging.  
-  
-**Logo/Mascot Wanted**  
-  
-Since every serious project has a cool mascot, it would be cool to get one for Dehydra. I'd be curious to see what people think could symbolize a code scanning monster that makes grep feel inadequate. I have a feeling a cartoon version of a giant [Heavy Metal Duck](http://photos-b.ak.facebook.com/photos-ak-sf2p/v181/152/124/53600064/n53600064_30549377_7914.jpg) might be it, but I haven't made up my mind yet.  
-  
-**Treehydra What?**  
-  
-Treehydra is a work-in-progress name for the low-level equivalent of Dehydra. Currently it is built as separate GCC plugin. I haven't yet made up mind on whether Treehydra will end up extending Dehydra or stay a separate tool. Since treehydra needs dehydra for bootstrap, they'll stay separate for now.  
-  
-Last week I managed to run treehydra to completition on my mozilla checkout and walk the resulting AST in JS correctly. Now comes the fun part of making it do useful tricks.
diff --git a/source/_posts/2008-04-14-mozillafisl08.markdown b/source/_posts/2008-04-14-mozillafisl08.markdown
deleted file mode 100644
index dab381a..0000000
--- a/source/_posts/2008-04-14-mozillafisl08.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2008-04-14 09:43:34
-layout: post
-slug: mozilla@fisl08
-title: Mozilla@FISL08
-wordpress_id: 58
-categories:
-- mozilla
----
-
-I will be presenting on the work we are doing on Mozilla 2 at [FISL08](http://fisl.softwarelivre.org/9.0/www/). Chris posted an excellent [breakdown](http://www.0xdeadbeef.com/weblog/?p=344) of Mozilla plans for the conference.  
-  
-If you are at all interested in ground-breaking development happening in Mozilla 2, the challenges of static analysis then look me up!  
-  
-This is all very exciting as it'll be a trip of many personal firsts: Brazil, the southern hemisphere and a conference of this scale.
diff --git a/source/_posts/2008-04-22-static-analyses-gadgets-of-mozilla-2-james-bonds.markdown b/source/_posts/2008-04-22-static-analyses-gadgets-of-mozilla-2-james-bonds.markdown
deleted file mode 100644
index 6249dc2..0000000
--- a/source/_posts/2008-04-22-static-analyses-gadgets-of-mozilla-2-james-bonds.markdown
+++ /dev/null
@@ -1,21 +0,0 @@
----
-comments: true
-date: 2008-04-22 12:49:42
-layout: post
-slug: static-analyses-gadgets-of-mozilla-2-james-bonds
-title: 'Static analyses: gadgets of Mozilla 2 James Bonds'
-wordpress_id: 59
-categories:
-- mozilla
----
-
-When started on my static analysis quest just over a year ago. I imagined a perfect world in which I make tools and people use them to do awesome analyses. Since I did not want to be disappointed, I imagined this, but did not think it would come true.  
-  
-Now we are at a point where static analysis use is growing rapidly, most analyses are done by people other than me as lately I barely have time to work on actual analyses. Treehydra and dehydra now have users and are well on their way to being released, which is taking up most of my time. Some of the most notable happenings: 
-
-  * Vlad Sukhoy appeared out of nowhere and [ported Dehydra](https://bugzilla.mozilla.org/show_bug.cgi?id=415289) to GCC 4.2 on OSX. This is exciting because it showed that the plugin system is portable between GCC release, and it's the biggest patch from a non-core dev.
-  * We finished the paper on our static analysis work to be presented at the [GCC summit](https://www.gccsummit.org/2008/summary.php). I am looking forward to meeting developers that built the GCC features that made the *hydras practical.
-  * There is a lot finishing touches being done such that we can release Dehydra 0.9 and eventually 1.0. [Bug](https://bugzilla.mozilla.org/show_bug.cgi?id=423898).
-  * Dave Mandelin implemented a proper testsuite for the *hydras. This is a massive step up from what we had before.
-  * There is a massive amount of Treehydra work going on. Looks like it is boldly going where no static analysis has gone before, even faster than Dehydra did. So far it looks like Treehydra is going to be a bigger deal than Dehydra could ever be. It is turning out to be a very potent combination of GCC for features and JavaScript for ease of use.
-I have elaborate plans on how to take over the world with static analysis, more on that later. In the meantime I've started compiling a [tracking bug](https://bugzilla.mozilla.org/show_bug.cgi?id=430328) of ongoing analyses for Moz 2.
diff --git a/source/_posts/2008-04-29-counting-down-to-a-dehydra-release.markdown b/source/_posts/2008-04-29-counting-down-to-a-dehydra-release.markdown
deleted file mode 100644
index 19d8778..0000000
--- a/source/_posts/2008-04-29-counting-down-to-a-dehydra-release.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2008-04-29 15:34:43
-layout: post
-slug: counting-down-to-a-dehydra-release
-title: Counting down to a Dehydra release
-wordpress_id: 60
-categories:
-- mozilla
-- dehydra
----
-
-I hope to release Dehydra 0.9  within a couple of weeks. There is already a community of users, but there are still too many barriers to entry keeping potential bug hunters away.  
-  
-In recent weeks there has been a lot of work on polishing rough areas. Now we have better error reporting, improved APIs for using libraries, etc. The remaining tasks are tracked in [this bug](https://bugzilla.mozilla.org/show_bug.cgi?id=423898).  
-  
-There few big remaining TODOs are low-tech: 
-
-  * Need a better homepage than the [current one](http://wiki.mozilla.org/Dehydra_GCC).
-  * Docs, tutorials and more docs. Currently, the plan is to puts more documentation on MDC and  have it also serve as a webpage. Any dehydra/treehydra guides or API doc contributions are welcome. For now if you need help, feel free to ask on the [mailing list](https://lists.mozilla.org/listinfo/dev-static-analysis) or #mmgc on irc.mozilla.org
-  * Verify, document and maintain the [OSX port](https://bugzilla.mozilla.org/show_bug.cgi?id=415289). Vlad Sukhoy did a lot of heavy lifting to make this happen, now we need to cement his achievement by setting up a [buildbot](https://bugzilla.mozilla.org/show_bug.cgi?id=430321)
-  * Spread the word! I would like to see other large projects such as KDE, OpenOffice, etc adopt application-specific static analysis in the form of *hydra. I am interested in seeing people use *hydra to scan code for security vunerabilities. Ok, so this isn't really needed to release Dehydra 0.9, but I am impatient!
-**RIP: Oink Dehydra**  
-  
-Between GCC Dehydra and Treehydra, there is nothing that pork Dehydra could do better, so I finally removed Dehydra from [Pork](http://wiki.mozilla.org/Pork). From now on Pork's purpose is large-scale C/C++ refactoring. For everything else one should use [Dehydra](http://wiki.mozilla.org/Dehydra_GCC).
diff --git a/source/_posts/2008-05-16-my-other-job-as-a-rolling-billboard.markdown b/source/_posts/2008-05-16-my-other-job-as-a-rolling-billboard.markdown
deleted file mode 100644
index 55ac058..0000000
--- a/source/_posts/2008-05-16-my-other-job-as-a-rolling-billboard.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2008-05-16 21:53:24
-layout: post
-slug: my-other-job-as-a-rolling-billboard
-title: My other job as a rolling billboard
-wordpress_id: 61
-categories:
-- mozilla
----
-
-I work on static analysis by lamp-light and proudly cycle wearing Firefox imagery by daylight. Today I was pleased to discover that the flyer for the [Portland Century](http://www.portlandcentury.com/) ride now prominently features the Firefox logo in one of the 4 photos. It's also in the scrolling thing on the website =D  
-  
-This picture was taken on one ride with the most firefox fans ever. On parts of the course, it felt like every 5 minutes someone was volunteering info on how awesome firefox is.  
-  
-![](http://myslider.com/v1/1484023162/IMG%5f4723%2ejpg)
diff --git a/source/_posts/2008-05-27-treehydra-goes-push-and-pop.markdown b/source/_posts/2008-05-27-treehydra-goes-push-and-pop.markdown
deleted file mode 100644
index 71d9b86..0000000
--- a/source/_posts/2008-05-27-treehydra-goes-push-and-pop.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2008-05-27 13:48:03
-layout: post
-slug: treehydra-goes-push-and-pop
-title: Treehydra goes Push and Pop
-wordpress_id: 62
-categories:
-- mozilla
-- dehydra
-- treehydra
----
-
-After writing a ton of [docs](http://developer.mozilla.org/en/docs/Dehydra_Manual) and working through other [Dehydra](http://developer.mozilla.org/en/docs/Dehydra) [0.9 blockers](https://bugzilla.mozilla.org/show_bug.cgi?id=423898), I decided to cool off by doing some actual analyses. Before I get to that, I'd like to say that the last big task is to setup a buildbot for Dehydra on Linux/OSX. Thanks to yet another awesome contribution from Vlad, that's [mostly done](https://bugzilla.mozilla.org/show_bug.cgi?id=430321).  
-  
-So I got working on [GC-safety static analysis](https://bugzilla.mozilla.org/show_bug.cgi?id=421934). Originally we tried to define a complete spec before writing a single line of code. That turned to be a bad idea and resulted in a spec full of bugs. [This time](https://bugzilla.mozilla.org/show_bug.cgi?id=432915) we are defining the analysis incrementally and as a surprise reward, it already caught [a bug](https://bugzilla.mozilla.org/show_bug.cgi?id=435546).  
-  
-**Pushing and Popping Our Way**  
-  
-SpiderMonkey has a lot of complex code doing applying Push/Pop-like operations on variables in a function-local manner. Examples of functions that this analysis would look at are: JS_PUSH_TEMP_ROOT/JS_POP_TEMP_ROOT and JS_LOCK/JS_UNLOCK. See [bug](https://bugzilla.mozilla.org/show_bug.cgi?id=432915) for more. Essentially, this will help with "code must flow through here" comments on "out:" goto labels that inhabit the SpiderMonkey source.  
-  
-This is an example of control-flow-sensitive analysis. It impossible without a compiler-like view of the code that [Treehydra](http://developer.mozilla.org/en/docs/Treehydra) provides. It also helps to have a scalable algorithm to iterate the CFG. Luckily, David Mandelin wrote such a beast by implementing [ESP](http://www.cs.cornell.edu/courses/cs711/2005fa/papers/dls-pldi02.pdf) for his [outparam analysis](https://bugzilla.mozilla.org/show_bug.cgi?id=420933). David factored-out the ESP analysis and made it available for reuse. See esp_lock.js in the [test suite](http://hg.mozilla.org/users/tglek_mozilla.com/dehydra-gcc/index.cgi/file/8f6914b2aaf9/test/) for an example of how to write control-flow sensitive analyses. locks_valid*.cc and locks_bad*.cc illustrate the code patterns that can be scanned for.  
-  
-So if you know of any further push/pop patterns in the rest of Moz that can be checked in this manner, leave a comment.  
-  
-PS. This is yet another account of Treehydra rocking the static analysis world. Exposing the slightly scary, but awesome GCC gutts via JavaScript allows one to perform precise static analyses in a civilized manner. What could be more fun?
diff --git a/source/_posts/2008-06-09-dehydra-09-its-alive.markdown b/source/_posts/2008-06-09-dehydra-09-its-alive.markdown
deleted file mode 100644
index a581765..0000000
--- a/source/_posts/2008-06-09-dehydra-09-its-alive.markdown
+++ /dev/null
@@ -1,20 +0,0 @@
----
-comments: true
-date: 2008-06-09 11:14:05
-layout: post
-slug: dehydra-09-its-alive
-title: 'Dehydra 0.9: It''s alive!'
-wordpress_id: 64
-categories:
-- mozilla
-- dehydra
-- treehydra
----
-
-I am finally happy enough with Dehydra API and functionality to release 0.9. [Dehydra](http://developer.mozilla.org/en/docs/Dehydra) is basically feature complete, the main reason I'm not calling it 1.0 is in case there are outstanding API bugs.  
-  
-I believe Dehydra is the first useful open source static analysis tool. I hope to see projects outside of Mozilla benefitting from it too.  
-  
-I would love to see someone package this up for various Linux distributions. You can grab there release [here](http://ftp.mozilla.org/pub/mozilla.org/dehydra/dehydra-0.9.tar.gz).  
-  
-Note, this release also features as a preview release of [Treehydra](http://developer.mozilla.org/en/docs/Treehydra). Most of the development lately has been focused on improving Treehydra and building analyses on top of it.
diff --git a/source/_posts/2008-06-19-gcc-summit.markdown b/source/_posts/2008-06-19-gcc-summit.markdown
deleted file mode 100644
index a5ecd50..0000000
--- a/source/_posts/2008-06-19-gcc-summit.markdown
+++ /dev/null
@@ -1,18 +0,0 @@
----
-comments: true
-date: 2008-06-19 06:01:08
-layout: post
-slug: gcc-summit
-title: GCC Summit
-wordpress_id: 66
-categories:
-- mozilla
-- dehydra
-- treehydra
----
-
-Our presentation on [Treehydra](http://developer.mozilla.org/en/docs/Treehydra) and [Dehydra](http://developer.mozilla.org/en/docs/Dehydra) GCC plugins was received well at the summit.  
-  
-The big news is that FSF is working on license changes to allow GPL-only GCC plugins. I'm looking forward to having our work be compatible with future GCC without any patching.  
-  
-In a few minutes we'll be having a meeting with users of other plugin frameworks to have an initial discussion on a common API. I'm working on forward porting my patches, so they can start getting reviewed ahead of license changes.
diff --git a/source/_posts/2008-06-24-status-report-nearterm-plans-for-pork-dehydra.markdown b/source/_posts/2008-06-24-status-report-nearterm-plans-for-pork-dehydra.markdown
deleted file mode 100644
index 9fee91f..0000000
--- a/source/_posts/2008-06-24-status-report-nearterm-plans-for-pork-dehydra.markdown
+++ /dev/null
@@ -1,38 +0,0 @@
----
-comments: true
-date: 2008-06-24 13:36:19
-layout: post
-slug: status-report-nearterm-plans-for-pork-dehydra
-title: 'Status Report: Nearterm plans for Pork, Dehydra'
-wordpress_id: 67
-categories:
-- mozilla
-- dehydra
-- treehydra
----
-
-[**Pork**](http://developer.mozilla.org/en/docs/Pork)  
-  
-I planned to release Pork 1.0 for a while now. The tools work great, even if all the love is going to the GCC-based toolchain. However, after hearing grumpy comments from a certain coworker about the uglyness of the oink build system it dawned on me that it's rather mean to release such a mess and call it 1.0.  
-  
-So I think I'll release Pork 0.9 in the current state, so I can focus on near term GCC toolchain work. Pork in the current form means [oink stack](http://danielwilkerson.com/oink/) + my refactoring tools + changes to elsa and other libs to support C/C++ refactoring needs.  
-  
-This will be followed up by Pork 1.0. 1.0 will involve changes to the build system to get rid of oink(we only use the oink build system and rarely use oink API). To put this another way: I don't expect any functionality changes between 0.9 and 1.0 other than an improved build system to make it easier to get started with writing new tools.  
-  
-**Pork - Future**  
-  
-I am pretty happy with Pork as it is. I think we've taken Elsa as far as it'll let us go. The only realistic improvement on the Pork side may be to have Dehydra generate a JS binding to Elsa's extensive AST to make rewriting stuff easier. However, I'm not sure if that's worth the effort nor that a C++ AST will reflect into JavaScript as well as GCC GIMPLE.  
-  
-_Preprocessing_  
-  
-On the other hand, something needs to be done about the main ingradient that makes Pork tick: MCPP. MCPP does a lovely job of annotating what the C preprocessor is doing, but configuring GCC to use a foreign preprocessor is a giant hassle and making sure it works correctly is troublesome. At the GCC summit, [Tom](http://tromey.com/blog/) gave me an idea on how similar functionality can be added to GCC directly by extending the include backtrace with macro expansions. Not only would such integration simplify Pork setup and increase Pork's operating speed, but it is also a clean way to expose preprocessor constructs to the AST presented in De/Treehydra. It should allow for more preprocessor awareness directly in analysis stage of refactoring instead of only in the final rewriting stage as is currently done. As a side-effect, GCC would gain better error messages too.  
-  
-So while this isn't going to affect Pork directly, it will simplify the lives of Pork users while opening new analysis frontiers. Even though I hate working on preprocessor stuff, I think this work will need to happen sometime in the near future.  
-  
-[The Hydras](Dehydra)  
-  
-Dehydra 0.9 has been out for a while, I planned to release 1.0 soon after unless there are major flaws discovered in the API. The situation changed at the GCC summit. The fact that FSF reversed their stance on GCC plugins means that we should be concentrating on getting the plugin stuff reviewed.  
-  
-So in the near term I'm forward porting the plugin stuff to trunk GCC, then I'll be generalize the plugin API to suit at least one other GCC plugin user that we met with at the summit. The downside is that I don't want to release Dehydra 1.0 and immediately break the plugin API. The upside is that the new API should be more general and more minimalistic and will likely be close to what will eventually become an official plugin API.  
-  
-_Summary_: In my mind Dehydra and Pork are 1.0 quality, but I want to future-proof them a little bit before calling them 1.0.
diff --git a/source/_posts/2008-06-30-pork-09-in-the-wild.markdown b/source/_posts/2008-06-30-pork-09-in-the-wild.markdown
deleted file mode 100644
index 781a7fa..0000000
--- a/source/_posts/2008-06-30-pork-09-in-the-wild.markdown
+++ /dev/null
@@ -1,13 +0,0 @@
----
-comments: true
-date: 2008-06-30 13:08:26
-layout: post
-slug: pork-09-in-the-wild
-title: Pork 0.9 in the wild
-wordpress_id: 68
-categories:
-- mozilla
-- pork
----
-
-Those who would like to play with Pork, but are allergic to pulling sources from version control can now download an actual [pork release](http://ftp.mozilla.org/pub/mozilla.org/static-analysis/pork/pork-0.9.tar.gz). Now someone needs to hook this into a GUI to provide easy Eclipse-style refactoring for C++.
diff --git a/source/_posts/2008-07-08-where-is-the-sanity-in-the-c-std-library.markdown b/source/_posts/2008-07-08-where-is-the-sanity-in-the-c-std-library.markdown
deleted file mode 100644
index c38160b..0000000
--- a/source/_posts/2008-07-08-where-is-the-sanity-in-the-c-std-library.markdown
+++ /dev/null
@@ -1,34 +0,0 @@
----
-comments: true
-date: 2008-07-08 10:52:42
-layout: post
-slug: where-is-the-sanity-in-the-c-std-library
-title: Where is the sanity in the C++ std library?
-wordpress_id: 69
-categories:
-- mozilla
----
-
-Dear lazyweb,  
-  
-Please explain to me why the following code works the way it does. From looking at the following code and stringstream::str(), stringstream::str(string) docs the behavior of the following code does not make sense to me. 
-```
-
-#include <sstream>
-#include <iostream>
-```
-  
-  
-using namespace std;  
-  
-int main(int argc, char**) { stringstream ss("foo"); cout << ss.str() << endl; ss << "bar"; cout << ss.str() << endl; ss << "more"; cout << ss.str() << endl; }  
-  
-Why is doing << after str(string) causing this stringstream to loose the initialization string? What possible API usecase would justify such behavior?  
-  
-For the curious, output is:  
-  
-foo bar barmore  
-  
-It seems that the only sensible way to use stringstream is to do ss.str("") unless you want to have your initial data reset for no reason. In that case why add a weird method overload instead of a .reset() method.  
-  
-**Update:** Note that stringstream ss("foo") is equivalent to stringstream ss; ss.str("foo");
diff --git a/source/_posts/2008-07-09-static-analysis-and-refactoring-tooling-updates.markdown b/source/_posts/2008-07-09-static-analysis-and-refactoring-tooling-updates.markdown
deleted file mode 100644
index bc3edbd..0000000
--- a/source/_posts/2008-07-09-static-analysis-and-refactoring-tooling-updates.markdown
+++ /dev/null
@@ -1,34 +0,0 @@
----
-comments: true
-date: 2008-07-09 14:59:00
-layout: post
-slug: static-analysis-and-refactoring-tooling-updates
-title: Static Analysis and Refactoring Tooling Updates
-wordpress_id: 70
-categories:
-- mozilla
----
-
-**Hydras**  
-  
-I am close to landing a [flow](https://bugzilla.mozilla.org/show_bug.cgi?id=432917) check. Turns out, it is super-easy to introduce new analyses into Mozilla due to a very nice build system hooks setup by bsmedberg.  
-  
-Since coming back from the GCC summit I have forward-ported our GCC patches to GCC trunk. The FSF legal paperwork came through today so I posted the first and biggest patch to the GCC for [review](http://gcc.gnu.org/ml/gcc-patches/2008-07/msg00741.html).  
-  
-I am not sure if I mentioned this before, but the C port of [Dehydra](http://developer.mozilla.org/en/docs/Dehydra) is somewhat operational. It doesn't yet have access to function bodies, but type traversal should work. Unfortunately, the C frontend has less features(pretty printing sucks, locations are even less reliable, etc) and thus is less awesome to work with than the C++ frontend.  
-  
-[**Pork**](http://wiki.mozilla.org/Pork)  
-  
-jst was awesome enough to list some interfaces that need some outparamdelling. The list is [here](http://wiki.mozilla.org/Gecko:DeCOMtamination) (in the content/ section). This lead me to spent some time making outparamdel's output prettier. There are still some improvements to be made, and I will be making them in the near future. However if someone is interested in refactoring of this kind land in the near future, they could easily complete outparamdel's work with some clever scripting and a bit of manual labour. Sure beats doing the entire thing manually. From outparamdel's perspective last 10% appear to be slightly painful and might take some time.  
-  
-Here is a [patch](http://people.mozilla.org/~tglek/nsinodeinfomanager_getnodeinfo.diff) that takes about 30seconds to produce.  
-  
-Another exciting aspect of this is that a certain emacs wizard has confirmed that it would be possible to feed emacs such a patch file and have it correct indentation for the affected areas only.  
-  
-I am also very excited that a certain volunteer came forward and decided to start improving some of the stomach-turning areas of Pork. Hopefully in the near future we'll modernize the C++ a little bit and a user's first reaction wont be: "What the hell, why can't I do 'using namespace std;'".  
-  
-To this end I have filed a bug to write a [renamer tool](https://bugzilla.mozilla.org/show_bug.cgi?id=441870) so we can dogfood renaming of unfortunately named pieces of code.  
-  
-**OSCON**  
-  
-The plan is to have some sort of a minisession on our static analysis efforts at Mozilla. So if you are attending OSCON and are interested in doing exciting things to depressingly large amounts of code, drop me a line.
diff --git a/source/_posts/2008-07-18-pork-mcpp-oink-and-elsawhats-going-on.markdown b/source/_posts/2008-07-18-pork-mcpp-oink-and-elsawhats-going-on.markdown
deleted file mode 100644
index 051e4e2..0000000
--- a/source/_posts/2008-07-18-pork-mcpp-oink-and-elsawhats-going-on.markdown
+++ /dev/null
@@ -1,67 +0,0 @@
----
-comments: true
-date: 2008-07-18 10:29:28
-layout: post
-slug: pork-mcpp-oink-and-elsawhats-going-on
-title: Pork, MCPP, Oink and Elsa...What's going on?
-wordpress_id: 71
-categories:
-- mozilla
-- pork
----
-
-It seems that there is some confusion as to what pork is and how it's related to oink and elsa. So here is my view of it.  
-  
-[**Pork**](http://developer.mozilla.org/en/docs/Pork) is my set of tools that use Elsa to rewrite sourcecode (mainly Mozilla code). Our use of Pork is solely for rewriting as it is not suited for [convenient](http://developer.mozilla.org/en/docs/Dehydra) and [hardcore](http://developer.mozilla.org/en/docs/Treehydra) analysis needs as much as the GCC based tools are.  
-  
-[MCPP](http://mcpp.sf.net/) is the secret sauce C preprocessor that makes C++ rewriting with Elsa possible by annotating preprocessed files with information to undo the lexical braindamage resulting from macro expansion.  
-  
-**Elsa** is a awesome C++ parser. Awesome in that is can preserve more information regarding parsed code than any other C/C++ parser and it is easy to extend.  
-  
-We maintain our own version of Elsa within pork.  
-  
-I think our version of Elsa is the most up to date and most compatible with newer C++ features and headers used by newer GCC releases. We encourage other projects with C++ parsing/rewriting needs to collaborate with us. We will be parsing code with Elsa for a few years to come and it's a lot of work to maintain a C++ parser by a single entity. I think elsa is a much better backend to build refactoring support onto than any other C++ parsing project out there right now.  
-  
-**The Messy Details**  
-  
-Now lets move on the more confusing parts: oink, oink-stack, and the oink mailing list.  
-  
-[**oink**](http://www.cubewano.org/oink) consists of some static analysis tools and was meant to be a central place where all of the Elsa and Elsa-related development was supposed to happen. When people refer to oink, they usually mean the oink-stack which is a subversion meta repository that pulls in a dozen of subrepositoes(smbase, elkhound, elsa, oink(where static analysis tools live), etc).  
-  
-So when I started working on refactoring tools I was told that I should aim to have my tools added to oink, but there were some legal hassles to work out in the meantime so I cloned the oink-stack and developed my tools with minimal changes to oink-stack. This included various elsa extensions, bugfixes, etc.  
-  
-However, the little momentum that oink had has fizzled out due to various personality conflicts and various academics loosing interest. The code has been bitrotting for as long as I've been working at Mozilla.  
-  
-So the end result of oink is that we have pork which is a superset of oink. I'm not even sure if I mention the name pork anywhere in the sources. So pork at the moment means "Taras' continuation and extension of oink". I am using the [oink mailing list](http://www.cubewano.org/lists/listinfo/oink-devel) for any discussion on changes to Elsa/etc in hopes that at least some of the genius lurkers there will regain their interest in elsa.  
-  
-**Where do We Go From Here?**  
-  
-Onward! Due to the original authors vision of what C++ is and the state of C++ at the time Elsa was conceived, current pork code causes people to have many WTF moments (followed by banging head against keyboard) when they first start using it.  
-  
-The short version of my plan is: 
-
-  * allow one to do "using namespace std" when using elsa
-  * Restructure pork repositories such that there are only 3 of them rather than 11 (elsa, elkhound, pork)
-  * get rid of the oink repository (those tools do not work for us)
-  * Make pork only consist of just my tools (with a sane build system) rather than be mixed into unmainted oink stuff
-  * Make pork compile with new compilers (GCC 4.3 and recent MSVC++)
-  * Keep track of this in a [bug](https://bugzilla.mozilla.org/show_bug.cgi?id=438061)
-  * Clean up various misc things
-Some of you might ask "But Taras, why now, why not just keep doing what you've been doing?". I was doing what I was doing because I had an overwhelming goal of devising a way to automate static analysis and refactoring of Mozilla on my shoulders and I wasn't convinced that it was feasible. I had to learn to split my time between tool development and actually using the tools. Naturally I cut corners on tool development :)  
-  
-Since then slowly, but surely various awesome hackers have started doing rewrites and analyses themselves freeing me up to focus more on development. To make matters sweeter, various hackers have started submitting bugreports, fixes, ports to my tools. This gives me more time to focus on the big picture.  
-  
-Finally, I belive that automation of the sort we are doing at Mozilla is something that has been missing from open source development practices and it will catch on once people realize what they've been missing. Reducing those WTF moments will help people think positively.  
-  
-  
-  
-**Update:**  
-  
-_Why three repositories instead of one?_
-
-  1. The three will be elkhound, elsa, pork
-  2. elkhound is useful on it's own
-  3. elsa is too and other elsa users are likely to not care about Mozilla's rewriting tools
-_I__s oink really dead?_  
-  
-Yes. The maintainers have moved on to other projects. When they were maintaining oink, outside contributors couldn't get their code upstream.
diff --git a/source/_posts/2008-07-22-dogfooding-pork-oscon.markdown b/source/_posts/2008-07-22-dogfooding-pork-oscon.markdown
deleted file mode 100644
index 50893e9..0000000
--- a/source/_posts/2008-07-22-dogfooding-pork-oscon.markdown
+++ /dev/null
@@ -1,18 +0,0 @@
----
-comments: true
-date: 2008-07-22 10:26:19
-layout: post
-slug: dogfooding-pork-oscon
-title: Dogfooding pork & OSCON
-wordpress_id: 72
-categories:
-- mozilla
----
-
-I wrote a class renamer and used it to [fix](https://bugzilla.mozilla.org/show_bug.cgi?id=445897) my pork pet-pieve #1: a class named string that isn't std::string. This has been a low priority goal for as long as I've been using Elsa. It's pretty cool to apply a tool to fix itself.  
-  
-The renamer is a 3x simpler than the next simplest tool. I plan to extend it to also rename class members. Renaming is the most trivial use-case for rewriting code, I plan to post a tutorial on using  the renamer in the near future.  
-  
-**OSCON**  
-  
-If you are at OSCON, you do not want to miss our [static analysis session](http://en.oreilly.com/oscon2008/public/schedule/detail/4383) on Wednesday.
diff --git a/source/_posts/2008-07-25-pull-pork-with-care.markdown b/source/_posts/2008-07-25-pull-pork-with-care.markdown
deleted file mode 100644
index 6f96fab..0000000
--- a/source/_posts/2008-07-25-pull-pork-with-care.markdown
+++ /dev/null
@@ -1,24 +0,0 @@
----
-comments: true
-date: 2008-07-25 14:01:04
-layout: post
-slug: pull-pork-with-care
-title: 'Pull pork with care
-
-  '
-wordpress_id: 74
-categories:
-- mozilla
----
-
-I just committed the large giant change to bring down elsa's namespace pollution to reasonable levels. Elsa code now is now using std::foo style, or using namespace std. As I mentioned before, Elsa's string is now sm::string, a summary of how to perform similar renames is [here](http://developer.mozilla.org/en/docs/Renaming_With_Pork). The good news is that Pork will soon work out of the box with a modern toolchain.  
-  
-For the handful of porkers out there, you need to hg pull & hg up all of the pork repositories. This has been a use-case in why splitting up a codebase into a billion repositories is a bad idea:  
-  
-a) Lovely, I have to do many commits instead of one  
-  
-b) To top it off, now my users will curse my name while updating whatever pork repository that interests them most.  
-  
-I feel like I'm going to throw up if I see any more C++ code diffs in the next 10minutes.  
-  
-In contrast, while rewriting things on the Mozilla-scale is a lot less feasible manually, it is very rewarding to automate. Gotta love big C++ codebases.
diff --git a/source/_posts/2008-08-04-summit.markdown b/source/_posts/2008-08-04-summit.markdown
deleted file mode 100644
index 30e7adc..0000000
--- a/source/_posts/2008-08-04-summit.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2008-08-04 18:40:28
-layout: post
-slug: summit
-title: Summit
-wordpress_id: 75
-categories:
-- mozilla
----
-
-The past week rocked. I was especially impressed with the localizers. The guys who bear through translating an entire browser with associated websites to expose their country to an awesome browsing experience are simply electrifying.  
-  
-It was great to see the South American guys again and to meet hordes of Europeans.  
-  
-The most exciting outcome of the summit in my neck of the static analysis woods is that DXR (a semantically aware successor to MXR) will be rewritten from scratch in Python. Another reason to rejoice is that a tracing spidermonkey should make Treehydra ridiculously fast without much (or any) effort on my part.
diff --git a/source/_posts/2008-08-11-oink-testsuite-within-pork-passes.markdown b/source/_posts/2008-08-11-oink-testsuite-within-pork-passes.markdown
deleted file mode 100644
index a4d7a5c..0000000
--- a/source/_posts/2008-08-11-oink-testsuite-within-pork-passes.markdown
+++ /dev/null
@@ -1,20 +0,0 @@
----
-comments: true
-date: 2008-08-11 14:49:28
-layout: post
-slug: oink-testsuite-within-pork-passes
-title: Oink testsuite within pork passes
-wordpress_id: 76
-categories:
-- mozilla
----
-
-I have never enjoyed the theory behind software engineering. It seems particularly depressing as it can be summarized as: "What can we learn from past software development experience in order to not repeat old mistakes such that we can come up with newer and shinier mistakes?".  
-  
-For that reason I haven't been able to stick to any particular software development doctrine (paired, test-driven, OO, SOA, etc) and instead taken shortcuts to whatever is practical at the time.  
-  
-One unfortunate result of such neglect is that the oink test suite ended up not being utilized. I tried it a couple of times while starting out with oink and it failed in many cumbersome ways. However, as pork evolved out of oink, I learned more about the "architecture" behind it, I fixed a couple of the issues that were causing funny make errors.  
-  
-However one giant bug remained. Turned out other people were able to run the original oink testsuite, but not the equivalent one in pork. Fearing that I somehow screwed up Elsa, I spent way too long investigating the failure only to learn it wasn't my [fault](https://bugzilla.mozilla.org/show_bug.cgi?id=444805). Pork users: rejoice, the testsuite should run as expected now.  
-  
-PS. I may not be a SENG believer, but I do think that open source + good version control + testsuites result in better software.
diff --git a/source/_posts/2008-08-13-this-week-in-the-static-analysis-corner.markdown b/source/_posts/2008-08-13-this-week-in-the-static-analysis-corner.markdown
deleted file mode 100644
index 1e400aa..0000000
--- a/source/_posts/2008-08-13-this-week-in-the-static-analysis-corner.markdown
+++ /dev/null
@@ -1,40 +0,0 @@
----
-comments: true
-date: 2008-08-13 15:55:50
-layout: post
-slug: this-week-in-the-static-analysis-corner
-title: This week in the Static Analysis Corner
-wordpress_id: 77
-categories:
-- mozilla
----
-
-**New Static Analysis Toys**  
-  
-I have been catching up on my backlog of little bugs, here are some of the most notable ones.  
-  
-Benjamin has been pushing the limits of what Dehydra can do for his DXR prototype which resulted in a couple of cool new features with one [new feature](https://bugzilla.mozilla.org/show_bug.cgi?id=449075) breaking backwards compatibility. Sorry about that, it is for the greater good.  
-  
-Dehydra now processes [more declarations](https://bugzilla.mozilla.org/show_bug.cgi?id=449428).  
-  
-Dehydra uses JavaScript prototypes to [distinguish](https://bugzilla.mozilla.org/show_bug.cgi?id=447679) between types and declarations.  
-  
-Treehydra is now built by [default](https://bugzilla.mozilla.org/show_bug.cgi?id=437524) when building with a plugin-enabled compiler.  
-  
-Treehydra now exposes the C++ frontend's verbose and as-close-as-gcc-gets-to-written-code syntax tree via [process_cp_pre_genericize](https://bugzilla.mozilla.org/attachment.cgi?id=332230). Access to the early C++ AST should make it easier to automatically translate a certain class of C++ functions into JavaScript.  
-  
-Coming soon: buildbot setup for Dehydra along with autobuilt debian packages.  
-  
-Also, Benjamin's GSoC student, Bo Yang, has been doing some awesome work making our static analysis toolchain work on mingw. In my mind, Bo sealed his awesomeness in not only getting Mozilla to build under mingw yet again, but also by fixing a couple of exciting compiler bugs on Win32.  
-  
-**Path to 1.0**  
-  
-For more information on these and other developments see the Dehydra 1.0 [tracking bug](https://bugzilla.mozilla.org/show_bug.cgi?id=437502).  
-  
-I am not yet sure what the next release of Dehydra will be. My giant GTY patch to GCC is still awaiting review in a GCC developer's inbox. Depending on whether that gets accepted I'll continue releasing Dehydra 0.9.x with the current GCC patchset or delay a 1.0 release to work on getting the GCC plugin API reviewed and more or less finalized.  
-  
-**Plans for Near Future**  
-  
-I think I figured out the missing pieces needed to make outparamdel's deCOMtamination patches acceptable, will work on that next. I'll be continuing to clean up pork to be more developer-friendly. After the recent unhappyness involving bisection 10separate repositories at once, I've decided to merge pork into one giant repository and if someone just wants a couple smaller of pieces, those should be proken up at the package management level.  
-  
-Additionally, I would like to start landing the SpiderMonkey analyses soon.
diff --git a/source/_posts/2008-08-14-meanwhile-in-a-parallel-universe.markdown b/source/_posts/2008-08-14-meanwhile-in-a-parallel-universe.markdown
deleted file mode 100644
index 146ec5b..0000000
--- a/source/_posts/2008-08-14-meanwhile-in-a-parallel-universe.markdown
+++ /dev/null
@@ -1,17 +0,0 @@
----
-comments: true
-date: 2008-08-14 08:48:04
-layout: post
-slug: meanwhile-in-a-parallel-universe
-title: Meanwhile in a parallel universe
-wordpress_id: 78
-categories:
-- mozilla
-- pork
----
-
-Someone else is developing their own app-specific rewrite tools. In this case app-specific refers to [automating porting code](http://people.imendio.com/richard/gtk-rewriter/) from gtk2 to gtk3. The approach is similar in that patches are produced, but it doesn't look like a patch aggregating tool is written yet. Instead of the elsa/mcpp magic sauce, [clang](http://clang.llvm.org/) is being used, so this is limited to C at the moment.  
-  
-KDE folks are behind in automated code rewrites arms race, perhaps the trolls should try some [pork](http://developer.mozilla.org/en/docs/Pork) to accelerate KDE3->4 transition :)  
-  
-All kidding aside, it is awesome to see that less-manual-labour-through-compiler-assisted-refactoring approach is gaining mindshare.
diff --git a/source/_posts/2008-09-02-converging-elsa-strains.markdown b/source/_posts/2008-09-02-converging-elsa-strains.markdown
deleted file mode 100644
index dad4e7c..0000000
--- a/source/_posts/2008-09-02-converging-elsa-strains.markdown
+++ /dev/null
@@ -1,23 +0,0 @@
----
-comments: true
-date: 2008-09-02 08:39:45
-layout: post
-slug: converging-elsa-strains
-title: Converging Elsa Strains
-wordpress_id: 79
-categories:
-- mozilla
-- pork
----
-
-One of the purposes of this blog is to inform people that while the original [Elsa author](http://www.cs.berkeley.edu/~smcpeak/elkhound/) is no longer actively developing it, Elsa is being used in production at Mozilla and is actively maintained within [Pork](http://developer.mozilla.org/en/docs/Pork).  
-  
-Recently two previously unknown to me Elsa forks have come to my attention via comments on my blog. Both of these are extrimely cool and something we have been wanting: 
-
-  * [ellcc](http://ellcc.org/) C (and soon C++) compiler via Elsa + LLVM. I've heard of attempts to get this to work before, but this looks like it is much further along than similar efforts.
-  * Alex Telia's souped up elsa with parser error recovery and an integrated C preprocessor among other awesomeness. See [this comment](http://taras.glek.net/blog/2008/06/30/pork-09-in-the-wild/#comment-18303) for more details. Some of [these tools](http://www.win.tue.nl/~lvoinea/VCN.html) are built on this Elsa fork.
-Both of these projects are interested in converging on a single codebase. It sounds like Alex's work will be ready for merging soon.  
-  
-I love open source.  
-  
-**I'm Back** ![](http://photos-e.ak.facebook.com/photos-ak-sf2p/v323/152/124/53600064/s53600064_30661500_3965.jpg) Some might've noticed that I disappeared off the net for two weeks. I have a good excuse: I was getting married.
diff --git a/source/_posts/2008-09-03-error-presentation.markdown b/source/_posts/2008-09-03-error-presentation.markdown
deleted file mode 100644
index f43b4ac..0000000
--- a/source/_posts/2008-09-03-error-presentation.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2008-09-03 14:09:53
-layout: post
-slug: error-presentation
-title: Error Presentation
-wordpress_id: 81
-categories:
-- mozilla
----
-
-Certain other cool open source projects are doing cool static analysis work. In this case, [here](http://yoyodyne.ath.cx/ccc-analyze/buildkernel/2008-08-16-1/) is an analysis of one of my favourite operating systems projects, [DragonFly BSD](http://www.dragonflybsd.org/).  
-  
-I'm blown away by the clean UI. The error filter and the interleaving of static analysis results in the source code are drool-inducing. This is powered by the [clang checker](http://clang.llvm.org/StaticAnalysis.html). Clang's checker doesn't yet do C++, doesn't do application-specific checks and has a lot of false positives, but it's an exciting preview of things to come.  
-  
-Oh and I hope that DXR will have similar analysis awesomeness. In the future, I hope to see static analysis become almost as common as unit-testing.
diff --git a/source/_posts/2008-09-08-must_flow_throughlabel.markdown b/source/_posts/2008-09-08-must_flow_throughlabel.markdown
deleted file mode 100644
index 906b24d..0000000
--- a/source/_posts/2008-09-08-must_flow_throughlabel.markdown
+++ /dev/null
@@ -1,15 +0,0 @@
----
-comments: true
-date: 2008-09-08 10:54:57
-layout: post
-slug: must_flow_throughlabel
-title: MUST_FLOW_THROUGH("label")
-wordpress_id: 83
-categories:
-- mozilla
-- dehydra
----
-
-Some time ago, Igor mentioned that there is code in SpiderMonkey that pleads to the programmer that from a certain point in a function code must flow through a label(ie a finalizer block). [Treehydra](http://developer.mozilla.org/en/docs/Treehydra) made it to possible to turn that weak plea into an error message when static [checking is enabled](http://developer.mozilla.org/En/Building_with_static_checking). See the [bug](https://bugzilla.mozilla.org/show_bug.cgi?id=432917) for more details. My favourite static analyses are all about turning informal "gurantees" into angry compiler complaints.  
-  
-This is my first static analysis that landed in the mozilla-central tree. It's also the simplest one and may be a decent starting point for solving similar problems. I'd be cool to see this particular feature utilized outside of SpiderMonkey. Unlike human-powered code-inspection, it excels at finding accidental early returns covered up by macros.
diff --git a/source/_posts/2008-09-19-outparamdelling-this-way-comes.markdown b/source/_posts/2008-09-19-outparamdelling-this-way-comes.markdown
deleted file mode 100644
index 46d9715..0000000
--- a/source/_posts/2008-09-19-outparamdelling-this-way-comes.markdown
+++ /dev/null
@@ -1,45 +0,0 @@
----
-comments: true
-date: 2008-09-19 14:06:08
-layout: post
-slug: outparamdelling-this-way-comes
-title: Outparamdelling this way comes
-wordpress_id: 86
-categories:
-- mozilla
-- DeCOMtamination
-- outparamdel
-- prbool
----
-
-Recently I dusted off outparamdel to see if I can get some refactorings landed. About a year ago, with the great QueryInterface outparamdelling experiment we ended up with a smaller binary footprint and tiny performance gain, but that never landed due to us not wanting to break compatability yet. Ever since, outparamdel has been patiently bitrotting within [Pork](http://developer.mozilla.org/en/docs/Pork) waiting for the day it's allowed to break APIs.  
-  
-Recently jst [listed](http://wiki.mozilla.org/Gecko:DeCOMtamination) some private API candidates for deCOMtamination and I have been letting outparamdel loose on them for the past week. So far only one such [change](http://hg.mozilla.org/mozilla-central/raw-rev/ec4733eb1bd8) has been committed, the rest are sitting in jst's review queue. It's exciting, as it's the first ever application of outparamdel that didn't get canned. For the whole list see the most recent bugs blocking my [analysis metabug](https://bugzilla.mozilla.org/show_bug.cgi?id=430328).  
-  
-Cool part about these patches is that after various outparamdel special-casing and manual cleanup the line count is reduced by 10-30% while maintaining existing functionality!  
-  
-So far I haven't touched much outside of content/, so if you know of any APIs that could have the outparam rotated into the return value, file some rewriting bugs against me.  
-  
-**Rewriting with Mercurial**  
-  
-Mercurial is now my favourite python program ever. It makes rewrites so easy. Here is my typical workflow:  
-  
-
-```
-
-# Write an outparamdel input file specifying functions to rewrite..run outparamdel with pork-barrel to generate patch
-hg qimport -f autopatch.diff && hg qpush && hg qref #make the patch nice and readable
-hg qnew manual.diff #create a manual cleanup patch for cosmetic touchups and rewrites screwed up by macros#of course to submit patch for review, those two patches need to be combined
-#do manual stuff
-hg diff -r 19277 #produce a combined diff without loosing ability to edit each applied patch individually! For example, can regenerate the autopatch.diff with different outparamdel parameters or a bugfixed outparamdel. 19277 is a revision that has to be looked up with hg log, unfortunately there isn't a relative syntax to do hg diff -r "tip - 2"
-
-```
-This is a huge improvement over the ad-hoc workflow prior to hg switch when I was prototyping my tools. CVS + quilt don't hold a candle to a modern revision control system.  
-  
-**Prcheck**  
-  
-I also have been doing another round of [prbool corrections](https://bugzilla.mozilla.org/show_bug.cgi?id=266048). Somehow I didn't notice that the system stopped working due to the CVS->hg switch. Once again when reviving my nightly checker scripts, it was a pleasure to substitute all of the CVS hacks with mercurial commands.  
-  
-I am waiting for the few remaining largeish (ie 3-4 bugs per file) patches to land before I can start submitting whackamole bugs with a single prbool correction per module.  
-  
-It also seems that cairo and every other pre-C99 project have the same set of issues as Mozilla with their typedefed-int boolean types. Perhaps prcheck isn't mozilla-specific at all.
diff --git a/source/_posts/2008-09-26-living-dead-code.markdown b/source/_posts/2008-09-26-living-dead-code.markdown
deleted file mode 100644
index f1cd8d3..0000000
--- a/source/_posts/2008-09-26-living-dead-code.markdown
+++ /dev/null
@@ -1,44 +0,0 @@
----
-comments: true
-date: 2008-09-26 10:58:37
-layout: post
-slug: living-dead-code
-title: Living Dead Code
-wordpress_id: 89
-categories:
-- mozilla
----
-
-The coolest part about my job is that I get to work on tasks that are cool, but typically are forever laid to rest in the would-be-cool-if-we-could-but-we-don't-have-time-or-resources category. However as project code sizes increases, the usefulness/coolness ratio of static analysis grows and moves from would-be-cool, to nice-to-have to this-is-the-only-way. Now, I'm not sure where Mozilla lies on this scale, but I do know for sure that the giant codebase is an analysis treasure trove.  
-  
-**Dead Code Motivation **  
-  
-I have been talking about dead code detection in Mozilla for ages. As software changes, some pieces of code unintentially get left behind, but often there is no way to tell. It results in unnessary maintanance burden and increased footprint. In [roc](http://weblogs.mozillazine.org/roc/)'s case randomly spotting dead methods may also involve a little IRC griping at me about not having any tools for it, even rudimentary ones. Between that and [blizzard's cheering](http://www.0xdeadbeef.com/weblog/?p=766) over reduced code size, I had no choice, but to give it a try once I had enough outparamdelling being reviewed.  
-  
-**Dead Code Results**  
-  
-First of, the approach described below seems to work well: [see bug](https://bugzilla.mozilla.org/show_bug.cgi?id=457262) with initial results. Now I get a few thousand reported methods to inspect and refine the results.  
-  
-**Dead Code Approach**  
-  
-I've been pondering dead code detection since I've started working on this stuff. There are lots of ways to do it, but I finally settled on the dead-simplest one: method-level granularity. [Ingredients](http://hg.mozilla.org/users/tglek_mozilla.com/deadlive/) are: 
-
-  * Dehydra/Treehydra extraction JavaScript: Dehydra makes it easy to enumerate methods and class hierarchies. Treehydra makes it possible to extract every mention of a method from the code(except for [pointers to virtual functions that were casted](http://mxr.mozilla.org/mozilla-central/source/content/events/src/nsEventListenerManager.cpp#206)...in that case we are left with vtable index and a type that the pointer was cast to). Additionally, Treehydra counts the number of AST nodes visited in every function body.
-  * Shell script to aggregate the result of processing Mozilla source. Gotta admit, perl's hashtables give GNU sort -u a run for its money.
-  * Ocaml program to do the super-dumb algorithm. Classes with the same names, are assumed to be the same class. Method overloads are assumed to be a single method. All methods are assumed to be virtual. Every ClassType::FUNCTION_CALL call walks down to all children & up through all the parents and marks the derived methods as called. Then all derivatives of scriptable XPIDL are filtered out and the uncalled methods are printed out. In order to find most exciting functions first, methods in the results are sorted by their AST count =D. **Language Nerd Trivia:** Why OCaml - because ADTs are no fun in other languages. Why is my OCaml so bad - because I lost the hang out if due to not writing anything it for the past 2 years.
-I'm sure most people reading this will go: "Wait a minute, this is unsound if you don't see the virtual function pointers?", to which I reply: "Once I nuke the method and mozilla compiles successfully, it's sound". In reality someone could make a puny GCC patch to preserve more data in virtual function pointer assignments.  
-  
-Since this is all in early stages there a bunch of things I don't deal with: method overloads, constructors, destructors and overloaded operators....and templates. All function bodies are scanned, but some function names are a pain to deal with or they aren't straightforward function calls in GCC so they don't participate in the dead/alive contest.  
-  
-**Where To Go From Here**  
-  
-Well, once we run out of dead code detected by the primitive caveman approach above, we'll have to investigate less conservative approaches possibly involving abstract interpretation and callgraphs.  
-  
-**How To Get Involved in Screwing With Software Cost Models By Contributing Negative Line Counts **  
-  
-This project has a lot of places to help out: 
-
-  * work through the dead method list, filing bugs accordingly and deleting any related code
-  * Extend the machinery to work on all non-static function
-  * Try this on your favourite large codebase.
-  * Write the virtual function pointer annotation patch :)
diff --git a/source/_posts/2008-10-07-note-this-is-not-called-yet-its-just-a-placeholder-for-future-changes.markdown b/source/_posts/2008-10-07-note-this-is-not-called-yet-its-just-a-placeholder-for-future-changes.markdown
deleted file mode 100644
index e8c5907..0000000
--- a/source/_posts/2008-10-07-note-this-is-not-called-yet-its-just-a-placeholder-for-future-changes.markdown
+++ /dev/null
@@ -1,18 +0,0 @@
----
-comments: true
-date: 2008-10-07 15:53:44
-layout: post
-slug: note-this-is-not-called-yet-its-just-a-placeholder-for-future-changes
-title: '"NOTE: This is not called YET. It''s just a placeholder for future changes."'
-wordpress_id: 91
-categories:
-- mozilla
----
-
-In my quest to rid Firefox of code that doesn't do anything it is possible to screw up and delete a method that is only used by outside code. So far, I've hit a [component](https://bugzilla.mozilla.org/show_bug.cgi?id=457302) that isn't used in Firefox, [methods](https://bugzilla.mozilla.org/show_bug.cgi?id=457965) that aren't used in Firefox and methods that [claim](https://bugzilla.mozilla.org/show_bug.cgi?id=458983) someone is about to use them (with a timestamp from 8 years ago). That and I discovered some code only appears to be used from BeOS or OS/2 specific ifdefs.  
-  
-Not surprisingly, I had someone comment that I do some "dangerous shit". Sure, I can see why someone would think that.  
-  
-My protection: I use the try server to make sure that everything builds on supported platforms. On top of that every patch gets reviewed.  
-  
-Furthermore, I would like to point out that methods that aren't called within Firefox are less likely to be tested and correct. So if one leaves code that should only be called from other projects, it'd be appropriate if we had some unit tests for it, which would flag the code as in-use. That would let us move to the next level and setup a tinderbox to detect dead code as soon as it is orphaned.
diff --git a/source/_posts/2008-10-09-cool-stuff-in-foreign-realms.markdown b/source/_posts/2008-10-09-cool-stuff-in-foreign-realms.markdown
deleted file mode 100644
index f3c981d..0000000
--- a/source/_posts/2008-10-09-cool-stuff-in-foreign-realms.markdown
+++ /dev/null
@@ -1,24 +0,0 @@
----
-comments: true
-date: 2008-10-09 09:18:29
-layout: post
-slug: cool-stuff-in-foreign-realms
-title: Cool Stuff in Foreign Realms
-wordpress_id: 93
-categories:
-- mozilla
----
-
-Open Source projects are often like parallel worlds. People reach the same conclusions, attempt similar solutions and are typically blissfully unaware of each other's existance.  
-  
-Here are two projects that came to my attention this week: 
-
-  * Via Planet KDE I stumbled on [Krazy](http://www.englishbreakfastnetwork.org/krazy/). It's neat if not somewhat depressing that even if C++ parsers are finally becoming accessible all this is still Perl.
-  * Helpful comment on my previous entry pointed me to [dead method hunting](http://blogs.linux.ie/caolan/) in OpenOffice.
-**Uncool Open Source Rant**  
-  
-Reason I switched to linux was because it seemed like a developer's dream come true. Compilers are a package manager operation away (and generally aren't tied to OS versions, I'm looking at you Apple), everything can be recompiled to address any particular concerns and there are crapload of weird languages to write your software in. This is especially awesome when compared to a typical proprietory software stack where one can't easily fix problems that involve multiple components due to licensing issues or due to not having the code available(or due to not having the development environment available). So one would think that Linux distributions hold the ultimate software power: unlimited pass to modify their offering to their target audience's content.  
-  
-Unfortunately my view of Linux ways is unrealistic. For example when people do [friggin' awesome work](http://lwn.net/Articles/299483/) knocking down boot time to 5 seconds by hacking and slashing their way through the entire software stack involved in boottime delays, distributions claim that it's not somethin they can seriously consider because they are too set in their ways of general purpose(and generally bloated) init systems and stock kernels(worst case: why can't we recompile the kernel on the user's machine or ship a couple of custom variations for common hardware out there). What's the point of open source if we continue pretending that everything is a general purpose black box that doesn't like to play together? It's been two weeks and I haven't seen a single distro bite the bullet and attempt to list 5 second boot in their goals. Come on guys, don't you like to be challenged?  
-  
-Hope someone proves me wrong.
diff --git a/source/_posts/2008-11-07-enabling-prcheck-email-notifications.markdown b/source/_posts/2008-11-07-enabling-prcheck-email-notifications.markdown
deleted file mode 100644
index b78cadb..0000000
--- a/source/_posts/2008-11-07-enabling-prcheck-email-notifications.markdown
+++ /dev/null
@@ -1,15 +0,0 @@
----
-comments: true
-date: 2008-11-07 15:58:08
-layout: post
-slug: enabling-prcheck-email-notifications
-title: Enabling prcheck email notifications
-wordpress_id: 96
-categories:
-- mozilla
-- prbool
----
-
-I've been running my prbool checker with nightly notifications for about a year now. There are some false positivies, but mostly it picks up real bugs. The checker pulls the blame source to try to guess who is responsible for the error, but so far it has only been emailing me.  
-  
-I'm going to make it emailed the hg blamed person starting this weekend, so if you commit something and get an email from me complaining about it don't take it too personally. Hopefully this will keep the amount of new detectable prbool bugs at 0. If you do get an email and decide you don't want to get these in the future, please complain and we'll try to come up with a better notification solution.
diff --git a/source/_posts/2008-12-23-fennec-a2-performance.markdown b/source/_posts/2008-12-23-fennec-a2-performance.markdown
deleted file mode 100644
index df4a4b0..0000000
--- a/source/_posts/2008-12-23-fennec-a2-performance.markdown
+++ /dev/null
@@ -1,42 +0,0 @@
----
-comments: true
-date: 2008-12-23 11:23:12
-layout: post
-slug: fennec-a2-performance
-title: Fennec A2 - Performance
-wordpress_id: 99
-categories:
-- mozilla
----
-
-**Static Analysis vs Performance**  
-  
-Two months ago I got the feeling that I gotta take a break from static analysis and do something that obviously affects Firefox at runtime. Luckily that coincided with ramp-up on Fennec performance work.  
-  
-I find that I enjoy fixing existing code a lot more than other sorts of programming, so I was extremely happy to switch focus from the static analysis way of fixing code to my other favourite: optimization. Both are peculiar programming endeavours because after a bunch of gruntwork the program ends up doing the exact same thing as before, but better.  
-  
-In static analysis I focus more on how different pieces fit together, whereas in an optimization I get to focus on what various pieces are trying to achieve so I learned a lot more random Mozilla mysteries.  
-  
-**Fennec**  
-  
-Fennec is pure joy to optimize because it runs in such a constrained Linux environment (compared to desktop Linux). Things seem to happen roughly 10x slower on the arm processor than on my core2duo laptop. Thus performance details that are hard to spot on the desktop almost trivial to discover.  
-  
-There is no hard drive seeks to introduce unpleasant surprise latency. This simplifies things a lot - there is a lot less variance between hot and cold start on [n810](http://en.wikipedia.org/wiki/Nokia_N810) than on hard drived desktop.  
-  
-Unfortunately the N810 linux environment also leaves a lot to be desired. Compiling stuff is a chore. It turns out the oprofile produces nonsense results when a compiler of [recent](https://wiki.mozilla.org/Mobile/Build/cs2007q3) vintage is used (ancient one cant really compile Mozilla).  
-  
-I had a lot of fun digging deep into Mozilla code and dealing with [mischievous](https://bugzilla.mozilla.org/show_bug.cgi?id=465128) timestamps, [misbehaving](https://bugzilla.mozilla.org/show_bug.cgi?id=465556) caches and [rude](https://bugzilla.mozilla.org/show_bug.cgi?id=466877) GC interruptions. All this was done using [stone-age](https://bugzilla.mozilla.org/show_bug.cgi?id=470116) instrumentation techniques on N810.  
-  
-Mark Finkle blogged some [details](http://starkravingfinkle.org/blog/2008/12/fennec-alpha2-performance/) on Fennec Alpha2 performance. Alpha2 is magnitudes faster than Alpha1, I expect more of the same in subsequent releases.  
-  
-**Software Improvements That  Santa Claus Should Get Me **  
-  
-Even though [oprofile](http://oprofile.sourceforge.net/news/) is useless on N810, one can get a pretty good idea of what the performance issues are from running it on x86. OProfile is a little rough to use, but I've learned to love it when sugared with [gprof2dot](http://code.google.com/p/jrfonseca/wiki/Gprof2Dot) and [xdot](http://code.google.com/p/jrfonseca/wiki/XDot). It's great for locating places in the code to stick printf()s into.  
-  
-OProfile has taught me that what I really want is Dtrace (or some knockoff) running on n810.  
-  
-Also, I really hate how embedded Linux takes away one of coolest things about Desktop Linux: ability to compile own kernel. I haven't been able to get a more modern kernel to run on N810 which means I can't try a newer version of oprofile or the new omap high res timers. I would also like to get a working image of N810 under qemu, but success has avoided me there too.  
-  
-**Static Stuff**  
-  
-Unfortunately I found that can't effectively work on static analysis stuff without giving it my full and undivided attention. Right now I'm hoping to set aside time to focus on writing a more general dead code finder and catch up on other misc things sometime in Janurary or February.
diff --git a/source/_posts/2009-01-13-seven-things-you-may-not-know-about-me.markdown b/source/_posts/2009-01-13-seven-things-you-may-not-know-about-me.markdown
deleted file mode 100644
index ab0ca16..0000000
--- a/source/_posts/2009-01-13-seven-things-you-may-not-know-about-me.markdown
+++ /dev/null
@@ -1,39 +0,0 @@
----
-comments: true
-date: 2009-01-13 19:17:49
-layout: post
-slug: seven-things-you-may-not-know-about-me
-title: Seven Things You May Not Know About Me
-wordpress_id: 101
-categories:
-- mozilla
----
-
-I got tagged by [Benjamin](http://benjamin.smedbergs.us/blog/2009-01-12/seven-things-you-may-not-know-about-me/), so I better comply and get my blog memed. 
-
-#### Rules
-
-  1. Link back to your original tagger and list the rules in your post.
-  2. Share seven facts about yourself.
-  3. Tag some (seven?) people by leaving names and links to their blogs.
-  4. Let them know they’ve been tagged.
-**Seven Things**
-
-  1. In Soviet Ukraine, kindergarten failed me (luckily they don't make you retake that). Apparently when I was six, my handwriting and reading skills were not up to the communist standards of time. I still fondly remember excepts of various communist hymns we got to sing along.
-  2. Grade 1 coincided with the fall of communism and me getting the most kickass grades of my academic career.
-  3. I have owned two cars, but I have since traded that lifestyle for a garage full of bikes. I never liked the effects that driving had on my health nor the effect that crappy German engineering had on my savings.
-  4. I met my wife on my first [midnight mystery ride](http://www.momentumplanet.com/features/moonlight-midnight-mystery-ride). Riding at midnight is awesome because that's the only time that traffic dies down enough that one sees nothing but fellow bikers and drunk pedestrians.
-  5. To buy groceries I ride a comical contraption called an adult tricycle. We even worked the trike into our wedding.
-  6. ![](http://photos-e.ak.fbcdn.net/photos-ak-snc1/v1925/118/14/122504458/n122504458_33849548_3260.jpg)  
-  
-I never had a real job. For some reason all of the Burger Kings and Subways that I applied at never took an interest in me. Instead, in grade 8 my first source of income was teaching Java to someone 2.5x my age for $3 an hour. From then on I bounced around various part-time jobs and internships until I ended up at Mozilla, my first real job.
-  7. For a something like six years I wore long hair to go along with my taste for Metal. I'm always looking for more awesome metal music, currently in heavy rotation are Testament, Winds of Plague, Dying Fetus and Opeth. If you think there is an awesome metal band I might be missing out on, let me know.
-**Tags**  
-  
-[Damon Sicore](http://mozilla.damon.sicore.org/) - There are seven random things I need to know about my boss.  
-  
-[Joshua Cranmer](http://quetzalcoatal.blogspot.com/) - lets hear seven things about you without mentioning dem0rkification.  
-  
-[Chris Double](http://www.bluishcoder.co.nz/) - I hope to hear seven reasons for one to program in Reverse Polish Notation  
-  
-[Graydon Hoare](http://blog.mozilla.org/graydon/) -  because his blog hasn't been memed. It's also getting a bit dated
diff --git a/source/_posts/2009-01-27-gcc-plugins-are-a-go.markdown b/source/_posts/2009-01-27-gcc-plugins-are-a-go.markdown
deleted file mode 100644
index 20189ea..0000000
--- a/source/_posts/2009-01-27-gcc-plugins-are-a-go.markdown
+++ /dev/null
@@ -1,19 +0,0 @@
----
-comments: true
-date: 2009-01-27 16:38:35
-layout: post
-slug: gcc-plugins-are-a-go
-title: GCC Plugins are a Go!
-wordpress_id: 106
-categories:
-- mozilla
-- dehydra
----
-
-The nice folks at FSF [allowed](http://gcc.gnu.org/ml/gcc-announce/2009/msg00000.html) GCC have plugins. In a couple of GCC releases, Dehydra(4.5 if we are lucky) will work with distribution GCCs. Of course the API is yet to be decided on, but we have been coordinating with authors of other GCC plugin efforts to ensure that the final API meets reasonable needs.  
-  
-In the future enabling static analysis checks will involve little more than specifying --with-static-checking in your Mozilla build!  
-  
-**JSHydra**  
-  
-The other breakthrough news is that Joshua Cranmer has been working on hooking up a *hydra style API to the Spidermonkey parser. This resulted in [JSHydra](http://quetzalcoatal.blogspot.com/2009/01/jshydra.html). Ability to look into JavaScript has been sorely missing from our stack, so this is extremely exciting.
diff --git a/source/_posts/2009-01-29-semantic-rewriting-of-code-with-pork-a-bitter-recap.markdown b/source/_posts/2009-01-29-semantic-rewriting-of-code-with-pork-a-bitter-recap.markdown
deleted file mode 100644
index d8007e1..0000000
--- a/source/_posts/2009-01-29-semantic-rewriting-of-code-with-pork-a-bitter-recap.markdown
+++ /dev/null
@@ -1,32 +0,0 @@
----
-comments: true
-date: 2009-01-29 00:17:47
-layout: post
-slug: semantic-rewriting-of-code-with-pork-a-bitter-recap
-title: Semantic Rewriting of Code with Pork - A bitter recap
-wordpress_id: 108
-categories:
-- mozilla
-- outparamdel
-- pork
-- prbool
----
-
-LWN [published](http://lwn.net/Articles/315686/) an article about a tool that does refactoring of C code. Guess what, it's yet another tool on top of a crappy C-parser that will never grok C well or even hope to support C++. To my great disappointment the author was not aware of my work on Pork. Clearly I have failed in letting people know that complex C and C++ can be refactored with (somewhat raw, but powerful) open source tools.  
-  
-In addition to [Dehydra](https://developer.mozilla.org/En/Dehydra) (which is even mentioned in the first comment, yay!), I also maintain [Pork](https://developer.mozilla.org/En/Pork) - a fork of oink that is well suited to large-scale refactoring of real-world C/C++ code.  
-  
-So far pork has been used for "minor" things like renaming classes&functions, rotating [outparameters](http://taras.glek.net/blog/2007/08/06/outparams-take-2/) and correcting [prbool](http://taras.glek.net/blog/2007/06/26/status-report-recent-work/) bugs. Additionally, Pork proved itself in an [experiment](http://taras.glek.net/blog/2007/11/02/garburator-works/#comments) which involved rewriting almost every function(ie generating a 3+MB patch) in Mozilla to use garbage collection instead of reference-counting.  
-  
-So to summarize: 
-
-  * Refactoring C is hard, but C++ is much harder
-  * For refactoring C++ there is no better toolchain to start with than Pork
-  * Pork shares no code with Dehydra.
-  * Pork is built on the Elsa parser which makes it well-suited for rewriting large amounts of code. Dehydra's isn't suitable for rewriting code due to GCC providing a very lossy AST and incomplete location information.
-  * Pork is not as convenient for analysis needs as Dehydra
-For any questions regarding Pork feel free to post on the [mailing list](https://lists.mozilla.org/listinfo/dev-static-analysis) or ping me on IRC.  
-  
-**Language Wars**  
-  
-I find it depressing that the comments to the LWN article ended up being about language wars rather than the refactoring topic. Pork is written in C++ which is much more widely known than OCaml. However, I seriously doubt it's easier for anyone to hack on advanced compiler frontend pieces in a language as ill-suited for the task as C++.
diff --git a/source/_posts/2009-02-16-security-with-dehydra.markdown b/source/_posts/2009-02-16-security-with-dehydra.markdown
deleted file mode 100644
index 5e4cddb..0000000
--- a/source/_posts/2009-02-16-security-with-dehydra.markdown
+++ /dev/null
@@ -1,14 +0,0 @@
----
-comments: true
-date: 2009-02-16 16:36:38
-layout: post
-slug: security-with-dehydra
-title: Security with Dehydra
-wordpress_id: 110
-categories:
-- mozilla
----
-
-When I wrote the initial prototype of Dehydra I pondered how long it would take before it's adopted by security guys. Unfortunately, until now take-up has been non-existent. Grep and Perl still seem to rule in that community even though the plain text approach restricts the range of possible security scans.  
-  
-Normally I would be tempted to rant on how grep is convenient yet limiting. However Ben Kurtz [discovered Dehydra for security scans](http://www.awgh.org/?p=73) and did a great job explaining the issues involved. Thanks to Georgi for linking me to Ben's post.
diff --git a/source/_posts/2009-02-19-quickfix-model-of-develoment.markdown b/source/_posts/2009-02-19-quickfix-model-of-develoment.markdown
deleted file mode 100644
index 552bec2..0000000
--- a/source/_posts/2009-02-19-quickfix-model-of-develoment.markdown
+++ /dev/null
@@ -1,19 +0,0 @@
----
-comments: true
-date: 2009-02-19 11:20:51
-layout: post
-slug: quickfix-model-of-develoment
-title: Quickfix Model of Develoment
-wordpress_id: 112
-categories:
-- mozilla
----
-
-I love new programming toys and this week is a good one for those. Ever since I laid the foundations for Dehydra I've been dreaming of a world where I can quickly lookup a piece of code(say something that someone complains about on IRC), fix it, get it reviewed and pushed in the most efficient manner possible. Seems that the pieces are finally falling into place. 
-
-  1. I want quick semantically aware code lookup via [DXR](http://zenit.senecac.on.ca/wiki/dxr/). And guess what, there is [progress](http://www.visophyte.org/blog/2009/02/19/dxrpy-with-references-against-mailnews-plus-bespin-wishes/) in that direction.
-  2. I want to DXR to provide a link to edit the code. [Bespin](http://bespin.mozilla.com/) looks like the most promising candidate for editing. As an aside, using canvas to do text editing is badass. I salute devs who are crazy enough to prove their point by reimplementing something (hopefully better) from scratch using an approach that hasn't been tried before.
-  3. I want my changes to be saved as a diff into bugzilla. I want that to be two way so I can edit existing patches and save them as new bugzilla attachments.
-  4. From there I'd like a commit feature in bugzilla so the patch would go through try-then-push cycle that Jesse [described](http://www.squarefree.com/).
-  5. Having all this inplace would make it trivial to integrate random features such as crash stack trace navigation or [Pork](https://developer.mozilla.org/En/Pork) automagic refactoring.
-Now I'm sure that most of us would still run Emacs and other desktop editors for longer development tasks. But just imagine being bored with a computer at a webcafe, boring friend, etc and having the ability to quickly jump into in the development process as easily as logging into webmail.
diff --git a/source/_posts/2009-03-18-fennec-beta-1-need-for-speed.markdown b/source/_posts/2009-03-18-fennec-beta-1-need-for-speed.markdown
deleted file mode 100644
index b0d6fd3..0000000
--- a/source/_posts/2009-03-18-fennec-beta-1-need-for-speed.markdown
+++ /dev/null
@@ -1,23 +0,0 @@
----
-comments: true
-date: 2009-03-18 06:52:42
-layout: post
-slug: fennec-beta-1-need-for-speed
-title: Fennec Beta 1 - Need for Speed
-wordpress_id: 115
-categories:
-- mozilla
----
-
-A couple of months ago Stuart casually asked me to investigate Fennec performance for moving about a page, zooming and loading pages in general. Beta 1 contains the result of that:
-
-  * There is little to no hardware graphics acceleration on mobile arm device. That combined with low memory bandwidth results in painfully slow screen updates (10x slower than crappy gfx on the desktop?). The painting engine now works hard to skip redundant draws of the page.
-  * During loading pages or zooming Fennec now only draws the minimum required. In my testing complicated pages load 2-5 times faster. Zooming is now 5 times faster.
-  * There is less DOM querying now. Things like checking an element's size can cause pages to reflow resulting in a less responsive UI
-
-Other performance highlights:
-
-  * Fennec now features a redesigned firstrun page which not only looks better, but also contributed to a 0.5second startup speedup. Overall Beta 1 should startup is almost a second quicker than the previous release
-  * The JavaScript JIT is now on by default providing a noticeable performance boost throughout Fennec.
-
-For more info on Fennec Beta 1 and where to get it see [Stuart's blog](http://blog.pavlov.net/2009/03/17/fennec-1-beta-1/).
diff --git a/source/_posts/2009-03-31-nsresult-analysis.markdown b/source/_posts/2009-03-31-nsresult-analysis.markdown
deleted file mode 100644
index bfa9d65..0000000
--- a/source/_posts/2009-03-31-nsresult-analysis.markdown
+++ /dev/null
@@ -1,24 +0,0 @@
----
-comments: true
-date: 2009-03-31 14:16:18
-layout: post
-slug: nsresult-analysis
-title: nsresult analysis
-wordpress_id: 119
-categories:
-- mozilla
----
-
-After I wrote [prcheck](http://taras.glek.net/blog/2008/11/07/enabling-prcheck-email-notifications/), I was surprised by the errors it found. I expected to find lots of cases of prbool variables having integers assigned into them. Indeed there were some of those, but the most frequent offenders were things like 
-```
-
-NS_ENSURE_SUCCESS(rv,rv);
-
-```
-in methods with a PRBool return value. In this case (and many similar  return values within macros) the function will likely do the opposite of what was intended if there is an error condition. Here is a less hypothetical [example](https://bugzilla.mozilla.org/show_bug.cgi?id=483589) in bugzilla.  
-  
-So I'm thinking that instead of porting the prbool analysis to [Treehydra](https://developer.mozilla.org/en/Treehydra) (such that it'd based on a less buggy [backend](https://developer.mozilla.org/En/Pork) and can be integrated into the build) it might be more interesting to ensure that nsresults do not mix with other integer types. That would catch all of the worst prbool offenders and possibly other nsresult misfortunes.  
-  
-_Has anyone run into bugs like this that do not involve prbools?_  
-  
-I suppose a general solution would be to define a lattice of typedefs with rules specifying which typedefs can be assigned to each other. This would make GCC distinguish certain typedefs as discrete and incompatible types. Thoughts?
diff --git a/source/_posts/2009-04-15-misc-static-analysis-news-smmgcstatic-codecon-piglet.markdown b/source/_posts/2009-04-15-misc-static-analysis-news-smmgcstatic-codecon-piglet.markdown
deleted file mode 100644
index 81db6ea..0000000
--- a/source/_posts/2009-04-15-misc-static-analysis-news-smmgcstatic-codecon-piglet.markdown
+++ /dev/null
@@ -1,22 +0,0 @@
----
-comments: true
-date: 2009-04-15 13:37:23
-layout: post
-slug: misc-static-analysis-news-smmgcstatic-codecon-piglet
-title: 'Misc Static Analysis News: s/#mmgc/#static/, Codecon, piglet, ...'
-wordpress_id: 124
-categories:
-- mozilla
----
-
-#static on irc.mozilla.org is now the correct irc channel for anything to do with static analysis.  
-  
-**Codecon** On Sunday, I will be presenting on [Pork](https://developer.mozilla.org/En/Pork) at codecon. I have been meaning to attend [codecon](http://www.codecon.org/) since the days when P2P was considered cool, was not able to make it until this year. It is a historical milestone for me. Codecon was how people at Mozilla first heard of Elsa, which is now the foundation of all our refactoring tools (it is also inherited baggage I get to maintain).  
-  
-**Piglet**  
-  
-I adopted [Piglet](http://hg.mozilla.org/users/tglek_mozilla.com/piglet), [Dave Mandelin](http://blog.mozilla.org/dmandelin/)'s de-oinkification project, and imported it into hg. It feels really good to finally be able to do a make -j without disturbing people nearby with surprise explosions of foul language. I plan to move all relevant static analysis tools into piglet. After that I shall finally merge a dozen or so elsa repositories and end up with Pork consisting of elsa/ + piglet/.  
-  
-**Pork***  
-  
-Chris Jones is quietly working on making Pork magnitudes more useful to average developers. It's exciting stuff and I'll let him announce it when he's ready. Between his work and [David Humphrey](http://vocamus.net/dave/)'s DXR. I think we are finally going to make it easier to hack on Mozilla for a much wider audience than before.
diff --git a/source/_posts/2009-04-23-benchmarks-and-instrumentation-for-fennecetc.markdown b/source/_posts/2009-04-23-benchmarks-and-instrumentation-for-fennecetc.markdown
deleted file mode 100644
index d539925..0000000
--- a/source/_posts/2009-04-23-benchmarks-and-instrumentation-for-fennecetc.markdown
+++ /dev/null
@@ -1,28 +0,0 @@
----
-comments: true
-date: 2009-04-23 10:19:14
-layout: post
-slug: benchmarks-and-instrumentation-for-fennecetc
-title: Benchmarks and Instrumentation for Fennec/etc
-wordpress_id: 121
-categories:
-- mozilla
----
-
-I wrote Fennecmark to automate some of the tasks that I did manually while doing performance debugging.  
-  
-I tried to capture some of the "perceived performance" in numbers. My goal is to focus on user-visible areas of performance. Ideally it will enable us to track performance better to ensure that key features do not regress in performance and enable us to compare Fennec speed on various platforms. I need to spend some quality time with QA people to figure out how to achieve that.  
-  
-Currently Fennecmark loads a slow-to-load webpage, zooms around it and then pans from the top to the bottom. This measures: responsiveness during pageload, zoom speed and panning lag.  
-  
-See code at [http://hg.mozilla.org/users/tglek_mozilla.com/fennecmark](http://hg.mozilla.org/users/tglek_mozilla.com/fennecmark).  
-  
-**JSD Instrumentation**  
-  
-Spidermonkey provides an API that allows one to get a notification on every method entry/exit. I was able to do most of my Fennec performance analysis via a component in [bug 470116](https://bugzilla.mozilla.org/show_bug.cgi?id=470116). My stopwatch component times the execution of every js function call and spits out a log that has been very useful in figuring out what is taking up time in Fennec chrome.  
-  
-**Porkstain**  
-  
-I am itching to write a tool that can instrument large portions of Mozilla code such that it can be profiled across C++/JS boundaries and without any external tool support. I am guessing this would be most useful on platforms with crappy sampling tools, but it would be cool if it made finding slow codepaths easier in general. If you know any lightweight instrumentation techniques, please share.  
-  
-I wrote a little prototype to insert stopwatch stuff into code deemed interesting by oprofile (stuff in the bug above). The code patching part works well, but it's a big runtime hit and outputs too much data.
diff --git a/source/_posts/2009-04-30-gcc-rant-progress.markdown b/source/_posts/2009-04-30-gcc-rant-progress.markdown
deleted file mode 100644
index 945b584..0000000
--- a/source/_posts/2009-04-30-gcc-rant-progress.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2009-04-30 13:51:35
-layout: post
-slug: gcc-rant-progress
-title: GCC Rant + Progress
-wordpress_id: 127
-categories:
-- mozilla
-- dehydra
-- treehydra
----
-
-I feel strange working on GCC-specific stuff and then discussing it on planet mozilla as mozilla work. However, without GCC, Dehydra and Treehydra would not be half as awesome (much less feasible even). The power of open source is that it allows us to leverage the entire open source ecosystem to achieve specific goals. When open source projects combine their efforts, not even the biggest software companies can compete as cross-project goals would be incredibly expensive and unpleasant otherwise.  
-  
-Occasionally, it is very frustrating to see people treat open source software as immutable and independent black boxes. In my personal experience, the browser and the compiler are viewed as finished products and therefore it is OK to bitch and complain about them. That's frustrating because the same users could be channeling that energy in a more positive way by reporting bugs, contributing code/documentation, etc.  
-  
-Sometimes these rants result in rather comical conclusions: Ingo's [rant](http://lwn.net/Articles/328685/) is priceless. My perspective on this: 
-
-  * what have Linux kernel devs done to help GCC help them?
-  * <flame>Sparse is a deadend. Writing compiler code in C is silly, writing analysis code in C is sillier (and frustrating and limiting). Taking a crappy parser and bolting a crappy compiler backend onto it will result in bigger pile of crap :) Given how smart kernel devs are, they sure like wasting their time on crappy solutions in crappy languages.</flame>
-  * Wouldn't it be cool if instead of complaining these talented people wrote a GCC plugin to do what they want?
-**GCC Plugin Progress**  
-  
-I finally landed the massively boring and annoying [GTY patch](http://hg.mozilla.org/users/tglek_mozilla.com/gcc-moz-plugin-mq/file/24bbb11d7346/gty.diff). I can barely believe that the patch went in so smoothly without excess complaining from GCC devs. From GCC perspective it's merely a cosmetic cleanup that affects a large number of headers. For us it enables [Treehydra](https://developer.mozilla.org/en/Treehydra) to be generated via [Dehydra](https://developer.mozilla.org/En/Dehydra) with little manual effort. It basically makes Treehydra possible without patching GCC. I have another 3-4 patches that need to land before trunk GCC can run the hydras out of the box. Those are mainly localized bugfixes and cleanups so I fully expect them to go in and for GCC 4.5 to rock my world. Once GCC 4.5 ships. analyzing code will depend on a trivial matter of apt-getting(or equivalent) the hydras and specifying the analysis flags on the GCC commandline!
diff --git a/source/_posts/2009-05-11-dehydra-updates.markdown b/source/_posts/2009-05-11-dehydra-updates.markdown
deleted file mode 100644
index 5e7b542..0000000
--- a/source/_posts/2009-05-11-dehydra-updates.markdown
+++ /dev/null
@@ -1,17 +0,0 @@
----
-comments: true
-date: 2009-05-11 10:55:14
-layout: post
-slug: dehydra-updates
-title: Dehydra Updates
-wordpress_id: 129
-categories:
-- mozilla
-- dehydra
----
-
-**How well are you packing your structs?** Arpad asked that question with an awesome [Dehydra scrip](https://bugzilla.mozilla.org/show_bug.cgi?id=492185)t and came up with an interesting list.  
-  
-**GCC 4.3.3 Is supported** GCC 4.3.3(4.3.[210] worked) broke C++ compatibility in the headers used by [Dehydra](https://developer.mozilla.org/En/Dehydra). Zach pointed out that passing -fpermissive to g++ solves the problem. Sorry to all the people who had issues building the hydras with GCC 4.3.3, that's fixed now.  
-  
-As I mentioned before, we are skipping GCC 4.4 support in Dehydra and aiming for supporting unpatched GCC 4.5. I wish that the small GCC patches were as quick to land as that big one I landed a couple of weeks ago :(.
diff --git a/source/_posts/2009-05-14-gcc-45-dehydra-is-a-go-and-other-updates.markdown b/source/_posts/2009-05-14-gcc-45-dehydra-is-a-go-and-other-updates.markdown
deleted file mode 100644
index 2dbcf65..0000000
--- a/source/_posts/2009-05-14-gcc-45-dehydra-is-a-go-and-other-updates.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2009-05-14 21:06:59
-layout: post
-slug: gcc-45-dehydra-is-a-go-and-other-updates
-title: GCC 4.5 + Dehydra is a go and other updates
-wordpress_id: 131
-categories:
-- mozilla
----
-
-I finally landed the remaining GCC patches needed to get a useful [Dehydra](https://developer.mozilla.org/En/Dehydra) without any of that gcc-patching pain!  
-  
-This week I also got some nice contributions from a contributor with a masterplan.  
-  
-Overall I expect cool things to happen once GCC 4.5 ships with plugin support. It'll open up a jar of whoopass like C++ has not seen before.  
-  
-**Dehydra Docs**  
-  
-Benjamin redid the [Dehydra](http://benjamin.smedbergs.us/blog/) documentation, it should be easier than ever to get started.  
-  
-**Static Analysis in Mozilla**  
-  
-Slowly but surely we are gathering static analysis momentum. More and more developers are pausing and thinking "I need to make sure this code has an analysis to go with it because there is no way I can prove it correct, time to write a [Treehydra](https://developer.mozilla.org/en/Treehydra) script...or ask someone else to make one for me". This mindset is important for being able to introduce complex changes in a controlled manner.  
-  
-On the refactoring side, things are held up a little by API compatibility. Perhaps multi-process stuff will shake things up. However, nothing can hold [Chris](https://blog.mozilla.org/cjones/) up from letting his piglet/porky gremlins chew through locking code.
diff --git a/source/_posts/2009-06-17-dehydratreehydra-c-support.markdown b/source/_posts/2009-06-17-dehydratreehydra-c-support.markdown
deleted file mode 100644
index 2c676c7..0000000
--- a/source/_posts/2009-06-17-dehydratreehydra-c-support.markdown
+++ /dev/null
@@ -1,27 +0,0 @@
----
-comments: true
-date: 2009-06-17 11:22:53
-layout: post
-slug: dehydratreehydra-c-support
-title: Dehydra/Treehydra C support
-wordpress_id: 133
-categories:
-- mozilla
----
-
-Every once in a while people want to be analyze C code. If you are one of those people, checkout [bug 494960](https://bugzilla.mozilla.org/show_bug.cgi?id=494960). For GCC 4.3, you'll need to update your patch queue. If you you followed the [Dehydra install instructions](https://developer.mozilla.org/En/Dehydra/Installing_Dehydra) do something like:  
-  
-
-```
-
-cd gcc-4.3.0/.hg/patches
-hg pull -u
-cd ../..
-hg qpush -a
-
-```
-  
-  
-and rebuild gcc to get C support in the plugin framework for GCC 4.5 (patch for trunk is in the bug).  
-  
-Everything other than process_function should work in both treehydra and dehydra. Note that the objects provided by GCC will be slightly different in structure due to the underlying difference between gcc/g++, so scripts that were written for C++ may need to be updated.
diff --git a/source/_posts/2009-06-25-dehydra-pork-sources-moved.markdown b/source/_posts/2009-06-25-dehydra-pork-sources-moved.markdown
deleted file mode 100644
index c291274..0000000
--- a/source/_posts/2009-06-25-dehydra-pork-sources-moved.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2009-06-25 15:32:57
-layout: post
-slug: dehydra-pork-sources-moved
-title: Dehydra & Pork Sources Moved
-wordpress_id: 137
-categories:
-- mozilla
-- dehydra
-- pork
----
-
-I moved dehydra to a more official location, please update your scripts and hg settings. New dehydra url: http://hg.mozilla.org/rewriting-and-analysis/dehydra/  
-  
-Pork got reshuffled during the move, it's now 2 repositories. oink is dead. It now depends on current versions of flex (as opposed to flex-old) and features a cleaned up buildsystem.  
-  
-New way to checkout pork: 
-```
-
-hg clone http://hg.mozilla.org/rewriting-and-analysis/pork
-hg clone http://hg.mozilla.org/rewriting-and-analysis/elsa pork/elsa
-
-```
-
diff --git a/source/_posts/2009-06-26-studying-fennec-performance.markdown b/source/_posts/2009-06-26-studying-fennec-performance.markdown
deleted file mode 100644
index 032d97d..0000000
--- a/source/_posts/2009-06-26-studying-fennec-performance.markdown
+++ /dev/null
@@ -1,36 +0,0 @@
----
-comments: true
-date: 2009-06-26 14:31:36
-layout: post
-slug: studying-fennec-performance
-title: Studying Fennec Performance
-wordpress_id: 140
-categories:
-- mozilla
-- fennec
-- performance
----
-
-Working on Fennec performance N810 has been very educational. I have been learning more and more about performance profiling on crappy platforms. I define a platform as crap if it has poor development tools, limited OS or other significant limitations. Linux is a crappy platform in this case because it's running on ARM where oprofile barely does anything and there are no other performance tools for N810 (more modern ARM cpus should user-space perf counters and be more useful for instrumentation).  
-  
-**JSD Secret Sauce for JS Optimization**  
-  
-In general there is a misconception that implementing stuff in JavaScript will result in slower code than doing the same in C++. That may be true if the code is implemented in the exact same manner. But in real life the expressiveness and safety of a high-level language like JavaScript permits algorithmic optimizations that would often not be realistic to do in C++ because of time/safety constraints.  
-  
-So how does one figure out what's slow in JS? timeless suggested that I checkout the JavaScript Debugging API. Using the API and a small hack in spidermonkey(JSD doesn't expose fast dom calls) I was able to hook into chrome code to get a timed trace of JavaScript functions being run.  
-  
-Once I had a trace it was relatively easy to figure out to "do not call this slow thing all the time" dance (aka optimize code). I collected that work in [bug 470116](https://bugzilla.mozilla.org/show_bug.cgi?id=470116). Last I checked there was relatively little room for optimization left on the JS side of Fennec, so then I went to look at what's lurking in C++.  
-  
-PS. Firebug is a popular consumer of the JSD API for those times when one isn't willing to write JS components to figure out why something is slow.  
-  
-**C++ Is Harder**  
-  
-I've some success with inserting probes into C++ code. I would find interesting code by running oprofile on the desktop (while doing things that I felt were slow on N810). Oprofile would then provide me a callgraph which I would visualize with [this awesome little script](http://code.google.com/p/jrfonseca/wiki/Gprof2Dot). Then I would stick [MeasurerOfTime](http://people.mozilla.com/~tglek/fennec/patches/measurer.diff) timing blocks into interesting "hot" code and hope that I would learn something useful.  
-  
-This got me thinking. Wouldn't it be nice if there existed a JSD for C++? It'd be cool to inspect the C++ callgraph just like one does for JS. It seems like it would help on platforms that aren't gcc and can't inject tracing code via -finstrument-functions. Even -finstrument-functions is of limited use due to the pain of looking up symbols in shared libraries. Stay tuned.  
-  
-**Measuring Progress**  
-  
-The worst part of doing optimizations is knowing that some time in a future an innocent programmer will slightly change some seemingly innocent code and things will no longer happen quickly. Short of policing every single patch by people who previously optimized code in question there is only one thing one can do: performance tests.  
-  
-[Fennecmark](http://hg.mozilla.org/users/tglek_mozilla.com/fennecmark) is a benchmark for measuring responsiveness of the Fennec features that I worked on most: panning, zooming and lag during pageload. I [blogged](http://taras.glek.net/blog/2009/04/23/benchmarks-and-instrumentation-for-fennecetc/) about it before. Since then Joel Maher has [gotten Fennecmark](https://bugzilla.mozilla.org/show_bug.cgi?id=493057) to run automatically and produce results on the graph server. I think we should be logging more numbers (Tpan, Tzoom), but it's an excellent first step in monitoring performance regressions.
diff --git a/source/_posts/2009-06-29-dxr-the-most-impressive-code-navigation-tool-ever.markdown b/source/_posts/2009-06-29-dxr-the-most-impressive-code-navigation-tool-ever.markdown
deleted file mode 100644
index e324a83..0000000
--- a/source/_posts/2009-06-29-dxr-the-most-impressive-code-navigation-tool-ever.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2009-06-29 09:19:16
-layout: post
-slug: dxr-the-most-impressive-code-navigation-tool-ever
-title: 'DXR: The Most Impressive Code Navigation Tool Ever'
-wordpress_id: 143
-categories:
-- mozilla
-- dehydra
----
-
-Are you are a developer who has been frustrated by the pathetic state of the art in code search engines and code browsing experience on the web? Have you been longing for being able to view code with more aid than coloured words?
-
-David Humphrey just [released](http://vocamus.net/dave/?p=557) his DXR bombshell. The "basic" concept behind DXR is extraction of the rich semantic information gathered by tools like GCC, Spidermonkey and [xpidl](https://developer.mozilla.org/en/XPIDL/xpidl). This data is then coherently linked together into a pretty UI in order to provide cleverness during code browsing sessions.
-
-DXR will be happy to answer seemingly trivial queries:
-
-  * List implementations of interfaces in C++ (and soon JS).
-  * Provide relevant search results by searching semantic data first. No, grep is no longer state of the art for searching code.
-  * Switch between definition and declaration.
-  * Walk up/down class hierarchies.
-  * Lookup typedefs, types, etc.
-
-I've been wanting to see this sort of tool built on top information exposed by [Dehydra](https://developer.mozilla.org/En/Dehydra) since I got it working. Words can not express how pumped I am about DXR and the magic powers that we will be granting it.
diff --git a/source/_posts/2009-07-01-python-gdb-logging-file-io.markdown b/source/_posts/2009-07-01-python-gdb-logging-file-io.markdown
deleted file mode 100644
index b00ccdf..0000000
--- a/source/_posts/2009-07-01-python-gdb-logging-file-io.markdown
+++ /dev/null
@@ -1,44 +0,0 @@
----
-comments: true
-date: 2009-07-01 15:05:42
-layout: post
-slug: python-gdb-logging-file-io
-title: Python GDB - Logging File IO
-wordpress_id: 146
-categories:
-- mozilla
----
-
-**Python GDB Rocks!**
-
-I wanted a non-painful way to figure out what's causing bonus file IO. I've noticed that gtk likes to open files, but I didn't have the exact details. So I grabbed [python gdb](http://sourceware.org/gdb/wiki/PythonGdb), and with some tips on syscalls from gdb old-timers managed to produce a [report](http://people.mozilla.com/~tglek/fennec/files.txt) to assign blame for open()ing files to relevant Mozilla functions.
-
-Other than the gdb-hating syscalls issue, achieving this was simple
-
-  1. Compile python-enabled gdb(Next set of distribution releases should have it..I hope)
-  2. Define a new gdb command in a python file. I called mine "taras" for lack of a better name.
-  3. Set a breakpoint, attach your command to it. :  
-
-```
-break open  
-
-source -p /path/to/your/script.py  
-
-command 1  
-
-taras  
-
-end
-```
-
-  4. Have the script walk the backtrace to figure out the filename and the last Mozilla function. Log the info, issue gdb continue command.
-  5. Print out a report and profit:  
-
-```
-python report()
-```
-
-
-Here is my [script](http://people.mozilla.com/~tglek/gdblog.py). The only nasty part here is that I had to read the filename out of a register (i'm on amd64, on 32 it'd be $esi instead of $rdi) because gdb doesn't deal well with system calls.  
-  
-I've never throught it would be this fun to use gdb. I always thought debuggers should be scriptable, thanks to [Tom Tromey](http://tromey.com/blog/) (lots of gdb tutorials on Tom's blog) and any others who finally made this a reality.
diff --git a/source/_posts/2009-07-14-virtualbox-rocks.markdown b/source/_posts/2009-07-14-virtualbox-rocks.markdown
deleted file mode 100644
index b67fbc5..0000000
--- a/source/_posts/2009-07-14-virtualbox-rocks.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2009-07-14 13:15:52
-layout: post
-slug: virtualbox-rocks
-title: VirtualBox 3.0 Rocks
-wordpress_id: 154
-categories:
-- mozilla
----
-
-With much pain I managed to convince a Vmware WinXP virtual machine to run in [VirtualBox](http://www.virtualbox.org/). At first it ran very sluggishly(>3 hours to do a build?), but after I turned off IO Apic stuff in Windows, it's become disturbingly fast. It now takes 40minutes to build a wince fennec vs almost 80minutes it took on VMware server. 
-
-VirtualBox's disk throughput is phenomenal, in fact, this is the first time I've seen almost-native speed disk io in virtual machine. A benchmark I tried reported 45mb/s 4K read/writes (these were cached on the linux side).
-
-Unlike Vmware server, VirtualBox's usb works without troubles, shared folders were easy to setup etc. It's an awesome app, hope Sun/Oracle keeps it up.
diff --git a/source/_posts/2009-07-21-those-crazy-comm-central-guys.markdown b/source/_posts/2009-07-21-those-crazy-comm-central-guys.markdown
deleted file mode 100644
index 0ae3756..0000000
--- a/source/_posts/2009-07-21-those-crazy-comm-central-guys.markdown
+++ /dev/null
@@ -1,14 +0,0 @@
----
-comments: true
-date: 2009-07-21 09:54:42
-layout: post
-slug: those-crazy-comm-central-guys
-title: Those crazy comm-central guys...
-wordpress_id: 158
-categories:
-- mozilla
----
-
-When it comes to taking on crazy tasks involving disguising code, you can always count on Joshua. This time Joshua has gone deep in [Pork](https://developer.mozilla.org/En/Pork) territory to do a very impressive rewrite (one that would not be even close to possible with anything other than Elsa-based tools) and he is blogging about it. He posted the [first installment](http://quetzalcoatal.blogspot.com/2009/07/guide-to-pork-part-1.html) of his rewriting-with-Pork guide.  
-  
-Still on the subject on mad csc-entist Joshua: Andrew Sutherland has finally gotten sick of crappy JS documentation tools and took matters into his own hands thanks to Joshua's JSHydra tool. Checkout his [blog post](http://www.visophyte.org/blog/2009/07/20/doccelerator-javascript-documentation-via-jshydra-into-couchdb-with-an-ajax-ui/) on how the documentation world will be a better place thanks to being able to build tools on top of *the JavaScript parser*.
diff --git a/source/_posts/2009-07-22-chasewamu-fraud-friendlyness.markdown b/source/_posts/2009-07-22-chasewamu-fraud-friendlyness.markdown
deleted file mode 100644
index f03d109..0000000
--- a/source/_posts/2009-07-22-chasewamu-fraud-friendlyness.markdown
+++ /dev/null
@@ -1,12 +0,0 @@
----
-comments: true
-date: 2009-07-22 08:09:24
-layout: post
-slug: chasewamu-fraud-friendlyness
-title: Chase/WaMu Fraud-friendlyness
-wordpress_id: 161
-categories:
-- mozilla
----
-
-Turns out that if someone compromises a merchant that you shop with, such as bikenashbar.com, then they are entitled to your money as long as they can show to the bank that they have your billing/shipping information. According to Chase it's not fraud if they steal your address along with the card number.  I recommend that people use a bank that protects their customer's finances, one that isn't called [Chase](http://chase.com/).
diff --git a/source/_posts/2009-08-03-this-month-in-static-analysis.markdown b/source/_posts/2009-08-03-this-month-in-static-analysis.markdown
deleted file mode 100644
index 0d9cdb6..0000000
--- a/source/_posts/2009-08-03-this-month-in-static-analysis.markdown
+++ /dev/null
@@ -1,30 +0,0 @@
----
-comments: true
-date: 2009-08-03 21:19:55
-layout: post
-slug: this-month-in-static-analysis
-title: This Month In Static Analysis
-wordpress_id: 164
-categories:
-- mozilla
-- dehydra
-- pork
----
-
-Lately I have been focusing on optimizing Fennec startup on a delightfully inadequate platform: Windows Mobile. More on fascinating startup, performance problems and solutions later. As a result I have been doing relatively little static analysis stuff.  
-  
-The main reason for taking a break is that I feel that I went from having no way to do any analysis to having production-quality tools for [analysis](https://developer.mozilla.org/En/Dehydra) and [rewriting](https://developer.mozilla.org/En/Pork).  I finally have a chance to move on from developing tools to using them in everyday development. The main puzzle piece that needs completion is GCC 4.5 support in Dehydra. We are feature-complete on 4.5, just need to stabilize once the trunk stabilizes.  
-  
-**Drowning In Pork **  
-  
-A number of other people did some cool stuff in the meantime. First and foremost: Joshua Cranmer has ventured into the land of [Pork](https://developer.mozilla.org/En/Pork) and is publishing a guide to doing refactoring tools on this blog ([part 1](http://quetzalcoatal.blogspot.com/2009/07/guide-to-pork-part-1.html), [part 2](http://quetzalcoatal.blogspot.com/2009/07/guide-to-pork-part-2.html), [part 3](http://quetzalcoatal.blogspot.com/2009/08/guide-to-pork-part-3.html)). This is cool, because until now, there were no Pork docs and nothing I write could ever match Joshua's documenting talents.  Thanks a bunch, Joshua.  
-  
-I have also received my first-ever bugfix patches to Elsa. Previously, I've received miscellaneous build fixes, etc, but these are the first patches that involved somebody pounding their head against the wall until they figured out why things were crashing or not accepting valid C++ code.  
-  
-**Introducing Dan Witte**  
-  
-Dan is the new static analysis go-to person. So far he facilitated an explosion of static analysis ideas (they are tracked in [bug 430328](https://bugzilla.mozilla.org/show_bug.cgi?id=430328)). A lot of these can be expressed as <10line Dehydra analyses, so they are excellent introductory projects. If you are dying to start analyzing code, but don't know where to begin, look in that bug. Dan has written an interesting analysis to do with finding accidental temporaries due to C++'s "wonderful" implicit conversions/etc (expect to see a blog post on that). He is also working on the holy grail of Mozilla static analysis: a full callgraph. It's a little embarrassing that we don't have that yet, but it's hard and once we do have it, a whole new world of analyses will be possible.  
-  
-**Speaking of Callgraphs...**  
-  
-So while various Mozillians were pondering how awesome it would be to do inter-function analysis, an intern has beat us to writing the first useful inter-function analysis! Sully had a problem, after a tiny bit of  Dehydra coaching, he solved his problem in the amount of time it took me to eat my lunch. Brilliant! See his [blog post](http://www.msully.net/blog/2009/08/03/doing-whole-tree-analysis-with-dehydra/) for details. My conclusion: either Dehydra is pretty easy to use and/or we get mad genius interns :).
diff --git a/source/_posts/2009-08-14-there-is-nothing-exciting-about-filesystems.markdown b/source/_posts/2009-08-14-there-is-nothing-exciting-about-filesystems.markdown
deleted file mode 100644
index 6eb0c9e..0000000
--- a/source/_posts/2009-08-14-there-is-nothing-exciting-about-filesystems.markdown
+++ /dev/null
@@ -1,22 +0,0 @@
----
-comments: true
-date: 2009-08-14 14:22:22
-layout: post
-slug: there-is-nothing-exciting-about-filesystems
-title: There is nothing exciting about filesystems
-wordpress_id: 171
-categories:
-- mozilla
----
-
-When I originally started at Mozilla, I only knew the people who interviewed me. But I quickly discovered beltzner when he uttered a sacrilegious statement that went something like: "..... nothing could be as boring as filesystems....". Mike Beltzner is one of my favourite characters at Mozilla for his ability to speak his mind, but this quote has troubled me greatly. How can one not care about filesystems? Linux's ability to do file stuff efficiently makes it magnitudes faster than other operating systems. Plan 9's file-system-centric layout proved that OSes don't have to consist of a series of poorly named and categorized system calls. In fact, a clean file layout allows many awesome optimizations. ZFS is one of the few things keeping Solaris relevant. HFS+ is one of the things keeping OSX from being fast.  
-  
-Being a Linux user, I was disappointed by the pointlessness of optimizing application IO. Sure we inefficiently open tons of files on startup, sure we hit the filesystem 10-100x more than we could, why would one optimize when there when there is no more than a few percent of startup being take up by terrible io patterns?  
-  
-**Excitingly Crappy Filesystems**  
-  
-Luckily Firefox runs on OSX and we are making it run on WinCE. I was delighted to discover that on wince* we paid 1-5ms per file existence check, modification date, size, etc. I was shocked to see that the throughput while reading certain files could be expressed in bytes per second (most crappy flash media seems to be able to pull in >1mb/s).  This brought upon switching our[ jar io to mmap](https://bugzilla.mozilla.org/show_bug.cgi?id=504864), [amalgamating](https://bugzilla.mozilla.org/show_bug.cgi?id=468011) jar files, moving more [files into jars](https://bugzilla.mozilla.org/show_bug.cgi?id=508421), etc. I'll blog about the details later. My basic idea is that we can utilize jar files as "controlled filesystem environments" to deal with having to run on crappy OSes with exceptionally bad filesystems. OSes such as OSX where file IO is barely faster than that of a WinCE phone.  
-  
-Beltzner, wouldn't it be exciting if OSes like Mac OSX had file systems worth being excited about?  
-  
-* MS likes to use puns for their product names
diff --git a/source/_posts/2009-08-20-cleaning-up-startup-disk-io.markdown b/source/_posts/2009-08-20-cleaning-up-startup-disk-io.markdown
deleted file mode 100644
index 5158905..0000000
--- a/source/_posts/2009-08-20-cleaning-up-startup-disk-io.markdown
+++ /dev/null
@@ -1,56 +0,0 @@
----
-comments: true
-date: 2009-08-20 15:50:12
-layout: post
-slug: cleaning-up-startup-disk-io
-title: Cleaning Up Startup Disk IO
-wordpress_id: 173
-categories:
-- mozilla
----
-
-**Maintaining a module, killing off another one **  
-  
-I was granted ownership of the [jar module](http://benjamin.smedbergs.us/blog/2009-08-19/taras-owns-libjar/). Today, I resumed my quest to [kill off ](https://bugzilla.mozilla.org/show_bug.cgi?id=457949)the barely limping stopwatch module. Together with nuking [STANDALONE](https://bugzilla.mozilla.org/show_bug.cgi?id=505784) mode in jar stuff, I will have landed 75KB worth of -ve diffs this month. It feels so good to delete code.  
-  
-**IO Report**  
-  
-Currently I am focusing on application IO (excluding libraries and IO caused by libraries).  
-  
-From my empirical measurements, opening individual files on a 7200RPM hard drive costs around 0-40ms. This is on Linux. I presume files open quickly when they are located near previously opened files and slower if a full disk seek is required for them. Combining files is usually a significant win in terms of throughput. It turns out that even warm starts and reading from SSDs can benefit from combined IO. Currently small file throughput ranges from <1KB/s to <200KB/s for files < 500K. Combining files into memory mapped jars bumps that up to 1-1.5MB/s (currently jar files are relatively small, making them responsible for a higher proportion of IO should boost that further).  
-  
-The biggest gains are to be had on Windows Mobile where almost every seemingly trivial filesystem operation takes 2-3ms.  
-  
-I would like to reduce the number of files read on startup to a dozen or so to be able to crank up disk throughput. Unfortunately, there is a lot to be done, I could use a great deal of help.  
-  
-Below is a long list of files gathered by stracing firefox-bin, and what I know about them:  /home/taras/builds/minefield/dist/bin/application.ini /home/taras/builds/minefield/dist/bin/browserconfig.properties /home/taras/builds/minefield/dist/bin/platform.ini Haven't investigated these yet. Perhaps, instead of reading these files should be compiling this info into the xulrunner launcher app?  
-  
-**Update**: ted says application.ini used to be compiled in: [bug 383167 ](https://bugzilla.mozilla.org/show_bug.cgi?id=383167) /home/taras/builds/minefield/dist/bin/plugins  
-  
-I'm ignoring plugins at the moment. /home/taras/builds/minefield/dist/bin/chrome /home/taras/builds/minefield/dist/bin/chrome/browser.jar /home/taras/builds/minefield/dist/bin/chrome/browser.manifest /home/taras/builds/minefield/dist/bin/chrome/comm.manifest /home/taras/builds/minefield/dist/bin/chrome/en-US.jar /home/taras/builds/minefield/dist/bin/chrome/en-US.manifest /home/taras/builds/minefield/dist/bin/chrome/pageloader.manifest /home/taras/builds/minefield/dist/bin/chrome/pippki.manifest /home/taras/builds/minefield/dist/bin/chrome/reftest.manifest /home/taras/builds/minefield/dist/bin/chrome/toolkit.jar /home/taras/builds/minefield/dist/bin/chrome/toolkit.manifest /home/taras/builds/minefield/dist/bin/chrome/xslt-qa.manifest  
-  
-The .manifest files describe how to find stuff in chrome jars. Parsing .manifest files is inefficient due to disk seeks. Additionally, current .manifest parsing code appears to be slow on mobile devices. [bug 506392](https://bugzilla.mozilla.org/show_bug.cgi?id=506392) I would like to move .manifest files within jars(and look for manifests within jars when a manifest isn't found alongside the .jar in the filesystem)  
-  
-.jar files are a little bit of  a  cpu hog when it comes  to parse the zip file index. This can be done lazily: [bug 511754](https://bugzilla.mozilla.org/show_bug.cgi?id=511754) /home/taras/builds/minefield/dist/bin/chrome/icons/default/default16.png /home/taras/builds/minefield/dist/bin/chrome/icons/default/default32.png /home/taras/builds/minefield/dist/bin/chrome/icons/default/default48.png These icons are parsed by gnome libs 3 times during startup. I wonder if we are initializing some gnome thing 3 times?  
-  
-/home/taras/builds/minefield/dist/bin/components /home/taras/builds/minefield/dist/bin/components/aboutCertError.js /home/taras/builds/minefield/dist/bin/components/aboutPrivateBrowsing.js /home/taras/builds/minefield/dist/bin/components/aboutRights.js /home/taras/builds/minefield/dist/bin/components/aboutRobots.js /home/taras/builds/minefield/dist/bin/components/aboutSessionRestore.js /home/taras/builds/minefield/dist/bin/components/FeedConverter.js /home/taras/builds/minefield/dist/bin/components/FeedWriter.js /home/taras/builds/minefield/dist/bin/components/fuelApplication.js /home/taras/builds/minefield/dist/bin/components/httpd.js /home/taras/builds/minefield/dist/bin/components/NetworkGeolocationProvider.js /home/taras/builds/minefield/dist/bin/components/nsAddonRepository.js /home/taras/builds/minefield/dist/bin/components/nsBadCertHandler.js /home/taras/builds/minefield/dist/bin/components/nsBlocklistService.js /home/taras/builds/minefield/dist/bin/components/nsBrowserContentHandler.js /home/taras/builds/minefield/dist/bin/components/nsBrowserGlue.js /home/taras/builds/minefield/dist/bin/components/nsContentDispatchChooser.js /home/taras/builds/minefield/dist/bin/components/nsContentPrefService.js /home/taras/builds/minefield/dist/bin/components/nsDefaultCLH.js /home/taras/builds/minefield/dist/bin/components/nsDownloadManagerUI.js /home/taras/builds/minefield/dist/bin/components/nsExtensionManager.js /home/taras/builds/minefield/dist/bin/components/nsFilePicker.js /home/taras/builds/minefield/dist/bin/components/nsFormAutoComplete.js /home/taras/builds/minefield/dist/bin/components/nsHandlerService.js /home/taras/builds/minefield/dist/bin/components/nsHelperAppDlg.js /home/taras/builds/minefield/dist/bin/components/nsLivemarkService.js /home/taras/builds/minefield/dist/bin/components/nsLoginInfo.js /home/taras/builds/minefield/dist/bin/components/nsLoginManager.js /home/taras/builds/minefield/dist/bin/components/nsLoginManagerPrompter.js /home/taras/builds/minefield/dist/bin/components/nsMicrosummaryService.js /home/taras/builds/minefield/dist/bin/components/nsPlacesAutoComplete.js /home/taras/builds/minefield/dist/bin/components/nsPlacesDBFlush.js /home/taras/builds/minefield/dist/bin/components/nsPlacesTransactionsService.js /home/taras/builds/minefield/dist/bin/components/nsPrivateBrowsingService.js /home/taras/builds/minefield/dist/bin/components/nsProgressDialog.js /home/taras/builds/minefield/dist/bin/components/nsProxyAutoConfig.js /home/taras/builds/minefield/dist/bin/components/nsSafebrowsingApplication.js /home/taras/builds/minefield/dist/bin/components/nsSample.js /home/taras/builds/minefield/dist/bin/components/nsSearchService.js /home/taras/builds/minefield/dist/bin/components/nsSearchSuggestions.js /home/taras/builds/minefield/dist/bin/components/nsSessionStartup.js /home/taras/builds/minefield/dist/bin/components/nsSessionStore.js /home/taras/builds/minefield/dist/bin/components/nsSetDefaultBrowser.js /home/taras/builds/minefield/dist/bin/components/nsSidebar.js /home/taras/builds/minefield/dist/bin/components/nsTaggingService.js /home/taras/builds/minefield/dist/bin/components/nsTryToClose.js /home/taras/builds/minefield/dist/bin/components/nsUpdateService.js /home/taras/builds/minefield/dist/bin/components/nsUrlClassifierLib.js /home/taras/builds/minefield/dist/bin/components/nsUrlClassifierListManager.js /home/taras/builds/minefield/dist/bin/components/nsURLFormatter.js /home/taras/builds/minefield/dist/bin/components/nsWebHandlerApp.js /home/taras/builds/minefield/dist/bin/components/pluginGlue.js /home/taras/builds/minefield/dist/bin/components/reftest-cmdline.js /home/taras/builds/minefield/dist/bin/components/storage-Legacy.js /home/taras/builds/minefield/dist/bin/components/storage-mozStorage.js /home/taras/builds/minefield/dist/bin/components/tp-cmdline.js /home/taras/builds/minefield/dist/bin/components/txEXSLTRegExFunctions.js /home/taras/builds/minefield/dist/bin/components/WebContentConverter.js Above files are only read in during the "slow" startup and are "fastloaded" afterward. However, they are stat()ed to make sure the fastload stuff isn't stale. This is bad: [bug 511761](https://bugzilla.mozilla.org/show_bug.cgi?id=511761). Making these depend on .autoreg seems reasonable.  
-  
-/home/taras/builds/minefield/dist/bin/extensions This probably should depend on .autoreg too  
-  
-/home/taras/builds/minefield/dist/bin/updates /home/taras/builds/minefield/dist/bin/updates/0/update.test /home/taras/builds/minefield/dist/bin/update.test This too?  
-  
-/home/taras/builds/minefield/dist/bin/greprefs /home/taras/builds/minefield/dist/bin/greprefs/all.js /home/taras/builds/minefield/dist/bin/greprefs/security-prefs.js /home/taras/builds/minefield/dist/bin/greprefs/xpinstall.js Reading a directory full of pref files that never change is crazy. [bug 507288](https://bugzilla.mozilla.org/show_bug.cgi?id=507288) provides 10-100x throughput improvement in reading gre prefs.  
-  
-/home/taras/builds/minefield/dist/bin/defaults/pref /home/taras/builds/minefield/dist/bin/defaults/pref/channel-prefs.js /home/taras/builds/minefield/dist/bin/defaults/pref/firefox-branding.js /home/taras/builds/minefield/dist/bin/defaults/pref/firefox.js /home/taras/builds/minefield/dist/bin/defaults/pref/firefox-l10n.js /home/taras/builds/minefield/dist/bin/defaults/pref/reporter.js This is similar to gre pref situation, but worse because there are more pref files. This is also harder to refactor. I propose having 2 hardcoded pref names for xulrunner applications: app.js burried in a jar file speed and l10n.js for localization convenience.  
-  
-/home/taras/builds/minefield/dist/bin/dictionaries /home/taras/builds/minefield/dist/bin/dictionaries/en-US.aff /home/taras/builds/minefield/dist/bin/dictionaries/en-US.dic For some reason only one of my computers is reading the spellcheck dictionary at startup, but it is costing me 70ms. I wonder if these can be moved to a locale jar.  
-  
-/home/taras/builds/minefield/dist/bin/modules/distribution.js /home/taras/builds/minefield/dist/bin/modules/DownloadLastDir.jsm /home/taras/builds/minefield/dist/bin/modules/ISO8601DateUtils.jsm /home/taras/builds/minefield/dist/bin/modules/NetUtil.jsm /home/taras/builds/minefield/dist/bin/modules/utils.js /home/taras/builds/minefield/dist/bin/modules/XPCOMUtils.jsm These modules should be moved into toolkit.jar: [bug 509755](https://bugzilla.mozilla.org/show_bug.cgi?id=509755)  
-  
-/home/taras/builds/minefield/dist/bin/res/broken-image.png /home/taras/builds/minefield/dist/bin/res/charsetalias.properties /home/taras/builds/minefield/dist/bin/res/charsetData.properties /home/taras/builds/minefield/dist/bin/res/forms.css /home/taras/builds/minefield/dist/bin/res/hiddenWindow.html /home/taras/builds/minefield/dist/bin/res/html.css /home/taras/builds/minefield/dist/bin/res/loading-image.png /home/taras/builds/minefield/dist/bin/res/quirk.css /home/taras/builds/minefield/dist/bin/res/ua.css  
-  
-These need to be in a jar too: [bug 508421](https://bugzilla.mozilla.org/show_bug.cgi?id=508421) /home/taras/builds/minefield/dist/bin/searchplugins /home/taras/builds/minefield/dist/bin/searchplugins/amazondotcom.xml /home/taras/builds/minefield/dist/bin/searchplugins/answers.xml /home/taras/builds/minefield/dist/bin/searchplugins/creativecommons.xml /home/taras/builds/minefield/dist/bin/searchplugins/eBay.xml /home/taras/builds/minefield/dist/bin/searchplugins/google.xml /home/taras/builds/minefield/dist/bin/searchplugins/wikipedia.xml /home/taras/builds/minefield/dist/bin/searchplugins/yahoo.xml I think these should be in a jar too.  
-  
-This concludes the list of Firefox application files read at startup. I haven't touched the stuff in the profile directories or libraries. I think it is realistic to get a tenfold reduction in physical files read by Firefox 3.6. 
-
-https://bugzilla.mozilla.org/show_bug.cgi?id=383167
diff --git a/source/_posts/2009-08-27-moving-files-into-jars.markdown b/source/_posts/2009-08-27-moving-files-into-jars.markdown
deleted file mode 100644
index 62c64a2..0000000
--- a/source/_posts/2009-08-27-moving-files-into-jars.markdown
+++ /dev/null
@@ -1,21 +0,0 @@
----
-comments: true
-date: 2009-08-27 10:40:09
-layout: post
-slug: moving-files-into-jars
-title: Moving Files Into JARs
-wordpress_id: 178
-categories:
-- mozilla
----
-
-Moving files into jars reduces amount of seeks on startup, and has miscellaneous other performance/organization benefits. I added resource://gre-resources/ which maps to jar:toolkit.jar!/res/.  
-  
-To move a file into a jar: 
-
-  1. Add a jar.mn entry.
-  2. Remove existing references to the file in Makefile.in, packages-static files
-  3. Add file to the removed-files.in list of dead files
-  4. Update urls refering to the file in the source. Sometimes one has to switch from using file streams and filenames to using channels and URIs. This is the hard part.
-  5. Set your bug as blocking bug [513027](https://bugzilla.mozilla.org/show_bug.cgi?id=513027).
-For an example see [bug 508421](https://bugzilla.mozilla.org/show_bug.cgi?id=508421).
diff --git a/source/_posts/2009-09-18-enforcing-inheritance-rules.markdown b/source/_posts/2009-09-18-enforcing-inheritance-rules.markdown
deleted file mode 100644
index 8883573..0000000
--- a/source/_posts/2009-09-18-enforcing-inheritance-rules.markdown
+++ /dev/null
@@ -1,17 +0,0 @@
----
-comments: true
-date: 2009-09-18 10:01:48
-layout: post
-slug: enforcing-inheritance-rules
-title: Enforcing Inheritance Rules
-wordpress_id: 180
-categories:
-- mozilla
-- dehydra
----
-
-While writing C++ sometimes one wishes that one could squeeze a little more out of the type system. In this particular case, Zack Weinberg (layout-refactorer extraordinaire), wanted to make sure that certain methods always get overridden in derived classes. Unfortunately, in that particular design, those methods were not pure-virtual. At this point most C++ hackers would cry a little and move on without any compiler assistance.  
-  
-Instead of crying, Zack added a NS_MUST_OVERRIDE attribute to methods along with a matching [Dehydra](https://developer.mozilla.org/En/Dehydra) script. See the [source code](http://hg.mozilla.org/mozilla-central/file/2047ed35d947/xpcom/analysis/must-override.js) and the [bug](https://bugzilla.mozilla.org/show_bug.cgi?id=512726) for how simple it can be to extend C++ with a useful new check.  
-  
-Nothing makes me happier than seeing developers land big code changes and accompany them with compiler checks instead of relying on programming folklore to maintain important invariants.
diff --git a/source/_posts/2009-09-30-corrupting-innocent-minds-with-gcc.markdown b/source/_posts/2009-09-30-corrupting-innocent-minds-with-gcc.markdown
deleted file mode 100644
index e63793c..0000000
--- a/source/_posts/2009-09-30-corrupting-innocent-minds-with-gcc.markdown
+++ /dev/null
@@ -1,14 +0,0 @@
----
-comments: true
-date: 2009-09-30 17:32:38
-layout: post
-slug: corrupting-innocent-minds-with-gcc
-title: Corrupting Innocent Minds With GCC
-wordpress_id: 184
-categories:
-- mozilla
----
-
-Ever since the plugin branch landed in GCC, I have been itching to explore the application-specific optimization space that it opens up. It's really hard to optimize code in the general case, but it's relatively easy to optimize for something for specific use-cases. We can rely on API-specific static analysis in order to get rid of the API-imposed overheads at compile time. Let me repeat, we can get rid of some API-induced suck (OO frameworks  usually have a lot of it) without sacrificing any of the benefits.  
-  
-Unfortunally, I got busy working on, supposedly, more important stuff such as making Firefox startup quicker, so my[ de-error-handling](https://bugzilla.mozilla.org/show_bug.cgi?id=517370) and de-virtualizer (basically possible with LTO, but we can prove that certain classes will never be overloaded via dynamic linking) ideas had to be put on indefinite hold. Luckily, one of David Humphrey's students decided to take on the first task, see his [blog post](http://ehren.wordpress.com/2009/09/30/popping-my-gimples-a-plan/) here. I'm really psyched about this, few things that are cooler than cross-project open source work involving the most important open source projects of our time :)
diff --git a/source/_posts/2009-10-08-restless-bug-fixing.markdown b/source/_posts/2009-10-08-restless-bug-fixing.markdown
deleted file mode 100644
index 9f1f8c0..0000000
--- a/source/_posts/2009-10-08-restless-bug-fixing.markdown
+++ /dev/null
@@ -1,20 +0,0 @@
----
-comments: true
-date: 2009-10-08 10:13:01
-layout: post
-slug: restless-bug-fixing
-title: Restless Bug Fixing
-wordpress_id: 186
-categories:
-- mozilla
----
-
-I spent the past couple weeks analyzing and improving fastload performance. I've long been suspicious of fastload, but only finally got around to investigating it in detail. I think there is some fundamentally ironic rule in software that if you put the word “fast” in the name of a component, it is bound to eventually become a performance bottleneck.  
-  
-Almost a decade has passed since the conception of this code, so it was time to update code's assumptions to reflect the capabilities of modern OSes. I landed the [fix](https://bugzilla.mozilla.org/show_bug.cgi?id=412796) today. It results in startup performance gains of 1-20% on various platforms I tested, making this the most exiting perf bug I've worked on.  
-  
-**Plans**  
-  
-Now that I've had my fill of almost a year's worth of startup performance analysis, for the remainder of the year I plan to refocus on static analysis. My main goal is decent  C support on Dehydra(not to mention the ever elusive GCC 4.5 compatibility) and to facilitate a production-quality DXR.  
-  
-I'm hoping that we'll end up with cool ways of dealing with the painful/slow boilerplate (bugs [520626](https://bugzilla.mozilla.org/show_bug.cgi?id=520626), [516085](https://bugzilla.mozilla.org/show_bug.cgi?id=516085) and [517370](https://bugzilla.mozilla.org/show_bug.cgi?id=517370))
diff --git a/source/_posts/2009-10-20-large-apps-just-have-to-start-slow.markdown b/source/_posts/2009-10-20-large-apps-just-have-to-start-slow.markdown
deleted file mode 100644
index 2d40201..0000000
--- a/source/_posts/2009-10-20-large-apps-just-have-to-start-slow.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2009-10-20 21:24:36
-layout: post
-slug: large-apps-just-have-to-start-slow
-title: Rant on Library IO
-wordpress_id: 188
-categories:
-- mozilla
----
-
-So I've been trying to figure out how optimize disk IO startup. I looked into IO caused by libraries and turns out that apps with big libraries are screwed. Here is how I came to this conclusion:  
-  
-Gnomer's [research](http://www.gnome.org/~lcolitti/gnome-startup/analysis/) on startup pointed out that dumb readahead leads to wins in terms file io. So I wrote some code and sure enough, reading in libxul on top of our main() function does indeed result in a significant measurable speed-up on both Linux and OSX.  
-  
-From the gnome page I found a link to some [diskstat](http://ds9a.nl/diskstat/) stuff. There lay a presentation with graphs that appear to show that OpenOffice has a much better cold IO pattern than Firefox. Given that there are some strong similarities between our application layouts I went digging to see if OpenOffice does something funny. And oh boy, it does do [funny](http://wiki.services.openoffice.org/wiki/Performance/Reorder_Symbols_For_Libraries) page reordering on Windows and "slightly-smarter-than-dumb-readahead-style library prefetch" on Linux...  
-  
-So here is an innocent question: Why is page-reordering not done as a PGO step? I mean shouldn't you fire up your app, feed some info back to the linker and be done with it? Another question: Why can't we mark certain files as "keep this whole file in ram if someone asks for part of it to be paged in"?  
-  
-So is the only way to fast application startup via static linking? It sure is easy to  
-  
-posix_fadvise(open(argv[0],O_RDONLY),  POSIX_FADV_WILLNEED);  
-  
-Are these hacks still the state of the art in making apps with large libraries startup fast?  
-  
-**Update:** Found some mentions of GNU Rope unfinishedware and a relatively recent blog [post](http://blogs.linux.ie/caolan/2007/04/24/controlling-symbol-ordering/)
diff --git a/source/_posts/2009-10-23-studying-library-io-systemtap-style.markdown b/source/_posts/2009-10-23-studying-library-io-systemtap-style.markdown
deleted file mode 100644
index 66a6f92..0000000
--- a/source/_posts/2009-10-23-studying-library-io-systemtap-style.markdown
+++ /dev/null
@@ -1,289 +0,0 @@
----
-comments: true
-date: 2009-10-23 16:25:39
-layout: post
-slug: studying-library-io-systemtap-style
-title: Studying Library IO - SystemTap Style
-wordpress_id: 194
-categories:
-- mozilla
----
-
-In my last blog [post](http://taras.glek.net/blog/2009/10/20/large-apps-just-have-to-start-slow/) I expressed frustation with slowness induced by library IO. Then I went on a mission to measure it. I have been wanting to this for a while, but I figured that only DTrace can get this info without recompiling my kernel. So I tried to build Mozilla under Slowlaris (but the linker got up to 3GB and then set there swapping, ensuring that the nickname is justified). Then I fired up DTrace on the mini, but ran screaming because it seemed like fbt DTrace provider refused to let me dereference structs (later Joel told me that I'm supposed to copy data explicitly [like here](http://blogs.sun.com/timf/entry/dtrace_saves_the_day_again)).  
-  
-But while googling for a fbt workaround, I stumbled upon a DTrace/SystemTap comparision wiki. [SystemTap](http://sourceware.org/systemtap/wiki)? The DTrace knockoff I have been hearing about? It works? This was a lightbulb moment where I realized that Linux was about to provide me with more information than I thought was possible.  
-  
-So here is the data I got out of it:  
-  
-Writing scripts in systemtap felt really natural after I figured out that pointers are to be dereferenced as arrays and what some of the error messages really meant. In the script I watch vfs_read() for io done via read() syscall, but it turns out that mmap() io actually happens via readahead. Here is the systemtap [script](http://people.mozilla.com/~tglek/kernelio.stp). I believe I accounted for all io. ext4_get_block (which seems to be the main function ext4 reads file data with) did not spend any time outside of that called by the functions I was tapping into.  
-  
-I haven't had much time to draw too many conclusions out of the data, posting it as an example of systemtap use. libxul accounts for most io both in terms of bytes and time spent. We'll be fixing that, not yet sure as to what strategy to employ for the rest of the libraries.  
-  
-SELECT file, sum(size) as bytesread, sum(time)/1000 as ms from startup  group by file order by bytesread desc ; 
-    
-    file                                   | bytesread | ms
-    -------------------------------------------------------------------------+-----------+-----
-    /home/taras/firefox/libxul.so/                                          |  19530240 | 103
-    /usr/lib/libgtk-x11-2.0.so.0.1800.2/                                    |   3277312 |  15
-    /home/taras/firefox/chrome/toolkit.jar/                                 |   2097152 |   8
-    /home/taras/firefox/libmozjs.so/                                        |   1835520 |  36
-    /home/taras/.mozilla/firefox/imph4tsg.default/XPC.mfasl/                |   1671168 |   3
-    /home/taras/firefox/chrome/browser.jar/                                 |   1572864 |   5
-    /usr/share/icons/gnome/icon-theme.cache/                                |   1441792 |   7
-    /home/taras/firefox/libnss3.so/                                         |   1311232 |  18
-    /usr/lib/libX11.so.6.3.0/                                               |   1049088 |   5
-    /home/taras/.mozilla/firefox/imph4tsg.default/XUL.mfasl/                |    995328 |   2
-    /usr/lib/libgnomeui-2.so.0.2400.1/                                      |    918016 |   3
-    /usr/lib/libfreetype.so.6.3.20/                                         |    786944 |   3
-    /home/taras/firefox/libsqlite3.so/                                      |    655872 |  10
-    /usr/lib/libgconf-2.so.4.1.5/                                           |    655872 |   1
-    /usr/lib/libbonoboui-2.so.0.0.0/                                        |    655872 |   2
-    /usr/lib/libgdk-x11-2.0.so.0.1800.2/                                    |    655872 |   2
-    /usr/lib/libcrypto.so.1.0.0/                                            |    655872 |   2
-    /home/taras/firefox/chrome/en-US.jar/                                   |    655360 |   2
-    /usr/lib/libORBit-2.so.0.1.0/                                           |    524800 |   2
-    /lib/libasound.so.2.0.0/                                                |    524800 |  18
-    /home/taras/firefox/libnspr4.so/                                        |    524800 |  17
-    /usr/lib/libxml2.so.2.7.5/                                              |    524800 |   1
-    /usr/lib/libbonobo-activation.so.4.0.0/                                 |    524800 |   1
-    /usr/lib/libgnomecanvas-2.so.0.2600.0/                                  |    524800 |   1
-    /usr/lib/libXt.so.6.0.0/                                                |    524800 |  14
-    /lib/libgssapi_krb5.so.2.2/                                             |    524800 |   1
-    /usr/lib/libatk-1.0.so.0.2809.1/                                        |    524800 |   2
-    /home/taras/firefox/libnssckbi.so/                                      |    524800 |   6
-    /usr/lib/libbonobo-2.so.0.0.0/                                          |    524800 |   1
-    /usr/lib/libgnomevfs-2.so.0.2400.2/                                     |    524800 |   2
-    /home/taras/firefox/libsmime3.so/                                       |    393728 |  15
-    /usr/lib/libart_lgpl_2.so.2.3.20/                                       |    393728 |   1
-    /usr/lib/libvorbis.so.0.4.3/                                            |    393728 |   1
-    /home/taras/firefox/components/libbrowsercomps.so/                      |    393728 |  12
-    /lib/libresolv-2.10.90.so/                                              |    393728 |   0
-    /home/taras/firefox/libnssdbm3.so/                                      |    393728 |  15
-    /home/taras/firefox/libfreebl3.so/                                      |    393728 |  13
-    /home/taras/firefox/libssl3.so/                                         |    393728 |   8
-    /usr/lib/libssl.so.1.0.0/                                               |    393728 |   1
-    /lib/libkrb5.so.3.3/                                                    |    393728 |  24
-    /lib/libglib-2.0.so.0.2200.2/                                           |    393728 |   1
-    /usr/share/fonts/dejavu/DejaVuSans.ttf/                                 |    393216 |   1
-    /home/taras/firefox/components/browser.xpt/                             |    378141 |   6
-    /usr/lib/gtk-2.0/2.10.0/engines/libclearlooks.so/                       |    262656 |   1
-    /lib/libexpat.so.1.5.2/                                                 |    262656 |   1
-    /usr/lib/libfontconfig.so.1.4.3/                                        |    262656 |   0
-    /home/taras/firefox/components/libimgicon.so/                           |    262656 |   1
-    /lib/libkeyutils-1.2.so/                                                |    262656 |   0
-    /usr/lib/libgnome-keyring.so.0.1.1/                                     |    262656 |   1
-    /usr/lib/libgnome-2.so.0.2800.0/                                        |    262656 |   0
-    /usr/lib/libXau.so.6.0.0/                                               |    262656 |   0
-    /usr/lib/libXinerama.so.1.0.0/                                          |    262656 |   0
-    /usr/lib/libXdamage.so.1.1.0/                                           |    262656 |   0
-    /usr/lib/libXcomposite.so.1.0.0/                                        |    262656 |   0
-    /usr/lib/libfam.so.0.0.0/                                               |    262656 |  22
-    /home/taras/firefox/components/libdbusservice.so/                       |    262656 |  12
-    /home/taras/firefox/components/libmozgnome.so/                          |    262656 |  11
-    /usr/lib/libICE.so.6.3.0/                                               |    262656 |   1
-    /home/taras/firefox/libnssutil3.so/                                     |    262656 |  22
-    /usr/lib/libpangoft2-1.0.so.0.2600.0/                                   |    262656 |   0
-    /lib/libk5crypto.so.3.1/                                                |    262656 |   1
-    /home/taras/firefox/components/libbrowserdirprovider.so/                |    262656 |   9
-    /home/taras/firefox/libsoftokn3.so/                                     |    262656 |  10
-    /usr/lib/libxcb.so.1.1.0/                                               |    262656 |   1
-    /home/taras/firefox/components/libnkgnomevfs.so/                        |    262656 |  14
-    /home/taras/firefox/firefox-bin/                                        |    262547 |  13
-    /usr/share/fonts/dejavu/DejaVuSerif.ttf/                                |    262144 |   0
-    /home/taras/.mozilla/firefox/imph4tsg.default/compreg.dat/              |    147563 |   0
-    /usr/share/X11/locale/locale.alias/                                     |    134322 |  18
-    /lib/libc-2.10.90.so/                                                   |    132608 |   1
-    /lib/libtinfo.so.5.7/                                                   |    132096 |   0
-    /usr/lib/gio/modules/libgioremote-volume-monitor.so/                    |    131584 |   0
-    /lib/libuuid.so.1.3.0/                                                  |    131584 |   0
-    /usr/lib/libvorbisfile.so.3.3.2/                                        |    131584 |   0
-    /lib/libkrb5support.so.0.1/                                             |    131584 |   0
-    /usr/lib/libgvfscommon.so.0.0.0/                                        |    131584 |   0
-    /lib/librt-2.10.90.so/                                                  |    131584 |   0
-    /usr/lib/libavahi-common.so.3.5.1/                                      |    131584 |   0
-    /usr/lib/libnotify.so.1.1.3/                                            |    131584 |   0
-    /usr/lib/libavahi-glib.so.1.0.1/                                        |    131584 |   0
-    /usr/lib/gio/modules/libgvfsdbus.so/                                    |    131584 |   0
-    /usr/lib/libXcursor.so.1.0.2/                                           |    131584 |   0
-    /usr/lib/libXi.so.6.1.0/                                                |    131584 |   3
-    /usr/lib/libgailutil.so.18.0.1/                                         |    131584 |   0
-    /usr/lib/libXrender.so.1.3.0/                                           |    131584 |   0
-    /lib/libcap-ng.so.0.0.0/                                                |    131584 |   0
-    /usr/lib/libSM.so.6.0.0/                                                |    131584 |   0
-    /lib/libudev.so.0.4.2/                                                  |    131584 |   0
-    /lib/libgmodule-2.0.so.0.2200.2/                                        |    131584 |   0
-    /usr/lib/libXfixes.so.3.1.0/                                            |    131584 |   0
-    /lib/libgobject-2.0.so.0.2200.2/                                        |    131584 |   0
-    /usr/lib/libXrandr.so.2.2.0/                                            |    131584 |   1
-    /lib/libgio-2.0.so.0.2200.2/                                            |    131584 |   1
-    /lib/libpopt.so.0.0.0/                                                  |    131584 |   0
-    /lib/libz.so.1.2.3/                                                     |    131584 |   0
-    /usr/lib/libXext.so.6.4.0/                                              |    131584 |   0
-    /usr/lib/libpangocairo-1.0.so.0.2600.0/                                 |    131584 |   0
-    /usr/lib/libogg.so.0.6.0/                                               |    131584 |   0
-    /usr/lib/libcairo.so.2.10800.8/                                         |    131584 |   0
-    /usr/lib/libavahi-client.so.3.2.5/                                      |    131584 |   1
-    /usr/lib/libtdb.so.1.1.5/                                               |    131584 |   0
-    /usr/lib/libORBitCosNaming-2.so.0.1.0/                                  |    131584 |   0
-    /usr/lib/libstdc++.so.6.0.13/                                           |    131584 |   1
-    /lib/libgthread-2.0.so.0.2200.2/                                        |    131584 |   0
-    /lib/libgcc_s-4.4.1-20091008.so.1/                                      |    131584 |   0
-    /lib/libdbus-1.so.3.4.0/                                                |    131584 |   0
-    /usr/lib/libcanberra-gtk.so.0.1.4/                                      |    131584 |   0
-    /usr/lib/libpango-1.0.so.0.2600.0/                                      |    131584 |   0
-    /usr/lib/libpng12.so.0.39.0/                                            |    131584 |   0
-    /usr/lib/libltdl.so.7.2.0/                                              |    131584 |   0
-    /usr/lib/gtk-2.0/modules/libcanberra-gtk-module.so/                     |    131584 |   0
-    /lib/libnss_files-2.10.90.so/                                           |    131584 |   0
-    /lib/libcom_err.so.2.1/                                                 |    131584 |   0
-    /usr/lib/libcanberra.so.0.2.1/                                          |    131584 |   0
-    /usr/lib/libdbus-glib-1.so.2.1.0/                                       |    131584 |   0
-    /usr/lib/gtk-2.0/modules/libpk-gtk-module.so/                           |    131584 |   0
-    /usr/lib/libpixman-1.so.0.16.2/                                         |    131584 |   0
-    /usr/lib/libgdk_pixbuf-2.0.so.0.1800.2/                                 |    131584 |   0
-    /home/taras/.fontconfig/3830d5c3ddfd5cd38a049b759396e72e-x86.cache-2/   |    131072 |   0
-    /usr/lib/gconv/gconv-modules.cache/                                     |    131072 |   0
-    /home/taras/.mozilla/firefox/imph4tsg.default/xpti.dat/                 |    101060 |  14
-    /home/taras/firefox/greprefs.js/                                        |     74132 |  12
-    /home/taras/.mozilla/firefox/imph4tsg.default/urlclassifier3.sqlite/    |     65832 |  85
-    /home/taras/.mozilla/firefox/imph4tsg.default/places.sqlite/            |     53396 |  43
-    /home/taras/firefox/defaults/pref/firefox.js/                           |     40803 |  17
-    /usr/lib/gio/modules/libgiofam.so/                                      |     33280 |  13
-    /usr/lib/gio/modules/libgiogconf.so/                                    |     33280 |  13
-    /home/taras/firefox/libxpcom.so/                                        |     33280 |  13
-    /usr/lib/gconv/UTF-16.so/                                               |     33280 |  16
-    /usr/lib/libXss.so.1.0.0/                                               |     33280 |  14
-    /home/taras/firefox/libplc4.so/                                         |     33280 |   5
-    /home/taras/firefox/libplds4.so/                                        |     33280 |   0
-    /usr/share/X11/locale/locale.dir/                                       |     32768 |  16
-    /home/taras/firefox/run-mozilla.sh/                                     |     27368 |  12
-    /usr/share/icons/hicolor/index.theme/                                   |     24293 |  25
-    /home/taras/firefox/chrome/icons/default/default48.png/                 |     22164 |   1
-    /home/taras/.mozilla/firefox/imph4tsg.default/cert8.db/                 |     16644 |  13
-    /usr/share/icons/gnome/index.theme/                                     |     12657 |  41
-    /home/taras/firefox/chrome/icons/default/default32.png/                 |     11964 |   1
-    /home/taras/.mozilla/firefox/imph4tsg.default/search.json/              |     11392 |  14
-    /usr/share/themes/Clearlooks/gtk-2.0/gtkrc/                             |     11287 |  18
-    /etc/fonts/conf.avail/65-fonts-persian.conf/                            |      9880 |   1
-    /dev/urandom/                                                           |      8468 |   4
-    /home/taras/.mozilla/firefox/imph4tsg.default/secmod.db/                |      8452 |   1
-    /usr/share/icons/Bluecurve/cursors/xterm/                               |      8192 |  12
-    /usr/share/icons/Bluecurve/cursors/bottom_right_corner/                 |      8192 |   7
-    /etc/fonts/conf.avail/65-nonlatin.conf/                                 |      7706 |   0
-    /home/taras/firefox/firefox/                                            |      7695 |   0
-    /etc/fonts/fonts.conf/                                                  |      5325 |  17
-    /usr/share/locale/locale.alias/                                         |      5024 |   8
-    /usr/share/icons/Mist/index.theme/                                      |      4771 |   7
-    /home/taras/.mozilla/firefox/imph4tsg.default/key3.db/                  |      4356 |   1
-    /home/taras/firefox/chrome/icons/default/default16.png/                 |      4332 |  21
-    /usr/share/X11/locale/en_US.UTF-8/XLC_LOCALE/                           |      4287 |  12
-    /proc/meminfo/                                                          |      4096 |   0
-    /etc/fonts/conf.avail/30-metric-aliases.conf/                           |      3939 |   0
-    /etc/passwd/                                                            |      3766 |   0
-    /etc/gtk-2.0/i386-redhat-linux-gnu/gdk-pixbuf.loaders/                  |      3618 |  16
-    /etc/pango/i386-redhat-linux-gnu/pango.modules/                         |      3452 |  16
-    /home/taras/.mozilla/firefox/imph4tsg.default/content-prefs.sqlite/     |      3252 |   8
-    /etc/fonts/conf.avail/25-unhint-nonlatin.conf/                          |      2941 |  12
-    /etc/localtime/                                                         |      2899 |   0
-    /home/taras/.mozilla/firefox/imph4tsg.default/permissions.sqlite/       |      2228 |   3
-    /home/taras/.mozilla/firefox/imph4tsg.default/cookies.sqlite/           |      2212 |  15
-    /home/taras/firefox/application.ini/                                    |      2128 |  18
-    /etc/fonts/conf.avail/40-nonlatin.conf/                                 |      2069 |   0
-    /usr/share/fontconfig/conf.avail/57-dejavu-sans.conf/                   |      2011 |   0
-    /etc/fonts/conf.avail/45-latin.conf/                                    |      1837 |   0
-    /home/taras/.mozilla/firefox/imph4tsg.default/prefs.js/                 |      1827 |  29
-    /etc/nsswitch.conf/                                                     |      1734 |  20
-    /etc/fonts/conf.avail/60-latin.conf/                                    |      1701 |   0
-    /etc/fonts/conf.avail/90-synthetic.conf/                                |      1691 |   6
-    /usr/share/fontconfig/conf.avail/57-dejavu-serif.conf/                  |      1649 |   0
-    /lib/libdl-2.10.90.so/                                                  |      1536 |   0
-    /usr/share/fontconfig/conf.avail/57-dejavu-sans-mono.conf/              |      1509 |   1
-    /home/taras/firefox/chrome/toolkit.manifest/                            |      1418 |   8
-    /usr/share/fontconfig/conf.avail/65-google-droid-sans.conf/             |      1403 |   0
-    /home/taras/firefox/chrome/en-US.manifest/                              |      1251 |   0
-    /usr/share/fontconfig/conf.avail/25-ttf-arphic-uming-bitmaps.conf/      |      1221 |  10
-    /home/taras/firefox/defaults/pref/firefox-branding.js/                  |      1186 |  11
-    /etc/fonts/conf.avail/30-urw-aliases.conf/                              |      1164 |   0
-    /etc/fonts/conf.d/25-no-bitmap-fedora.conf/                             |      1160 |   0
-    /etc/fonts/conf.avail/20-unhint-small-vera.conf/                        |      1157 |   0
-    /home/taras/.mozilla/firefox/imph4tsg.default/formhistory.sqlite/       |      1156 |  14
-    /usr/share/icons/Fedora/index.theme/                                    |      1128 |  32
-    /usr/share/fontconfig/conf.avail/90-smc-fonts.conf/                     |      1094 |  15
-    /usr/share/fontconfig/conf.avail/41-ttf-arphic-uming.conf/              |      1043 |   0
-    /home/taras/firefox/chrome/browser.manifest/                            |       963 |   0
-    /usr/share/fontconfig/conf.avail/64-ttf-arphic-uming.conf/              |       951 |   0
-    /etc/fonts/conf.avail/20-fix-globaladvance.conf/                        |       912 |   0
-    /usr/share/fontconfig/conf.avail/20-unhint-small-dejavu-sans-mono.conf/ |       866 |  20
-    /home/taras/startup.html/                                               |       864 |  17
-    /usr/share/fontconfig/conf.avail/20-unhint-small-dejavu-serif.conf/     |       858 |   0
-    /usr/share/fontconfig/conf.avail/20-unhint-small-dejavu-sans.conf/      |       856 |   0
-    /home/taras/.mozilla/firefox/imph4tsg.default/localstore.rdf/           |       850 |  11
-    /home/taras/.mozilla/firefox/imph4tsg.default/sessionstore.js/          |       762 |  13
-    /usr/share/fontconfig/conf.avail/65-ipa-pgothic.conf/                   |       705 |   8
-    /lib/ld-2.10.90.so/                                                     |       704 |   0
-    /etc/fonts/conf.avail/69-unifont.conf/                                  |       672 |   0
-    /usr/share/fontconfig/conf.avail/75-ttf-arphic-ukai-select.conf/        |       611 |  22
-    /etc/gtk-2.0/i386-redhat-linux-gnu/gtk.immodules/                       |       598 |  11
-    /etc/fonts/conf.avail/49-sansserif.conf/                                |       545 |   0
-    /usr/share/fontconfig/conf.avail/90-ttf-arphic-uming-embolden.conf/     |       541 |  14
-    /usr/share/fontconfig/conf.avail/90-ttf-arphic-ukai-embolden.conf/      |       540 |   0
-    /lib/libselinux.so.1/                                                   |       512 |   0
-    /lib/libpthread-2.10.90.so/                                             |       512 |   0
-    /lib/libutil-2.10.90.so/                                                |       512 |   0
-    /lib/libm-2.10.90.so/                                                   |       512 |   0
-    /usr/share/fontconfig/conf.avail/66-lohit-kashmiri@devanagari.conf/     |       488 |   0
-    /usr/share/fontconfig/conf.avail/66-lohit-sindhi@devanagari.conf/       |       484 |   0
-    /usr/share/fontconfig/conf.avail/66-lohit-maithili.conf/                |       478 |   3
-    /usr/share/fontconfig/conf.avail/66-lohit-assamese.conf/                |       477 |  18
-    /usr/share/fontconfig/conf.avail/66-lohit-gujarati.conf/                |       477 |   9
-    /usr/share/fontconfig/conf.avail/66-lohit-konkani.conf/                 |       476 |  14
-    /usr/share/fontconfig/conf.avail/66-lohit-bengali.conf/                 |       475 |  15
-    /usr/share/fontconfig/conf.avail/66-lohit-marathi.conf/                 |       475 |   7
-    /usr/share/fontconfig/conf.avail/66-lohit-kannada.conf/                 |       475 |   0
-    /usr/share/fontconfig/conf.avail/66-lohit-punjabi.conf/                 |       475 |   0
-    /proc/cpuinfo/                                                          |       474 |   0
-    /usr/share/fontconfig/conf.avail/67-lohit-nepali.conf/                  |       473 |   0
-    /usr/share/fontconfig/conf.avail/66-lohit-telugu.conf/                  |       473 |   1
-    /usr/share/fontconfig/conf.avail/66-lohit-tamil.conf/                   |       471 |   0
-    /usr/share/fontconfig/conf.avail/66-lohit-hindi.conf/                   |       471 |   0
-    /usr/share/fontconfig/conf.avail/66-lohit-oriya.conf/                   |       471 |   0
-    /bin/bash/                                                              |       403 |   0
-    /usr/share/fontconfig/conf.avail/41-ttf-arphic-ukai.conf/               |       400 |   0
-    /etc/gnome-vfs-2.0/modules/default-modules.conf/                        |       399 |   6
-    /etc/fonts/conf.avail/80-delicious.conf/                                |       388 |   1
-    /usr/share/fontconfig/conf.avail/25-ttf-arphic-uming-render.conf/       |       362 |   0
-    /usr/share/fontconfig/conf.avail/25-ttf-arphic-ukai-render.conf/        |       361 |  18
-    /usr/share/fontconfig/conf.avail/35-ttf-arphic-uming-aliases.conf/      |       353 |   0
-    /usr/share/fontconfig/conf.avail/60-google-droid-sans-mono.conf/        |       345 |  16
-    /usr/share/fontconfig/conf.avail/35-ttf-arphic-ukai-aliases.conf/       |       343 |   1
-    /usr/share/fontconfig/conf.avail/61-stix.conf/                          |       332 |  10
-    /usr/share/fontconfig/conf.avail/59-google-droid-serif.conf/            |       329 |   4
-    /home/taras/firefox/defaults/pref/firefox-l10n.js/                      |       257 |   9
-    /etc/fonts/conf.avail/50-user.conf/                                     |       245 |   0
-    /home/taras/firefox/defaults/pref/reporter.js/                          |       205 |  16
-    /etc/fonts/conf.avail/51-local.conf/                                    |       189 |   0
-    /var/cache/fontconfig/0251a5afa6ac727a1e32b7d4d4aa7cf0-x86.cache-2/     |       160 |  15
-    /home/taras/.mozilla/firefox/imph4tsg.default/compatibility.ini/        |       159 |  15
-    /home/taras/.mozilla/firefox/imph4tsg.default/urlclassifierkey3.txt/    |       154 |  13
-    /etc/hosts/                                                             |       147 |  13
-    /home/taras/firefox/defaults/pref/channel-prefs.js/                     |       143 |   0
-    /etc/resolv.conf/                                                       |       134 |  10
-    /home/taras/firefox/platform.ini/                                       |       132 |   7
-    /usr/share/gvfs/remote-volume-monitors/hal.monitor/                     |       123 |   0
-    /usr/share/gvfs/remote-volume-monitors/gdu.monitor/                     |       123 |   7
-    /usr/share/gvfs/remote-volume-monitors/gphoto2.monitor/                 |       115 |  32
-    /home/taras/.mozilla/firefox/imph4tsg.default/extensions.ini/           |       112 |  12
-    /home/taras/.mozilla/firefox/imph4tsg.default/extensions.cache/         |       106 |  14
-    /etc/gtk-2.0/gtkrc/                                                     |        97 |  20
-    /home/taras/.mozilla/firefox/profiles.ini/                              |        94 |  21
-    /usr/share/themes/Default/gtk-2.0-key/gtkrc/                            |        82 |  20
-    /home/taras/firefox/chrome/pippki.manifest/                             |        69 |   0
-    /home/taras/firefox/browserconfig.properties/                           |        68 |  37
-    /home/taras/.Xauthority/                                                |        52 |  13
-    /var/lib/dbus/machine-id/                                               |        33 |  13
-    /etc/host.conf/                                                         |        26 |  13
-    /etc/gnome-vfs-2.0/modules/ssl-modules.conf/                            |        12 |   1
-    /home/taras/.mozilla/firefox/Crash Reports/InstallTime20091022031207/   |        10 |  22
-    /home/taras/.mozilla/firefox/Crash Reports/LastCrash/                   |        10 |   1
-    /home/taras/.mozilla/firefox/imph4tsg.default/cookies.sqlite-journal/   |         5 |   1
-    (263 rows)
diff --git a/source/_posts/2009-11-06-fsoss-dehydra-update.markdown b/source/_posts/2009-11-06-fsoss-dehydra-update.markdown
deleted file mode 100644
index efa566b..0000000
--- a/source/_posts/2009-11-06-fsoss-dehydra-update.markdown
+++ /dev/null
@@ -1,33 +0,0 @@
----
-comments: true
-date: 2009-11-06 17:27:53
-layout: post
-slug: fsoss-dehydra-update
-title: FSOSS & Dehydra Update
-wordpress_id: 196
-categories:
-- mozilla
-- dehydra
----
-
-Last week I was in Canada to present at [FSOSS](http://fsoss.senecac.on.ca/2009/) with [David Humphrey](http://vocamus.net/dave/) on awesome Mozilla Tools: Dehydra, DXR, Pork, etc. I think we managed to convey the message regarding what a sad affair that current developer development tools are.  
-  
-**General-Purpose Dehydra Scripts**  
-  
-Dehydra grew out of Mozilla's constant need to figure out what is going on in the source code. As a result most of our scripts are very Mozilla API-specific. This makes harder for people outside of Mozilla to learn Dehydra. There is no library of Dehydra code that one can just plugin to start analyzing their codebase. Instead one has to sit down, figure out what Dehydra is capable of and then see if any of the problems facing the developer can be solved this way. If anyone wants to contribute such a library, let me know.  
-  
-In the meantime, more general-purpose analyses are surfacing.  
-  
-**Shadowed Members**  
-  
-My favourite script so far is the member-shadowing checker. I ran into a member-shadowing warning that is unique to Sun's C++ compiler. It was triggered by some code that I just landed on the tree. I fixed the warning, but within a few days a coworker ran into a bug caused by that member shadowing(due to having an unlucky revision of the code). The following example shows how simple it was to implement the warning in GCC/Dehydra.  
-  
-  
-  
-See [bug 522776](https://bugzilla.mozilla.org/show_bug.cgi?id=522776) for the complete story on adding the member shadowing check to Mozilla.  
-  
-**Printf** Another general purpose analysis was done outside of Mozilla by Philip Taylor for [his game](http://os.wildfiregames.com/). His [script](http://svn.wildfiregames.com/public/ps/trunk/build/dehydra/printf-type-check.js) checks wide printf format strings (which are overlooked by gcc). Independently, Benjamin wrote a printf checker for Mozilla printf-like code, see [bug 493996](https://bugzilla.mozilla.org/show_bug.cgi?id=493996).  
-  
-**Custom Sections in Object Files** We have long speculated about how nice it would be if Dehydra could emit info into object files that could then be yanked out of the resulting binary (by say, valgrind). [bug 523435](https://bugzilla.mozilla.org/show_bug.cgi?id=523435) will soon make that a reality.  
-  
-**Update:** [Two](http://www.flickr.com/photos/mhoye/4058902208/in/photostream/) [photos](http://www.flickr.com/photos/mhoye/4058902456/sizes/l/in/photostream/) from FSOSS.
diff --git a/source/_posts/2009-11-20-dehydra-testsuite-passes-on-gcc-4-5.markdown b/source/_posts/2009-11-20-dehydra-testsuite-passes-on-gcc-4-5.markdown
deleted file mode 100644
index c22f2ad..0000000
--- a/source/_posts/2009-11-20-dehydra-testsuite-passes-on-gcc-4-5.markdown
+++ /dev/null
@@ -1,19 +0,0 @@
----
-comments: true
-date: 2009-11-20 16:24:04
-layout: post
-slug: dehydra-testsuite-passes-on-gcc-4-5
-title: Dehydra Testsuite Passes on GCC 4.5
-wordpress_id: 209
-categories:
-- mozilla
-- dehydra
----
-
-I spent couple of days fixing the remaining test-suite failures on GCC 4.5 trunk for [Dehydra](https://developer.mozilla.org/En/Dehydra). Since the last time I looked into this, GCC went from crashing all over the place to only crashing if I did something bad. It was nice to discover that as a result of switching to 4.5 Dehydra users will get saner .isExplicit behavior and more precise location info.  
-  
-Treehydra will take more work due to me [misunderstanding](https://bugzilla.mozilla.org/show_bug.cgi?id=510190) GTY annotations.  
-  
-By the way, I am really grateful for all of the people who contributed GCC 4.5 fixes so far. You guys have been a big help in getting Dehydra testsuite to 100% on 4.5. Looks like I will meet my goals to finish De+Treehydra by the end of the year in time for GCC 4.5 release and my "Introducing Dehydra to the Developer World"-type talk at [LinuxConf.au.nz 2010](http://www.lca2010.org.nz/programme/schedule/view_talk/50151?day=thursday).  
-  
-**Startup** I reduced my focus on startup speed at the moment to catch up on Dehydra. I plan to work on reducing xpconnect overhead during startup next, ie more of [this bug](https://bugzilla.mozilla.org/show_bug.cgi?id=512584).
diff --git a/source/_posts/2009-12-17-javascript-dom.markdown b/source/_posts/2009-12-17-javascript-dom.markdown
deleted file mode 100644
index 37c5d89..0000000
--- a/source/_posts/2009-12-17-javascript-dom.markdown
+++ /dev/null
@@ -1,24 +0,0 @@
----
-comments: true
-date: 2009-12-17 15:43:01
-layout: post
-slug: javascript-dom
-title: JavaScript DOM
-wordpress_id: 213
-categories:
-- mozilla
----
-
-I filed[ bug 533874](https://bugzilla.mozilla.org/show_bug.cgi?id=533874) to expose the JavaScript AST to JS, but turns out I need to explain why it's important to expose the JavaScript AST. So lets start from the beginning.  
-  
-My name is Taras and I like to wrestle useful information out of tools that do not think to offer it. I firmly believe that writing/maintaining code is more difficult than it should be. I think the current organization of compilers is partially responsible for it.  
-  
-**Related Prior Work **Some groups at Mozilla have realized that inspection and refactoring of code are tasks that will often consume as many people as can be thrown at it so there has to be a better way. That better way is through tools: get computers to do things that are difficult for humans. We do that a lot for other kinds of tasks, but not so much for computers. For example, when was the last something you googled something using telnet? Yet our tools for presenting and analyzing code are about as sophisticated as telnet. For some reason it is easier to find some random piece of information on the web than it is to find what code implements a function that is being called from my code.  
-  
-As the original author, I think [Dehydra](https://developer.mozilla.org/En/Dehydra), [Treehydra](https://developer.mozilla.org/en/Treehydra) on top of the GCC plugin [API](http://gcc.gnu.org/wiki/GCC_PluginAPI) give us a pretty reasonable way to extract useful information out of our C++ code. I feel lost and confused without Dave's [DXR](http://australia.proximity.on.ca/dxr/), the JS team routinely breaks (and fixes) invariants in the JS engine and we've been able to wipe out certain classes of bugs (ie code patterns that cause them) mozilla-wide. I'm looking forward to reducing the footprint of Mozilla by deleting [more](https://bugzilla.mozilla.org/show_bug.cgi?id=457262) dead code.  
-  
-**JavaScript Needs** My efforts so far have focused on C++ because it is finicky language and developers need all the help they can get with it. I think we need to the same thing for JavaScript. I think there is a lot of useful information in JavaScript code that is burried and hard to get to. [Joshua Cranmer](http://quetzalcoatal.blogspot.com/) broke new ground in building [JSHydra](https://developer.mozilla.org/en/JSHydra) on top of SpiderMonkey. This way one can parse JavaScript in exact same way as Spidermonkey sees it (something that can only be approximated with other approaches). I think we should offer the ability to analyze js code within Spidermonkey. Unfortunately, he is a busy student so he doesn't have the time to develop JSHydra this to the next level. ** How Would JavaScript Developers Benefit?** Currently we have jshydra deployed on AMO to scan javascript for potential issues to make the reviewer's job more productive. Dave Humphrey is working away on integrating JSHydra into DXR so we can have semantic navigation of JavaScript: what components are implemented JavaScript, wouldn't it be nice to know who calls certain methods(including javascript callsites), etc. Gandalf has a cool idea where he needs to be able to extract translatable strings out of JetPacks. I believe JetPack people in general would like to be able to analyze JS code more.  
-  
-I think it's clear that the common trend in all these tasks is to turn an opaque text blob into something that can be easily navigated programatically. Wouldn't it suck to not to be able to walk the DOM for HTML? Why is it ok to accept that handicap for the essense of all programs?  
-  
-**How Should This Be Solved?** I don't know for sure, but my friend Jim Blandy, came up with a good suggestion. We already have eval/uneval in SpiderMonkey. it would be really cool to extend uneval to produce a iteratable data structure instead of a text blob. So I filed a [bug 533874](https://bugzilla.mozilla.org/show_bug.cgi?id=533874) on this, and this my explanation of why I think that would be a very empowering feature to expose ASTs in JavaScript.
diff --git a/source/_posts/2010-01-04-some-developers-manually-grope-around-in-the-dark.markdown b/source/_posts/2010-01-04-some-developers-manually-grope-around-in-the-dark.markdown
deleted file mode 100644
index d5b2f32..0000000
--- a/source/_posts/2010-01-04-some-developers-manually-grope-around-in-the-dark.markdown
+++ /dev/null
@@ -1,20 +0,0 @@
----
-comments: true
-date: 2010-01-04 20:27:03
-layout: post
-slug: some-developers-manually-grope-around-in-the-dark
-title: Some developers manually grope around in the dark
-wordpress_id: 216
-categories:
-- mozilla
-- dehydra
-- static-analysis
----
-
-Cool thing about static analysis is that you can ask painful-for-humans questions about your codebase AND have them answered. Here are two that got answered by Ehren:  
-  
-Where do function bodies continue after return statements (ie obviously dead/broken code)? [Bug 535646](https://bugzilla.mozilla.org/show_bug.cgi?id=535646).  
-  
-How many functions in Mozilla could/should be marked static? [Bug 536427](https://bugzilla.mozilla.org/show_bug.cgi?id=536427).  
-  
-Awesome!
diff --git a/source/_posts/2010-01-04-windows-7-startup-exploration.markdown b/source/_posts/2010-01-04-windows-7-startup-exploration.markdown
deleted file mode 100644
index e66f72e..0000000
--- a/source/_posts/2010-01-04-windows-7-startup-exploration.markdown
+++ /dev/null
@@ -1,60 +0,0 @@
----
-comments: true
-date: 2010-01-04 11:28:49
-layout: post
-slug: windows-7-startup-exploration
-title: Windows 7 Startup Exploration
-wordpress_id: 212
-categories:
-- mozilla
-- startup
----
-
-I did some digging to figure out if one can setup cold-startup testing in Windows 7 without nasty hacks. My conclusion is: sorta-kinda.  
-  
-**The Good - Most of the Ingredients Are Present **  
-  
-I haven't actively used Windows since pre-XP days. It looks like it has come a long way since then: there is now a decent interactive shell, all kinds of settings/services can be controlled from the commandline and there is even sudo-like functionality.  
-  
-PowerShell takes inspiration from the korn shell and throws in .net which allows for much nicer "shell programming" than the dominant bash shell.  
-  
-mountvol is a terrible equivalent to mount in linux - but it exists, so I'm happy.  
-  
-NTFS junctions are frustrating equivalents to links in a unix filesystem.  
-  
-**The Bad**  
-  
-The essential ability to completely flush filesystem caches isn't there. This isn't quite as embarrassing as it seems as Mac OS X's purge command does not flush the page cache (resulting in mmapped files not purged from cache), so technically OS X has the same limitation and only Linux gets it right.  
-  
-**The Ugly Workaround**  
-  
-After much brainstorming we figured out that we can clear all relevant caches on Mac OS X by putting files that we care about on a separate partition and mounting/unmounting it for every measurement.  
-  
-Ridiculously, Windows is "smarter" than that and appears to cache stuff per-drive, such that mounting/unmounting a partition has no effect on the cache. The best workaround I could come up with involves putting the said partition onto a USB disk and unplugging it in-between unmount/mount testing cycle.  
-  
-**Windows 7 Startup Recipe**  
-  
-1) Set up junctions for the 2 profile directories to point to the USB partition, unzip firefox onto that partition.  
-  
-2) 
-```
-$old = (get-location)
-$mountpoint = $env:userprofile + "\cold"
-# magic name given by running mountvol
-$drive = "\\?\Volume{885d5bc3-e918-11de-a4e5-002268e3077c}\"
-# Based on http://poshcode.org/696 + fiddling with UAC settings to avoid prompts
-sudo mountvol $mountpoint $drive
-# Mountvol doesn't seem to block until drive is mounted
-sleep 1
-#mountvol
-cd $mountpoint\firefox
-echo (pwd)
-# The following command shows PowerShell awesomeness
-# based on [Vlad's approach](http://blog.vlad1.com/2009/07/28/measuring-startup/)
-./firefox.exe -no-remote "file://$(pwd)\startup.html#$([Int64](([DateTime]::utcnow - (new-object DateTime 1970,1,1)).ticks/10000))"
-cd $old
-# I haven't yet figured out how to wait on firefox.exe to finish
-sleep 10
-sudo mountvol $mountpoint /d
-```
-3) Unplug USB drive
diff --git a/source/_posts/2010-01-19-chromium-vs-minefield-cold-startup-performance-comparison.markdown b/source/_posts/2010-01-19-chromium-vs-minefield-cold-startup-performance-comparison.markdown
deleted file mode 100644
index 372a722..0000000
--- a/source/_posts/2010-01-19-chromium-vs-minefield-cold-startup-performance-comparison.markdown
+++ /dev/null
@@ -1,52 +0,0 @@
----
-comments: true
-date: 2010-01-19 17:05:28
-layout: post
-slug: chromium-vs-minefield-cold-startup-performance-comparison
-title: 'Chromium vs Minefield: Cold startup performance comparison'
-wordpress_id: 219
-categories:
-- mozilla
-- startup
----
-
-**Hunting Down Mythical "Slowness"**  
-  
-I recently met a developer who used Chromium instead of Firefox. Chromium's superior startup speed was his reason for using it.This got me excited because said developer was running Linux, so it was relatively easy to measure cold startup and get a complete [IO breakdown](http://taras.glek.net/blog/2009/10/23/studying-library-io-systemtap-style/).  
-  
-Turned out Firefox took roughly 23 seconds to start. After much cursing about how I've never seen Firefox startup this slow, I eventually gave up on figuring out what's slowing his startup and instead we measured Chromium startup. It also turned out to also be roughly 23 seconds. The super-slow hard drive made everything slow. Turned out Chromium's superior startup was a myth in this case.  
-  
-**Measuring Startup**  
-  
-As a result of investigating the startup myth above, my kiwi coworkers encouraged me to post a comparison of Chrome/Firefox startup. I am at [linuxconf](http://www.lca2010.org.nz/) at the moment so I did the comparison on my laptop.  
-  
-Laptop configuration: 
-
-  * Intel(R) Core(TM)2 Duo CPU  L9400 running at 800Mhz to amplify any performance differences.
-  * HITACHI HTS722020K9SA00 harddrive for the user profile and browser binaries
-  * OCZ Vertex 30GB SSD for system libraries/configuration.
-  * Fedora 12, Minefield 20100119 tarball, chromium-4.0.285.0-0.1.20091230svn35370.fc12.i686
-  * sudo sync && sudo sysctl -w vm.drop_caches=3 && sudo sysctl -w vm.drop_caches=0 to clear the disk cache inbetween runs
-What am I testing? I am measuring the time between invoking the browser until a JavaScript snippet embedded within a basic webpage is executed (ie [Vlad's approach](http://blog.vlad1.com/2009/07/28/measuring-startup/), with a slightly modified [startup.html](http://people.mozilla.com/~tglek/startup/startup.html)). The above sysctl command clears disk caches, this creates a similar situation to when one turns on the computer and it hasn't yet loaded all of the browser libraries from disk into memory. This is a blackbox approach to measuring how long it takes from clicking on the browser icon to get an interactive browser.  
-  
-Firefox commandline: firefox -profile /mnt/startup/profile/firefox  -no-remote file://`pwd`/startup.html#`python -c 'import time; print int(time.time() * 1000);'`  
-  
-Chromium commandline: chromium-browser --user-data-dir=/mnt/startup/profile/chrome  file://`pwd`/startup.html#`python -c 'import time; print int(time.time() * 1000);'`  
-  
-Both of these tests are done with an empty profile that was populated and has settled after running the browser a few times.  
-  
-**Results**  
-  
-The following numbers are milliseconds reported by the startup.html above.  
-  
-Running Chromium five times: 4685, 4168, 4222, 4197, 4232  
-  
-Running Minefield five times: 3155, 3273, 3352, 3311, 3322  
-  
-I picked Minefield because that's the browser that I run and the codebase that I focus on. The linux Chromium channel seems to be the closest parallel to Minefield. I did not test on Windows because it is a bit of a [nightmare](http://taras.glek.net/blog/2010/01/04/windows-7-startup-exploration/) to measure cold startup there.  
-  
-**Conclusion**  
-  
-On my system Minefield is around 30% faster at starting up with  an empty profile than Chromium (the difference is amplified by running the CPU at 800Mhz). For comparison of Minefield against older Firefox versions, see [Dietrich's post](http://autonome.wordpress.com/2009/11/21/firefox-startup-performance-weekly-summary-11/).  
-  
-I suspect that there is a relatively small difference between the two browsers because we are running into the fundamental limitations of loading large applications into memory ([my rant](http://taras.glek.net/blog/2009/10/20/large-apps-just-have-to-start-slow/)).
diff --git a/source/_posts/2010-01-21-state-of-static-analysis-at-mozilla.markdown b/source/_posts/2010-01-21-state-of-static-analysis-at-mozilla.markdown
deleted file mode 100644
index 87078d1..0000000
--- a/source/_posts/2010-01-21-state-of-static-analysis-at-mozilla.markdown
+++ /dev/null
@@ -1,43 +0,0 @@
----
-comments: true
-date: 2010-01-21 17:24:03
-layout: post
-slug: state-of-static-analysis-at-mozilla
-title: State of Static Analysis At Mozilla
-wordpress_id: 227
-categories:
-- mozilla
-- static-analysis
----
-
-Mozilla has static analyses built into the buildsystem that can be turned on with --with-static-checking= flag. The analyses live in [xpcom/analyses](http://mxr.mozilla.org/mozilla-central/source/xpcom/analyses) directory. The testcases (aka documentation) are in [xpcom/tests/static-checker](http://mxr.mozilla.org/mozilla-central/source/xpcom/tests/static-checker/). Analyses are implemented in either [Dehydra](https://developer.mozilla.org/En/Dehydra) or [Treehydra](https://developer.mozilla.org/en/Treehydra) and run within a patched GCC 4.3.  
-  
-The currently landed checks are: 
-
-  * final.js: Java-like "final" keyword for C++
-  * flow.js: Ensure code in a function flows through a particular label
-  * must-override.js: Force derived classes to override certain methods
-  * override.js: Ensure methods exist in base class
-  * outparams.js: Ensure outparameters and return error codes are in sync
-  * stack.js: Mark classes as stack-only
-A whole lot more analyses in various states of completion can be tracked in the static analysis [bug](https://bugzilla.mozilla.org/show_bug.cgi?id=430328).  
-  
-Asynchronous discussion happens in the mailing list. #static irc channel is the place for interactive discussion.  
-  
-**Nearterm Plans For Plugins **  
-  
-GCC 4.5 has an official plugin framework enabled by default. I will try to switch to GCC 4.5 as soon as it is out. Currently 4.5 is still changing too often for me to bother fixing Treehydra (Dehydra usually works). As soon as 4.5 is out I will revise the installation instructions to use distribution GCC and JavaScript packages to avoid the current mess (draft can be found [here](http://groups.google.com/group/mozilla.dev.static-analysis/browse_thread/thread/a773ebdbc5479f9a#)). Sometime after that I'll switch Mozilla static analysis to GCC 4.5 and drop 4.3 support.  
-  
-Hopefully, this will make it easier for other open source projects to adapt the hydras.  
-  
-**Plans for Analyses**  
-  
-I'm a big believer into application-specific static analyses, but I would like to see some heavy duty open source analyzers built on top of GCC.  
-  
-Some of the not-so-Mozilla-specific analyses should be bundled together to make them easy to try out on other projects.  
-  
-Hopefully 2010 will be the year that open source static analysis catches on.  
-  
-**LCA2010**  
-  
-I posted my [slides](http://people.mozilla.com/~tglek/lca2010/) from yesterday.
diff --git a/source/_posts/2010-02-09-static-analysis-articles.markdown b/source/_posts/2010-02-09-static-analysis-articles.markdown
deleted file mode 100644
index 0b94484..0000000
--- a/source/_posts/2010-02-09-static-analysis-articles.markdown
+++ /dev/null
@@ -1,19 +0,0 @@
----
-comments: true
-date: 2010-02-09 14:22:40
-layout: post
-slug: static-analysis-articles
-title: Static Analysis Articles
-wordpress_id: 229
-categories:
-- mozilla
-- static-analysis
----
-
-A really good [ACM article](http://cacm.acm.org/magazines/2010/2/69354-a-few-billion-lines-of-code-later/fulltext) about static analysis from Coverity's perspective has been making rounds in Mozilla. What struck me most was the following paragraph:_ _  
-  
-_At the most basic level, errors found with little analysis are often better than errors found with deeper tricks. A good error is probable, a true error, easy to diagnose; best is difficult to misdiagnose. As the number of analysis steps increases, so, too, does the chance of analysis mistake, user confusion, or the perceived improbability of event sequence. No analysis equals no mistake._  
-  
-My personal view has been that "dumb" analyses are the most effective ones in terms of mistakes spotted vs time wasted writing/landing the analysis. It is interesting to see that sophisticated analyses are difficult to deploy even for Coverity.  
-  
-In other news, LCA 2010 was my favourite conference so far. I met a number of awesome developers there. Mozilla's static analysis work finally got [mentioned](http://lwn.net/Articles/370717/) in LWN!
diff --git a/source/_posts/2010-02-19-teaching-ld-to-optimize-binaries-for-startup.markdown b/source/_posts/2010-02-19-teaching-ld-to-optimize-binaries-for-startup.markdown
deleted file mode 100644
index 978d8d5..0000000
--- a/source/_posts/2010-02-19-teaching-ld-to-optimize-binaries-for-startup.markdown
+++ /dev/null
@@ -1,35 +0,0 @@
----
-comments: true
-date: 2010-02-19 11:28:51
-layout: post
-slug: teaching-ld-to-optimize-binaries-for-startup
-title: Teaching ld to optimize binaries for startup
-wordpress_id: 231
-categories:
-- mozilla
-- startup
----
-
-I have been told that it should be possible to control the way the GNU linker lays out binaries. Unfortunately until recently I couldn't figure out the right incantations to convince ld to do my bidding. Turns out what I needed was to be stranded on a beach in Fiji with nothing better to do than to reread the ld info page a few times.  
-  
-Recipe: 
-
-  1. Produce 2 mozilla builds: A tracing build with -finstrument-functions in CXXFLAGS/CFLAGS A release build with -ffunction-sections and -fdata-sections CXXFLAGS/CFLAGS to allow the linker to move stuff at function or static data(mostly variables) granularity
-  2. Link my [profile.cpp](http://people.mozilla.com/~tglek/startup/ld/profile.cpp) into libxul in the tracing build (without -finstrument-functions flag)
-  3. Run the tracing build, capturing the spew from profile.cpp into a log file
-  4. Feed the log file to [my script](http://people.mozilla.com/~tglek/startup/ld/generate_sections_ff.py) to produce a linker script. This will produce library.so.script files for all of Mozilla libraries.
-  5. Rebuild relevant libraries in the release build with -T library.so.script linker flag
-  6. Enjoy faster startup
-This results in 200ms faster startup my 7200rpm laptop harddrive which is about a 10% of my startup. I think that's pretty good for a proof of concept. Unfortunately there isn't a measurable win on the SSD (not surprising) nor a reduction in memory usage (I expected one due to not having to page in code that isn't needed for firefox startup).  
-  
-I suspect the problem is that data sections need to be laid out adjacent to functions that refer to them. I started sketching out a treehydra [script](http://people.mozilla.com/~tglek/startup/ld/map_functions_and_symbols.js) to extract that info.  
-  
-I posted the relevant testcase and scripts. Do hg clone [http://people.mozilla.com/~tglek/startup/ld](http://people.mozilla.com/~tglek/startup/ld/) to see the simple testcase and various WIP firefox scripts.  
-  
-**Long-term Expectations**  
-  
-The majority of Firefox startup overhead (prior to rendering of web pages) comes from frustrating areas such inefficient libraries (eg fontconfig, gtk) and the mess caused by crappy layout of binaries and overuse of dynamic libraries. This post describes one small step towards fixing the crappy layout of our binaries.  
-  
-I would like to end up in a world where our binaries are static and laid out such that they are read sequentially on startup (such that we can use the massive sequential read speeds provided by modern storage media). Laying out code/data properly should result in memory usage reductions which should be especially welcome on Fennec (especially on Windows Mobile).  
-  
-I am hoping to see 30-50% startup time improvements from this work if everything goes according to plan.
diff --git a/source/_posts/2010-02-26-updated-dehydra-installation-instructions.markdown b/source/_posts/2010-02-26-updated-dehydra-installation-instructions.markdown
deleted file mode 100644
index 92a130a..0000000
--- a/source/_posts/2010-02-26-updated-dehydra-installation-instructions.markdown
+++ /dev/null
@@ -1,12 +0,0 @@
----
-comments: true
-date: 2010-02-26 11:02:46
-layout: post
-slug: updated-dehydra-installation-instructions
-title: Updated Dehydra Installation Instructions
-wordpress_id: 234
-categories:
-- mozilla
----
-
-The [Dehydra installation instructions](https://developer.mozilla.org/En/Dehydra/Installing_Dehydra) got to the point where they were more confusing than helpful. I spent this morning cutting out irrelevant crud, please let me know if there are any further cleanups that need to be done.
diff --git a/source/_posts/2010-03-05-mirror-mirror-on-the-wall-why-is-my-binary-slow.markdown b/source/_posts/2010-03-05-mirror-mirror-on-the-wall-why-is-my-binary-slow.markdown
deleted file mode 100644
index a478aa1..0000000
--- a/source/_posts/2010-03-05-mirror-mirror-on-the-wall-why-is-my-binary-slow.markdown
+++ /dev/null
@@ -1,29 +0,0 @@
----
-comments: true
-date: 2010-03-05 17:48:25
-layout: post
-slug: mirror-mirror-on-the-wall-why-is-my-binary-slow
-title: Mirror, Mirror on the Wall, Why is my Binary Slow?
-wordpress_id: 238
-categories:
-- mozilla
----
-
-In an [earlier](http://taras.glek.net/blog/2010/02/19/teaching-ld-to-optimize-binaries-for-startup/) post I described my Fiji hack: how to use some nasty instrumentation to spit out ld scripts to speed up cold startup. This week I tried to extract more data out of the binary to lay it out even better. Trouble is that even if one lays out functions perfectly, they load data for things like variable initializers which will cause more IO.  
-  
-A very clever friend suggested that I can write a valgrind plugin that can detect data accesses and function access and write the linker input files in one step. So with much hand-holding I hacked a sample valgrind plugin to do what I [want](https://bugzilla.mozilla.org/show_bug.cgi?id=549749). Unfortunately, my binaries ended up not being significantly faster(if at all) than the Fiji ones. They also ended up 20% bigger.  
-  
-Fortunately, the GCC devs were able to point out my linker mistakes and pointed me at a [linker patch](http://sourceware.org/ml/binutils/2010-03/msg00050.html) that does what I want without linker scripts(and has less binary-bloating side-effects). Unfortunately, that just confirmed that the speedup I was looking for wasn't hiding behind data symbols. So I am going to have to sit down with my [io tracing script ](http://taras.glek.net/blog/2009/10/23/studying-library-io-systemtap-style/)and study what the heck is going on.  
-  
-**Cool Things I Learned**  
-  
-In the process of helping me, GCC people namedropped some compiler flags that may prove very helpful: 
-
-  * -freorder-blocks-and-partition: Apparently this breaks up functions into hot/cold parts and gives them different section names so they can be moved around at link time.
-  * -fno-common, -fno-zero-initialized-in-bss should go well with my favourites: -ffunction-sections -fdata-sections
-Additionally, it may be possible to benefit from linking with large page support. I have some doubts about that.  
-  
-I did learn about some cool GNU Gold flags: 
-
-  * --compress-debug-sections=zlib: Most of the overhead of linking a development libxul.so is writing out a near gig of debug data
-  * --icf: Identical code folding, I think that matches the deduplication feature found in the ms linker. Saves 5% on my libxul.so
diff --git a/source/_posts/2010-03-11-extensions-startup.markdown b/source/_posts/2010-03-11-extensions-startup.markdown
deleted file mode 100644
index 028ba34..0000000
--- a/source/_posts/2010-03-11-extensions-startup.markdown
+++ /dev/null
@@ -1,50 +0,0 @@
----
-comments: true
-date: 2010-03-11 11:20:35
-layout: post
-slug: extensions-startup
-title: Extensions & Startup
-wordpress_id: 241
-categories:
-- mozilla
-- startup
----
-
-Dietrich [blogged](http://autonome.wordpress.com/2010/03/10/firefox-extensions-and-performance/) a "wake up and smell the startup" executive overview of startup issues caused by our extension practices. This post is a "numbers" followup. For this experiment I installed a brand-spankin-new copy of Linux Firefox 3.6. Firefox is installed on a 7200 hard drive, the rest of my system lives on an SSD. The CPU is core2duo, keep in mind these numbers will be significantly worse for people running on netbooks and other common hardware. The numbers vary +/- 150ms, but the general picture is pretty clear.  
-  
-**Results**
-
-**Startup Time**
-
-Firefox 3.6 with no extensions:
-2240ms
-
-+[Adblock Plus](https://addons.mozilla.org/en-US/firefox/addon/1865) (no subscriptions)
-2538ms
-
-+[Video Download Helper](https://addons.mozilla.org/en-US/firefox/addon/3006)
-2727ms
-
-+[Personas](https://addons.mozilla.org/en-US/firefox/addon/10900)
-3220ms
-
-+[Greasemonkey](https://addons.mozilla.org/en-US/firefox/addon/748)
-3300ms
-
-+EasyList subscription for adblock
-4044ms
-I just doubled cold startup time for Firefox by merely adding 4 extensions. It takes weeks or even months of developer time to shave off every 100ms off Firefox startup, but mere seconds to undo any of those gains by installing extensions. These are just the top-4 extensions in the list (presumably they are higher quality too), I'm sure there are lots of other extensions with more drastic performance hits.  
-  
-Dietrich's [post](http://autonome.wordpress.com/2010/03/10/firefox-extensions-and-performance/) details some of the remedies that should reduce the startup cost of extensions. For the inquisitive minds: I used [SystemTap](http://taras.glek.net/blog/2009/10/23/studying-library-io-systemtap-style/) to produce a [report](http://people.mozilla.com/~tglek/startup/extensions_report.txt) of files read by Firefox on startup ordered by their startup cost.  
-  
-**Update:** Dietrich asked me to summarize warm startup too: 
-
-  * Without extensions: 550ms
-  * With above Extensions: 1800ms
-Note that this is a developer blog, so by "remedies" I meant "things developers can do to". There is little normal users can do short of complaining to the extension authors.  
-  
-This post isn't meant to shame specific extension authors into speeding up their extensions. The aim is to show that a measurable percentage of startup is due to extensions and that we need to: 
-
-  1. Educate extension developers about it
-  2. Provide better tools to measure slowdowns caused by extensions
-  3. Make sure that the Firefox side of extension handling is sufficiently efficient
diff --git a/source/_posts/2010-03-23-when-in-trouble-draw-a-picture.markdown b/source/_posts/2010-03-23-when-in-trouble-draw-a-picture.markdown
deleted file mode 100644
index 3b1ea86..0000000
--- a/source/_posts/2010-03-23-when-in-trouble-draw-a-picture.markdown
+++ /dev/null
@@ -1,33 +0,0 @@
----
-comments: true
-date: 2010-03-23 15:12:52
-layout: post
-slug: when-in-trouble-draw-a-picture
-title: When in Trouble, Draw a Picture
-wordpress_id: 253
-categories:
-- mozilla
-- startup
----
-
-**Graphs**  
-  
-_Note: the following graphs broke on the nightlies this week. I would appreciate help with reducing this to a proper testcase. They work fine on older nightlies and released versions of Firefox. Non-spidermonkey JS engines wont work as they don't support [destructuring assignment](https://developer.mozilla.org/en/New_in_JavaScript_1.7#Destructuring_assignment) and other goodies._  
-  
-Once I graphed my file-access logs, most of my problems became clear. Here is the [first](http://people.mozilla.org/~tglek/startup/systemtap_graphs/visualize.html#original.data.html) graph([screenshot](http://people.mozilla.org/~tglek/startup/systemtap_graphs/orig.png)). The y-axis is time; once you click on a square, x-axis is the file offset. One can clearly see that libxul (4th rectangle) is a big chunk of our io. It's also clear that initially the file is being accessed in the begining and near the end. One can also see that there is a some "backwards" io. It's ugly stuff.  
-  
-I first saw this picture on Friday evening, I spent the last 2 days trying to make libxul.so load less stupidly. [Here](http://people.mozilla.org/~tglek/startup/systemtap_graphs/visualize.html?#madvise.hack.html) is a graph([screenshot](http://people.mozilla.org/~tglek/startup/systemtap_graphs/madvise1.png)) from a hack I tried this morning (approach b in the [bug](https://bugzilla.mozilla.org/show_bug.cgi?id=554421)) . The top is still stupid, but near the bottom, libxul is being read in a much more efficient manner (>50% less io).  
-  
-This [graph](http://people.mozilla.org/~tglek/startup/systemtap_graphs/visualize.html??#madvise_ahead.html) is from a lunch-time hack(approach c). IO is being spread across two processes so it's evading my systemtap script for  now. Fortunately, "approach c" also shaved off a second of my startup time, so I know the libxul graph would've been real pretty.  
-  
-What follows is a story of how I ended up graphing stuff; more on lessons learned later...  
-  
-  
-  
-**Story**  
-  
-Last week I was about to give up and live with a [meager](http://taras.glek.net/blog/2010/03/05/mirror-mirror-on-the-wall-why-is-my-binary-slow/) 10% win on libxul.so cold startup. I just couldn't squeeze any more useful ideas out of my timing and io logs. I reached out to Jim Blandy, who confirmed that things seemed to be working as expected (unlike me, Jim actually knows this stuff).  
-  
-Upon hearing of my quest, surprising number of people strongly suggested that I chat with [Michael Meeks](http://people.gnome.org/~michael/blog/). He was digging around in the binary cesspool for OpenOffice recently and asked many of the same questions. We had a fun conversation, where Michael proved me wrong. I said I couldn't imagine a useful way to graph the file io logs. In response Michel, dug up this [beauty](http://people.gnome.org/~michael/blog/). He built it with a [fun](http://live.gnome.org/iogrind) mix of valgrind + c#.  
-  
-Feeling massive diagram envy, I decided that I had to get an interactive graph of my [SystemTap](http://taras.glek.net/blog/2009/10/23/studying-library-io-systemtap-style/) data. A brief Google search revealed that [RaphaelJS](http://raphaeljs.com/) would be awesome for my needs (the most [j***worthy](http://www.youtube.com/watch?v=4pXfHLUlZf4) vector gfx library ever). After many happy hours of messing with with pretty graphics and colours, the ugly truth emerged (hint: it's about the linker/kernel relationship). More on that soon.
diff --git a/source/_posts/2010-03-24-linux-why-loading-binaries-from-disk-sucks.markdown b/source/_posts/2010-03-24-linux-why-loading-binaries-from-disk-sucks.markdown
deleted file mode 100644
index ed87654..0000000
--- a/source/_posts/2010-03-24-linux-why-loading-binaries-from-disk-sucks.markdown
+++ /dev/null
@@ -1,50 +0,0 @@
----
-comments: true
-date: 2010-03-24 15:47:28
-layout: post
-slug: linux-why-loading-binaries-from-disk-sucks
-title: 'Linux: Why Loading Binaries From Disk Sucks'
-wordpress_id: 260
-categories:
-- mozilla
-- startup
----
-
-_Note: I am doing my measurements and experiments on Fedora 12, once I feel that I understand and can solve the problems on Linux, other operating systems will follow. The aim of this post is to document what I have learned about the mysterious process of loading programs from the filesystem perspective._  
-  
-A binary is broken up into segments. There are about half dozen different segments in an executable, but only two that matter here:
-
-  1. A segment that mostly contains function-bodies and some const data. It's mapped in read+execute mode
-  2. A segment that contains variable initializers, GOT, PLT, lists of constructors/destructors, etc
-The compile-time linker composes segments out of sections that contain variable data, function bodies, etc. The run-time linker maps the segments into memory via [mmap](http://en.wikipedia.org/wiki/Mmap). It resolves references to data and code in dynamic libraries (eg relocation) via COW. IO happens when the program (on behalf of the run-time linker) is trying to access memory that hasn't been read from disk yet. These interruptions are called page faults. They cause the kernel to interrupt the program to read in some multiple of pages (4096byte chunks) from disk. On my system, page faults trigger ﻿﻿131072byte (32 pages) reads.  
-  
-For a detailed explanation of how linkers work check out the guides written by experts. Out of the scant [list](http://lambda-the-ultimate.org/node/3474) of literature on the subject, my "favourite" is Ulrich Drepper's "How to Write Shared Libraries". It actually explains things in terms of file offsets, not just virtual addresses.  
-  
-A common misconception is that mmap()-caused IO is free (because you don't issue any explicit read() statements). IO via page faults is just another "API" for file-access, there is no reason for it to be free. Another misconception is that one has no control over IO-patterns triggered by mmap(). On Linux-like OSes one can use madvise(). (Windows is more limited, afaik one can only set io-pattern-flags on the filehandles).  
-  
-**Prelinking Fail **  
-  
-Having the run-time linker fix up the binary causes a huge amount of IO even before any application code gets executed. These faults are visible in the second graph in my [previous post](http://taras.glek.net/blog/2010/03/23/when-in-trouble-draw-a-picture/). The linker's faults (pun intended) are the small green rectangles above the big ones. The graph clearly shows the huge relative cost of inefficient run-time linker memory prodding.  
-  
-Supposedly, this problem is largely solved by [prelinking](http://en.wikipedia.org/wiki/Prelink). I can't confirm that as prelink does not work on Firefox on the systems that I can measure IO with SystemTap. This non-determinism is frustrating; we should figure out a way to warn to the user that the OS infrastructure failed them. ****  
-  
-**Post-linker Fail**  
-  
-Above IO patterns can be blamed on careless run-time linker behavior. IO after that can be attributed to lack of organization in the output of the compiler and the compile-time linker. Turns out that the layout of the .text section (where all of the function bodies lie) and to a smaller degree .data[, .bss, etc] sections(ie variable initializers) is completely unhelpful. For a good laugh look at how the official nightly libxul.so is read mostly through backwards io ([graph link](http://people.mozilla.com/~tglek/startup/systemtap_graphs/visualize.html?#stock.io.html)).  
-  
-_<aside>The libxul.so graphs in the previous post did not exhibit this kind of insanity. I did my best to order functions based on chronological order of access (courtesy of my _[_valgrind hack_](https://bugzilla.mozilla.org/show_bug.cgi?id=549749)_). Unfortunately, the chronological log is not deterministic. Someone suggested that statistical fudging via _[_markov chains_](http://en.wikipedia.org/wiki/Markov_chain)_ will help. From the io patterns in the graph I'm guessing that io patterns detected by valgrind and those that actually happen diverge due to threading differences. Linux users that are interested in fast startup should pray to the GCC Santas to reorder binaries as part of Profile-Guided-Optimization.</aside>_ ****  
-  
-**Are Large Programs Screwed Out of Fast Startup?**  
-  
-Yes, but it doesn't have to be this way. Turns out this utter disaster is caused by naive use of mmap() in the dynamic-linker. The second graph (previous post) shows, that even a late madvise call (delightfully nasty [patch](https://bugzilla.mozilla.org/attachment.cgi?id=434721&action=edit)) can significantly improve the situation. Specifying madvise(MADV_WILLNEED) causes individual faults to read in 2097152bytes (512 pages,  16x larger reads than default),  3x(10x if one counts only ones after madvise()) reduction in the number of total faults, saves about 1 second of startup.  
-  
-The basic trick is outlined as "approach c" in this [bug](https://bugzilla.mozilla.org/show_bug.cgi?id=554421). My current thinking is to:
-
-  1. use Jim Blandy's executable-parsing library from breakpad(which is already in our build) to parse our binaries
-  2. calculate what the dynamic linker will mmap() at runtime. 
-  3. have some firefox.sh-like native frontend mmap()/madvise() it with appropriate flags
-In the longer term some fixes for madvise() should land in both runtime and compile-time linkers.  
-  
-**Conclusion**  
-  
-It took me a long time to produce the above story from my runtime linker observations. As recently as December I had no idea what a runtime linker was or what linker segments, sections, etc were. I'd like to thank Valgrind authors, kind folks on #gcc and numerous individuals who helped me connect the pieces. The above is written to the best of my still-incomplete understanding; I will appreciate any corrections.
diff --git a/source/_posts/2010-03-25-madvise-prelink-update.markdown b/source/_posts/2010-03-25-madvise-prelink-update.markdown
deleted file mode 100644
index ec717d2..0000000
--- a/source/_posts/2010-03-25-madvise-prelink-update.markdown
+++ /dev/null
@@ -1,28 +0,0 @@
----
-comments: true
-date: 2010-03-25 11:09:25
-layout: post
-slug: madvise-prelink-update
-title: Madvise, Prelink Update
-wordpress_id: 264
-categories:
-- mozilla
----
-
-Got some helpful comments on my [previous post](http://taras.glek.net/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/).  
-  
-**madvise(WILLNEED) in ld.so**  
-  
-Frank Ch. Eigler pointed out that other people have [noticed](http://www.google.com/search?q=ld.so%20madvise) the madvise/mmap deficiency in the dynamic linker. Unfortunately those unfortunate people did not have the ability to flush caches or to measure page faults exactly. Linux has gotten a lot nicer for diagnosing this. Frank also filed a [glibc bug](http://sourceware.org/bugzilla/show_bug.cgi?id=11431). SuSE already ships with a madvise()ed dynamic linker.  
-  
-**Prelink saga**  
-  
-Both Bradley Baetz and Frank pointed me at the FIPS-caused [bug](https://bugzilla.redhat.com/show_bug.cgi?id=504949) which causes prelink to get angry at Firefox. This isn't the first time that practically-useless FIPS has gotten in the way of a higher performing Firefox.  
-  
-The most common response to people who complain about run-time linker issue is "are you using prelink?". So I did my best to assume that prelink would erase a bunch of the overhead I saw in the previous bug.  
-  
-I got rid of the offending nss rule in the prelink configuration as the bug instructed; prelink started working on Firefox (according to LD_DEBUG=statistics). Unfortunately the IO pattern was identical to what I was seeing before.  
-  
-Frank suggested that I try prelink -u to undo any prelinking. This caused a bunch more runtime-linker IO from which one can conclude that the overhead I am seeing is not solved by prelink. The is still a lot of IO that happens before any application code is executed, so the runtime linker is still my primary suspect.  
-  
-Going to spend some quality time with SystemTap to try to figure out what the linker is doing.
diff --git a/source/_posts/2010-03-29-linux-startup-inefficiency.markdown b/source/_posts/2010-03-29-linux-startup-inefficiency.markdown
deleted file mode 100644
index e8f2b39..0000000
--- a/source/_posts/2010-03-29-linux-startup-inefficiency.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2010-03-29 13:11:02
-layout: post
-slug: linux-startup-inefficiency
-title: 'Linux Startup Inefficiency '
-wordpress_id: 268
-categories:
-- mozilla
----
-
-There is a little bit of a disconnect between the kernel, the dynamic linker and compile-time linker. As I mentioned in my main "startup sucks" [post](http://taras.glek.net/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/): not-notifying the kernel of your patterns can kill performance, so can reading files backwards.  
-  
-Turns out that if the compile-time linker lays out files without considering *exactly* how they are read by the runtime linker, binaries will load slower. I filed a [bug](http://sourceware.org/bugzilla/show_bug.cgi?id=11447) on that.  
-  
-Currently, SuSE appears to be leading in startup performance by shipping their glibc with the fadvise() patch (to load binaries from disk in bigger chunks). A [bug](http://sourceware.org/bugzilla/show_bug.cgi?id=11431) is filed for this to get fixed in glibc, but in the meantime distributions should consider including SuSE's patch (glibc-2.3.90-ld.so-madvise.diff) in their libc.
diff --git a/source/_posts/2010-03-31-how-to-get-reviews-fast-delete-code.markdown b/source/_posts/2010-03-31-how-to-get-reviews-fast-delete-code.markdown
deleted file mode 100644
index 8ddf548..0000000
--- a/source/_posts/2010-03-31-how-to-get-reviews-fast-delete-code.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2010-03-31 20:17:48
-layout: post
-slug: how-to-get-reviews-fast-delete-code
-title: 'How to get reviews fast: Delete Code!'
-wordpress_id: 271
-categories:
-- mozilla
----
-
-The fastest review I ever got was when I deleted a bunch of code from libjar. It was so riddled crud it was next to impossible to modify the code. That was a mere [24KB patch](https://bugzilla.mozilla.org/show_bug.cgi?id=505784) produced manually.  
-  
-[Ehren](http://ehren.wordpress.com/) just put my personal records to shame with a [94KB patch](https://bugzilla.mozilla.org/show_bug.cgi?id=556446) that got r+ed at breakneck speed. Best part is that he generates these by plucking off dead parts of the Mozilla callgraph via static analysis. I bet if he tried he could land 90KB patches every day. Way to go Ehren!  
-  
-I expect more good code deletions to make themselves known via this [meta bug](https://bugzilla.mozilla.org/show_bug.cgi?id=457262).
diff --git a/source/_posts/2010-04-05-linux-how-to-make-startup-suck-less-and-reduce-memory-usage.markdown b/source/_posts/2010-04-05-linux-how-to-make-startup-suck-less-and-reduce-memory-usage.markdown
deleted file mode 100644
index f1c48d3..0000000
--- a/source/_posts/2010-04-05-linux-how-to-make-startup-suck-less-and-reduce-memory-usage.markdown
+++ /dev/null
@@ -1,97 +0,0 @@
----
-comments: true
-date: 2010-04-05 12:36:01
-layout: post
-slug: linux-how-to-make-startup-suck-less-and-reduce-memory-usage
-title: 'Linux: How to Make Startup Suck Less (Also Reduce Memory Usage!)'
-wordpress_id: 277
-categories:
-- mozilla
----
-
-As I explained before, loading binaries from disk [sucks](http://taras.glek.net/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/). Aside from [switching](http://taras.glek.net/blog/2010/03/25/madvise-prelink-update/) glibc to use madvise/fadvise, what can application developers do to minimize this suckyness?  
-  
-I am going to start with numbers to give an idea of the magnitudes involved here. I'm still using my 1.8ghz core2duo laptop with a 7200 200GB harddrive. 
-
-Time(ms)
-# of libxul.so reads
-
-Typical Firefox build
-2300
-147
-
-Prelinked Firefox
-2130
-139
-
-Ordered Firefox
-2500
-131
-
-Ordered+Prelinked
-2065
-124
-
-Prelinked-Ordered Firefox
-1860
-72
-
-Prelink-Ordered + Prelinked Firefox
-1636
-66
-Additionally, proper binary reordering results in >2mb reduction in memory usage(out of 14mb that's mapped in for code) since less random code gets paged in during readahead. This should be interesting for mobile where our binaries are RISC-bloated and there is less RAM is available.  
-  
-**Analysis**  
-  
-****A commonly-suggested linux adage is to [prelink](http://en.wikipedia.org/wiki/Prelink) if your binaries are loading slowly. All of the good Linux distributions are doing using it. Unfortunately that alone gives pretty pathetic improvements. Beyond the weak 8.5% speed one has to do own tools to speed things up.  
-  
-As I mentioned before, application binaries are laid out in a basically random order. This seemed like an obvious optimization so I embarked on a non-obvious quest to capture every single memory access and to use that info to order our binaries sensibly.  
-  
-**Valgrind Adventures**  
-  
-Due to disappointing results I had to change my strategies a few times. The happy numbers(easy 30% speedup) in the above table were produced after the 3rd rewrite of my valgrind plugin. Before I seemed perpetually stuck at 10%.  
-  
-In the current revision of my valgrind plugin I produce a section listing by inferring section names from symbol names via a libelf-based program(unfortunately I do not know of a way get ld to retain function sections in the final binary). This turned out to be easier to get right than abusing Valgrind's symbol-lookup APIs into figuring out what sections they came from.  
-  
-Also in addition to reordering executable code in .text, the plugin now reorders the various .data sections. Turned out that even though data is a relatively small portion of the executable, it is located on the opposite end of the executable from code. This means that every page fault in the .data section kills continuous reading of the .text section.  
-  
-I also switched to using gold with a section-ordering patch, it seems to produce binaries that are basically the same size as unordered ones(unlike ones produced by my linker script hack).  
-  
-**What is a Prelink-Ordered binary?**  
-  
-In the end, turned out prelink was the key to my problem. I realized that I am measuring memory accesses in valgrind on a non-prelinked binary causing the linker-induced memory accesses  to drive my binary layout. During symbol relocation, the dynamic linker rummages through the .text and .data sections (which I am trying to layout correctly) in order that does not correlate later execution of the program. Unfortunately I was using that data to order my binary even if the final result was meant to be prelinked.  
-  
-Perhaps that explains why, in the above table, ordered non-prelinked firefox is actually slower than default non-prelinked firefox. Another explanation is that this could be to additional disk fragmentation or other factors. Cold startup numbers depend hard-drive's luck at seeking + filesystem fragmentation, so the only reliably comparator is the number of reads/page-faults.  
-  
-As of now my recipe to producing fast-starting binaries is: 
-
-  1. Build firefox
-  2. Switch to root, set LD_LIBRARY_PATH to /dist/bin/ in the object directory, run: prelink $LD_LIBRARY_PATH/firefox-bin $LD_LIBRARY_PATH/*.so
-  3. Run my libelf utility: elflog  --contents  dist/bin/libxul.so > dist/bin/libxul.so.sections
-  4. As a normal user run Firefox under my valgrind plugin. It will output a list of section names to dist/bin/libxul.so.log
-  5. Relink libxul.so with -Wl,--section-ordering-file,$HOME/builds/minefield.release/dist/bin/libxul.so.log
-  6. make dist, copy resulting binaries somewhere, prelink em
-  7. Enjoy faster startup
-**Conclusion**  
-  
-Using prelink incorrectly can cause massive performance variation.  
-  
-My plugin does .data reordering now, but it would be very hard to do .data reordering as part of profile-guided optimization. Valgrind is the best tool for this job.  
-  
-I will try to cleanup the code and release my plugin this week. Pretty much every significant application can benefit from this, might as well let this loose. I need to decide on a name: ldgrind? startupgrind? binarymaidgrind?  
-  
-We need to develop a built-in diagnostic for detecting when the user isn't using prelink (or has other startup misconfiguration issues).  
-  
-Measuring startup times is highly machine-specific and varies even on individual machines. A much better metric is to measure the amount of io(ie number and size of pagefaults and non-cached reads) serviced by the kernel, that's very consistent.  
-  
-**Misc**  
-  
-Prelink sure gets upset easily. The last (fastest) result in the table above causes:  
-  
-prelink $LD_LIBRARY_PATH/firefox-bin prelink: /hd/startup.test/firefox//firefox-bin: section file offsets not monotonically increasing  
-  
-What's going on? I'm only modifying libxul inbetween prelink runs, why is prelink complaining about firefox-bin which stays constant?  
-  
-prelink: /hd/startup.test/firefox.ordered.static/firefox-bin: DT_JMPREL tag not adjacent to DT_REL relocations  
-  
-What does that mean?
diff --git a/source/_posts/2010-04-07-icegrind-valgrind-plugin-for-optimizing-cold-startup.markdown b/source/_posts/2010-04-07-icegrind-valgrind-plugin-for-optimizing-cold-startup.markdown
deleted file mode 100644
index 4736c6f..0000000
--- a/source/_posts/2010-04-07-icegrind-valgrind-plugin-for-optimizing-cold-startup.markdown
+++ /dev/null
@@ -1,40 +0,0 @@
----
-comments: true
-date: 2010-04-07 15:03:24
-layout: post
-slug: icegrind-valgrind-plugin-for-optimizing-cold-startup
-title: icegrind - Valgrind Plugin for Optimizing Cold Startup
-wordpress_id: 283
-categories:
-- mozilla
----
-
-Most program binaries are laid out with little to no regard to how programs get loaded from disk. This disconnect between compile-time and runtime behaviour of binaries imposes a significant performance penalty to on large applications such as browsers, office suites, etc.  
-  
-It is incredibly difficult to observe both the cause (ie calling a random function) of binary-induced IO and the effect (the program gets suspended during startup while parts being loaded from disk), so this area doesn't get as much optimization love as it deserves.  
-  
-My estimate is that around 50% of Firefox startup time is wasted on subobtimal binary layout. My previous [post](http://taras.glek.net/blog/2010/04/05/linux-how-to-make-startup-suck-less-and-reduce-memory-usage/) demonstrated the kind of difference a better binary layout can make. Note that reordering executables isn't the only solution, eliminating dead code should also speed things up (deleting [dead code](https://bugzilla.mozilla.org/show_bug.cgi?id=457262) is a [hard](http://ehren.wordpress.com/)).  
-  
-**Optimizing Binary Layout**_ Disclaimer:I just finished my 3rd rewrite of icegrind a few hours ago, be gentle._  
-  
-Ingredients: [Valgrind](http://valgrind.org/) SVN trunk + [icegrind patch](https://bugzilla.mozilla.org/show_bug.cgi?id=549749), GNU Gold + [section-ordering-file patch](http://sourceware.org/ml/binutils/2010-03/msg00050.html), a way to describe contents of binaries.  
-  
-_Step 1a: Produce a build _Since I am interested in reorganizing program binaries, I build mozilla with "-ffunction-sections -fdata-sections" in CFLAGS/CXXFLAGS  
-  
-I also prelink the binaries in dist/bin such that my binaries better correspond to how they will be used: prelink $LD_LIBRARY_PATH/firefox-bin $LD_LIBRARY_PATH/*.so  
-  
-_Step 1b: Produce a description of interesting files _I use my [elflog](http://hg.mozilla.org/users/tglek_mozilla.com/startup/file/6453ad2a7906/elflog.cpp) utility to produce a .sections description of files I'm interested in. Elflog looks at the symbol table and tries to infer section names (produced by -ffunction-sections -fdata-sections) from symbol names/locations(see also --print-map option for ld).  
-  
-elflog  --contents  libxul.so >  libxul.so.sections elflog currently emits non-existent .comment.* sections because it gets confused by 0-length sections such as .bss. Note, one can also build tools to describe other kinds of files, such as jar or sqlite files. The only limitation is that Icegrind currently only tracks mmap()-caused disk IO, it would be trivial to extend it to deal with open/seek/read kind of disk IO.  
-  
-_Step 2: Produce a log with icegrind! _Apply my icegrind [patch](https://bugzilla.mozilla.org/attachment.cgi?id=437664&action=edit), build+install valgrind. Run Firefox valgrind --tool=icegrind firefox-bin -profile /tmp/ff -no-remote This will produce a .log file for every mmap()ed file with a .sections description. This log chronologically lists sections in the order of access.  
-  
-_Step 3: Tell gold to link using the above log_ Build/install binutils (I use a CVS checkout from a month ago) with the [section ordering patch](http://sourceware.org/ml/binutils/2010-03/msg00050.html), specify --enable-gold. To reorder the binary, I just add -Wl,--section-ordering-file,libxul.so.log to my linker commandline. Note there are still some teething issues with using this patch, it exhibits N^2 behavior (ie takes 10min to link libxul.so with it) and occasionally swaps order for .rela.plt and .rela.dyn, which makes prelink upset. But unlike my [earlier attempt](http://taras.glek.net/blog/2010/02/19/teaching-ld-to-optimize-binaries-for-startup/) with linker scripts, it does not affect the binary size.  
-  
-Step 4: Enjoy! Now strip, install, prelink your binaries and enjoy faster startup.  
-  
-**Plans**  
-  
-I would like to see the gold patch fixed up and landed. Once that is done I'd like to turn this on for our Linux and mobile linux builds.  
-  
-I am hoping that some sort of sensible ordering of binaries will become commonplace in the future.
diff --git a/source/_posts/2010-04-12-squeezing-every-last-bit-of-performance-out-of-the-linux-toolchain.markdown b/source/_posts/2010-04-12-squeezing-every-last-bit-of-performance-out-of-the-linux-toolchain.markdown
deleted file mode 100644
index 05aaafb..0000000
--- a/source/_posts/2010-04-12-squeezing-every-last-bit-of-performance-out-of-the-linux-toolchain.markdown
+++ /dev/null
@@ -1,55 +0,0 @@
----
-comments: true
-date: 2010-04-12 15:16:08
-layout: post
-slug: squeezing-every-last-bit-of-performance-out-of-the-linux-toolchain
-title: Squeezing Every Last Bit of Performance Out of The Linux Toolchain
-wordpress_id: 288
-categories:
-- mozilla
-- startup
----
-
-**Magic of GCC PGO**  
-  
-On Friday I finally got gold to produce a prelinkable static binary([bug](http://sourceware.org/bugzilla/show_bug.cgi?id=11483)). I also got around to trying out GCC [profile-guided-optimization](https://developer.mozilla.org/en/Building_with_Profile-Guided_Optimization) with the debloatifying -freorder-blocks-and-partition option. This option breaks up every profiled function into cold and hot "functions". It then lumps all of the hot functions together.  
-  
-PGO performance is amazingly close to that of binaries produced by [icegrind ](http://taras.glek.net/blog/2010/04/07/icegrind-valgrind-plugin-for-optimizing-cold-startup/)(within 10% based on page-counts). 
-
-**Startup Time**
-**RSS (KB)**
-
-firefox.stock
-2515ms
-49452
-
-firefox.ordered
-1919ms
-45344
-
-firefox.static
-2321ms
-49616
-
-firefox.static.ordered
-1577ms
-37072
-
-firefox.static.pgo
-1619ms
-38436
-In above table, ordered means application of [icegrind](http://taras.glek.net/blog/2010/04/07/icegrind-valgrind-plugin-for-optimizing-cold-startup/), [static](https://bugzilla.mozilla.org/show_bug.cgi?id=525013) means a fat firefox-bin. To generate the PGO profile I just started and closed Firefox. So it's not too surprising that the results are similar to those of an explicitly ordered binary. RSS refers to how much memory is mmap()ed into the process(lower RSS usage means we are paging in less junk). I was not able to control the layout of PGO builds; will need some linker hackery to deal with split functions.  
-  
-I think the numbers speak for themselves. Isn't it scary how wasteful binaries are by default? It amazes me that Firefox can shrug off a significant amount of resource bloat without changing a single line of code. I think this is a good demonstration on why application developers should a) expect more out of their toolchain (Linux, GCC, Binutils) b) contribute to their toolchain.  
-  
-I think my next step is to tackle PGO Firefox builds([bug](https://bugzilla.mozilla.org/show_bug.cgi?id=418866)). From there I would like to teach icegrind to play together with PGO.  
-  
-**Pieces of The Startup Puzzle**  
-  
-It took a long time since I [first noticed](http://taras.glek.net/blog/2009/10/20/large-apps-just-have-to-start-slow/) the suckyness of library io. After much digging, help by smart people on #gcc + [LKML discussion](http://thread.gmane.org/gmane.linux.kernel/970483/focus=970920), I think I finally have a pretty clear list of the remaining/inprogress things needed for Linux applications to start faster. 
-
-  1. Wu Fengguang is making headway on [smarter readahead](http://lwn.net/Articles/372384/) that makes better use of available RAM + disk bandwidth. Firefox could be read in 512kb chunks instead of 128 (4x page-fault reduction). Distributions should be aggressively testing this patch.
-  2. Better agreement on binary organization between the compile-time [linker](http://sourceware.org/bugzilla/show_bug.cgi?id=11447), run-time [linker](http://sourceware.org/bugzilla/show_bug.cgi?id=11431) and the kernel (see LKML discussion). Can shave off a handful of unneeded page-faults per file this way.
-  3. A linker flag to specify how much of a particular library should be read-in via madvise(). For example any xulrunner apps will know ahead of time that they need large parts of libxul.so - might as well let the OS know.
-  4. Transparent read-only per-file ext4 compression ([like OSX](https://bugzilla.mozilla.org/show_bug.cgi?id=514083)). Ted Tso indicated that this would be easy to add to ext4, but as far as I know nobody has jumped on this.
-I think with all of the above combined, we could load apps like Firefox at near-warm (0.5 second) speeds. Most of these are easy. #1 is hard, but it's already being worked on. I'll be happy to point someone at how to solve items 2-4 while I work on the Firefox side of things. The end result of all this should be a more instant gratification for all Linux users.
diff --git a/source/_posts/2010-04-19-windows-sucks-at-memory-mapped-io-during-startup.markdown b/source/_posts/2010-04-19-windows-sucks-at-memory-mapped-io-during-startup.markdown
deleted file mode 100644
index 2ec15b3..0000000
--- a/source/_posts/2010-04-19-windows-sucks-at-memory-mapped-io-during-startup.markdown
+++ /dev/null
@@ -1,43 +0,0 @@
----
-comments: true
-date: 2010-04-19 14:00:00
-layout: post
-slug: windows-sucks-at-memory-mapped-io-during-startup
-title: Windows Sucks At Memory-Mapped IO During Startup
-wordpress_id: 294
-categories:
-- mozilla
-- performance
-- startup
----
-
-Last week I learned about how Windows handles page faults backed by files (specifically xul.dll). I already knew that Linux was [suboptimal](http://taras.glek.net/blog/2010/04/12/squeezing-every-last-bit-of-performance-out-of-the-linux-toolchain/) in this area, perhaps the clever people at Redmond did better.  
-  
-Shaver pointed me at [xperf](https://developer.mozilla.org/En/Profiling_with_Xperf), which is sort of like the new Linux perf tools. Xperf rocks in that it can capture the relevant data and it can export it as .csv.  
-  
-Even with profile-guided-optimization Windows causes 3x as much IO in xul.dll than linux does on libxul.so. That's especially interesting given that xul.dll is one-third smaller on Windows. Here is the [graph](http://people.mozilla.com/~tglek/startup/systemtap_graphs/visualize.html?#../win7/noprefetch.csv.html). PGO isn't helping on Windows as much as it can help on Linux because MSVC PGO doesn't do the equivalent of GCC's -freorder-blocks-and-partition (unless I missed something in the docs).  
-  
-With the Windows [prefetcher](http://en.wikipedia.org/wiki/Prefetcher), there were 4x less xul.dll IOs (graph [here](http://people.mozilla.com/~tglek/startup/systemtap_graphs/visualize.html?#../win7/prefetch.csv.html)). Unfortunately, the prefetcher can't figure out that the whole xul.dll should be paged in and we still end up with an excess of random IO.  
-  
-**Why?**  
-  
-When a page fault occurs, Windows goes to read the page from the file and reads a little extra (just like any other sane OS) assuming that there will be more IO nearby. Unfortunately the gods of virtual memory at Microsoft decided that for every page fault, only 7 extra pages should read. So reads occur in 32K chunks (vs 128K in Linux, which is still too small). To make matters worse, segments mapped in as data only read in 3 extra pages (ie 16K chunks).  
-  
-This is funny in a sad way. Reading in 32K chunks is supposed to minimize ram usage (which makes no bloody sense when Win7 officially requires 1GB of RAM). As a result of being so thrifty on easy-to-evict file cache, windows ends up doing 4x as much file IO as Linux. The 16K reads are particularly funny as one can see the result of that misoptimization in the string of puny reads on the top right of the graphs.  
-  
-**Surely There is an API like madvise()** On Posix systems madvise() can be used to influence the caching behavior of the OS. fadvise() is another such call for IO based on filehandles. For example, Firefox fastload files are now madvise()ed such that they are read in a single 2mb chunk on startup. Unfortunately, it appears that Windows has no such APIs so one is stuck with pathetically small reads.   
-  
-At first, I thought that, passing FILE_FLAG_SEQUENTIAL_SCAN when opening the file handle will work like a crappy fadvise()-equivalent. Turns out that mmaping files completely bypasses the Windows Cache Manager, so that flag just gets ignored.  
-  
-So as far as I can tell the only way to convince Windows to not read stuff in stupidly small chunks is to mmap() everything we care about using large pages. Unfortunately that comes with some significant costs.  
-  
-We are going to try to [order](https://bugzilla.mozilla.org/show_bug.cgi?id=553721) the binaries better which should halve the amount of page faults.  
-  
-**Can Windows Do Anything Better?**  
-  
-Yes. The "Unix way" of breaking up everything into a billion libraries and configuration files results in 10x more files being read on startup on Linux vs Windows. Just because Linux can read individual libraries 4x faster, doesn't mean that IO becomes free.  
-  
-Presently, in ideal conditions, Firefox starts up 30-50% faster on Windows. The Windows Prefetcher hack sweeps a lot of Windows suck under the carpet, but Microsoft has a lot of room for improvement.  
-  
-**Update:**  
-People seem to prefer to comment on [reddit](http://www.reddit.com/r/programming/comments/bu2do/windows_sucks_at_memorymapped_io_during_startup/). If you want me to not miss your comment, make sure you comment here.
diff --git a/source/_posts/2010-04-20-mozillaservices.markdown b/source/_posts/2010-04-20-mozillaservices.markdown
deleted file mode 100644
index e7b0892..0000000
--- a/source/_posts/2010-04-20-mozillaservices.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2010-04-20 11:20:10
-layout: post
-slug: mozillaservices
-title: mozilla::services
-wordpress_id: 305
-categories:
-- mozilla
----
-
-I landed the mozilla::services [bug](https://bugzilla.mozilla.org/show_bug.cgi?id=516085) around the same time as Gavin [announced](http://www.gavinsharp.com/blog/2010/02/25/services-jsm/) the Services.jsm equivalent. Services.jsm came a pleasant surprise to me, it's nice to have API symmetry.  
-  
-[mozilla::services](https://developer.mozilla.org/en/XPCOM/mozilla::services_namespace) namespace provides a fast C++ way to refer to common services. This replaces a myriad layers of indirection that happened in the XPCOM [GetService()](https://developer.mozilla.org/en/XPCOM_Interface_Reference/nsIServiceManager/getService) call. Too much generality hurts.   
-  
-So far I only replaced the common IOService getters. URL objects are 30% less slow to create now. A contributor, Mitchell Field, has volunteered to switch over a huge amount of other common services in [bug 560095](https://bugzilla.mozilla.org/show_bug.cgi?id=560095). That rocks.
diff --git a/source/_posts/2010-05-24-teethig-troubles-assigning-blame-for-pagefaults.markdown b/source/_posts/2010-05-24-teethig-troubles-assigning-blame-for-pagefaults.markdown
deleted file mode 100644
index 096d129..0000000
--- a/source/_posts/2010-05-24-teethig-troubles-assigning-blame-for-pagefaults.markdown
+++ /dev/null
@@ -1,44 +0,0 @@
----
-comments: true
-date: 2010-05-24 10:52:22
-layout: post
-slug: teethig-troubles-assigning-blame-for-pagefaults
-title: 'Teething Troubles: Assigning blame for pagefaults'
-wordpress_id: 318
-categories:
-- mozilla
----
-
-I have been able to get precise filed-backed page fault logging(systemtap on Linux, xperf on Windows) for a while. It is incredibly useful to see exactly how Firefox is being loaded from disk. From there one I deduce what is causing the IO, try to make improvements and measure if I accomplished anything.  
-  
-Unfortunately, a mere IO log requires a lot of pondering of why IO is happening. It would be so much easier if one could just get a report of every IO operation + an application backtrace to easily identify the cause. I was having trouble figuring out why some of my optimizations were not having the impact I expected, so i embarked on adding a backtrace to my log.  
-  
-**XPerf Fail** I fed [xperf](https://developer.mozilla.org/En/Profiling_with_Xperf) my Firefox symbols hoping this would plop stack traces next to my faults, but no such luck. It records backtraces in just about every probe, except for the "hard faults" probe I care about. I wonder if a custom perf probe could log what I want.  
-  
-**Perf Fail**  
-  
-Some prominent kernel hackers have long been complaining about OProfile/SystemTap/NIH performance monitoring tools. They finally produced a [perf](http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=tree;f=tools/perf;h=3f4245bfe10b67348c5cd41606f3fdc0396cbbea;hb=7e125f7b9cbfce4101191b8076d606c517a73066) tool (It's like they tried to make it hard to google for. It does not have a [proper](https://perf.wiki.kernel.org/index.php/Main_Page) website; Real men read the source and skim LKML archives) to do profiling the Linux way(tm). I might be wrong, but so far it appears to be a functional equivalent of Microsoft's xperf minus the nice UI.  
-  
-Turned out that my Fedora 2.6.32 perf implementation is too buggy to even log pagefaults. Apparently this works in the current Linus kernels. I'm not completely sure, but looks like even if xperf pagefault logging worked, it's pretty neutered. It does not appear that it can log file offsets next to pagefaults, nor stacks.  
-  
-I think perf could be fixed to log io and accompanying userspace backtraces. There are some talented folks contributing to it. However I think that the pre-canned analysis model sucks. It is useful for building sophisticated versions of top, but when you really need to dig into what's causing a particular issue, it really sucks to be restricted by what the developers foresaw as useful.  
-  
-**SystemTap**  
-  
-As awesome as the kernel side of [SystemTap](http://sourceware.org/systemtap/) is, I keep running into userspace bugs and limitations. Getting userspace stacks for large collections of large libraries that Firefox relies on has been a systemtap-bug-finding affair. I can occasionally get useful userspace tracks for userspace probes, but apparently recording a userspace stack from a kernel probe is a hard problem that SystemTap devs haven't fully addressed yet.  
-  
-Luckily SystemTap provides a uaddr() function which appears to get correct addresses from my kernel probes(which is way more than the other tools offer). Unfortunately usymname() fails to resolve those addresses.  
-  
-As a workaround, Jim Blandy suggested turning off [address-space randomization](http://gcc.gnu.org/wiki/Randomization) so I can log uaddr() and resolve the values in gdb. I've been manually printing this with gdb's "p/a <addr>" command until recently.  
-  
-**Success?**  
-  
-Then it dawned on me that I can use python gdb-scripting to automatically post-process the log. So now with a combination of a [systemtap io logging script](http://hg.mozilla.org/users/tglek_mozilla.com/startup/file/74e2f62fe64c/kernelio.stp) and a hacky [gdb python script](http://hg.mozilla.org/users/tglek_mozilla.com/startup/file/74e2f62fe64c/gdb_resolve.py) I can produce logs like [this](http://people.mozilla.com/~tglek/startup/pagefault_blame.txt).  
-  
-I still don't have backtraces, but at least now I have the name of the function that's causing trouble. This is surprisingly useful already. One can now easily tell how much of startup is being wasted on relocations(dlopen() in a prelinked binary!). Another obvious one is the [harm](http://sourceware.org/bugzilla/show_bug.cgi?id=11618) of single-page COW faults to zero .bss (memset entries in the log). Turns out [sprinkling](http://gcc.gnu.org/bugzilla/show_bug.cgi?id=44236) initializers all over the binary is a bad idea. Looks like there are significant performance wins to be had with a bit of 'easy' compiler/linker hacking.  
-  
-All of the above problems are really obvious and would've been fixed a long time ago if it was easier to get at this information. Unfortunately, there is still a lot of room for improvement in developer tools**.**  
-  
-**Update:**  
-  
-Sounds like I can use addr2line instead of gdb.
diff --git a/source/_posts/2010-05-27-startup-backward-constructors.markdown b/source/_posts/2010-05-27-startup-backward-constructors.markdown
deleted file mode 100644
index b220531..0000000
--- a/source/_posts/2010-05-27-startup-backward-constructors.markdown
+++ /dev/null
@@ -1,57 +0,0 @@
----
-comments: true
-date: 2010-05-27 16:35:20
-layout: post
-slug: startup-backward-constructors
-title: 'Startup: Backward Constructors'
-wordpress_id: 322
-categories:
-- mozilla
-- startup
----
-
-_This post is a result of debugging [bug 561842](https://bugzilla.mozilla.org/show_bug.cgi?id=561842). Turns out one needs to go far beyond lumping libraries together to reap startup benefits._  
-  
-I made a [pdf](http://hg.mozilla.org/users/tglek_mozilla.com/startup/raw-file/ca994a12e2a8/xulanatomy.pdf) to illustrate the cost centers of loading libxul.so (the essence of Firefox).  
-  
-With [Icegrind](http://taras.glek.net/blog/2010/04/07/icegrind-valgrind-plugin-for-optimizing-cold-startup/) I demonstrated that better binary layout can significantly improve application startup. However I still didn't have a breakdown of reasons of why loading binaries is so damn inefficient. That's what the above pdf is about.  
-  
-Loading libxul consists of 4 major phases: 
-
-  1. Runtime linker setup: mapping segments in, zeroing .bss, loading dependent libraries, etc
-  2. Runtime linker relocations.
-  3. Library intializers.
-  4. main() and the rest of application code runs
-I blogged about 1, 2, 4, this post is about #3.  
-  
-**Library Initializers?**  
-  
-[Michael Meeks](http://people.gnome.org/~michael/) pointed me at the funny backwards IO pattern in his IO logs. I even [made fun](http://taras.glek.net/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/) of how by default libxul.so is read mostly via backwards IO. Once I [assigned](http://taras.glek.net/blog/2010/05/24/teethig-troubles-assigning-blame-for-pagefaults/) userspace symbols to my pagefault log, it became clear that the backwards IO pattern was entirely due to library initializers. C++ compiler generates code that runs on library initialization to initialize globals and run relevant C++ constructors. In C one can assign a "constructor" GNU attribute to a function to participate in this mayhem.  
-  
-**Running Backwards?**  
-  
-Ian Lance Taylor clued me in on why these things run backwards.When one links the program, the object files are laid out sequentially. Static libraries are specified after the code that depends on them. Once an object is linked, the easiest way to make sure that libraries are initialized before their users is to invoke initializers backwards. The list of initializers is stored in the .ctors section and they loaded by libgcc.  
-  
-In Mozilla (and likely other C++ codebases) these global initializers are more or less evenly scattered throughout the codebase. By the time main() is run, most of the program has been paged in an unfortunately inefficient manner.  
-  
-**Run Faster Please?**  
-  
-The most interesting part about all this that the compiling toolchain can make a rather precise guess at how a large part of the initial program execution is going to go. To test this theory I wrote my best Mozilla [patch](https://bugzilla.mozilla.org/attachment.cgi?id=447253&action=edit) ever.  
-  
-One can place a function near the beginning of the library file and another one at the end (with a "constructor" attribute). The function at the end runs first and it can figure out the approximate range of memory that will need to be paged in and madvise() it. This results in a 5x reduction in libxul pagefaults. Unfortunately since constructors execute backwards and readahead forwards, the constructor execution stalls to wait for readahead, so the speedup is rather hard to detect.  
-  
-**Run Forward Faster!**  
-  
-Depressed about my hack failing to make a dent in startup time I patched gcc to run initializers in a forward order (and reversed the function-placement logic in above patch). Now readahead happened in the same direction as library initialization and my Firefox started 30% faster! I wrapped this up into a standalone [gcc patch](http://people.mozilla.com/~tglek/startup/ctors.diff) (speed up any bloated C++ startup with a simple change to the compiler!). Note this hack reverses the library initialization order discussed above, this happens to not be a problem for Mozilla.  
-  
-**Conclusion: Order Matters! **  
-  
-The linker can reverse the per-library initializers such that initializers run forward, but cross-library dependencies are honoured. That in itself isn't enough to boost startup without cleverer readahead on the kernel side (or application-side hacks).  
-  
-It's weird to have initializers page in most of the binary. An interesting optimization would to have the compiler transitively mark functions reached by library initialization and place those in a .text.initializers section. Then one could have the linker group the initializers together.  
-  
-**Plans**  
-  
-I haven't made up my mind on how to proceed. This madvise() hack + a simple linker patch could be deployed more easily than icegrind. This hack also appears to be as performant as a static firefox build + icegrind (due to inadequate kernel readahead without madvise()). Icegrid + libxul.so isn't quite as efficient. I have a feeling that we'll end up with a combination of icegrind + some form the initializer madvise() hack.  
-  
-
diff --git a/source/_posts/2010-06-09-galois-talk.markdown b/source/_posts/2010-06-09-galois-talk.markdown
deleted file mode 100644
index b311ba1..0000000
--- a/source/_posts/2010-06-09-galois-talk.markdown
+++ /dev/null
@@ -1,24 +0,0 @@
----
-comments: true
-date: 2010-06-09 10:08:44
-layout: post
-slug: galois-talk
-title: Galois talk
-wordpress_id: 325
-categories:
-- mozilla
-- dehydra
-- static-analysis
----
-
-I was invited to present a [Galois tech talk](http://www.galois.com/blog/2010/06/03/tech-talk-large-scale-static-analysis-at-mozilla/) on Mozilla static analysis. It was really cool to give a talk locally to such an expert audience. I was surprised to discover a vibrant Programming Languages + Analysis community in Portland.  
-  
-Edward Z. Yang did an [excellent write-up](http://blog.ezyang.com/2010/06/static-analysis-mozilla/) on the talk.  
-  
-**PLDi**  
-  
-Robert O'Callahan mentioned Dehydra in his [PLDI talk](http://weblogs.mozillazine.org/roc/archives/2010/06/sleepless_in_to.html).  
-  
-**Dehydra/Treehydra in GCC 4.5**  
-  
-There a few fixes that are about to land. I'm hoping that by the end of the week GCC 4.5 support will be production-quality. Sorry that it's taken so long, but I've been busy focusing on startup. [Ehren](http://ehren.wordpress.com/) has picked up the slack, we should be able to produce a fairly polished Dehydra 1.0 by the end of the summer.
diff --git a/source/_posts/2010-07-14-my-startup-summary.markdown b/source/_posts/2010-07-14-my-startup-summary.markdown
deleted file mode 100644
index f75f6c4..0000000
--- a/source/_posts/2010-07-14-my-startup-summary.markdown
+++ /dev/null
@@ -1,19 +0,0 @@
----
-comments: true
-date: 2010-07-14 11:27:13
-layout: post
-slug: my-startup-summary
-title: My Startup Summary
-wordpress_id: 328
-categories:
-- mozilla
----
-
-I try to blog about interesting things I encounter while solving various issues in Mozilla. Some things are less bloggable than others. If this blog don't fulfill your startup + static analysis needs you can follow my [status](http://benjamin.smedbergs.us/weekly-updates.fcgi/user/tarasglek/posts) updates and [twitter](http://twitter.com/crazyhackerdude). For now here is a summary of various half-baked/inprogress work: 
-
-  * I worked on [upgrading](https://bugzilla.mozilla.org/show_bug.cgi?id=559964) to GCC 4.5 which turned out to be a performance regression. While tracking down a workaround, I got into helping GCC guys help us by fixing gcc trunk's LTO to work on Mozilla.
-  * I am also determined to see Firefox come out with a [fat](https://bugzilla.mozilla.org/show_bug.cgi?id=561842) libxul and not link to [useless](https://bugzilla.mozilla.org/show_bug.cgi?id=577522) to us libraries by default.
-  * I spent a lot of time figuring out why our sqlite io [hurting](https://bugzilla.mozilla.org/show_bug.cgi?id=572459), ended up bumping block size to 32K. I am really hoping that Marco can [deliver](https://bugzilla.mozilla.org/show_bug.cgi?id=541373) VACUUM for all of the Firefox databases in time for Firefox 4.
-  * I refactored most of icegrind so in addition optimizing startup, it can also facilitate investigative work like [Mike Hommey ](http://glandium.org/blog/?p=1016)is doing.
-  * Posted a [summary](http://groups.google.com/group/mozilla.dev.platform/browse_thread/thread/abf60ad5fd03a708?pli=1) on the evils of static initializers. Came across a Chrome [equivalent](http://comments.gmane.org/gmane.comp.web.chromium.devel/16789) today.
-I plan to blog more on each of these subjects as they get closer to realization.
diff --git a/source/_posts/2010-07-22-file-fragmentation.markdown b/source/_posts/2010-07-22-file-fragmentation.markdown
deleted file mode 100644
index e43a333..0000000
--- a/source/_posts/2010-07-22-file-fragmentation.markdown
+++ /dev/null
@@ -1,70 +0,0 @@
----
-comments: true
-date: 2010-07-22 14:55:44
-layout: post
-slug: file-fragmentation
-title: File Fragmentation
-wordpress_id: 330
-categories:
-- mozilla
-- startup
----
-
-Files are considered fragmented when they aren't laid out in a continuous chunk on disk. This causes extra seeks even if the file is being read sequentially.  
-  
-I was discussing startup over dinner, someone asked about how much of an issue fragmentation is in Firefox.  
-  
-Early on I decided to pretend that fragmentation does not exist as we had bigger fish to fry. We were opening too many files on startup, effectively causing our own high-level fragmentation. Luckily, that problem should be mostly solved in Firefox 4 once [omnijar](https://bugzilla.mozilla.org/show_bug.cgi?id=556644) and [fat xul](https://bugzilla.mozilla.org/show_bug.cgi?id=561842) bugs land (unfortunately, extensions can cause similar issues until we stick em into a [single file](https://bugzilla.mozilla.org/show_bug.cgi?id=533038)).  
-  
-To measure fragmentation I used my SystemTap [script](http://hg.mozilla.org/users/tglek_mozilla.com/startup/file/782c42e1d6a4/kernelio.stp) to get a list of files opened (one could also use strace or any similar tool) and piped the results to filefrag. Filefrag is a Linux fragmentation-measuring utility. On Windows one can use [contig](http://technet.microsoft.com/en-us/sysinternals/bb897428.aspx) and Mac OS X features [hfsdebug](http://www.osxbook.com/software/hfsdebug/). I'm using ext4 on Linux.  
-  
-My top offenders were:
-```
-
-places.sqlite: 34 extents
-cookies.sqlite: 18 extents
-XPC.mfasl: 11 extents
-Cache/_CACHE_003_: 11 extents
-urlclassifier3.sqlite: 6 extents
-Cache/_CACHE_002_: 6 extents
-Cache/_CACHE_001_: 6 extents
-XUL.mfasl: 5 extents
-formhistory.sqlite: 5 extents
-content-prefs.sqlite: 4 extents
-libxul.so: 4 extents
-signons.sqlite: 3 extents
-icon-theme.cache: 2 extents
-libatk-1.0.so.0.2809.1: 2 extents
-libflashplayer.so: 2 extents
-Cache/_CACHE_MAP_: 2 extents
-
-```
-  
-  
-I did an informal poll of my friends and it seems that the order of fragmentation is similar among them, only the magnitude differs. For example, XFS tends to be 10-20 times more fragmented than ext4 :). I don't have any numbers for HFS+, but I suspect XFS takes the crown as most fragmentation-prone filesystem to run Firefox.  
-  
-Interestingly, my friend running NTFS reported similar fragmentation to ext4. That was disappointing as Windows Prefetch supposedly defragments files used with the first 10 seconds of startup. Clearly, isn't keeping up in this case.  
-  
-**Preliminary Conclusions**  
-  
-places.sqlite is the largest and most performance-critical file in Firefox. It contains browser history and bookmarks. It is the brains behind the AwesomeBar.The fact that it is severely affected by fragmentation significantly impacts Firefox responsiveness. There are no easy fixes for fragmentation there. mak suggested moving history to a separate file to mitigate this, but that isn't an easy change.  
-  
-In contrast, cookies.sqlite is tiny(<1mb for me) and probably so fragmented due to cookie expiration. I am guessing that easiest workaround here is to write a new sqlite file every time there is a mass update to the file.  
-  
-urlclassifier.sqlite is a large file that may be mitigated similarly to cookies.  
-  
-[SQLite 3.7.0](http://www.sqlite.org/releaselog/3_7_0.html) came out today which features WAL logging, which may reduce fragmentation (or make battling it easier). In general, sqlite's VACUUM (used to clean and compact the database) command does not help with fragmentation, we really need to be doing something like hot backup which would create a new database file every VACUUM.  
-  
-Our cache code is ancient and sucks. The cache files get fragmented immediately and severely. They are accessed in insane patterns and they get laid out insanely on disk. There are some efforts to improve the code, but I suspect that's equivalent to putting [lipstick](https://bugzilla.mozilla.org/show_bug.cgi?id=513008) on a pig.  
-  
-*.mfasl files are due to be obsoleted by a [startup cache](https://bugzilla.mozilla.org/show_bug.cgi?id=520309) jar. It may get less fragmented. Should be a straight-forward fix it if it does get fragmented.  
-  
-I'm disappointed to see the .so files get fragmented. This might be an ext4 bug or has something to do with how the updater works (both ours and yum on Fedora).  
-  
-**Further Work**  
-  
-I would like to see more data on fragmentation on Windows/OSX. Feel free to leave a comment with fragmentation numbers for cache, mfasl, sqlite and .dll files in your Firefox. We should look into online [defragmentation API](https://bugzilla.mozilla.org/show_bug.cgi?id=556326)s in modern OSes.  
-  
-**Workarounds?**  
-  
-Easiest way to fix fragmented files is to make a copy of the original file, delete the original and then rename the copy. This works on sane filesystems, apparently it doesn't work too well on OS X.
diff --git a/source/_posts/2010-07-30-msvc-static-initializers-decent-stuff.markdown b/source/_posts/2010-07-30-msvc-static-initializers-decent-stuff.markdown
deleted file mode 100644
index 37f1047..0000000
--- a/source/_posts/2010-07-30-msvc-static-initializers-decent-stuff.markdown
+++ /dev/null
@@ -1,27 +0,0 @@
----
-comments: true
-date: 2010-07-30 12:56:17
-layout: post
-slug: msvc-static-initializers-decent-stuff
-title: MSVC Static Initializers - Decent Stuff
-wordpress_id: 336
-categories:
-- mozilla
-- startup
----
-
-I was digging through a MSVC++ [map file](http://msdn.microsoft.com/en-us/library/k7xkk3e2%28v=VS.80%29.aspx) for xul.dll. Turns out MSVC++ isn't as [naive](http://taras.glek.net/blog/2010/05/27/startup-backward-constructors/) about virtual initializers as the GNU toolchain. Initializers are all laid out next to each other. Same goes for what looks like finalizers and exception unwinding stuff. Initializers have an __E prefix and look like this: 
-```
-
-0001:0089b470       ??__E?config@AvmCore@avmplus@@2UConfig@nanojit@@A@@YAXXZ 1089c470 f    CIL library: CIL module
-0001:0089b475       ??__EkStaticModules@@YAXXZ 1089c475 f   nsStaticXULComponents.obj
-0001:0089b638       ??__E?sSnifferEntries@nsUnknownDecoder@@1PAUnsSnifferEntry@1@A@@YAXXZ 1089c638 f   necko:nsUnknownDecoder.obj
-
-```
-  
-  
-Now if only Microsoft fixed their kernel to do [
-```
-memory-mapped IO
-```
-](http://taras.glek.net/blog/2010/04/19/windows-sucks-at-memory-mapped-io-during-startup/) efficiently, it'd be a superior OS for starting Firefox.
diff --git a/source/_posts/2010-09-07-fighting-fragmentation-sqlite.markdown b/source/_posts/2010-09-07-fighting-fragmentation-sqlite.markdown
deleted file mode 100644
index 1d69ed1..0000000
--- a/source/_posts/2010-09-07-fighting-fragmentation-sqlite.markdown
+++ /dev/null
@@ -1,35 +0,0 @@
----
-comments: true
-date: 2010-09-07 09:57:56
-layout: post
-slug: fighting-fragmentation-sqlite
-title: 'Fighting fragmentation: SQLite'
-wordpress_id: 338
-categories:
-- mozilla
----
-
-Thanks for all of those who commented on [previous post](http://taras.glek.net/blog/2010/07/22/file-fragmentation/) on fragmentation. My first fragmentation [fix](https://bugzilla.mozilla.org/show_bug.cgi?id=581606) has landed. In current nightlies and future releases the main Firefox databases will grow more aggressively to avoid fragmentation. This should translate into better history/awesomebar/cookie performance for our most dedicated users.  
-  
-Unfortunately fixing existing profiles is [hard](https://bugzilla.mozilla.org/show_bug.cgi?id=592678) from within Firefox. In the meantime advanced users on non-Windows platforms who are suffering from fragmentation can manually copy *.sqlite files to another directory and back.  
-  
-**Windows: Ahead of the pack**  
-  
-Evidence suggests that the Windows fragmentation situation is slightly better than on other platforms. Firefox fragmentation behavior on Windows is similar to other OSes but Windows periodically defragments Firefox files opened on startup. So one ends up with a cycle of deteriorating performance, followed by better performance(ie right after defrag), followed by deteriorating performance, etc.  
-  
-I haven't observed Windows defragmenting files for me, but it seems to do this for most users. Would love to learn more on how/when it decides to defragment files.  
-  
-**Horror Stories **  
-  
-I found a few other places that are horridly affected by fragmentation, will be blogging about those as I fix them. Fragmentation is an interesting problem to optimize because it affects dedicated users most, yet it is very tricky to replicate in a developer environment. Furthermore, there are a lot of misconceptions floating around: 
-
-  1. Fragmentation is a Windows problem that Linux is immune to due to having awesomer filesystems.
-  2. Mac OSX automatically defragments files, so fragmentation isn't a problem there.
-  3. Fragmentation isn't a problem on SSDs
-To which I say: 
-  1. Linux might be good at avoiding fragmentation for server workloads. It sucks for desktop users.
-  2. OSX will defragment small files, but big ones hurt most.
-  3. Cheap SSDs suck at tiny reads caused by fragmentation resulting in spectacularly bad IO. More on this in a future post.
-To summarize: there are a lot of misleading stories floating around. I am always happy to hear more measurements/docs/bugs/etc on this subject, but I have zero patience for folk stories and speculation.  
-  
-I should also mention that the fragmentation problem isn't limited to Firefox. Other browsers suffer from it too.
diff --git a/source/_posts/2010-09-09-help-wanted-does-fcntlf_preallocate-work-as-advertised-on-osx.markdown b/source/_posts/2010-09-09-help-wanted-does-fcntlf_preallocate-work-as-advertised-on-osx.markdown
deleted file mode 100644
index cf45be9..0000000
--- a/source/_posts/2010-09-09-help-wanted-does-fcntlf_preallocate-work-as-advertised-on-osx.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2010-09-09 14:06:11
-layout: post
-slug: help-wanted-does-fcntlf_preallocate-work-as-advertised-on-osx
-title: 'Help Wanted: Does fcntl(F_PREALLOCATE) Work as Advertised on OSX?'
-wordpress_id: 342
-categories:
-- mozilla
----
-
-To fight fragmentation it is best to tell the OS to allocate a continuous chunk of space for your file. With specialized APIs, the OS can do this without performing any IO (not counting metadata). I am adding support for this as part of [bug 592520](https://bugzilla.mozilla.org/show_bug.cgi?id=592520).  Linux features [posix_fadvise](http://linux.die.net/man/3/posix_fallocate) for preallocating files. Windows's [SetEndOfFile](http://msdn.microsoft.com/en-us/library/aa365531%28VS.85%29.aspx) achieves the same result. [Supposedly](http://lists.apple.com/archives/darwin-dev/2007/Dec/msg00040.html) OSX can do this via [fcntl](http://www.manpages.info/macosx/fcntl.2.html)(F_PREALLOCATE), but does it?  
-  
-I've experimented with posix_fadvise/SetEndOfFile and determined that they both change the file size and do their best to avoid fragmentation. Unfortunately I do not see any effect of fcntl(F_PREALLOCATE) on OS X 10.6 (the return code is successful). The file size does not change and if I then write to the file, it seems to fragment just as much as before. Can a Mac expert demonstrate that fcntl(F_PREALLOCATE) makes any difference at all?  
-  
-**Update:** Thanks a lot for the useful feedback, it was extremely helpful in producing this [patch](https://bug592520.bugzilla.mozilla.org/attachment.cgi?id=474233). It appears that the posix_fallocate equivalent is to the fnctl followed by a truncate() call (which actually forces data to be written to the file).
diff --git a/source/_posts/2010-09-14-firefox-4-jar-jar-jar.markdown b/source/_posts/2010-09-14-firefox-4-jar-jar-jar.markdown
deleted file mode 100644
index 52ae329..0000000
--- a/source/_posts/2010-09-14-firefox-4-jar-jar-jar.markdown
+++ /dev/null
@@ -1,48 +0,0 @@
----
-comments: true
-date: 2010-09-14 10:32:35
-layout: post
-slug: firefox-4-jar-jar-jar
-title: 'Firefox 4: jar jar jar'
-wordpress_id: 349
-categories:
-- mozilla
----
-
-Opening files is relatively expensive. There is a small syscall overhead and a higher overhead of fetching data from disk. Depending on physical data layout and disk type, this can leave modern CPUs twiddling their thumbs for a long time while the disk skips around fetching all of the different file pieces.  
-  
-**Optimization #1: Fewer naked files**  
-  
-About two years ago I started gathering naked files on disk and shoving them into jars (eg [bug 508421](https://bugzilla.mozilla.org/show_bug.cgi?id=508421)). We made jar reading as efficient as possible by cleaning up code and switching to [mmap](https://bugzilla.mozilla.org/show_bug.cgi?id=504864). Eventually all application data files read from disk during "normal" startup ended up in jars. Unfortunately we ended up with four jars (toolkit, chrome + 2 locale jars), which felt silly. Due to limitations in XPCOM, a lot of naked files were still read from disk on version upgrades and extension installation.  
-  
-**Optimization #2: One jar to rule them all**  
-  
-Recently Michael Wu unleashed a can of [omnijar](http://blog.mozilla.org/mwu/2010/08/13/omnijar-how-does-it-work/) whoopass. This was a massive effort driven by Android packaging requirements. Now application startup data is always being read from one file. This implies better data locality, less seeking, less waiting. One benefit of packing files tightly is that the OS speculatively reads data from disk in chunks that are usually larger than what the application requests. This makes reading nearby files free. Unfortunately there was no good way to predict the order that files will be accessed in without actually running Firefox, so there was more room for improvement.  
-  
-**Optimization #3: Optimized jar layout **  
-  
-So now that all of our data was in one file, the next logical step was to pack it intelligently. The only way to do this is to profile Firefox startup and then order the jar according to that. Unfortunately even once one lays out all of the jar entries sequentially we were still doing our io suboptimally. This was due to the fact that the zip index (jars are zip files) is traditionally located on the end of the file. Wikipedia [entry](http://en.wikipedia.org/wiki/ZIP_(file_format)) has pictures to illustrate this.  
-  
-In order to maximize readahead benefits and minimize disk seeks it would be nice to have the file index in the front of the file. So I changed our zip layout from  
-  
-<entry1><entry2>...<entryN><central directory><end of central directory>  
-  
-to  
-  
-<offset of the last entry read on startup><central directory><end of central directory><entry1><entry2>...<entryN><end of central directory>  
-  
-So all I did was change the offset in <end of central directory> to always be 4 (it can't be 0 because anal zip programs balk at "NULL" central directory offsets). Then I added a second identical <end of central directory> entry to keep the the rule that the central directory is always followed by one. I also used the extra space forced upon me by overly vigilant zip programs to store a number indicating how much data we can preread on startup.  
-  
-This yielded a 2-3x reduction in disk io over an unoptimized omnijar. This is on top of a >30-100x reduction achieved by going from naked files to omnijar.  
-  
-The downside of my interpretation of the zip spec is that some zip programs expect zip files to be more rigid than the spec allows. Older versions of Firefox, Microsoft zip support in windows, WinRAR, unix zip programs, etc accept my optimized jars. 7zip, broken antivirus (it's a security risk to be overly picky) [fail](https://bugzilla.mozilla.org/show_bug.cgi?id=595473).  
-  
-Trivia: this isn't the first time we got tripped up by picky zip reading code. For example, the Android apk reader irritatingly insists at having a zip entry at byte zero of an Android package. This means that one can't use apks to do the Android equivalent of self-extracting .exe files on Windows. Michael Wu is writing a custom library loader to deal with that :)  
-  
-**Optimization #4: More Omnijar**  
-  
-Feeling that omnijar wasn't awesome enough, Michael Wu went ahead and [omnijared extensions](http://blog.mozilla.org/mwu/2010/09/10/extensions-now-installed-packed/). Most extensions will no longer need to be unpacked from xpi files. This also means that extension authors can opt to use the optimized jar format above to further speed up Firefox startup.  
-  
-**Other jar optimizations**  
-  
-Switching to jars via[ startup cache](https://bugzilla.mozilla.org/show_bug.cgi?id=520309) will allow us to further [optimize](https://bugzilla.mozilla.org/show_bug.cgi?id=562406) our first startup. There is option of halving our jar IO further by actually making use of that readahead integer I added to optimized jars.
diff --git a/source/_posts/2010-10-04-None.markdown b/source/_posts/2010-10-04-None.markdown
deleted file mode 100644
index d667a66..0000000
--- a/source/_posts/2010-10-04-None.markdown
+++ /dev/null
@@ -1,13 +0,0 @@
----
-comments: true
-date: 2010-10-04 20:12:39
-layout: post
-published: false
-slug: None
-title: Auto Draft
-wordpress_id: 361
-categories:
-- mozilla
----
-
-None
diff --git a/source/_posts/2010-10-04-diagnosing-slow-startup.markdown b/source/_posts/2010-10-04-diagnosing-slow-startup.markdown
deleted file mode 100644
index f64473d..0000000
--- a/source/_posts/2010-10-04-diagnosing-slow-startup.markdown
+++ /dev/null
@@ -1,41 +0,0 @@
----
-comments: true
-date: 2010-10-04 17:30:56
-layout: post
-slug: diagnosing-slow-startup
-title: Diagnosing Slow Startup
-wordpress_id: 358
-categories:
-- mozilla
-- startup
----
-
-I spent last week trying to reproduce slow startup on Windows. Some users were reporting >30 second startup, supernova_00 has been feeding me [xperf](https://developer.mozilla.org/En/Profiling_with_Xperf) traces on IRC reproducing slow startups.  
-  
-**Startup Bugs**  
-  
-Turns out that if a website uses non-standard font names this can trigger Firefox to start parsing every single font on the system, freezing the browser in the meantime. Turns out facebook does this :(. This is now a blocker [bug 600713](https://bugzilla.mozilla.org/show_bug.cgi?id=600713). This bug has the unfortunate effect of overshadowing any startup improvements in Firefox 4.  
-  
-We have some code to keep our databases in good shape by VACUUMing them. This is getting revamped in Firefox in [bug 541373](https://bugzilla.mozilla.org/show_bug.cgi?id=541373). In the meantime, for many current users performance suffers due to missing vacuums. If you are suffering from slow Firefox startup, and/or slow Awesomebar try this [manual vacuum](http://mozillalinks.org/wp/2009/08/vacuum-firefox-databases-for-better-performance-now-with-no-restart/). This helps in older Firefox releases, but in Firefox 4 this has the effect of supercharging the SQLite database performance by switching to [32K pages](https://bugzilla.mozilla.org/show_bug.cgi?id=416330).  
-  
-**Scareware**  
-  
-Another fun discovery was the effect of anti-virus software(AVG in this case). Like an annoying pet, AVG has to have a sniff and fondle every file that Firefox opens on startup. Apparently this is a feature called on-demand scanning, yuck.  
-  
-But the fun doesn't stop there, Windows has a wonderful [prefetch](http://en.wikipedia.org/wiki/Prefetcher) mechanism that speeds up app startup. Unfortunately for supernova_00, \Windows\Prefetch just wouldn't get populated with Firefox info, meaning that Windows wasn't optimizing Firefox startup. Once I installed AVG, I ran into the same problem. Uninstalling AVG didn't help. For whatever reason deleting every file in \Windows\Prefetch fixes that problem. For both of us prefetch got repopulated after being cleaned.  
-  
-**XPerf**  
-  
-Microsoft XPerf makes trivial to optimize cold startup. None of the other OSes have precanned analyses showing how much each individual file access is contributing to slow startup.  
-  
-If you have a startup problem, I'm much more likely to be able to reproduce it if the report comes with an xperf trace. To get xperf run the Microsoft Platform SDK [installer](http://www.microsoft.com/downloads/en/details.aspx?FamilyID=6b6c21d2-2006-4afa-9702-529fa782d63b&displaylang=en), select "Windows Performance Toolkit".  
-  
-To record an IO trace: 
-
-  1. Reboot
-  2. run cmd.exe as Administrator
-  3. xperf -on latency+FILE_IO+FILE_IO_INIT+DISK_IO
-  4. run Firefox, reproduce the bug
-  5. xperf -d report.etl
-  6. Run xperf report.etl to view the report.
-Click on "IO Counts" or "Hard faults" graph, select "Summary Table". "IO Time (ms)" is the interesting column there. To get an idea of the sequence of IO operations, export the summary table to .csv and load it in a spreadsheet/grep/whatever. Every Firefox developer should give xperf a try, addon authors are encouraged too.
diff --git a/source/_posts/2010-10-05-None.markdown b/source/_posts/2010-10-05-None.markdown
deleted file mode 100644
index c87217f..0000000
--- a/source/_posts/2010-10-05-None.markdown
+++ /dev/null
@@ -1,13 +0,0 @@
----
-comments: true
-date: 2010-10-05 13:27:35
-layout: post
-published: false
-slug: None
-title: Auto Draft
-wordpress_id: 362
-categories:
-- mozilla
----
-
-None
diff --git a/source/_posts/2010-11-16-performance-progress.markdown b/source/_posts/2010-11-16-performance-progress.markdown
deleted file mode 100644
index b07a99c..0000000
--- a/source/_posts/2010-11-16-performance-progress.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2010-11-16 15:14:02
-layout: post
-slug: performance-progress
-title: 'Performance Update. Fragmentation: Mostly fixed. GCC: work-in-progress.'
-wordpress_id: 364
-categories:
-- mozilla
----
-
-**Fragmentation: SQLite & Friends **  
-  
-I am happy to report that the SQLite fragmentation [problem](http://taras.glek.net/blog/2010/09/07/fighting-fragmentation-sqlite/) is now [solved](https://bugzilla.mozilla.org/show_bug.cgi?id=581606). I copied my profile a month ago, and my places.sqlite is still in a single fragment! There was a similar [fix](https://bugzilla.mozilla.org/show_bug.cgi?id=592520) done to Firefox disk cache. Thanks to helpful comments on my OSX preallocation [cry for help](http://taras.glek.net/blog/2010/09/09/help-wanted-does-fcntlf_preallocate-work-as-advertised-on-osx/), we now preallocate efficiently on OSX too.  
-  
-Startup cache is the last [remaining](https://bugzilla.mozilla.org/show_bug.cgi?id=593349) bastion of fragmentation, but that's already 10x better than it was a month ago. I have two complimentary solutions for that: either [omnijar startup cache generation](https://bugzilla.mozilla.org/show_bug.cgi?id=562406) for core code and/or write the cache more [efficiently](https://bugzilla.mozilla.org/show_bug.cgi?id=586859).  
-  
-Firefox 4 will be a lot more gentle on those spinning platters.  
-  
-**GCC**  
-  
-I helped Jan Hubicka on a GCC [summit paper](http://gcc.gnu.org/wiki/summit2010). Those nasty static initializers will not be a hassle in GCC 4.6!  
-  
-I keep wanting to blog about how we switched to [GCC 4.5](https://bugzilla.mozilla.org/show_bug.cgi?id=559964) and how life is wonderful, but life didn't work out this way. So far we tried switching away from 4.3 compiler three times. The first time GCC completely failed in terms of -Os performance. C++ -Os is more bloated in 4.5 (because that option is benchmarked on C apps). Then it turned out that libffi was being [miscompiled](http://gcc.gnu.org/bugzilla/show_bug.cgi?id=45623) (we also found a related bug in libffi). Last time, we tried switching to GCC 4.5 + -O3 since that performs much better than -Os, but that [broke](https://bugzilla.mozilla.org/show_bug.cgi?id=609543#c45) sunspider. Hopefully we can fix the sunspider issue and try again next week. I would really like to utilize GCC [PGO](https://bugzilla.mozilla.org/show_bug.cgi?id=418866) to produce fastest possible Linux Firefox builds.  
-  
-Nonetheless I happy with recent GCC progress. With Jan's help, GCC will eventually be very good at compiling Mozilla. In my spare cycles I've been working on setting up GCC benchmarks using Mozilla to help avoid future surprises like we discovered in GCC 4.5. More on this later.
diff --git a/source/_posts/2010-11-23-of-linkers-and-avoiding-suck.markdown b/source/_posts/2010-11-23-of-linkers-and-avoiding-suck.markdown
deleted file mode 100644
index b984f36..0000000
--- a/source/_posts/2010-11-23-of-linkers-and-avoiding-suck.markdown
+++ /dev/null
@@ -1,15 +0,0 @@
----
-comments: true
-date: 2010-11-23 10:41:47
-layout: post
-slug: of-linkers-and-avoiding-suck
-title: Of linkers and avoiding suck
-wordpress_id: 369
-categories:
-- mozilla
-- startup
----
-
-There is a common fallacy that since linkers and compilers are written by really smart people, there aren't any huge performance wins left in the toolchain. My theory is that the efficiency of any given codebase varies inversely with the number of people who tried to optimize it.  
-  
-I have long complained of suboptimal binaries generated from our code. Modern profiling tools such as [systemtap](http://taras.glek.net/blog/2009/10/23/studying-library-io-systemtap-style/) and [icegrind](http://taras.glek.net/blog/2010/04/07/icegrind-valgrind-plugin-for-optimizing-cold-startup/) made this painfully obvious. Mike Hommey opted for actually doing something about it. What started as a simple ld.so hack grew into a[ badass binary-rewriting tool](http://glandium.org/blog/?p=1177) (and the most interesting blog post I've read this year).
diff --git a/source/_posts/2010-11-30-crapware-and-firefox.markdown b/source/_posts/2010-11-30-crapware-and-firefox.markdown
deleted file mode 100644
index 6c50b3f..0000000
--- a/source/_posts/2010-11-30-crapware-and-firefox.markdown
+++ /dev/null
@@ -1,22 +0,0 @@
----
-comments: true
-date: 2010-11-30 11:14:20
-layout: post
-slug: crapware-and-firefox
-title: Crapware and Firefox
-wordpress_id: 372
-categories:
-- mozilla
----
-
-I completely agree with [Asa](http://weblogs.mozillazine.org/asa/archives/2010/11/why_do_they_think_th.html) that having unwanted crap forced upon the user is morally wrong. We should do a better job of undoing this kind of braindamage. In the meantime here is a brief rant on the parasitic underpinnings of crapware.  
-  
-Until recently, I have been testing Firefox on my own installs of Windows. I had no idea how aggressive bundleware could be. Then I got this piece-of-crap i7 Acer laptop with Windows 7 (and relatively little crapware preinstalled) and tried to use it as my primary machine. Suddenly, I could reproduce a lot more "slow" scenarios. I even went further and tried installing common crapware known as AVG to reproduce more bugs.  
-  
-Turns out almost every vendor tries to mix in crap into Firefox. Acer, Microsoft Office/Silverlight, Adobe flash/acrobat, Google, AVG, etc all added unwanted functionality to my Firefox. I marveled at all kinds of "helpful" functionality such as the wonderful ability to click on a link in a webpage and have Google chrome install without any warning that the webpage is about to execute a windows program. AVG adds a couple of extensions that make Firefox start up 0.5-4x slower.  
-  
-So far I noticed 2 vectors of attack: plugins and extensions. Plugins are fun because those get added by registering bonus plugin directories. Plugin directories are usually just application directories that contain plugins. This means Firefox gets to [slowly](https://bugzilla.mozilla.org/show_bug.cgi?id=614423) rummage through bonus application directories looking for what might be a plugin. Extensions are fun because unlike plugins (which affect most browsers on the computer), extensions are very browser-specific. Most extension crapware doesn't yet support Chrome. Installing things like AVG retards Firefox performance while Chrome escapes unmolested.  
-  
-[Benjamin](http://benjamin.smedbergs.us/blog/2010-11-29/software-integration-is-not-evil/), I don't think these software vendors are "doing exactly as we ask of them."  
-  
-Personally, I would like us to be a lot more aggressive about blacklisting ill-performing software. Ie we need to go above and beyond [warning](https://bugzilla.mozilla.org/show_bug.cgi?id=476430) users when crapware. I would like to to actively check performance of popular plugins/addons and ban them if they are substandard.
diff --git a/source/_posts/2010-12-21-rude-surprise-startup-overhead-of-windows-font-apis.markdown b/source/_posts/2010-12-21-rude-surprise-startup-overhead-of-windows-font-apis.markdown
deleted file mode 100644
index 8dbf35d..0000000
--- a/source/_posts/2010-12-21-rude-surprise-startup-overhead-of-windows-font-apis.markdown
+++ /dev/null
@@ -1,21 +0,0 @@
----
-comments: true
-date: 2010-12-21 13:33:14
-layout: post
-slug: rude-surprise-startup-overhead-of-windows-font-apis
-title: 'Rude Surprise: Startup Overhead of Windows Font APIs'
-wordpress_id: 375
-categories:
-- mozilla
-- startup
----
-
-Imagine a typical Firefox user who starts their Windows computer in order to surf the web. First app they launch is Firefox 4. Turned out that on systems that support hardware-acceleration for 2D graphics, Firefox 4 takes minutes to startup. WTF? XPerf-aided investigation showed that, the Windows font enumeration code causes us to do 30x more disk IO (~300MB) than the rest of Firefox code.  
-  
-In order to hardware accelerate Firefox, we switched from GDI to using DirectWrite for font stuffs. Apparently, DirectWrite is a wonderful api, but the implementation has some teething issues. DirectWrite opens a connection to the Font Service (and starts it if it isn't already running), however if service fails to respond DirectWrite proceeds to enumerate all of the system fonts on the client-side. This isn't cool for multiple reasons: a) it is [slow as hell](https://bugzilla.mozilla.org/show_bug.cgi?id=602792) b) it causes Firefox to [run out of memory](https://bugzilla.mozilla.org/show_bug.cgi?id=617266)(installing IE9 helps!) sooner.  This means that currently Firefox 4 starts up a lot slower than 3.6. [John Daggett](http://blog.mozilla.org/nattokirai/) is busy working on a workaround by using older GDI APIs to enumerate fonts. Firefox is one of the first popular Windows applications to switch to DirectWrite, so we get to suffer the consequences.  
-  
-Unfortunately it turns out that using Microsoft GDI APIs to [enumerate fonts](https://bugzilla.mozilla.org/show_bug.cgi?id=600713) still causes a significant amount of disk IO (~30-60MB), John plans to fix that next.  
-  
-**How Did We Miss This?**  
-  
-This bug came from a fundamental difference of how developers and users start Firefox. A developer will restart Firefox a dozen times an hour. This means we rarely get to observe true cold startup. Our tests only measure warm startup (because most operating systems make it difficult to test cold startup). Windows is also incredibly slow to develop on, so a lot of us test in a virtual machine to speed things up and avoid rebooting the computer all the time. This also makes observing cold startup hard. Fortunately xperf makes IO much easier to observe. We should deploy xperf on our [test infrastructure](https://bugzilla.mozilla.org/show_bug.cgi?id=609111) as soon as possible.
diff --git a/source/_posts/2011-01-14-builtin-startup-measurement.markdown b/source/_posts/2011-01-14-builtin-startup-measurement.markdown
deleted file mode 100644
index 40472d4..0000000
--- a/source/_posts/2011-01-14-builtin-startup-measurement.markdown
+++ /dev/null
@@ -1,48 +0,0 @@
----
-comments: true
-date: 2011-01-14 13:25:20
-layout: post
-slug: builtin-startup-measurement
-title: Builtin Startup Measurement
-wordpress_id: 384
-categories:
-- mozilla
----
-
-I got used to measuring startup the complicated way (example [here](http://taras.glek.net/blog/2010/01/04/windows-7-startup-exploration/)). It's complicated enough that many people prefer to use stopwatches.  
-  
-Turns out modern operating systems can help applications self-diagnose startup speed. Thanks to landing [bug 522375](https://bugzilla.mozilla.org/show_bug.cgi?id=522375) we now provide an API for measuring startup speed. For example, now I know that xpcshell takes forever to startup on mac 
-```
-
-./xpcshell -e 'print(new Date() - Components.classes["@mozilla.org/toolkit/app-startup;1"].getService(Components.interfaces.nsIAppStartup_MOZILLA_2_0).getStartupInfo().process)'
-
-```
-At any point one can now go to the error console and type in 
-```
-
-uneval(Components.classes["@mozilla.org/toolkit/app-startup;1"].getService(Components.interfaces.nsIAppStartup_MOZILLA_2_0).getStartupInfo())
-
-```
-or 
-```
-
-var si=Components.classes["@mozilla.org/toolkit/app-startup;1"].getService(Components.interfaces.nsIAppStartup_MOZILLA_2_0).getStartupInfo(); si.sessionRestored-si.process
-
-```
-to get various interesting timestamps. So next time you see a startup take a surprising amount of time, you can go and poke around to see where that time was spent. At the moment there are 4 datapoints: 
-
-  1. .process - Process creation timestamp. This is cool because this happens before any library code is executed.
-  2. .main - XRE_main timestamp. My favourite thing to do is to subtract .process from .main. This demonstrates huge overheads that many application programmers refuse to believe in.
-  3. .firstPaint - Timestamp of the first intended paint. This coincides with when the user sees the first sign of life.
-  4. .sessionRestore - Timestamp of session restore, ie when the browser becomes useful.
-Lots of people helped in getting this feature landed, but two people stand out. Daniel Brooks originally figured how to expose Windows/Linux startup speed in Mozilla. Mike Hommey devised a morally-reprehensible way to get precise startup speed out of the idiotic way that Linux presents it.  
-  
-**Linux Sucks **  
-  
-Mac and Windows expose process creation times via human time. It's just like any other API with time in it. Linux provides process startup speed in imbecile jiffies-since-boot. That'd be irritating enough, but to piss people off further there is no way to convert that into human time. Clever ps developers resort to calculating jiffies/second by comparing against seconds-since-start in /proc/uptime. Unfortunately that does not even come close to providing anything close to millisecond resolution needed for useful numbers. Mike's idea of timing startup of another thread/task to get a known jiffy-stamp got us precise-enough numbers (around 10ms resolution with most kernels, see [patch](http://hg.mozilla.org/mozilla-central/rev/dfdf3e5dc749) for details). At least Linus was kind enough to let mere user-space devs obtain the current tick-rate.  
-  
-**Update:**  
-  
-Linux doesn't suck anymore, a commenter pointed me to a relatively new(2006) taskstats interface which appears to work sanely like the BSD one.  
-  
-Mike Hommey made an [about:startup extension](http://glandium.org/blog/?p=1575) using this API.
diff --git a/source/_posts/2011-02-09-magic-patch-that-doubles-windows-startup.markdown b/source/_posts/2011-02-09-magic-patch-that-doubles-windows-startup.markdown
deleted file mode 100644
index 1287043..0000000
--- a/source/_posts/2011-02-09-magic-patch-that-doubles-windows-startup.markdown
+++ /dev/null
@@ -1,19 +0,0 @@
----
-comments: true
-date: 2011-02-09 16:38:38
-layout: post
-slug: magic-patch-that-doubles-windows-startup
-title: Magic patch that halves Windows startup
-wordpress_id: 399
-categories:
-- mozilla
-- startup
----
-
-Internet as of late have been obsessing over magically short patches that improve performance _ times(probably as a result of LKML cgroups patch from a few weeks ago). So my work in [bug 627591](https://bugzilla.mozilla.org/show_bug.cgi?id=627591) got picked up in all kinds of news sources(mostly due to @limi's [manlove](http://twitter.com/#!/limi/status/28983240966541312)). Apparently all that internet fame is good for is getting script-kiddies to upload viruses as bugzilla attachments. Dear Internet, please do not interrupt me in the middle of an investigation.  
-  
-To crux of the optimization lies in trading waiting for random io for fast sequential IO. Turned out that my patch worked great if windows prefetch wasn't trying to help (ie firefox ran faster without prefetch on my test systems). With prefetch on, the patch was either a smaller win or a downright loss. When I dug in deeper, it turned that the Windows Prefetch helpfully spends 3-6 seconds doing IO before any Firefox code gets to run. It also doesn't read in a very clever pattern, resulting in a very small speed up for Firefox, but preventing my exciting optimization.  
-  
-So I curled up into my defeated fetal position and pondered on how would I prevent Windows Prefetch from being so "helpful". One way would be to [install](http://taras.glek.net/blog/2010/10/04/diagnosing-slow-startup/) some crapware to cripple prefetch (kidding!), another way is to do the sequential IO in a separate executable(ala[ run-mozilla.sh](http://glandium.org/blog/?p=1719) on Unix). This way Windows doesn't try to do insane amounts of IO before my preloading logic gets to run. This seems to work (see wrapper.exe talk in the bug) and has potential to double Firefox startup times. It's also ugly as sin, but if that's what it takes...  
-  
-So now I need more reports to make sure the executable wrapper approach reliably/significantly speeds up cold(post-reboot) startup. Then we can make a decision on how to integrate this into Firefox. But until we have all the data, please don't jump to conclusions on what will and wont make Firefox 2x faster.
diff --git a/source/_posts/2011-04-14-arguing-about-startup-communicating-performance.markdown b/source/_posts/2011-04-14-arguing-about-startup-communicating-performance.markdown
deleted file mode 100644
index 40d251c..0000000
--- a/source/_posts/2011-04-14-arguing-about-startup-communicating-performance.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2011-04-14 11:15:46
-layout: post
-slug: arguing-about-startup-communicating-performance
-title: 'Arguing about startup: Communicating performance'
-wordpress_id: 410
-categories:
-- mozilla
----
-
-Recently the addon team started working towards penalizing addons that penalize our startup. We have solid data shows that startup gets worse as more addons installed so the effort is justified. Justin published this picture to illustrate the problem: ![](http://people.mozilla.com/~fligtar/performance/num-addons-med.png)  
-  
-However some technical mistakes were made. Wladimir (AdBlock+ guy!) has been busy exposing them on his [blog](http://adblockplus.org/blog/the-wrong-way-of-allowing-users-to-make-informed-decisions). Thanks Wladimir! I spent a couple of years understanding Firefox startup, so I really appreciate Wladimir's remarkable speed/quality in poking holes in AMO approach.  
-  
-**Rating Addon Performance******  
-  
-Wlad's latest [point](http://adblockplus.org/blog/the-wrong-way-of-allowing-users-to-make-informed-decisions) is regarding how addon impact is measured on warm startup with an empty profile. I agree that addon impact on warm startup with clean profile is going to be different from that of cold startup with a dirty real-world profile. I also agree that it is weird to primarily measure warm startup given that our data clearly indicates that most users are experiencing cold startup.  
-  
-However startup is an irritating multidimensional problem influenced by a large number of factors. Should we suck it up and let addons kill warm startup (and risk ruining firefox upgrade times, pissing off web developers)? How does one choose a typical dirty profile? Creating a "typical" dirty profile is a tough problem (ie due to privacy, disk fragmentation) and there is no reason to let clean profile performance be degraded.  
-  
-So an addon performance rating will not be perfect. Time added by addon during warm startup is the easiest starting point and is one of the more deterministic measures (Wlad's blog says otherwise, but measuring other startup kinds have even more noise). This is no worse than choosing browsers based on their JavaScript benchmark performance.  
-  
-I think a much awesomer addon performance rating may be obtainable by clever statistics boffins by analyzing our aggregated startup data. Perhaps the Mozilla Metrics will make it a reality, but in the meantime we'll have to make do with an imperfect approach.  
-  
-_**Coming soon:** Why is the measurement approach in Jorge's [post](http://xulforge.com/blog/2011/04/testing-add-on-startup-performance/) is overly complicated and somewhat incorrect._
diff --git a/source/_posts/2011-04-26-measuring-startup-speed-correctly.markdown b/source/_posts/2011-04-26-measuring-startup-speed-correctly.markdown
deleted file mode 100644
index df60b79..0000000
--- a/source/_posts/2011-04-26-measuring-startup-speed-correctly.markdown
+++ /dev/null
@@ -1,29 +0,0 @@
----
-comments: true
-date: 2011-04-26 14:34:02
-layout: post
-slug: measuring-startup-speed-correctly
-title: Measuring Startup Speed Correctly
-wordpress_id: 412
-categories:
-- mozilla
-- startup
----
-
-Until recently our state of the art method for measuring startup was to subtract a timestamp passed via commandline from a 
-```
-new Date()
-```
-timestamp within a 
-```
-<script>
-```
-tag. Vlad [pioneered](http://blog.vlad1.com/2009/07/28/measuring-startup/) this approach, [me](http://taras.glek.net/blog/2010/01/19/chromium-vs-minefield-cold-startup-performance-comparison/) and others adopted it.  
-  
-Turns out there are two problems with this approach: 
-
-  1. It is cumbersome, especially on Windows where there is no easy way to pass a timestamp via the commandline.
-  2. It is wrong. Turns out that Firefox starts loading web pages before the UI is shown. One can't be sure that the page being loaded is within a visible browser
-Our oldest startup benchmark, ts,  has been gathering wrong numbers all along.  This resulted in a class of perverse optimizations that decreased the ts number, but increased the time taken for UI to appear (ie [bug 641691](http://bugzil.la/641691)). The new [tpaint (bug 612190)](https://bugzilla.mozilla.org/show_bug.cgi?id=612190) benchmark should should address this. On my machine measuring pageload vs paint-time results in a 50-100ms difference. See the [graph server](http://graphs.allizom.org/graph.html#tests=[[83,1,1],[83,1,17],[83,1,12],[83,1,13],[83,1,14],[16,1,12]]&sel=none&displayrange=7&datatype=running) for more data.  
-  
-This is why AMO's [complicated method](http://xulforge.com/blog/2011/04/testing-add-on-startup-performance/) of measuring startup is wrong. Please use our shiny new [about:startup](https://wiki.mozilla.org/Firefox/Projects/StartupPerformance/MeasuringStartup) extension or if you absolutely want to avoid adding any overhead use [getStartupInfo](https://developer.mozilla.org/en/XPCOM_Interface_Reference/nsIAppStartup_MOZILLA_2_0#getStartupInfo%28%29) API directly.
diff --git a/source/_posts/2011-05-13-firefox-telemetry.markdown b/source/_posts/2011-05-13-firefox-telemetry.markdown
deleted file mode 100644
index 4643ca6..0000000
--- a/source/_posts/2011-05-13-firefox-telemetry.markdown
+++ /dev/null
@@ -1,32 +0,0 @@
----
-comments: true
-date: 2011-05-13 16:35:45
-layout: post
-slug: firefox-telemetry
-title: Firefox Telemetry
-wordpress_id: 418
-categories:
-- mozilla
----
-
-**Benchmarks Suck**  
-  
-Mozilla has traditionally relied on [Talos, Sunspider, Kraken, etc] benchmarks to optimize Firefox. Unfortunately there are two problems with benchmarks: a) it is hard to write good benchmarks (see all of the complaints about Sunspider) b) the most perfect synthetic benchmarks do not completely correspond to actual user usage. Firefox with a well-used profile, anti-viral software, well-aged Windows and 30 addons will not perform the same as it does in our clean benchmarking environment.  
-  
-For my team this became obvious in Firefox 4 once we started recording Firefox startup times. Turned out that it is easier to work on fixing startup performance than make our synthetic test closely reflect real world startup speed.  
-  
-**Telemetry**  
-  
-There is only one solution to this problem: develop telemetry infrastructure to measure Firefox performance in the wild. Beginning with version 6, Firefox will ask users to opt-in to sending anonymous usage statistics about performance, user interface feature usage, memory usage, and responsiveness to Mozilla. This information will help us improve future versions of Firefox to better fit actual usage patterns.  
-  
-This functionality is already present in our major competitors. Unlike our competition we do not plan to tag reported data with unique identifiers. This will make it harder for us see how Firefox performance changes over time for particular users (or easily tell whether some users are disproportionately represented due to sending more reports). We take our users' privacy seriously, so this seems like a reasonable trade off.  
-  
-Yesterday I landed the reporting part of telemetry (bug [585196](https://bugzilla.mozilla.org/show_bug.cgi?id=585196)). We are still working on UI, official server-side and on updating the privacy policy.  
-  
-![](http://people.mozilla.com/~tglek/telemetry/telemetry.jpg)  
-  
-Above screenshot shows some of the data that will be gathered for users that opt-in to telemetry.  
-  
-Please help us get a headstart on telemetry. In the recent nightlies, go to about:config and set toolkit.telemetry.enabled to true. Once the pref is set, Firefox will send interesting performance data to the telemetry test server. The metrics are very compact and are sent out no more than once a day.  
-  
-Since there is no UI yet, install my [about:telemetry](https://addons.mozilla.org/en-US/firefox/addon/abouttelemetry/) extension and navigate to "about:telemetry" to see the metrics collected.
diff --git a/source/_posts/2011-06-01-telemetry-updates.markdown b/source/_posts/2011-06-01-telemetry-updates.markdown
deleted file mode 100644
index 3d94574..0000000
--- a/source/_posts/2011-06-01-telemetry-updates.markdown
+++ /dev/null
@@ -1,20 +0,0 @@
----
-comments: true
-date: 2011-06-01 12:03:47
-layout: post
-slug: telemetry-updates
-title: Telemetry Updates
-wordpress_id: 422
-categories:
-- mozilla
-tags:
-- telemetry
----
-
-My [previous post](http://taras.glek.net/blog/2011/05/13/firefox-telemetry/) was too optimistic. There will be no telemetry in Firefox 6. Due to the multitude of reviews involved we slipped and are now aiming for Firefox 7. [Bug 659396](https://bugzilla.mozilla.org/show_bug.cgi?id=659396) tracks various ongoing telemetry tasks.  
-  
-I updated my [about:telemetry](http://people.mozilla.com/~tglek/telemetry/ping.telemetry.xpi) extension to work with Firefox 7 nightlies. Additionally, my friend, David, helped me apply some nasty CSS tricks to make the histograms look like histograms. I'm open to further CSS contributions. I haven't listed the extension on AMO because we plan to have this functionality integrated into Firefox soon (hopefully 7).  
-  
-To turn on telemetry,we have to: a) finish up the telemetry [opt-in UI](https://bugzilla.mozilla.org/show_bug.cgi?id=652657) and b) [update](http://www.archivum.info/mozilla.governance/2011-05/00009/Update-to-Firefox-Privacy-Policy.html) our privacy policy.  
-  
-Thanks to everybody who manually flipped the pref to turn on telemetry. Having early feedback on this feature is awesome.
diff --git a/source/_posts/2011-06-22-developers-how-to-submit-telemetry-data.markdown b/source/_posts/2011-06-22-developers-how-to-submit-telemetry-data.markdown
deleted file mode 100644
index ceeb5c6..0000000
--- a/source/_posts/2011-06-22-developers-how-to-submit-telemetry-data.markdown
+++ /dev/null
@@ -1,41 +0,0 @@
----
-comments: true
-date: 2011-06-22 14:06:14
-layout: post
-slug: developers-how-to-submit-telemetry-data
-title: 'Developers: How To Submit Telemetry Data'
-wordpress_id: 424
-categories:
-- mozilla
----
-
-Telemetry is a way to gather stats about Firefox. Currently histograms are the main mechanism by which to gather data. There are 3 histogram types currently supported: exponential, linear and boolean. Exponential+linear histograms can accumulate numbers between 0 and a user-defined integer maximum, they differ in bucket size increments. Boolean histograms are meant to store 0 or 1.  
-  
-**Steps to Add a New Metric**  
-  
-1) Add a histogram definition to [TelemetryHistograms.h](http://mxr.mozilla.org/mozilla-central/source/toolkit/components/telemetry/TelemetryHistograms.h) specifying a histogram id, parameters and a description. For example HISTOGRAM(MYHGRAM, 1, 10000, 50, EXPONENTIAL, "Time (ms) taken by shiny new metric") defines a MYHGRAM histogram with a minimum value of 1, maximum 10000 and 50 buckets that grow exponentially with the description specifying units as milliseconds. 2a) C++: 
-```
-
-#include <mozilla/Telemetry.h>
-```
-  
-  
-.... Telemetry::Accumulate(Telemetry::MYHGRAM, <some interestin integer value goes here>)  
-  
-2b) JS: 
-```
-
-Telemetry = Cc["@mozilla.org/base/telemetry;1"].getService(Ci.nsITelemetry)
-var h = Telemetry.getHistogramById("MYHGRAM");
-h.Add(<some interesting value goes here>);
-
-```
-3) Install [about:telemetry](https://addons.mozilla.org/en-US/firefox/addon/abouttelemetry/) addon, go to about:telemetry to check that the chosen histogram type and parameters summarize your data in a useful way.  
-  
-4) Commit and wait for results to come in. **FAQ** _Q: What about those UMA_* macros?_ A: Don't use them. I added TelemetryHistograms.h so telemetry can be easily reviewed by security and privacy police. It also avoids a few pitfalls such as accidentally initializing the same histogram with different parameters, etc.  
-  
-_Q: When will telemetry be deployed?_ A: We will land the [UI](https://bugzilla.mozilla.org/show_bug.cgi?id=652657) to turn it on as soon as an updated [privacy policy](http://www.mozilla.com/en-US/legal/privacy/firefox.html) is [posted](https://bugzilla.mozilla.org/show_bug.cgi?id=664845). It should show up in nightly builds by the end of the week.  
-  
-_Q: How do I access the gathered telemetry data?_ A: TBD. Data is stored on metrics server, we will figure this out soon.  
-  
-_Q: What about addons?_ A: TBD. At the moment addons are free to inspect telemetry data in their browser. We haven't decided on a process to let addon authors add new probes and access stats. For now, addons should not participate in telemetry.
diff --git a/source/_posts/2011-06-27-telemetry-is-on-in-nightly-firefox-builds.markdown b/source/_posts/2011-06-27-telemetry-is-on-in-nightly-firefox-builds.markdown
deleted file mode 100644
index fa6fffb..0000000
--- a/source/_posts/2011-06-27-telemetry-is-on-in-nightly-firefox-builds.markdown
+++ /dev/null
@@ -1,18 +0,0 @@
----
-comments: true
-date: 2011-06-27 11:26:12
-layout: post
-slug: telemetry-is-on-in-nightly-firefox-builds
-title: Telemetry is on in Nightly Firefox builds
-wordpress_id: 427
-categories:
-- mozilla
----
-
-Telemetry went live in Firefox Nightly builds over the weekend. Everyone who wants to contribute to making Firefox better now has an easy new way: opt-in to telemetry. There are two ways to opt in: A) Click yes when prompted to report performance B) Enable it by going to Options/Preferences, then Advanced/General tab  
-  
-[![](/assets/images/2011-06-27-telemetry-is-on-in-nightly-firefox-builds/Optimized-out.jpg)](/assets/images/2011-06-27-telemetry-is-on-in-nightly-firefox-builds/Optimized-out.jpg)  
-  
-You can check on the data collected by installing my [about:telemetry](https://addons.mozilla.org/en-US/firefox/addon/abouttelemetry/) extension.  
-  
-
diff --git a/source/_posts/2011-06-30-dehyratreehydra-static-analysis-thoughts.markdown b/source/_posts/2011-06-30-dehyratreehydra-static-analysis-thoughts.markdown
deleted file mode 100644
index 64b4510..0000000
--- a/source/_posts/2011-06-30-dehyratreehydra-static-analysis-thoughts.markdown
+++ /dev/null
@@ -1,44 +0,0 @@
----
-comments: true
-date: 2011-06-30 12:07:20
-layout: post
-slug: dehyratreehydra-static-analysis-thoughts
-title: Dehyra/Treehydra Static Analysis Thoughts
-wordpress_id: 433
-categories:
-- mozilla
-- dehydra
----
-
-I was pleased to see Mozilla static analysis [mentioned](http://lwn.net/Articles/447916/) on lwn. Yes indeed, the [mailing list](https://lists.mozilla.org/listinfo/dev-static-analysis) has been pretty dead (most of our communication happens on irc.mozilla.org #static). I completely failed to build a community around my static analysis tools. Perhaps more people will try [Dehydra](https://developer.mozilla.org/en/Dehydra) now that it's [getting](http://packages.debian.org/experimental/dehydra) into Debian. The hydras are still alive, [evidence](http://hg.mozilla.org/rewriting-and-analysis/dehydra/) can be seen in the mercurial commit log. Development has slowed because the hydras are now considered to be feature-complete and my primary focus is elsewhere in Mozilla now.  
-  
-As to why open source static analysis has failed to take off, I have a few theories. I think the main problem is that static analysis requires a compiler/correctness/type-system-nerd/large-scale-development-nerd type personality. That's a pretty rare intersection of hobbies to begin with. One also has to hate the [stone age](http://people.mozilla.com/~tglek/lca2010/) that C/C++ ecosystem we are in, but not move on to shiny new Haskell/Ocaml/whatever communities.  
-  
-**Have I failed at igniting the static analysis revolution?**
-
-  1. My goal primary goal was: provide a way to analyze Mozilla source code to speed up our development + refactoring efforts.
-  2. My secondary goal was to make sure that whatever work I do, nobody else has to suffer through the unbelievably sucky infrastructure cruft I had to work through.
-  3. Lastly, I did put in some effort at promoting open source static analysis (by giving talks at conferences, etc) since working in an active community is more fun.
-_Mozilla side_:  
-  
-I'm happy to report that I achieved a culture shift at Mozilla. Instead of people saying "oh god, I can't find all instances of ___ issue in 3million lines of C++ code", it's pretty common to hear "lets solve this through static analysis". Dehydra was designed to take the bitchwork (boilerplate of compiler integration, etc) out of static analysis so one can focus on the analysis part. New Dehydra users within Mozilla seem to confirm that. Instead of pondering whether certain tool-assisted refactorings are feasible, we plan to embark on some now (turned out we were understaffed to keep up with tool output and overburdened by api compatibility before; more on this in a future blog post).  
-  
-_No More Static Analysis Bitchwork:_  
-  
-The worst aspect of dealing with C++ is parsing it. The second worst aspect is dealing with the preprocessor. With respect to parsing C++ we went from weirdo-custom-frontends(ie Elsa, EDG, etc) and "GCC will never allow plugins, don't waste your time" to GCC adopting a plugin architecture that suited my static analysis needs. I also implemented source-location transformation tracking(-K) in [mcpp](http://mcpp.sourceforge.net/), so nobody has to suffer through undoing braindamage inflicted by the C proprocessor again. I hear at least a couple of people benefited from MCPP work and I take partial credit for every new analysis GCC plugin. I suspect I saved a few person-months for somebody :)  
-  
-Btw, I think Chris Lattner's from-scratch effort on [Clang](http://clang.llvm.org/) is way awesomer than anything I could ever accomplish.  
-  
-_Conferences & Stuff:_  
-  
-I admit complete and utter failure in this regard. Most open source people have low regard for static analysis. Linus seems to take a million-monkeys-with-type-writers approach (ala the open source eyeballs approach to security) to ensuring kernel code quality (which is a reasonable approach when you have mobs of contributors). Most other projects do not have the resources to spare on unproven tech such as static analysis.  
-  
-To make matters worse, at first people thought JavaScript was a toy language worth only cut'n'pasting from recipes online. Then just as JavaScript was getting more popular, SpiderMonkey embedding got buggier and made for some unpleasant first experiences with the Hydras.  
-  
-**Conclusion**  
-  
-There isn't much to show for my work outside of Mozilla; that's fine since my primary goal was Mozilla :) The Hydras aren't dead, they are in maintenance mode.  
-  
-I'm glad to see [python-as-gcc-plugin ](http://lwn.net/Articles/448698/)approach, it seems to fill the same niche as [Treehydra](https://developer.mozilla.org/en/Treehydra). I regret not starting out with Python (I think it's slightly better than JavaScript for this task), I hope David Malcolm succeeds in attracting wider interest.  
-  
-PS. I'm super-excited about the new [DXR work](http://quetzalcoatal.blogspot.com/2011/06/alpha-release-of-dxr.html). [DXR](http://dxr.mozilla.org/) is something that makes my daily life easier. DXR is by far the smartest code-indexing system out there, it's bound to transform my life as a developer far more than any static analysis ever could :)
diff --git a/source/_posts/2011-07-01-telemetry-status.markdown b/source/_posts/2011-07-01-telemetry-status.markdown
deleted file mode 100644
index c7fdbed..0000000
--- a/source/_posts/2011-07-01-telemetry-status.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2011-07-01 11:48:33
-layout: post
-slug: telemetry-status
-title: Telemetry Status
-wordpress_id: 440
-categories:
-- mozilla
----
-
-**Telemetry Present**  
-  
-Telemetry infrastructure has only been deployed for week, but we are already gathering interesting data_:_
-
-  * _Memory usage _from about:memory gives us an idea of what constitutes typical memory usage for Firefox
-  * _Cycle-collection overhead, stats_ tell us about browser pauses due to memory cleanup
-  * _Detailed startup profiling_ tells us whether our new [library preloading logic](http://glandium.org/blog/?p=2105) is effective
-  * Info on whether the browser was _shutdown_ correctly will help us diagnose shutdown problems
-  * _Plugin enumeration timing_ to make sure my [faster plugin enumeration](http://taras.glek.net/blog/2010/12/29/faster-plugin-enumeration-help-wanted/) stays fast
-  * _HTTP connection profiling_ to help optimize page loads
-Since the branch point for Aurora is approaching in less than a week, I don't expect many more probes for Firefox 7.  
-  
-**Telemetry Future**  
-  
-One problem with doing awesome optimizations that as code changes, they frequently get accidentally undone. I plan to add telemetry to keep tabs on every significant optimization that I do in the future, in addition to retroactively adding it to the past ones. I expect other Mozilla developers to do the same. In addition to keeping tabs on Firefox performance, we can also learn about JavaScript feature adoption, the kind of hardware (and OS) that users run Firefox on, etc to better match users' needs.
diff --git a/source/_posts/2011-08-03-effective-static-analysis.markdown b/source/_posts/2011-08-03-effective-static-analysis.markdown
deleted file mode 100644
index 6577edc..0000000
--- a/source/_posts/2011-08-03-effective-static-analysis.markdown
+++ /dev/null
@@ -1,29 +0,0 @@
----
-comments: true
-date: 2011-08-03 20:27:54
-layout: post
-slug: effective-static-analysis
-title: Effective Static Analysis
-wordpress_id: 449
-categories:
-- mozilla
-- static-analysis
----
-
-Static analysis can be a very fun pastime. One gets to sift through giant codebases looking for interesting clues, what could be more fun? A couple things qualify: a) static analysis accompanied by cool rewrites b) static analysis accompanied by cool visualizations.  
-  
-**Cool Rewrite**  
-  
-Michael Wu's [boolcheck](http://blog.mozilla.org/mwu/2011/07/28/the-twelve-booleans-of-mozilla/) tool is awesome. He wrote it to check that "typedef int" bools are really being used as booleans and aren't perversely carrying integer values. The process of writing the tool is cool. As Michael is discovers bugs/disagreements stemming from setting "typedef bool PRBool", he just adds another pattern to check for to the tool and never has to worry about that pattern again. I hope to see someone apply boolcheck to the linux kernel, GTK projects or anything else with int booleans. Some projects don't have the luxury of switching to real bools, so they can continue using a static checker to make up for it.  
-  
-**Pretty Code**  
-  
-I've blogged about [DXR](http://dxr.mozilla.org/clang/) many times. As of this week clang-based DXR is on par with the old Dehydra-based one. Callgraph, inheritance, etc queries now work. [Joshua](http://quetzalcoatal.blogspot.com/) did an outstanding job gutting and rewriting the DXR backend this summer and is now going back to school. I'm extremely impressed with his work this summer. I didn't think it was possible to get as far as he did.  
-  
-We are looking for more help with DXR. Please deploy it on your pet project, contribute plugins for various languages, simplify deployment, etc.  
-  
-Additionally, now that the backed is in a fairly decent shape, we are looking for someone to help us turn DXR into the slickest code browsing tool ever(we have some ideas [written down](https://wiki.mozilla.org/DXR_Future_Work_Plan)). I'd like interactive graphs, various code visualizations, integration with bugzilla, etc. This needs a JSON-query frontend and a few other bits & pieces to be implemented.  
-  
-**Interns Wanted**  
-  
-We would love to hire more static analysis interns. Are you student who dreams about making large codebases easy to grasp? Do you want to spend a few months making Control Flow Graphs behave? If that sounds like your calling: leave a comment, send me an email.
diff --git a/source/_posts/2011-08-09-ride-to-the-coast.markdown b/source/_posts/2011-08-09-ride-to-the-coast.markdown
deleted file mode 100644
index 7a3f51b..0000000
--- a/source/_posts/2011-08-09-ride-to-the-coast.markdown
+++ /dev/null
@@ -1,62 +0,0 @@
----
-comments: true
-date: 2011-08-09 21:45:55
-layout: post
-slug: ride-to-the-coast
-title: Ride to The Coast
-wordpress_id: 452
-categories:
-- mozilla
----
-
-I like having guests who bike. So when Brian came over I decided this would be a great opportunity to explore going to the coast and back by bike ([velodirt](http://velodirt.com) style). The following is a map of our trip (190miles, 2 nights).  
-  
-[![](/assets/images/2011-08-09-ride-to-the-coast/bike.jpg)](http://taras.glek.net/blog/files/2011/08/map.jpg)  
-  
-The gravel roads were somewhat challenging. It was hard to climb in the heat so at times we had to push our bikes.  
-  
-[![](/assets/images/2011-08-09-ride-to-the-coast/push_small.jpg)](/assets/images/2011-08-09-ride-to-the-coast/push_small.jpg)  
-  
-Things got more unpleasant when we encountered loose gravel by Tillamook which sent Brian sliding over the edge :(  
-  
-[![](/assets/images/2011-08-09-ride-to-the-coast/205869_704363319326_122500004_37237117_241562_n.jpg)](/assets/images/2011-08-09-ride-to-the-coast/205869_704363319326_122500004_37237117_241562_n.jpg)  
-  
-Amazingly he got off without a single scratch (type-inference will go on!).  
-  
-Eventually we got to [Cape Lookout](http://www.oregonstateparks.org/park_186.php).  
-  
-[![](/assets/images/2011-08-09-ride-to-the-coast/beach1_small.jpg)](/assets/images/2011-08-09-ride-to-the-coast/beach1_small.jpg)  
-  
-The next day we biked to and spent the night in [Nehalem Bay](http://www.oregonstateparks.org/park_201.php).  
-  
-[![](/assets/images/2011-08-09-ride-to-the-coast/beach2_small.jpg)](/assets/images/2011-08-09-ride-to-the-coast/beach2_small.jpg)  
-  
-Then it was time to head back :(  
-  
-On the way back we did some more gravel roads, this time they were really nice. The road took us through a berry-laden forest and rewarded us with some pretty awesome views.  
-  
-[![](/assets/images/2011-08-09-ride-to-the-coast/brian_far.jpg)](/assets/images/2011-08-09-ride-to-the-coast/brian_far.jpg)  
-  
-_(If you squint you can see Brian)_  
-  
-[![](/assets/images/2011-08-09-ride-to-the-coast/view1_small.jpg)](/assets/images/2011-08-09-ride-to-the-coast/view1_small.jpg)  
-  
-  
-  
-The thing to keep in mind about gravel roads is that they like to get out of sync with the maps. We had to reroute due to roads going in a different direction, and due to various kinds of deadends.  
-  
-In one extreme case a road was clearly on the map, but had a "DEAD END" sign on it. Which got us thinking "is this a dead end for cars or is it for real?". After some climbing, the gravel road reduced to a nice forest path.  
-  
-[![](/assets/images/2011-08-09-ride-to-the-coast/dead1_small.jpg)](/assets/images/2011-08-09-ride-to-the-coast/dead1_small.jpg)  
-  
-Further on it became obvious that someone tried hard to kill this road. Some road hater put up over a dozen tree pile barriers, with some reaching my height.  
-  
-[![](/assets/images/2011-08-09-ride-to-the-coast/piles.jpg)](/assets/images/2011-08-09-ride-to-the-coast/piles.jpg)  
-  
-Turned out the road did indeed go through. Perhaps some day someone will start a cyclocross race dedicated to bringing this road back :)  
-  
-The last highlight of the trip was this delicious-looking buffalo herd.  
-  
-[![](/assets/images/2011-08-09-ride-to-the-coast/buffalo.jpg)](/assets/images/2011-08-09-ride-to-the-coast/buffalo.jpg)  
-  
-I love cycling in Oregon.
diff --git a/source/_posts/2011-10-10-misc.markdown b/source/_posts/2011-10-10-misc.markdown
deleted file mode 100644
index 9bb4586..0000000
--- a/source/_posts/2011-10-10-misc.markdown
+++ /dev/null
@@ -1,27 +0,0 @@
----
-comments: true
-date: 2011-10-10 15:28:14
-layout: post
-slug: misc
-title: Misc
-wordpress_id: 482
-categories:
-- mozilla
----
-
-**Linux Plumbers**  
-  
-A few of us attend LinuxPlumbers last month, I gave [talk](http://people.mozilla.com/~tglek/lpc2011/). Basic summary: kernel + toolchain could add a few straight-forward features to make Firefox and other apps start faster and use less memory.  
-  
-**Performance Team**  
-  
-I am no longer alone on my quest of performance whack-a-mole. Since spring I've been growing a team of extremely talented people to help make Firefox faster and slimmer. As a manager I do more people tasks now, so I have less " ____ sucks" blog posts to write. We are currently working on massively speeding up Fennec startup via [incremental decompression](https://bugzilla.mozilla.org/show_bug.cgi?id=686805) (sort of like an efficient UPX for android), fixing SQLite + other IO [usage](https://bugzilla.mozilla.org/show_bug.cgi?id=611837) in Firefox, [reordering binaries](https://bugzilla.mozilla.org/show_bug.cgi?id=662397) for faster startup, faster [shutdown](https://bugzilla.mozilla.org/show_bug.cgi?id=662444). The idea is to focus on all areas of browser performance other than rendering the web (for now).  
-  
-**Performance Help**  
-  
-"Perf work is cool, but I wouldn't know where to start with finding a good first perf-bug" <-- is this you? Would any of my readers be interested in a roundup of next set of "low hanging fruit" perf-improvements to be had?  
-  
-Example bugs: 
-
-  * [Implement ](https://bugzilla.mozilla.org/show_bug.cgi?id=693485)readahead support on Android
-  * Use [readahead](https://bugzilla.mozilla.org/show_bug.cgi?id=613124#c1) for omnijars
diff --git a/source/_posts/2011-10-19-alternative-to-the-indignity-of-dealing-with-the-error-console.markdown b/source/_posts/2011-10-19-alternative-to-the-indignity-of-dealing-with-the-error-console.markdown
deleted file mode 100644
index 5482a25..0000000
--- a/source/_posts/2011-10-19-alternative-to-the-indignity-of-dealing-with-the-error-console.markdown
+++ /dev/null
@@ -1,23 +0,0 @@
----
-comments: true
-date: 2011-10-19 06:56:09
-layout: post
-slug: alternative-to-the-indignity-of-dealing-with-the-error-console
-title: Alternative to the Indignity of Dealing with the Error Console
-wordpress_id: 485
-categories:
-- mozilla
----
-
-The JavaScript error console is a relic from the Mozilla stone age. There are two problems with it: 
-
-  1. It lives in a separate window
-  2. It is not helpful
-I've been drooling over the new Firefox Web Console, but unfortunately it doesn't have chrome privs [yet?] so it isn't a replacement for the error console since it operates with privileges of the webpage displayed. Turns out I was 2 steps away from nirvana: 
-  1. Navigate to [chrome://global/content/console.xul](chrome://global/content/console.xul).
-  2. Menu -> "Web Developer" -> "Web Console"
-Turns out that one can load a url with chrome privs (about:memory works too) and the web console becomes a very helpful [with autocompletion, less noise, etc) tool for typing Components.interfaces...  
-  
-**Update:**  
-  
-Scratchpad can also do this sans autocompletion, see Rob's comment below.
diff --git a/source/_posts/2011-10-20-emacs-cmd-exe.markdown b/source/_posts/2011-10-20-emacs-cmd-exe.markdown
deleted file mode 100644
index c32df9a..0000000
--- a/source/_posts/2011-10-20-emacs-cmd-exe.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2011-10-20 08:00:56
-layout: post
-slug: emacs-cmd-exe
-title: Emacs > CMD.EXE
-wordpress_id: 490
-categories:
-- mozilla
----
-
-Mozilla requires a unixy dev environment. Makefiles, hg, patches, ssh, irc, etc. Unfortunately Windows lacks in terminal abilities. No tabs, crappy cut/paste, limited size, slow, etc.  
-  
-[![](/assets/images/2011-10-20-emacs-cmd-exe/emacs.jpg)](/assets/images/2011-10-20-emacs-cmd-exe/emacs.jpg)  
-  
-Emacs has a wonderful shell-mode(ie my bottom-left buffer). This means that windows can now do proper command history, cut/paste & use multiple emacs buffers(like tabs in a more sane terminal). Like all good features in emacs, out of the box shell mode is pretty busted, but can be [fixed](http://www.khngai.com/emacs/cygwin.php) to default to bash. Microsoft also [provides](http://oscarbonilla.com/2008/01/beautiful-emacs-windows-edition/) a very nice fixed width font for emacs. I keep my [emacs config](http://hg.mozilla.org/users/tglek_mozilla.com/emacs/) in hg. I really appreciate the operating system that is emacs.
diff --git a/source/_posts/2011-12-01-introducing-project-snappy.markdown b/source/_posts/2011-12-01-introducing-project-snappy.markdown
deleted file mode 100644
index 462663e..0000000
--- a/source/_posts/2011-12-01-introducing-project-snappy.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2011-12-01 16:15:39
-layout: post
-slug: introducing-project-snappy
-title: Introducing Project Snappy
-wordpress_id: 493
-categories:
-- mozilla
-- snappy
----
-
-Two weeks ago I started project [Snappy](https://wiki.mozilla.org/Performance/Snappy). The purpose of the meeting is to help us focus on eradicating jarring pauses in Firefox.  
-  
-Today we had our second meeting ([notes](https://wiki.mozilla.org/Performance/Snappy/2011-12-01)).  A surprising amount of work has happened between the first and second meeting: 
-
-  * [Chromehang ](https://bugzilla.mozilla.org/buglist.cgi?quicksearch=chromehang&list_id=1813678)was briefly turned on. This converted browser stalls of >30seconds into crashes. This showed that a number of issues are worse than previously assumed
-  * We are about to start [tracking](https://bugzilla.mozilla.org/show_bug.cgi?id=699051) slow SQL queries via telemetry
-  * Even though [IndexedDB](http://www.w3.org/TR/IndexedDB) is the new hotness, existing websites use the evil old DOM Storage API. This API is not asynchronous and degrades browser performance. The workaround is to [tell](https://bugzilla.mozilla.org/show_bug.cgi?id=704933) the backend to use async IO.
-Just like MemShrink, Snappy bugs fall into three categories: 
-  * P1: Should be fixed ASAP
-  * P2: Should be fixed as soon as developers have cycles for it
-  * P3: Everything else
-Multiple people have asked whether Snappy is appropriate for bugs caught by Chromehang: ie should we focus on one-off long delays (ie font enumeration) or small delays that happen frequently (ie tab animations). After reflecting on this I decided that UI jank can be thought of as a risk of frustrating the user. Risk has a scientific definition: severity of event multiplied by probability.  Thus a long occasional pause during browsing is equivalent to a frequent short pause.  
-  
-For next week we plan to wrap up a [profiler](http://benoitgirard.wordpress.com/2011/11/08/firefox-built-in-profiler/), come up with a fix for cache io on startup/shutdown, look into submitting hang stacks in a less [brutal way](https://bugzilla.mozilla.org/show_bug.cgi?id=706916).
diff --git a/source/_posts/2011-12-05-24-hour-reviews.markdown b/source/_posts/2011-12-05-24-hour-reviews.markdown
deleted file mode 100644
index 4fc8e88..0000000
--- a/source/_posts/2011-12-05-24-hour-reviews.markdown
+++ /dev/null
@@ -1,28 +0,0 @@
----
-comments: true
-date: 2011-12-05 16:51:10
-layout: post
-slug: 24-hour-reviews
-title: 24-hour reviews
-wordpress_id: 496
-categories:
-- mozilla
----
-
-I would like to see Firefox developers switch to 24hour review turn-around times. Note that in my definition review turn-around means any of the following: 
-
-  * r+/r-
-  * unset/reassign r? to someone else
-It is ridiculous in our recent faster release cycle if a patch takes half (or more) of the cycle loitering in the review queue. I believe that a shorter review cycle is the simplest way to accelerate Firefox evolution.  
-  
-I view fast review times as a matter of respect. Posting a patch usually requires a significant time/effort commitment, reviewers should act appropriately. There is no bigger buzzkill than having your work pushed back to the bottom of somebody's TODO list like some annoying chore.  
-  
-As far as I can tell there are 3 main reasons* that lead to long review times:  
-  
-1) People like gavin, bz, dbaron having disproportionally high review loads. We need a process to hand-off patches to other reviewers. High-load people shouldn't shy away from passing on the r? to someone else when possible. 2) Bugzilla-fobic people (like myself) loosing track of bugzilla r? requests due to not having bugzilla [whines](https://bugzilla.mozilla.org/editwhines.cgi) setup. Bugzilla whines should be enabled by default. 3) Bad review habits.  I met a number of Mozilla developers that like to batch their reviews up and then do them all on a single weekday. Please stop, you are killing all kinds of coding momentum/fun/etc.Lets make it our policy to set aside time every day to clear the review queue.  
-  
-Clearly people with existing backlogs will take a while to catch up, but most MoCo employees should be capable of this. I have yet to hear a good reason against doing daily reviews.  
-  
-It has been a few months since I proposed this on [dev.platform](http://groups.google.com/group/mozilla.dev.platform/browse_thread/thread/d563bf8329089a5/cdc47838866b0bea).  I have tried to live by the 24hour rule, I think a few others tried this too. I find that morning bugzilla r? whines work best for me. I still occasionally loose track of a patch for a few days, but nobody is perfect. I think people appreciate fast reviews, but nobody thanked me yet.  
-  
-**Dec 6 Update**: My goal is to have *some* response within 24hours with an ETA for next followup in the worst case.
diff --git a/source/_posts/2011-12-13-slow-sql-tracking.markdown b/source/_posts/2011-12-13-slow-sql-tracking.markdown
deleted file mode 100644
index ee576cc..0000000
--- a/source/_posts/2011-12-13-slow-sql-tracking.markdown
+++ /dev/null
@@ -1,13 +0,0 @@
----
-comments: true
-date: 2011-12-13 11:55:43
-layout: post
-slug: slow-sql-tracking
-title: Slow SQL tracking
-wordpress_id: 508
-categories:
-- mozilla
-- snappy
----
-
-[Vladan](http://blog.mozilla.org/vdjeric) is working on adding slow SQL tracking to Telemetry, part of that has [already landed](https://bugzilla.mozilla.org/show_bug.cgi?id=699051). He recently exposed this information via the [about:telemetry](https://addons.mozilla.org/en-US/firefox/addon/abouttelemetry/) addon. We are working out a few remaining issues so we can [send](https://bugzilla.mozilla.org/show_bug.cgi?id=709406) this data to our telemetry servers. In the meantime [install](https://addons.mozilla.org/en-US/firefox/addon/abouttelemetry/) the addon in your nightly builds (if you are upgrading from an older version, you need to restart Firefox) and check for yourself whether SQL is to blame for pauses in Firefox.
diff --git a/source/_posts/2011-12-13-snappy-summary-for-dec-8.markdown b/source/_posts/2011-12-13-snappy-summary-for-dec-8.markdown
deleted file mode 100644
index ffc73b2..0000000
--- a/source/_posts/2011-12-13-snappy-summary-for-dec-8.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2011-12-13 10:55:47
-layout: post
-slug: snappy-summary-for-dec-8
-title: Snappy summary for Dec 8
-wordpress_id: 500
-categories:
-- mozilla
-- snappy
-tags:
-- snappy
----
-
-Our last meeting was last Thursday, at 11am PST ([meeting notes](https://wiki.mozilla.org/Performance/Snappy/2011-12-08)). This blog post is late because of a combination of email disasters and travel.  
-  
-Cheng from the SUMO team mined SUMO inputs to see what our users are complaining most about. There were complaints about things were slow, unresponsive, frozen, etc. See meeting notes the complete blurb.  
-  
-The networking team has identified issues leading to slow [shutdown](https://bugzilla.mozilla.org/show_bug.cgi?id=709297) and [startup](https://bugzilla.mozilla.org/show_bug.cgi?id=695003).  
-  
-Most of the the [responsiveness profiler](https://developer.mozilla.org/en/Performance/Profiling_with_the_Built-in_Profiler#Running%20the%20profiler) landed.  
-  
-UX team provided an extensive list of Firefox features that needed tweaking, see meeting notes for details.  We are working on improving tab interactions and scrolling.  
-  
-I'll post a beefier summary of plans/accomplishments next week.
diff --git a/source/_posts/2011-12-16-snappy-update-for-dec-15.markdown b/source/_posts/2011-12-16-snappy-update-for-dec-15.markdown
deleted file mode 100644
index e3a25ed..0000000
--- a/source/_posts/2011-12-16-snappy-update-for-dec-15.markdown
+++ /dev/null
@@ -1,21 +0,0 @@
----
-comments: true
-date: 2011-12-16 16:31:05
-layout: post
-slug: snappy-update-for-dec-15
-title: Snappy update for Dec 15
-wordpress_id: 514
-categories:
-- mozilla
-- snappy
----
-
-[Meeting notes](https://wiki.mozilla.org/Performance/Snappy/2011-12-15).  
-  
-Not much exciting new stuff happened this week. There was some progress on responsiveness profiler, snappy scrolling, dom storage. We are starting investigations into reporting per-tab overhead, interruptable JavaScript, etc  
-  
-Slow (>100ms) SQL telemetry landed in Thursday's nightly. Here are some preliminary results: 
-
-  * Slow SQL on [UI thread](http://people.mozilla.org/~xstevens/telemetry/main-bycount.txt) (ie blocking our UI)
-  * Slow SQL on [other threads](http://people.mozilla.org/~xstevens/telemetry/other-bycount.txt) (harmless, but annoying)
-These files of the format: sql, count, average time per query.
diff --git a/source/_posts/2011-12-20-fosdem-anyone.markdown b/source/_posts/2011-12-20-fosdem-anyone.markdown
deleted file mode 100644
index 5a465c0..0000000
--- a/source/_posts/2011-12-20-fosdem-anyone.markdown
+++ /dev/null
@@ -1,18 +0,0 @@
----
-comments: true
-date: 2011-12-20 14:57:10
-layout: post
-slug: fosdem-anyone
-title: FOSDEM Anyone?
-wordpress_id: 516
-categories:
-- mozilla
-- performance
-- snappy
----
-
-Team Perf and a significant number of other Mozillians will be attending [FOSDEM](http://fosdem.org/2012/) this year. My team will be giving talks on android linkers, IO, toolchain stuff, other TBD stuff. This will be my first FOSDEM, I'm really excited about it. There are a lot of European open sourcers to meet that don't make it to this side of the pond much.  
-  
-Team perf & other snappy people (10+ people) plan to spend the week before FOSDEM hacking on [Snappy](http://taras.glek.net/blog/category/snappy/) and other perf projects. Does anyone have suggestions on a cool hackerspace (I sent an email to hackerspaces.be folks) or a coworking facility that could host us in Brussels?  
-  
-**Update:** Looks like hackerspaces.be will be hosting us. Looking forward to checking out HSBXL-NG :)
diff --git a/source/_posts/2011-12-22-growing-reviewers.markdown b/source/_posts/2011-12-22-growing-reviewers.markdown
deleted file mode 100644
index 8fd710f..0000000
--- a/source/_posts/2011-12-22-growing-reviewers.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2011-12-22 17:09:29
-layout: post
-slug: growing-reviewers
-title: Growing reviewers
-wordpress_id: 524
-categories:
-- mozilla
----
-
-One of the challenges of a growing organization is that people become managers and have less time for coding. A scary proportion of module owners are managers now.  
-  
-We were discussing this with Dietrich and he came up with a really simple solution: module owner's entire team should be able to review patches for that module. Obviously new people can't review every little detail, for those they can pass the buck to their manager(and learn in the process). I really like the new [Firefox review policy](http://groups.google.com/group/mozilla.dev.apps.firefox/browse_thread/thread/9c6072c52cc5165c/fbc124d0fbe8782a?pli=1) of having a large set of candidates for reviews who have an option of passing the patch along.  
-  
-Perhaps bugzilla can change r?:taras queries into r?:taras+his+team and do this automagically.
diff --git a/source/_posts/2011-12-22-snappy-dec-22.markdown b/source/_posts/2011-12-22-snappy-dec-22.markdown
deleted file mode 100644
index 1d465af..0000000
--- a/source/_posts/2011-12-22-snappy-dec-22.markdown
+++ /dev/null
@@ -1,17 +0,0 @@
----
-comments: true
-date: 2011-12-22 14:42:22
-layout: post
-slug: snappy-dec-22
-title: Snappy Dec 22
-wordpress_id: 522
-categories:
-- mozilla
-- snappy
----
-
-Work is continuing from last week: jank profiler, DOM storage fixes, font enumeration and SQL telemetry analysis. This was the last Snappy meeting of the year.  
-  
-We plan to hold a perf + snappy hack week at [hackerspace.be](https://hackerspace.be/) Jan 31 - Feb 3, followed by attending FOSDEM.  
-  
-I'm off until January 3rd,  see #perf for taras-substitutes in meantime.
diff --git a/source/_posts/2012-01-05-snappy-jan-5.markdown b/source/_posts/2012-01-05-snappy-jan-5.markdown
deleted file mode 100644
index 2d46275..0000000
--- a/source/_posts/2012-01-05-snappy-jan-5.markdown
+++ /dev/null
@@ -1,45 +0,0 @@
----
-comments: true
-date: 2012-01-05 14:07:36
-layout: post
-slug: snappy-jan-5
-title: Snappy, Jan 5
-wordpress_id: 528
-categories:
-- mozilla
-- snappy
----
-
-I expected to a slow week, but there was a surprising amount of progress. I  take this as further evidence that having managers  go on vacation does wonders to engineer productivity :)  
-  
-**Interactivity with lots of tabs**  
-  
-We spent a lot of time pondering how to approach browser sluggishness in light of having tons of tabs open. On one hand people should understand, that one can't expect the browser perform the same whether 1 tab is active or infinity. On the other hand we should do more to a) make the browser punish background tab hogs and b) communicate hogs to the user.  
-  
-For now we will look at throttling background setTimeouts better (bug [715376](https://bugzilla.mozilla.org/show_bug.cgi?id=715376), [715378](https://bugzilla.mozilla.org/show_bug.cgi?id=715378), [715380](https://bugzilla.mozilla.org/show_bug.cgi?id=715380)), XMLHttpRequest loops, etc more aggressively. We also plan to make more use of interactive state so Firefox can suspend non-critical tasks (bug [712478](https://bugzilla.mozilla.org/show_bug.cgi?id=712478)).  
-  
-Occasionally the cycle collector misbehaves, Andrew will look into not running cycle collection frequently when it is slow: bug [710496](https://bugzilla.mozilla.org/show_bug.cgi?id=710496). Olli has been fixing many of the cycle-collection extremes, I don't have bug #s for that, but apparently the improvements are dramatic.  
-  
-**Super-Slow Startups**  
-  
-Thanks to telemetry we now know that some users experience tragic startup speeds ranging from 30seconds to 34hours (bug [701872](https://bugzilla.mozilla.org/show_bug.cgi?id=701872)). Our network cache is to blame for some of these (bug [707436](https://bugzilla.mozilla.org/show_bug.cgi?id=707436)). Another theory is that an unfortunate turn of events causes us to start loading webpages before the UI is shown (bug [715402](https://bugzilla.mozilla.org/show_bug.cgi?id=715402)).  
-  
-Vlad will post some of his analysis and interested people can help us with telemetry forensics.  
-  
-**Profiling**  
-  
-Being able to profile interactivity bugs is an important key to making the browser snappier. Large parts of Benoit's [interactivity profiler](https://developer.mozilla.org/en/Performance/Profiling_with_the_Built-in_Profiler) have landed (bug [713227](https://bugzilla.mozilla.org/show_bug.cgi?id=713227)). Using this [extension]( https://builder.addons.mozilla.org/addon/1023834/latest/) on nightly win/mac should give you an idea of what it will look like when completed.  
-  
-We make heavy use of compiler optimizations. Unfortunately one of them is to omit the stack pointer. Ehsan has setup a developer-friendly [profiling branch](http://groups.google.com/group/mozilla.dev.platform/browse_thread/thread/3389798e5ef9744b#).  
-  
-Vlad is making progress on non-destructive chromehang(bug [712109](https://bugzilla.mozilla.org/show_bug.cgi?id=712109)). Traditionally we could not do this, but with a combination of telemetry + cycling Ehsan's shiny new profiling branch on nightly channel... we'll be in developer heaven.  
-  
-**Responsiveness testing**  
-  
-[Peptest](https://wiki.mozilla.org/Auto-tools/Projects/peptest) should be landing on try soon, Aki is wrapping stuff up. This should enable us to catch responsiveness regressions on our infrastructure.  
-  
-**Smooth Scrolling**  
-  
-Jared is almost done fixing tests to land smooth scrolling to gather feedback and move on to fancy physics (bug [710372](https://bugzilla.mozilla.org/show_bug.cgi?id=710372)).  
-  
-Other ongoing projects with nothing specific to link to: Vlad's slow-sql telemetry, Rafael's quest to close sql connections so we can exit(0), QA browser-cache-effectiveness comparisons.
diff --git a/source/_posts/2012-01-11-call-for-snappy-help-looking-for-a-lots-of-tabs-sessions-with-lag.markdown b/source/_posts/2012-01-11-call-for-snappy-help-looking-for-a-lots-of-tabs-sessions-with-lag.markdown
deleted file mode 100644
index f79ad63..0000000
--- a/source/_posts/2012-01-11-call-for-snappy-help-looking-for-a-lots-of-tabs-sessions-with-lag.markdown
+++ /dev/null
@@ -1,15 +0,0 @@
----
-comments: true
-date: 2012-01-11 10:59:02
-layout: post
-slug: call-for-snappy-help-looking-for-a-lots-of-tabs-sessions-with-lag
-title: 'Call for Snappy Help: Looking for a lots-of-tabs sessions with lag'
-wordpress_id: 533
-categories:
-- mozilla
-- snappy
----
-
-I have been working under assumption that the browser gets less snappy as more tabs are opened. This increases the chances of having an ill-behaved website in the background. An ill-behaved tab (or a couple of them) can in theory ruin scrolling, typing, clicking, etc in active tabs. However I do not have anything behind anecdotal evidence on this. There are bugs on specific websites in bugzilla, but it would be nice to get them mixed into a realistic set of tabs.  
-  
-Would someone be willing to contribute a list of webpages they use often that cause Firefox to lag (maybe a session restore file?)? I am a low-tab person myself, so I can't easily reproduce this. Please make sure that Firefox is slow with your list of tabs even when all addons are disabled, include a description of slowness encountered.
diff --git a/source/_posts/2012-01-12-snappy-jan12.markdown b/source/_posts/2012-01-12-snappy-jan12.markdown
deleted file mode 100644
index 5115aab..0000000
--- a/source/_posts/2012-01-12-snappy-jan12.markdown
+++ /dev/null
@@ -1,21 +0,0 @@
----
-comments: true
-date: 2012-01-12 15:21:03
-layout: post
-slug: snappy-jan12
-title: Snappy Jan12
-wordpress_id: 535
-categories:
-- mozilla
-- snappy
----
-
-The most user facing fix has been [discovery](https://bugzilla.mozilla.org/show_bug.cgi?id=715774) and [removal](https://bugzilla.mozilla.org/show_bug.cgi?id=716293) of some sneaky cache IO on the main thread.  
-  
-Saptashi did some analysis on the impact of running sqlite in async mode on mobile. Turns out it's only a win for DELETEs. Expect a blog post from him soon.  
-  
-Dave [discovered](https://bugzilla.mozilla.org/show_bug.cgi?id=715774#c3) that we sometimes wait on locks on the main thread.  
-  
-Jeff and Bas are looking into diagnosing when d2d causes a slowdown.  
-  
-There was discussion of 4x reduction in cycle collection times landing soon, focusing on having cycle collector run less, etc. Lots of work(chromehang, profiler, ...) is continuing from last week.
diff --git a/source/_posts/2012-01-20-snappy-january-19-brought-you-by-ironic-js.markdown b/source/_posts/2012-01-20-snappy-january-19-brought-you-by-ironic-js.markdown
deleted file mode 100644
index 237358d..0000000
--- a/source/_posts/2012-01-20-snappy-january-19-brought-you-by-ironic-js.markdown
+++ /dev/null
@@ -1,37 +0,0 @@
----
-comments: true
-date: 2012-01-20 13:50:54
-layout: post
-slug: snappy-january-19-brought-you-by-ironic-js
-title: 'Snappy, January 19: Brought you by Ironic JS'
-wordpress_id: 537
-categories:
-- mozilla
-- snappy
----
-
-[Meeting notes](https://wiki.mozilla.org/Performance/Snappy/2012-01-19).  
-  
-**Network Cache Horrors**  
-  
-[Last week](http://taras.glek.net/blog/2012/01/12/snappy-jan12/) we discovered that our cache uses main thread locks to successfully block on off-main thread io. See ([Bug 695399](https://bugzilla.mozilla.org/show_bug.cgi?id=695399), [Bug 717761](https://bugzilla.mozilla.org/show_bug.cgi?id=717761)). QA did an [experiment](http://groups.google.com/group/mozilla.dev.tech.network/browse_thread/thread/6dfa3e6ebe80c336) which confirmed that our disk cache is performing poorly.  
-  
-**Flash Lag**  
-  
-We are looking into reports of flash lag, tracking [Bug 720000](https://bugzilla.mozilla.org/show_bug.cgi?id=720000). Initial QA data shows a significant slowdown when page is first loaded and smaller slowdowns later. There are also long browser pauses when the flash container progress freezes.  
-  
-**Profiling**  
-  
-Vlad continued work on non-destructive chromehang, [Bug 712109](https://bugzilla.mozilla.org/show_bug.cgi?id=712109). Client-side is ready to land and he is wrapping up symbolification for the server-side.  
-  
-[Interactivity profiler](https://developer.mozilla.org/en/Performance/Profiling_with_the_Built-in_Profiler) is now able to collect stacks on 64-bit MacOS. Benoit is looking for contributors to add Windows, Linux support ([Bug 719536)](https://bugzilla.mozilla.org/show_bug.cgi?id=719536). I highly encourage adventurous contributors to help out with that as it involves modifying some concise, straightforward, yet highly [ironic JavaScript](https://github.com/bgirard/Gecko-Profiler-Addon/blob/master/lib/symbolicate.js). We are also looking for help with the profiler UI. If you are a skilled addon/frontend person, see [Bug 719530](https://bugzilla.mozilla.org/show_bug.cgi?id=719530).  
-  
-Jeff posted an early preview of about:jank [addon](http://people.mozilla.com/~jmuizelaar/aboutjank-0.1.xpi). He also working on measuring painting speed via telemetry. Note this addon is buggy and requires a very recent nightly.  
-  
-Last week I asked for some laggy session restore profiles. I'm behind on reproducing those(will be done today or next week). I've been in email contact with several of the commenters. I really appreciate the data gathered so far.  
-  
-**Snappy UX**  
-  
-Jared landed smooth scrolling, [Bug 198964](https://bugzilla.mozilla.org/show_bug.cgi?id=198964). He is now working on hooking it up to scrolling via scrollbar, [Bug 710373](https://bugzilla.mozilla.org/show_bug.cgi?id=710373). Up next: fixing fallout from turning on smooth scrolling, hooking it up to the refresh driver and tweaking scrolling physics.  
-  
-Marco landed inline autocomplete, [Bug 566489](https://bugzilla.mozilla.org/show_bug.cgi?id=566489) and is now fixing fallout from that too.
diff --git a/source/_posts/2012-01-26-snappy-january-26.markdown b/source/_posts/2012-01-26-snappy-january-26.markdown
deleted file mode 100644
index 2607955..0000000
--- a/source/_posts/2012-01-26-snappy-january-26.markdown
+++ /dev/null
@@ -1,35 +0,0 @@
----
-comments: true
-date: 2012-01-26 15:22:09
-layout: post
-slug: snappy-january-26
-title: Snappy, January 26
-wordpress_id: 543
-categories:
-- mozilla
-- snappy
----
-
-**Slow Sessions - Tabs-on-Demand**  
-  
-Armed to the teeth with [about:jank](https://addons.mozilla.org/en-US/firefox/addon/aboutjank/), I was testing session restore scenarios that people [reported](http://taras.glek.net/blog/2012/01/11/call-for-snappy-help-looking-for-a-lots-of-tabs-sessions-with-lag/). While at it I came up with a [testcase](https://plus.google.com/108936502671219351445/posts/UMzBAQr3xDS) for bug [711193](https://bugzilla.mozilla.org/show_bug.cgi?id=711193). At first we were going to use telemetry to debate the merits of tabs on demand by default, but I feel my example illustrates responsiveness problems with session-restore well enough. Gavin is looking into this so we can make a decision this week.  
-  
-**Laggy ****Sessions **  
-  
-On my machine about:jank indicated that most lag was caused by our direct2d accelerated drawing code, [bug 721273](https://bugzilla.mozilla.org/show_bug.cgi?id=721273). Turning off graphics acceleration made things a lot less slow (Options/Advanced/use hardware acceleration) . It would be nice if people experiencing lots of lag in their sessions (on youtube, blogs with high quality backgrounds, etc) could try [about:jank](https://addons.mozilla.org/en-US/firefox/addon/aboutjank/). This requires running a very recent nightly.  
-  
-Install the extension, go to about:jank, browse around, then refresh about:jank. In the case of gfx lag, DrawThebesLayers shows up on top.  
-  
-**Imminent Cycle Collector + GC Improvements **  
-  
-Olli is landing huge cycle collector improvements (half of the patches landed so far), [bug 705582](https://bugzilla.mozilla.org/show_bug.cgi?id=705582), [bug 717500](https://bugzilla.mozilla.org/show_bug.cgi?id=717500). If that doesn't solve all CC problems by Tuesday, Andrew is standing by with bug [710496](https://bugzilla.mozilla.org/show_bug.cgi?id=710496) to limit how often CC can run. If we are lucky, incremental JS GC will land before Tuesday too (bug [641025](https://bugzilla.mozilla.org/show_bug.cgi?id=641025)). Landing by Tuesday means that these improvements have a good chance of showing up in Firefox 12. CC + GC are the most well-known causes of pauses in Firefox, so this is very exciting.  
-  
-**Other stuff** ****  
-  
-Profiling tools are moving along at a good clip. Benoit's [profiler](https://developer.mozilla.org/en/Performance/Profiling_with_the_Built-in_Profiler) works well on Mac now, hopefully Windows support will happen next week. Non-destructive chromehang is [almost](https://bugzilla.mozilla.org/show_bug.cgi?id=712109) landed.  
-  
-Telemetry histograms should now survive restarts (so we can do shutdown telemetry, etc), [bug 707320](https://bugzilla.mozilla.org/show_bug.cgi?id=707320).  
-  
-Peptest didn't manage to survive deployment on try due to [bug 719618](https://bugzilla.mozilla.org/show_bug.cgi?id=719618), [719511](https://bugzilla.mozilla.org/show_bug.cgi?id=719511).  
-  
-We are now transitioning from identifying issues to fixing identified issues. It's exciting to move from speculation as to what sucks to actual results. For more details see [meeting notes](https://wiki.mozilla.org/Performance/Snappy/2012-01-26).
diff --git a/source/_posts/2012-01-30-at-hackerspace-be-getting-ready-for-fosdem.markdown b/source/_posts/2012-01-30-at-hackerspace-be-getting-ready-for-fosdem.markdown
deleted file mode 100644
index 7177f3e..0000000
--- a/source/_posts/2012-01-30-at-hackerspace-be-getting-ready-for-fosdem.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2012-01-30 03:49:53
-layout: post
-slug: at-hackerspace-be-getting-ready-for-fosdem
-title: At hackerspace.be getting ready for FOSDEM
-wordpress_id: 549
-categories:
-- mozilla
----
-
-!["Lubricants"](http://lh3.googleusercontent.com/-gI4k_kzhP34/TyZ9_NzQi_I/AAAAAAAACgc/nRzbygBz6Jw/s800/IMG_20120130_120734.jpg)  
-  
-We just started our Perf/Snappy workweek in Brussels, Belgium. [hackerspace.be](https://hackerspace.be/) let us use their space. If you are also performance hacker in the area, why not drop in for some beers?  
-  
-See Dietrich's [post ](http://autonome.wordpress.com/2012/01/30/firefox-performance-work-week-fosdem/)for more details.
diff --git a/source/_posts/2012-01-31-fast-dxr.markdown b/source/_posts/2012-01-31-fast-dxr.markdown
deleted file mode 100644
index 777be8f..0000000
--- a/source/_posts/2012-01-31-fast-dxr.markdown
+++ /dev/null
@@ -1,12 +0,0 @@
----
-comments: true
-date: 2012-01-31 09:29:05
-layout: post
-slug: fast-dxr
-title: fast DXR
-wordpress_id: 557
-categories:
-- mozilla
----
-
-[DXR ](http://dxr.lanedo.com/index.html)is now [uber-fast](https://bugzilla.mozilla.org/show_bug.cgi?id=722743). See bottom of search pages for timing info. Give it a try. We have a few more bugs to fix before we jump into fixing the UI.
diff --git a/source/_posts/2012-02-02-at-betagroup-in-brussels.markdown b/source/_posts/2012-02-02-at-betagroup-in-brussels.markdown
deleted file mode 100644
index 29b1aab..0000000
--- a/source/_posts/2012-02-02-at-betagroup-in-brussels.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2012-02-02 02:01:50
-layout: post
-slug: at-betagroup-in-brussels
-title: At BetaGroup in Brussels
-wordpress_id: 559
-categories:
-- mozilla
----
-
-As the outside temperature reached -10C, the DIY heating system at hackerspace.be proved insufficient. On Wednesday the Perf/Snappy workweek was relocated to [BetaGroup Coworking Brussels](http://coworking.betagroup.be/). We'll be here until FOSDEM.  
-  
-Betagroup Coworking Brussels is an industrial-strength coworking space with lots of desk space, internet, kitchen, ping-pong and a bunch of heavy metal...  
-  
-![](http://farm8.staticflickr.com/7168/6800567379_2c052c4f55_z.jpg)
diff --git a/source/_posts/2012-02-07-snappy-feb-2nd-fosdem-help-wanted.markdown b/source/_posts/2012-02-07-snappy-feb-2nd-fosdem-help-wanted.markdown
deleted file mode 100644
index da2195c..0000000
--- a/source/_posts/2012-02-07-snappy-feb-2nd-fosdem-help-wanted.markdown
+++ /dev/null
@@ -1,28 +0,0 @@
----
-comments: true
-date: 2012-02-07 16:52:06
-layout: post
-slug: snappy-feb-2nd-fosdem-help-wanted
-title: Snappy, Feb 2nd - FOSDEM, Help Wanted
-wordpress_id: 565
-categories:
-- mozilla
-- snappy
----
-
-We cancelled last week's snappy meeting due to Perf/Snappy workweek + FOSDEM. See Jared's post for a [summary](http://msujaws.wordpress.com/2012/02/03/firefox-performancesnappy-work-week-recap/) of the workweek, I'll mention the rest below.  
-  
-We figured out a strategy for avoiding blocking DOM Storage IO (use scriptblocker to async preload relevant dom storage. Do async writeback to commit). We have a plan for cancellable SQL queries, [bug 722243](https://bugzilla.mozilla.org/show_bug.cgi?id=722243).  
-  
-SetTimeouts/30s telemetry landed in bug [715953](https://bugzilla.mozilla.org/show_bug.cgi?id=715953), I attached result of that in bug [715376](https://bugzilla.mozilla.org/show_bug.cgi?id=715376). Persistent telemetry was backed out while Nathan investigates problems, [bug 707320](https://bugzilla.mozilla.org/show_bug.cgi?id=707320).  
-  
-Brian Bondy has been fixing our usage of Windows APIs: 
-
-  * bug [722225 ](https://bugzilla.mozilla.org/show_bug.cgi?id=722225)- Firefox startup opt on Windows by optimizing D3D10CreateDevice1 (pending review)
-  * bug [722315 ](https://bugzilla.mozilla.org/show_bug.cgi?id=722315)- Firefox startup opt on Windows by lazy loading CLSID_DragDropHelper (landed)
-  * bug [692255 ](https://bugzilla.mozilla.org/show_bug.cgi?id=692255)- Find a way to get rid of prefetch files on Windows for faster startup (pending review)
-We spent the weekend at FOSDEM. I re-presented my Plumbers talk on why Linux [sucks ](http://people.mozilla.com/%7Etglek/lpc2011)for starting big apps. I also did a [Telemetry talk](http://people.mozilla.com/%7Etglek/fosdem2012/). The audience was great.  
-  
-**Help Wanted**  
-  
-To my great regret, I forgot to mention that Mozilla is [hiring](http://www.mozilla.com/en-US/about/careers.html) in my talks. In particular, I'm looking for more performance hackers. If enjoy spending quality time with stack traces,writing profilers or analyzing performance logs leave a comment or send me an email. Compiler toolchain and/or kernel hacking experience would be a great bonus.
diff --git a/source/_posts/2012-02-09-snappy-feb-9-blame-canada.markdown b/source/_posts/2012-02-09-snappy-feb-9-blame-canada.markdown
deleted file mode 100644
index 5937db0..0000000
--- a/source/_posts/2012-02-09-snappy-feb-9-blame-canada.markdown
+++ /dev/null
@@ -1,27 +0,0 @@
----
-comments: true
-date: 2012-02-09 15:01:02
-layout: post
-slug: snappy-feb-9-blame-canada
-title: 'Snappy Feb 9: Blame Canada!'
-wordpress_id: 568
-categories:
-- mozilla
-- snappy
----
-
-The meeting was short this time because all of the participating people in the Toronto office conspired be busy or on vacation today.  
-  
-Our UX team helped us decide to turn on tabs-on-demand + do tab restore by default, Bug [711193](https://bugzilla.mozilla.org/show_bug.cgi?id=711193). This change will make interacting with the browser more responsive after startup, help [MemShink](https://wiki.mozilla.org/Performance/MemShrink) and not trigger as much captive wifi portal badness.  
-  
-Frontend people are busy adding telemetry to everything that matters, [bug 671038](https://bugzilla.mozilla.org/show_bug.cgi?id=671038). Some of this has already paid off in terms of us catching a tab animation regression in [bug 724349](https://bugzilla.mozilla.org/show_bug.cgi?id=724349). We plan to switch our awesomebar searching from SQL to an FTS. If you are a text-search/tokenizer expert, perhaps you help us with [bug 725821](https://bugzilla.mozilla.org/show_bug.cgi?id=725821). There is also a lot of activity on making various sync IO things async, see the [meeting notes](https://wiki.mozilla.org/Performance/Snappy/2012-02-09#Projects) for complete details.  
-  
-Brian Bondy posted an [update](http://www.brianbondy.com/blog/id/127/) documenting his two-week rampage through Firefox startup inefficiencies on Windows. Brian's blog post contains tips on xperf, Firefox profiler, about:startup - [read it](http://www.brianbondy.com/blog/id/127/).  
-  
-The networking team is busy nuking the big cache lock, see bug [717761](https://bugzilla.mozilla.org/show_bug.cgi?id=717761).  
-  
-Olli has landed most of the cycle collector fixes. Telemetry shows a dramatic reduction in cycle collection times for Firefox 13. He and Andrew investigating the remaining causes of long CC times.  
-  
-I'll end this post with a pretty picture demonstrating recent cycle collection improvements. [ ![](/assets/images/2012-02-09-snappy-feb-9-blame-canada/cc13_12.png)](/assets/images/2012-02-09-snappy-feb-9-blame-canada/cc13_12.png) * y: frequency, x: milliseconds  
-  
-
diff --git a/source/_posts/2012-02-16-snappy-feb-16.markdown b/source/_posts/2012-02-16-snappy-feb-16.markdown
deleted file mode 100644
index 87efa57..0000000
--- a/source/_posts/2012-02-16-snappy-feb-16.markdown
+++ /dev/null
@@ -1,33 +0,0 @@
----
-comments: true
-date: 2012-02-16 16:20:17
-layout: post
-slug: snappy-feb-16
-title: Snappy, Feb 16
-wordpress_id: 573
-categories:
-- mozilla
-- snappy
----
-
-**Canadians and their Profilers**  
-  
-Much like eating bacon, writing profiling tools is a favourite Canadian pastime. Unfortunately, while [today's meeting](https://wiki.mozilla.org/Performance/Snappy/2012-02-16) had more Canadians than last time, a few the usual suspects are still busy with Android bugs this week and weren't able to attend.  There are no updates on about:jank or our [profiler](https://developer.mozilla.org/en/Performance/Profiling_with_the_Built-in_Profiler) this week. Next week, Vlad plans to hook up Windows symbolification to the profiler bringing it up to par with Mac64.  
-  
-**UX Tweaks**  
-  
-Jared is almost done with preparation for snappy scrolling. He is wrapping up making scrollbar + arrow keys behave in a consistent manner, bug [710373](https://bugzilla.mozilla.org/show_bug.cgi?id=710373). The next step is to tweak our scrolling physics, which may lead us to integrate addon scrolling code in [bug 206438](https://bugzilla.mozilla.org/show_bug.cgi?id=206438). Jared also got rid of pointless "connecting..." tab title on refresh, [bug 709182](https://bugzilla.mozilla.org/show_bug.cgi?id=709182).****  
-  
-**IO Optimizations**  
-  
-Brian recently worked out a way to neuter prefetch in bug [692255](https://bugzilla.mozilla.org/show_bug.cgi?id=692255), this week he added Firefox hooks to take advantage of that in bug [727864](https://bugzilla.mozilla.org/show_bug.cgi?id=727864). Once that is done our startup speed will be up to us - no longer at the mercy of a misbehaving Microsoft heuristic. Brian also discovered a single-character typo (bug [726503](https://bugzilla.mozilla.org/show_bug.cgi?id=726503)) in my code,which apparently resulted in a 15% speed up in our page-loading benchmark, tp5. I'm disturbed that we didn't notice respective slowdown when we landed this.  
-  
-Brian is also bravely battling download-manager lag in bug [632556](https://bugzilla.mozilla.org/show_bug.cgi?id=632556), [727275](https://bugzilla.mozilla.org/show_bug.cgi?id=727275).  
-  
-Marco is working on reducing thread contention due to vacuum/pragmas, bug [723611](https://bugzilla.mozilla.org/show_bug.cgi?id=723611). Marco is also almost done with rewriting our ill-conceived, jank-happy livemarks code in bug  [613588](https://bugzilla.mozilla.org/show_bug.cgi?id=613588).  
-  
-**Content**  
-  
-Vladan landed a DOM storage fix that should significantly reduce the amount of main thread SQL done by content [bug 714964](https://bugzilla.mozilla.org/show_bug.cgi?id=714964). We plan to make dom storage not cause main thread io lag in bug [712009](https://bugzilla.mozilla.org/show_bug.cgi?id=712009).  
-  
-More of the content team is jumping into Snappy work next week, expect to see more in this section.
diff --git a/source/_posts/2012-02-22-psa-dom-local-storage-considered-harmful.markdown b/source/_posts/2012-02-22-psa-dom-local-storage-considered-harmful.markdown
deleted file mode 100644
index 2fdda90..0000000
--- a/source/_posts/2012-02-22-psa-dom-local-storage-considered-harmful.markdown
+++ /dev/null
@@ -1,47 +0,0 @@
----
-comments: true
-date: 2012-02-22 17:39:39
-layout: post
-slug: psa-dom-local-storage-considered-harmful
-title: 'PSA: DOM Local Storage considered harmful'
-wordpress_id: 578
-categories:
-- mozilla
-- snappy
----
-
-Recently there have been a number of blog posts on optimizations possible via [Local StorageAPI](https://developer.mozilla.org/en/DOM/Storage#Storage_location_and_clearing_the_data). When Microsoft, Google, Amazon and a number of others aggressively adopt a new feature, people notice.  
-  
-The optimization is to use Local Storage to reduce network requests and/or payload size. This should result in a more responsive experience for the user... except when it doesn't.  
-  
-This strategy can backfire because: 
-
-  * Local Storage is a synchronous API
-  * Local Storage does IO
-Disk IO is particularly problematic because it's non-deterministic for a multitude of reasons. A simple disk operation can take anywhere from zero milliseconds to a few seconds. Browsers cope with this by preloading the entire Local Storage key/value store into memory on first request. While testing a website the developer is likely to _frequently_ reload the same page multiple times. This means that the relevant disk IO is very likely to be cached in the os file cache.  
-  
-Now consider the case of a user turning on their computer, firing up the browser and going to an optimized site: 
-
-  1. The webpage starts to load
-  2. Data is read in from Local Storage
-  3. _Webpage completely freezes for a few seconds while the browser populates Local Storage key/value store_.
-This freeze can last anywhere from a few milliseconds on an unburdened computer to dozens of seconds on a computer with stock Windows settings (AntiVirus, Windows Indexing Service, etc). Firefox, Chrome, Safari suffer this fate to various degrees.  
-  
-Local Storage has the following costs: 
-
-  1. It can take a long unresponsive while to read in maximum allowable 5megs of data
-  2. This data is then in memory for the lifetime of the webpage session wasting memory. Imagine if every one of your tabs decided to do this.
-  3. LS is persistent. My profile has 0.5MB of meebo.com data that will haunt me forever even though meebo is long gone from my history.
-**What should webdevs do instead?**  
-  
-Cry, rely on browser cache. There are no viable alternative at the moment. [IndexedDB ](https://developer.mozilla.org/en/IndexedDB)is complex, requires user to approve it and isn't widely implemented. WebSQL is all about bringing SQLite problems we've been studying and fixing within Firefox to every single webpage.  
-  
-My best guess is that we'll end up with webdevs using convenience libraries built on top of IndexedDB. We will likely add promptless operation to IndexedDB.  
-  
-We have already made Local Storage hurt less, we have a plan to make it relatively painless, but it will always degrade user experience when compared to something like IndexedDB.  
-  
-**Are there any other convenient APIs with terrible complications?**  
-  
-Of course, see [sync XHR](http://blogs.msdn.com/b/wer/archive/2011/08/03/why-you-should-use-xmlhttprequest-asynchronously.aspx).  
-  
-
diff --git a/source/_posts/2012-02-27-snappy-feb-23rd.markdown b/source/_posts/2012-02-27-snappy-feb-23rd.markdown
deleted file mode 100644
index f1d3008..0000000
--- a/source/_posts/2012-02-27-snappy-feb-23rd.markdown
+++ /dev/null
@@ -1,44 +0,0 @@
----
-comments: true
-date: 2012-02-27 11:46:17
-layout: post
-slug: snappy-feb-23rd
-title: Snappy, Feb 23rd
-wordpress_id: 580
-categories:
-- mozilla
-- snappy
----
-
-**SUMO Problem investigation**  
-  
-There was an increase in negative feedback regarding Firefox 11 beta relative to Firefox 10 beta on [SUMO](http://blog.mozilla.org/sumo/about/).  Cheng and me will be analyzing SUMO reports to see if we can find a _concrete_ regression or two in Firefox 11.  
-  
-(One of the reasons this update is late is because I was digging through our telemetry data looking for something to correlate with user reports)  
-  
-**Cycle Collector + GC**  
-  
-Olli and Jan cooked up (as part of MemShrink?) [about:ccdump](https://addons.mozilla.org/en-US/firefox/addon/cycle-collector-analyzer/) addon for assist with finding leaks (bug [726346](https://bugzilla.mozilla.org/show_bug.cgi?id=726346), bug [728669](https://bugzilla.mozilla.org/show_bug.cgi?id=728669)). See Jan's blog post for [more details](http://www.softwareishard.com/blog/planet-mozilla/hunting-zombie-memory-leaks-in-firefox/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+SoftwareIsHardPlanetMozilla+%28Software+is+hard+%C2%BB+Planet+Mozilla%29).  
-  
-Andrew is working on: 
-
-  * reducing how often cycle collector runs in worst-case scenarios, bug [710496](https://bugzilla.mozilla.org/show_bug.cgi?id=710496)
-  * A fix that might increase the time between cyclecollector runs 10x, bug [728460](https://bugzilla.mozilla.org/show_bug.cgi?id=728460), [728547](https://bugzilla.mozilla.org/show_bug.cgi?id=728547)
-  * Triggering GC from CC less often, bug [727965](https://bugzilla.mozilla.org/show_bug.cgi?id=727965)
-Bill landed incremental GC this week, bug [719492](https://bugzilla.mozilla.org/show_bug.cgi?id=719492). Most users will not benefit from incremental GC until Bill finishes up handling frequent "corner cases" that end up disabling incremental GC.  
-  
-**DOM**  
-  
-Kyle is adding infrastructure to allow webpages to wait on [local storage](http://taras.glek.net/blog/2012/02/22/psa-dom-local-storage-considered-harmful/) without blocking user interactions, see [729769](https://bugzilla.mozilla.org/show_bug.cgi?id=729769).  
-  
-**Profiling**  
-  
-Vlad's non-destructive chromehang got mostly r+ed, bug [712109](https://bugzilla.mozilla.org/show_bug.cgi?id=712109).  
-  
-**Frontend**  
-  
-Livemarks will soon be async, bug [613588](https://bugzilla.mozilla.org/show_bug.cgi?id=613588). What are livemarks? An example of a livemark is the bbc livefeed/folder that we used ship on the bookmarks toolbar. Turned out when we rewrote the UI to hide the bookmarks toolbar, the livemark was still alive and well, hogging the UI while doing disk IO. We took out the default livemark a few releases back, now the code is being converted so users with preexisting bbc livemark (or their own livemarks) don't suffer accompanying browser lag.  
-  
-**Scrolling**  
-  
-Avi ported his smoothscroll logic to C++, Jared pushed it to the UX branch, bug [206438](https://bugzilla.mozilla.org/show_bug.cgi?id=206438). If you are interested in fluid scrolling, give it a try, play with acceleration prefs to help us find optimal values. Once this is done, bug [629507 ](https://bugzilla.mozilla.org/show_bug.cgi?id=629507)is next and then we get to tell the rest of the browser to not interrupt scrolling/etc in bug [712478](https://bugzilla.mozilla.org/show_bug.cgi?id=712478). If any readers are interested in helping desktop browsers catch up to mobile levels of responsiveness, this is area is a good place to contribute to.
diff --git a/source/_posts/2012-03-01-24hour-code-reviews-still-aiming-for-it.markdown b/source/_posts/2012-03-01-24hour-code-reviews-still-aiming-for-it.markdown
deleted file mode 100644
index 6678014..0000000
--- a/source/_posts/2012-03-01-24hour-code-reviews-still-aiming-for-it.markdown
+++ /dev/null
@@ -1,18 +0,0 @@
----
-comments: true
-date: 2012-03-01 14:32:17
-layout: post
-slug: 24hour-code-reviews-still-aiming-for-it
-title: '24hour code reviews: still aiming for it'
-wordpress_id: 577
-categories:
-- mozilla
----
-
-I mainly review code written by team perf. You'd think a 6 person team would imply a fairly chill review queue. The team must've conspired to burn me out, for a few weeks I was spending half of my day reviewing patches. A few patches took >3 days to review. I think I even let a patch lapse for almost a week (don't always have mental capacity to review linker code). Recently, my review inbox is often empty and recent patches have been <10KB, I'm not falling behind anymore.  
-  
-My point is that 24hour reviews are not bounded by time. It's an aspirational target. If you value time spent writing the patch, please review accordingly. Same goes for people requesting reviews, I'm a lot more likely to give you a quick review if your patches are broken up into reasonably small logical pieces.  
-  
-The 24hour-review-turn-around dream is still alive. I haven't been making noise about it because I'm waiting on #metrics to provide us with hard review-latency data. I'm hoping my review turn-around is 24hours, but there is no easy way to find out atm.  
-  
-Thanks to everyone who adopted 24-hour review goal. I have noticed reviews flying by at a faster pace. One reviewer even let a team-perf patch jump to the front of his review in return for pushing on 24hour reviews.
diff --git a/source/_posts/2012-03-05-snappy-march-1st.markdown b/source/_posts/2012-03-05-snappy-march-1st.markdown
deleted file mode 100644
index 4a1611c..0000000
--- a/source/_posts/2012-03-05-snappy-march-1st.markdown
+++ /dev/null
@@ -1,47 +0,0 @@
----
-comments: true
-date: 2012-03-05 16:09:45
-layout: post
-slug: snappy-march-1st
-title: 'Snappy: March 1st'
-wordpress_id: 590
-categories:
-- mozilla
-- snappy
----
-
-**SUMO Problem Investigation**  
-  
-Looks like increase in negative SUMO reports that I mentioned [last time](http://taras.glek.net/blog/2012/02/27/snappy-feb-23rd/) was due to over-counting. There might be some networking regressions, but no general slowdown. Without solid data it's hard to tell.  
-  
-In order to provide more context to make SUMO reports more useful to developers we are looking into allowing users to attach their telemetry data: bug [732522](https://bugzilla.mozilla.org/show_bug.cgi?id=732522).  
-  
-**Work in Progress**  
-  
-There are few exciting landings to report this week, but there is a lot of exciting work going on.  
-  
-Nick is getting rid of main thread cache locks, bug [723577](https://bugzilla.mozilla.org/show_bug.cgi?id=723577). Limited initial testing indicates this can significantly improve Firefox responsiveness.  
-  
-Brian's prefetch nuking bug [692255 ](https://bugzilla.mozilla.org/show_bug.cgi?id=692255)is moving along. Interactivity profiling is also close to landing, bug [710935](https://bugzilla.mozilla.org/show_bug.cgi?id=710935).  
-  
-Dietrich is pushing automation changes to how we monitor startup so we can alter our startup sequence to show the main window sooner, bug [715402](https://bugzilla.mozilla.org/show_bug.cgi?id=715402).  
-  
-Vlad tweaked chromehang to work on all windows versions and is working on the serverside component with Benjamin, bug [712109](https://bugzilla.mozilla.org/show_bug.cgi?id=712109).  
-  
-I posted [our plan](https://groups.google.com/forum/#!topic/mozilla.dev.platform/1fn0Vz20wu8) on shutting down Firefox efficiently, speak up if I missed an important detail. Rafael is working on this in bug [662444](https://bugzilla.mozilla.org/show_bug.cgi?id=662444).  
-  
-Jared has landed more of Avi's smooth scrolling tweaks on the ux-branch, bug [198964](https://bugzilla.mozilla.org/show_bug.cgi?id=198964). Take the [ux nightlies](http://ftp.mozilla.org/pub/mozilla.org/firefox/nightly/latest-ux) for a spin to try improved scrolling.  
-  
-Dietrich and Andrew are looking into massive CC pauses after resume, bug [639262](https://bugzilla.mozilla.org/show_bug.cgi?id=639262).  
-  
-**Landed**  
-  
-Async livemarks changes landed, bug [613588](https://bugzilla.mozilla.org/show_bug.cgi?id=613588). Macro is following up to fix any slowdown for livemark users.  
-  
-Nathan landed persistent telemetry, bug [707320](https://bugzilla.mozilla.org/show_bug.cgi?id=707320). It's not quite working yet, bug [732970](https://bugzilla.mozilla.org/show_bug.cgi?id=732970).  
-  
-**Local Storage Discussion**  
-  
-Chris wrote a great [post](http://hacks.mozilla.org/2012/03/there-is-no-simple-solution-for-local-storage/) on DOM Local Storage, the discussion is great. I did a [post](http://taras.glek.net/blog/2012/02/22/psa-dom-local-storage-considered-harmful/) on this a few weeks ago.  
-  
-I have some raw data on exactly how slow DOM Local Storage is, I will post it once Xavier has time to yank data properly out of the cluster.
diff --git a/source/_posts/2012-03-07-planet-should-be-technical.markdown b/source/_posts/2012-03-07-planet-should-be-technical.markdown
deleted file mode 100644
index 4762e33..0000000
--- a/source/_posts/2012-03-07-planet-should-be-technical.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2012-03-07 14:12:18
-layout: post
-slug: planet-should-be-technical
-title: Planet should be technical
-wordpress_id: 593
-categories:
-- mozilla
----
-
-I ask every new Mozilla person to follow planet Mozilla. It's the only easiest way to keep an eye on what is going on in Mozilla. Because it is the single most useful source of mozilla news, it irritates me to no end to see funny pictures of cats mixed in with useful posts at a 9:1 ratio. It's like the funny pictures, personal agenda people are taking the rest of us hostage. I understand that the official planet policy encourages personal noise, but policies can evolve.  
-  
-There are multiple proposals on how to fix this situation. IMHO the most correct one is to have planet refocus on relevant content and add noise.mozilla.org for everything else. People who like noise can subscribe to that. Polite people with personal blogs already syndicate moz-tech-only parts of the blogs to planet, others have personal blogs. Arguments on marriage, definition of hate speech, far leftyness, funny cats, other memes really drain the will to live when I want to get work done.  
-  
-I do think we could use a better code of conduct for people deeply involved in the community. Open source is a bit too good with letting assholes get away with being assholes.
diff --git a/source/_posts/2012-03-09-snappy-march-8.markdown b/source/_posts/2012-03-09-snappy-march-8.markdown
deleted file mode 100644
index 864d735..0000000
--- a/source/_posts/2012-03-09-snappy-march-8.markdown
+++ /dev/null
@@ -1,33 +0,0 @@
----
-comments: true
-date: 2012-03-09 15:53:00
-layout: post
-slug: snappy-march-8
-title: Snappy, March 8
-wordpress_id: 597
-categories:
-- mozilla
-- snappy
----
-
-I was away on Thursday, so the following is based on Lawrence's [notes](https://wiki.mozilla.org/Performance/Snappy/2012-03-08).  
-  
-**Work in Progress**  
-  
-The content team is working on reducing lag caused by background tabs (no specific bug numbers in notes, but I suspect [734015](https://bugzilla.mozilla.org/show_bug.cgi?id=734015), [715376](https://bugzilla.mozilla.org/show_bug.cgi?id=715376), [674779](https://bugzilla.mozilla.org/show_bug.cgi?id=674779)).  
-  
-Vlad is almost done with bug [722368](https://bugzilla.mozilla.org/show_bug.cgi?id=722368). This will give us coverage of all SQL activity within Firefox. For queries with private data we will only report duration + database name. Locally, within about:telemetry, we'll be able to report full sql strings if the pref for it is turned on.  
-  
-Vlad is aiming to wrap up cancelable SQL queries next week, bug [722243](https://bugzilla.mozilla.org/show_bug.cgi?id=722243). Apparently he's also almost done with the python symbol server for bug [712109](https://bugzilla.mozilla.org/show_bug.cgi?id=712109).  
-  
-Pointless-stat()-reducing bug [521264 ](https://bugzilla.mozilla.org/show_bug.cgi?id=521264)is asymptotically reaching landing. Paolo is asyncing favicon consumers in bug [728143 ](https://bugzilla.mozilla.org/show_bug.cgi?id=728143)(on the way toward async places). Drew is asyncing content prefs in bug [699859](https://bugzilla.mozilla.org/show_bug.cgi?id=699859).  
-  
-Nick is still working on making cache async in bug [723577](https://bugzilla.mozilla.org/show_bug.cgi?id=723577).  
-  
-Mark decided to change [peptest ](https://wiki.mozilla.org/Auto-tools/Projects/peptest)to be more like talos and to integrate [SPS](https://developer.mozilla.org/en/Performance/Profiling_with_the_Built-in_Profiler). I am guessing he'll blog about this.  
-  
-**Landed This Week**  
-  
-Andrews work in bug [728460 ](https://bugzilla.mozilla.org/show_bug.cgi?id=728460)should result in the cycle collector running less often.  
-  
-Most depressing bugfix of the week award goes to Rafael. Firefox no longer considers it appropriate to tickle idle-daily observers tasks late during shutdown, bug [732368](https://bugzilla.mozilla.org/show_bug.cgi?id=732368).
diff --git a/source/_posts/2012-03-14-abouttelemetry-diff-mode-search.markdown b/source/_posts/2012-03-14-abouttelemetry-diff-mode-search.markdown
deleted file mode 100644
index 0cf8fc5..0000000
--- a/source/_posts/2012-03-14-abouttelemetry-diff-mode-search.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2012-03-14 15:27:53
-layout: post
-slug: abouttelemetry-diff-mode-search
-title: 'about:telemetry: diff mode + search'
-wordpress_id: 600
-categories:
-- mozilla
----
-
-[![](/assets/images/2012-03-14-abouttelemetry-diff-mode-search/telemetry.png)](/assets/images/2012-03-14-abouttelemetry-diff-mode-search/telemetry.png)  
-  
-I cleaned up about:telemetry to be a bit less of a hack. It mostly generates charts using proper DOM manipulations now, so should be easier to contribute to.  
-  
-**Diff Mode**  
-  
-Now that we have a few hundred histograms in telemetry, it's become a chore to figure out if something changed. I added a 'Diff' button which re-polls telemetry since last telemetry-page-load/diff-press and highlights buckets with new activity in red. This is useful for cases when you see lag in the browser, but have no idea what's causing it (sort of like [about:jank](https://addons.mozilla.org/en-US/firefox/addon/aboutjank/)). This turns histogram bars red when stuff changed. Unfortunately one still needs a pretty intimate knowledge of the browser to figure out if any of the histograms are related to observed lag.  
-  
-**Search**  
-  
-I added a little input box to make finding relevant histograms quicker.  
-  
-**Help Wanted**  
-  
-If you find any bugs or have improvements to contribute, see [the source](https://github.com/tarasglek/about-telemetry). The updated addon is in the AMO review queue, in the meantime you can jump the queue via [this link](https://addons.mozilla.org/firefox/downloads/file/146870/abouttelemetry-0.11-tb+fx.xpi?src=devhub).
diff --git a/source/_posts/2012-03-16-localstorage-pageload-perf.markdown b/source/_posts/2012-03-16-localstorage-pageload-perf.markdown
deleted file mode 100644
index d34bb35..0000000
--- a/source/_posts/2012-03-16-localstorage-pageload-perf.markdown
+++ /dev/null
@@ -1,41 +0,0 @@
----
-comments: true
-date: 2012-03-16 10:26:51
-layout: post
-slug: localstorage-pageload-perf
-title: LocalStorage pageload perf
-wordpress_id: 604
-categories:
-- mozilla
-- snappy
----
-
-Sorry for the delay in posting this. We don't yet have a frontend for tracking SQL performance in Firefox. Had to wait on Xavier to become available to do the [manual reports](http://people.mozilla.org/~xstevens/telemetry/slowsql/) for me. 
-
-product
-product_version
-channel
-sql
-doc_count
-sum_count
-quantiles(min,0.25,0.5,0.75,0.95,max)
-
-Firefox
-12.0a2
-aurora
-INSERT INTO webappsstore2_temp (scope, key, value, secure, owner) SELECT scope, key, value, secure, owner FROM webappsstore2 WHERE scope = :scope AND NOT EXISTS ( SELECT scope, key FROM webappsstore2_temp WHERE scope = webappsstore2.scope AND key = webappsstore2.key )
-2970
-6676
-(100.0,133.0,199.0,365.0,1731.0,244503.0)
-
-Last column shows the time it takes to prepopulate DOM local storage for a webpage in milliseconds. It means in the worst case it took 4minutes before the filesystem decided to give us what we asked for. For 95% of the users reporting it took < 1.7seconds to preload local storage, for 75% < 0.36seconds, etc.  
-  
-Generally IO is quite fast, but these terrible corner cases means that responsible software developers should always do async IO in interactive applications. Note that this has little to do with how we are accessing data from disk and everything to do with disk IO latency being non-deterministic.  
-  
-  
-  
-**What about other SQL queries?**  
-  
-Feel free to explore the other slow SQL queries in the product, most of them already have Snappy:P1 bugs filed. The plan for snappy is to systematically annihilate the worst performing IO in the browser ASAP.  
-  
-This data shows why doing SQL IO in applications is both a curse and a blessing. On one hand, a general purpose relational database is always going to be slower than an application-specific storage mechanism. On the other hand, it is a very nice abstraction that makes analysis like this trivial.
diff --git a/source/_posts/2012-03-16-snappy-march-15th.markdown b/source/_posts/2012-03-16-snappy-march-15th.markdown
deleted file mode 100644
index 939594e..0000000
--- a/source/_posts/2012-03-16-snappy-march-15th.markdown
+++ /dev/null
@@ -1,48 +0,0 @@
----
-comments: true
-date: 2012-03-16 15:39:30
-layout: post
-slug: snappy-march-15th
-title: Snappy, March 15th
-wordpress_id: 612
-categories:
-- mozilla
-- snappy
----
-
-Firefox 13 became Aurora this week. Firefox 13 is the first release that contains a significant amount of Snappy improvements. Some work got backported to 11 & 12, but 13 is where the bulk of work landed. I am very proud of how much we accomplished in 13.  
-  
-[caption id="attachment_613" align="alignnone" width="600" caption="Distribution of Snappy fixes"][![](/assets/images/2012-03-16-snappy-march-15th/ff13.png)](/assets/images/2012-03-16-snappy-march-15th/ff13.png)[/caption]  
-  
-I suspect the unnamed bar mostly consists of bugs that did not get version-tagged, but those should also be FF13.  
-  
-**Smooth Scrolling**  
-  
-About 10 years ago Avi Halachmi embarked on perfecting scrolling via his [smoothwheel extention](http://smoothwheel.mozdev.org/). It may be that Firefox was the first browser to feature kinetic scrolling (with his extension). This Tuesday Avi landed some of those smarts in Firefox; see bug [206438](https://bugzilla.mozilla.org/show_bug.cgi?id=206438). I'm sad that it took us 10 years to notice an awesome UX improvement like this. However, it is awesome to work with community developers who can focus on in on a particular feature and perfect it to their liking. To me this is what open source is about: enabling amazing people to perfect their software experience (and have everybody else benefit). Thanks, Avi!  
-  
-My secret plan is to clean up a few primary user experiences and freeze the rest of the browser while the user is interacting via bug [712478](https://bugzilla.mozilla.org/show_bug.cgi?id=712478). Scrolling is one such activity, watching video is another, typing, etc.  
-  
-**Peptest**  
-  
-There is now a [graph](http://mrcote.info/peptest/) for peptest results. Mark is figuring out how to deal with outlier, and considering integrating telemetry histograms.  
-  
-**Cycle Collector**  
-  
-Olli reduced CC lag observed after closing tabs like gmail, bug [734057](https://bugzilla.mozilla.org/show_bug.cgi?id=734057).  
-  
-**WIP**  
-  
-We have fixed a lot of the low-hanging fruit and are working on larger projects at the moment. Going forward I'll stick to mentioning projects when they get started, finish, or post builds for people to test.  
-  
-**Plans for Firefox 14**  
-  
-I'm very proud of Snappy fixes in Firefox 13, as a result I have high expectations for Firefox 14. The following are within reach: 
-
-  * Get rid of remaining main thread SQL (including Local Storage).
-  * Make background maintenance tasks interruptable
-  * Fix themes to not ruin our [startup](https://bugzilla.mozilla.org/show_bug.cgi?id=650968)
-  * Teach Firefox to suspend background processing during[ user interaction](https://bugzilla.mozilla.org/show_bug.cgi?id=712478)
-  * Ensure that graphics acceleration does not [regress ](https://bugzilla.mozilla.org/show_bug.cgi?id=692557)browser responsiveness
-  * [Exit ](https://bugzilla.mozilla.org/show_bug.cgi?id=662444)quickly
-  * De-jank animations
-  * Make our network cache more responsive
diff --git a/source/_posts/2012-04-05-snappy-apr-5-snappy-goals-for-q2.markdown b/source/_posts/2012-04-05-snappy-apr-5-snappy-goals-for-q2.markdown
deleted file mode 100644
index ccd8cad..0000000
--- a/source/_posts/2012-04-05-snappy-apr-5-snappy-goals-for-q2.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2012-04-05 13:16:19
-layout: post
-slug: snappy-apr-5-snappy-goals-for-q2
-title: 'Snappy, Apr 5: Snappy Goals for Q2'
-wordpress_id: 616
-categories:
-- mozilla
-- snappy
----
-
-It is time to set goals for the next 3 months at Mozilla. A lot of them should be Snappy-related.  
-  
-As I mentioned before, we have made a lot of snappy progress lately. We identified a lot of problematic areas, fixed some of them and the end is in sight for others. It is extremely important that we maintain the current Snappy momentum, such that we can wrap up Snappy this year and move on to scaling Firefox on multiple cores, etc.  
-  
-The following [platform goals](https://wiki.mozilla.org/Platform/2012-Q2-Goals#Perf) have been proposed: 
-
-  * Graphics: More rendering off main thread (this work is split between graphics/layout), Fix GFX acceleration lag (not yet on wiki)
-  * Layout: More rendering off main thread (this work is split between graphics/layout), Invalidation via DisplayList Analysis
-  * Video: Off main thread rendering (not yet on wiki)
-  * DOM: Prevent [to a reasonable extent] background tabs from starving the main thread, Reduce CC pauses significantly when there are cycles to collect
-  * Perf Team: Async local storage via blocking pageload, Combine IndexedDB/LocalStorage quotas to allow indexeddb to remove prompt, provide js file api (in workers) for all supported platforms, Reorder xul.dll on windows to speed up startup, continue exit(0) progress
-  * Networking: Resolve listed high priority cache locking/async issues
-  * Firefox: Fix top three Snappy offenders - lightweight themes, add-on manager, main thread SQL (under discussion, not on wiki)
-We do a lot of work outside of our goal process, so above goals represent only the big ticket items that we'd like to see accomplished in the near future. There will be other snappy work going on too.
diff --git a/source/_posts/2012-04-05-snappy-april-5-change-in-meeting-format.markdown b/source/_posts/2012-04-05-snappy-april-5-change-in-meeting-format.markdown
deleted file mode 100644
index 9367718..0000000
--- a/source/_posts/2012-04-05-snappy-april-5-change-in-meeting-format.markdown
+++ /dev/null
@@ -1,152 +0,0 @@
----
-comments: true
-date: 2012-04-05 13:52:12
-layout: post
-slug: snappy-april-5-change-in-meeting-format
-title: 'Snappy, April 5: Change in meeting format'
-wordpress_id: 619
-categories:
-- mozilla
-- snappy
----
-
-Lawrence, thanks for posting [snappy updates](http://lawrencemandel.com/tag/snappy/) while I was on leave.  
-  
-Snappy meetings have gotten a bit dull lately. There hasn't been much arguing about what needs fixing, or much discussion, everybody gave status updates and was in agreement. Going forward we will do less status updating, except for major developments to save some energy for discussion.  
-  
-Discussion centered around personas...err themes [murdering ](https://bugzilla.mozilla.org/show_bug.cgi?id=650968)firefox performance and goals for q2. Ehsan will post details how to reimplement themes. I made a separate [post ](http://taras.glek.net/blog/2012/04/05/snappy-apr-5-snappy-goals-for-q2/)about goals.  
-  
-Vlad raised a question on whether we should proceed with [cancellable ](https://bugzilla.mozilla.org/show_bug.cgi?id=722243)SQL queries given SQLite limitations. SQLite can only cancel all outstanding queries, which requires us to track carefully what requests are outstanding and/or do some SQLite feature development. Consensus was that we should proceed to avoid embarrassing situations like reading the places database [backwards ](https://bugzilla.mozilla.org/show_bug.cgi?id=684513)during shutdown.  
-  
-Lawrence also revamped the [meeting notes](https://wiki.mozilla.org/Performance/Snappy/2012-04-05) to be more readable.  As an experiment I'm going to paste them in here. Let me know if you prefer my cherry-picking summaries from before. 
-
-# Snappy Apr. 5 Minutes
-
-  * Sample Q2 goals: [https://wiki.mozilla.org/Performance/Snappy#Snappy_TODO](https://wiki.mozilla.org/Performance/Snappy#Snappy_TODO)
-  * Chart showing Snappy bugs resolved in the last week [https://wiki.mozilla.org/Performance/Snappy/Dashboard#Resolved_in_the_last_week](https://wiki.mozilla.org/Performance/Snappy/Dashboard#Resolved_in_the_last_week).
-  * did anyone attend the Intel sessions? 
-    * might be useful information at the next profiling session
-
-## Actions
-
-No actions. 
-
-## Incoming
-
-  * hardware acceleration: i disabled hwa on all macs in my family, and Firefox has been noticeably snappier across multiple types of macs. related bugs: bug 600763, bug 721273, bug 721892. should have someone from perf team or gfx dig in and at least confirm. 
-    * Taras asked to put on gfx q2 goals
-
-## Projects
-
-### Persona slowness(ehsan?)
-
-Results from the past week
-    
-
-  * issues discovered with animated personas and those that heavily use svg and css
-  * Ehsan to summarize the issue in a blog/wiki
-  * look at moving image decoding off of the main thread
-
-### Mainthread+Slow SQL (gavin/taras/vlad)
-
-Results from the past week
-    
-
-  * Worked on cancellable sql (bug 722243), have to figure out if benefit from cancellable queries justifies additional locking
-
-Todo this week
-    
-
-  * Ask SQLite guys about fine-grained cancels
-
-### Better DOM event/task scheduling - jst (telemetry)
-
-Results from the past week
-    
-
-  * starting to work on slowing down parser in background tabs
-
-### Super-slow-startup investigations - vlad, taras
-
-Results from the past week
-    
-
-  * Received batch of slow startup data from March
-
-### Startup optimizations - bbondy
-
-Results from the past week
-    
-
-  * bbondy: Bug 692255 - WIll have implemented super review comments for prefetch
-
-### Front-end - Dietrich/bbondy
-
-Results from the past week
-    
-
-  * Dashboard: [https://wiki.mozilla.org/SnappyFrontEndDashboard](https://wiki.mozilla.org/SnappyFrontEndDashboard)
-  * QA chrome leak testing - should most affect frontend [https://wiki.mozilla.org/QA/Snappy/Chrome_Leak_Testing](https://wiki.mozilla.org/QA/Snappy/Chrome_Leak_Testing)
-  * IE Migrator changes started landing, Safari coming soon after.
-  * Tim Taubert put up AreWeSmallYet, tracking changes in build size: [http://arewesmallyet.com/](http://arewesmallyet.com/)
-
-Todo this week
-    
-
-  * telemetry for home tab vs session restored
-  * telemetry for # of tabs restored
-  * taras: investigate if startup cache/omnijar is still of benefit
-
-### Profiler - jrmuizel/BenWa/Ehsan (and more)
-
-Todo this week
-    
-
-  * There seems to be an issue with symbolication with latest SPS extension version
-
-### Nondestructive chromehang - vlad
-
-Results from the past week
-    
-
-  * Co-ordinate with Softronics QA people & Moz privacy review
-  * bug 742008: Nightly profiling updates consistently failing
-
-Todo this week
-    
-
-  * Integrate about-telemetry into Firefox as a bundled addon
-  * Add a pass through mode so local symbolication server can pass symbolication requests to remote server (e.g. local Firefox symbols + remote Windows system symbols)
-
-### Peptest - mcote
-
-Results from the past week
-    
-
-  * revision numbers, with links, now in peptest graphs as of March 30
-  * results keep coming in!
-
-### GC pause reduction - billm
-
-Results from the past week
-    
-
-  * bug 641025: incremental GC - disabled due to leaks
-  * investigating leaks due to incremental GC
-  * landed bug 716142 (allow multi-compartmental GCs), which enables:
-  * worked on bug 739899, to keep compartment creation from stopping incremental GC
-  * Multi compartment GCs should also enable scheduling smaller chunks of GC and CC.
-
-### CC pause reduction - smaug, mccr8 (meta bug 698919)
-
-Results from the past week
-    
-
-  * smaug worked on trying to reduce the impact of leaked documents on the CC
-  * mccr8 worked on bug 653191 (collapse SCCs of JS in CC graph)
-  * remove more stuff from the CC graph (bug 740185)
-  * QA is working on plan to test for leaked documents
-
-#### bug710935 - measure lag in handling user input (needs owner)
-
-  * bbondy: I'll probably be starting on this next week, but if you have someone else please feel more than free to take :)
diff --git a/source/_posts/2012-04-10-argh-at-our-unresponsive-tab-strip-settimeoutfoo-0-can-be-very-harmful.markdown b/source/_posts/2012-04-10-argh-at-our-unresponsive-tab-strip-settimeoutfoo-0-can-be-very-harmful.markdown
deleted file mode 100644
index 8656435..0000000
--- a/source/_posts/2012-04-10-argh-at-our-unresponsive-tab-strip-settimeoutfoo-0-can-be-very-harmful.markdown
+++ /dev/null
@@ -1,29 +0,0 @@
----
-comments: true
-date: 2012-04-10 09:51:01
-layout: post
-slug: argh-at-our-unresponsive-tab-strip-settimeoutfoo-0-can-be-very-harmful
-title: 'ARGH at our unresponsive tab strip: setTimeout(foo, 0) can be very harmful'
-wordpress_id: 623
-categories:
-- mozilla
-- snappy
----
-
-As I mentioned before, I've been a manager for a year. I've focused solely on paper pushing for the past 6 months. Even though I love programming, it's surprisingly enjoyable to merely tell others what to do :) However, as all technical managers find out, eventually one gets very bored without doing something technical. So here it goes...  
-  
-**Why The Frick Are My Tabs So Damn Laggy?**  
-  
-****I noticed that tab switching has become unbearable lately. I finally filed a bug and with Gavin's help investigated the brokenness. Turned out that we [awesomely](http://mxr.mozilla.org/mozilla-central/source/toolkit/content/widgets/tabbox.xml#800) 
-```
-setTimeout(do_stuff, 0)
-```
-in the mousedown handler (bug 743877). This means that I click on my tab, only to suggest to the browser to schedule an event to be handled some time in the future. The browser will also go ahead and flush the existing event queue before getting to handling my event. I measured lag anywhere from 30 to 160+milliseconds before the browser even started handling my click.  
-  
-_This code is pretty ancient, why has tab switching gotten slow within the last few months?_ Turns out we now take a tab thumbnail on every tabselect, which takes >100ms on my machine... We then carefully use async IO to store that image in our network disk cache. Unfortunately our cache uses locks in creative ways effectively making that code path synchronous ([723577](https://bugzilla.mozilla.org/show_bug.cgi?id=723577), [723582](https://bugzilla.mozilla.org/show_bug.cgi?id=723582), [722033](https://bugzilla.mozilla.org/show_bug.cgi?id=722033), [722034](https://bugzilla.mozilla.org/show_bug.cgi?id=722034)). See [742594](https://bugzilla.mozilla.org/show_bug.cgi?id=742594) for thumbnail jank. Naturally, all of the above + cycle collection + garbage collection + etc gets scheduled right in the middle of handling tab switching :)  
-  
-Thanks to a strategically misplaced setTimeout, the browser currently can spend a very long time not responding to user input (seconds sometimes). I bet we have a quite a few places that "solve" problems with setTimeouts like above.  
-  
-**There is hope**  
-  
-See [bug 743069](https://bugzilla.mozilla.org/show_bug.cgi?id=743069) for some proof of concept patches on making tab switching more responsive. As far as I can see, there is no technical reason for us to not to have a buttery-smooth tab strip. Next steps are figuring out why XUL draws slowly, throttling other browser activity while interacting with tab strips, etc.
diff --git a/source/_posts/2012-04-16-snappy-april-12.markdown b/source/_posts/2012-04-16-snappy-april-12.markdown
deleted file mode 100644
index d86f0a2..0000000
--- a/source/_posts/2012-04-16-snappy-april-12.markdown
+++ /dev/null
@@ -1,23 +0,0 @@
----
-comments: true
-date: 2012-04-16 13:45:17
-layout: post
-slug: snappy-april-12
-title: Snappy, April 12
-wordpress_id: 625
-categories:
-- mozilla
-- snappy
----
-
-Notes are[ here](https://wiki.mozilla.org/Performance/Snappy/2012-04-12). Time was spent on administrative issues like overlap/conflict between Snappy and Kilimanjaro, plans for security review for Vladan's symbol server and bug triage.  
-  
-I'm usually really bad at noticing UI lag, but now my mind is focused on tab switching and I notice the lag every time click on tabs (keyboard switching is unaffected). We discussed how to fix tab lag I blogged about [earlier](http://blog.mozilla.com/tglek/2012/04/10/argh-at-our-unresponsive-tab-strip-settimeoutfoo-0-can-be-very-harmful/). It's hard because there is some funny interaction between focus and drag & drop and us switching tabs on mousedown. Neil will look into addressing focus issues this week.  
-  
-Tim is addressing thumbnail capture slowness in bugs: [744388](https://bugzilla.mozilla.org/show_bug.cgi?id=744388), [742594](https://bugzilla.mozilla.org/show_bug.cgi?id=742594), [726347](https://bugzilla.mozilla.org/show_bug.cgi?id=726347).  
-  
-Paolo is busy switching code away from synchronous places APIs: [728168](https://bugzilla.mozilla.org/show_bug.cgi?id=728168), [728174](https://bugzilla.mozilla.org/show_bug.cgi?id=728174), [728142 ](https://bugzilla.mozilla.org/show_bug.cgi?id=728142), [739213](https://bugzilla.mozilla.org/show_bug.cgi?id=739213).  
-  
-The networking team is expected to make a decision this week on how to fix the big networking cache lock. See Nick's [notes](https://wiki.mozilla.org/Performance/Snappy/2012-04-12#Fix_cache_-_hurley) on options presented.  
-  
-Thanks for feedback on preferred snappy update format: we'll stick with cherries.
diff --git a/source/_posts/2012-04-18-web-2-0-a-collection-of-settimeouts.markdown b/source/_posts/2012-04-18-web-2-0-a-collection-of-settimeouts.markdown
deleted file mode 100644
index 903f1f1..0000000
--- a/source/_posts/2012-04-18-web-2-0-a-collection-of-settimeouts.markdown
+++ /dev/null
@@ -1,35 +0,0 @@
----
-comments: true
-date: 2012-04-18 16:13:19
-layout: post
-slug: web-2-0-a-collection-of-settimeouts
-title: 'Web 2.0: A Collection of SetTimeouts'
-wordpress_id: 629
-categories:
-- mozilla
-- snappy
----
-
-Earlier I [blogged ](http://taras.glek.net/blog/2012/04/10/argh-at-our-unresponsive-tab-strip-settimeoutfoo-0-can-be-very-harmful/)about terrible UI responsiveness resulting from a poorly placed setTimeout. I've long suspected that SetTimeouts are to blame for everything. Now with help of bz and sfink I have proof.  
-  
-Turns out webpages like to keep users entertained and spin setTimeout loops to poll the servers to synchronize news tickers, social networking shoe-ins, collaborative editing, etc. Most pages do this regardless of whether they are a background or a foreground tab. Firefox tries to mitigate this by not allowing background tabs to schedule setTimeouts < 2seconds. Turns out this is a pretty weak defense.  
-  
-In my personal browsing: etherpad, twitter, zimbra burn through cpu cycles. See this bug [comment ](https://bugzilla.mozilla.org/show_bug.cgi?id=744470#c12)for an example of setTimeout terrorism with less than 10 tabs. In Firefox these setTimeouts cause significant UI lag, but they will also eat your battery life, overheat your laptop, etc. I filed bug [715376](https://bugzilla.mozilla.org/show_bug.cgi?id=715376) to add functionality to cope with this.  The plan is to prioritize foreground tab activity and do exponential setTimeout decay on abusive background tabs. We basically have to write something similar to an OS scheduler. Ideally we'd also follow that up with unloading idle tabs, ie bug [675539](https://bugzilla.mozilla.org/show_bug.cgi?id=675539).  
-  
-If you are curious about what tabs are abusing your browser my [diagnostic builds](http://ftp.mozilla.org/pub/mozilla.org/firefox/try-builds/tglek@mozilla.com-520630fd738e) will be available on try in a few hours. Install a [modified ](http://people.mozilla.com/~tglek/telemetry/ping.telemetry.xpi)version of about:telemetry to see the report.  
-  
-**What should well-behaved web apps do?**  
-  
-You can detect when your tab becomes inactive via [window.onblur](https://developer.mozilla.org/en/DOM/window.onblur), then throttle or disable your page activity. I know using focus is suboptional for this. There is also a vendor-prefixed [visibility api](https://developer.mozilla.org/en/API/PageVisibility/Page_Visibility_API) (thanks!).  
-  
-Now you know why your browser keeps your CPU wide awake :)  
-  
-  
-  
-_Update:_  
-  
-Wrote this post in a rush on the way out, thanks for the visibility links. I am aware that some webpages need to do work in the background. However that work should be as minimal as possible, this is often not the case.  
-  
-_Project Idea:_  
-  
-Would be nice if someone wrote an extension that goes through tabs and nukes any outstanding setTimeouts/XHRs/etc.
diff --git a/source/_posts/2012-04-19-snappy-april-19.markdown b/source/_posts/2012-04-19-snappy-april-19.markdown
deleted file mode 100644
index 4d085f8..0000000
--- a/source/_posts/2012-04-19-snappy-april-19.markdown
+++ /dev/null
@@ -1,21 +0,0 @@
----
-comments: true
-date: 2012-04-19 14:47:40
-layout: post
-slug: snappy-april-19
-title: Snappy, April 19
-wordpress_id: 637
-categories:
-- mozilla
-- snappy
----
-
-At 15 minutes, this might've been our shortest meeting yet ([notes](https://wiki.mozilla.org/Performance/Snappy/2012-04-19)).  
-  
-Most of the work happened in [frontend stuff](https://wiki.mozilla.org/Performance/Snappy/2012-04-19#Front-end_-_Dietrich). Most notable improvements are reduced screenshot overhead (by taking less screenshots, bug [744152](https://bugzilla.mozilla.org/show_bug.cgi?id=744152)) and a brand new IE migrator (a step towards fully async places API, bug [710895](https://bugzilla.mozilla.org/show_bug.cgi?id=710895)).  
-  
-Work resumed on making peptest return more [consistent ](https://wiki.mozilla.org/Performance/Snappy/2012-04-19#peptest_-_mcote)results.  
-  
-The necko team decided to take a more involved approach to solve our cache locking(bug [722034](https://bugzilla.mozilla.org/show_bug.cgi?id=722034)) which means the fix will land later than we originally hoped for.  
-  
-My little investigation into setTimeout [overhead](http://taras.glek.net/blog/2012/04/18/web-2-0-a-collection-of-settimeouts/) exposed more overhead than I expected. After our regularly scheduled snappy meeting, we had a follow up meeting to spec out how to change our event handling to cope with this (bug [715376](https://bugzilla.mozilla.org/show_bug.cgi?id=715376)). Our best people are on this :) I asked for someone to prototype an extension to suspend background tab activity, sounds like  Wladimir of adblockplus might lend a hand.
diff --git a/source/_posts/2012-04-26-snappy-april-26.markdown b/source/_posts/2012-04-26-snappy-april-26.markdown
deleted file mode 100644
index 4d1e0ac..0000000
--- a/source/_posts/2012-04-26-snappy-april-26.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2012-04-26 15:43:50
-layout: post
-slug: snappy-april-26
-title: Snappy, April 26
-wordpress_id: 643
-categories:
-- mozilla
-- snappy
----
-
-Notes from today's meeting are [here](https://wiki.mozilla.org/Performance/Snappy/2012-04-26).  
-  
-No major snappy fixes landed this week. However, if you look in the notes, there are quite a few projects going through the review cycle.  
-  
-Personally, I'm most excited by progress in getting rid of the setTimeout on tab click(bug [743877](https://bugzilla.mozilla.org/show_bug.cgi?id=743877)). Neil posted a diagnosis of why we need setTimeout while switching tabs. Tim followed up with a patch to avoid the setTimeout for non-focus bits. On the subject of SetTimeouts: we devised a plan for managing SetTimeout [overhead ](http://taras.glek.net/blog/2012/04/18/web-2-0-a-collection-of-settimeouts/)in background tabs. This will involve breaking up our global event queue into a global queue + smaller per-page queues, bug [715376](https://bugzilla.mozilla.org/show_bug.cgi?id=715376). This will not be a pleasant task, but Nathan aims to have a proof of concept ready next week. With this infrastructure we should be able start prioritizing which events we handle and punish misbehaving tabs.  
-  
-The graphics team is wrapping up the big Android push, freeing up cycles for elsewhere. Bas is back to looking at slowdowns due to hw acceleration (bug [721273](https://bugzilla.mozilla.org/show_bug.cgi?id=721273)). Bas is also looking into changing our chrome CSS to be less expensive to paint.  
-  
-Ehsan is working with Paul to change firefox themes to not be horrible [performance hogs](https://bugzilla.mozilla.org/show_bug.cgi?id=650968).  
-  
-**Update:** A very significant snappy fix [landed ](http://blog.kylehuey.com/post/21892343371/fixing-the-memory-leak)this week as part of memshrink. It should significantly reduce memory usage and thus cycle-collector pauses, etc.  
-  
-**Update #2**: I missed another very cool Snappy fix: [bug 729133](https://bugzilla.mozilla.org/show_bug.cgi?id=729133). This is based on revising old assumptions about cache being faster than disk. We learned from telemetry data that a significant portion of disk cache requests are processed slower than they would if we just went straight to network. Firefox now hedges bets and warms up a TCP connection while checking cache. For details see Patricks's [blog](http://bitsup.blogspot.com/2012/04/making-firefox-search-snappier.html).
diff --git a/source/_posts/2012-05-01-pushing-the-borders-out-of-firefox-performance.markdown b/source/_posts/2012-05-01-pushing-the-borders-out-of-firefox-performance.markdown
deleted file mode 100644
index d5ccd73..0000000
--- a/source/_posts/2012-05-01-pushing-the-borders-out-of-firefox-performance.markdown
+++ /dev/null
@@ -1,15 +0,0 @@
----
-comments: true
-date: 2012-05-01 16:57:33
-layout: post
-slug: pushing-the-borders-out-of-firefox-performance
-title: Pushing the borders [out] of Firefox performance
-wordpress_id: 650
-categories:
-- mozilla
-- snappy
----
-
-As I mentioned before, we are back to investigating some gfx deceleration issues. Preliminary investigation shows that our border+gradient code is inefficient and since Firefox uses these features heavily, we get some epic slowdowns when tab switching.  
-  
-To test out this theory Bas put up a test build that simply does not draw gradients or borders. See [bug 75087](https://bugzilla.mozilla.org/show_bug.cgi?id=750871)  for a screenshot demonstrating drastic reduction in browser attractiveness. There is also a test build for people suffering from slow drawing to try out.
diff --git a/source/_posts/2012-05-03-snappy-may-3rd-faint-hope-of-handling-mousedown-events-without-a-settimeout.markdown b/source/_posts/2012-05-03-snappy-may-3rd-faint-hope-of-handling-mousedown-events-without-a-settimeout.markdown
deleted file mode 100644
index 540171d..0000000
--- a/source/_posts/2012-05-03-snappy-may-3rd-faint-hope-of-handling-mousedown-events-without-a-settimeout.markdown
+++ /dev/null
@@ -1,33 +0,0 @@
----
-comments: true
-date: 2012-05-03 14:23:13
-layout: post
-slug: snappy-may-3rd-faint-hope-of-handling-mousedown-events-without-a-settimeout
-title: 'Snappy, May 3rd: Faint hope of handling mousedown events without a setTimeout'
-wordpress_id: 653
-categories:
-- mozilla
-- snappy
----
-
-Meeting [notes](https://wiki.mozilla.org/Performance/Snappy/2012-05-03).  
-  
-Memshink had a good idea to switch to bi-weekly meetings. We are going to try the same for Snappy. My plan is to still solicit status updates and blog weekly, but only meet in person every two weeks. The next meeting will be on May 17.  
-  
-**Borders/Gradients**  
-  
-Turns out that most of the painting overhead in accelerated versions of Firefox is spent rendering borders and gradients. I [blogged ](http://taras.glek.net/blog/2012/05/01/pushing-the-borders-out-of-firefox-performance/)a little about this earlier. It's a combination us not caching gradients and being overly picky about rendering border corners perfectly (ie to spec). Our chrome renders particularly slowly because as our chrome CSS changed (after implementing d2d accel and optimizing for exists codepaths), we started hitting more slow paths in the border code. We need telemetry to notice when things are rendering slower than expected.  
-  
-According to Bas we need to enable Azure for content and then start implementing respective caches. We should get significant speedups within 3-4 weeks, but to get close to the baseline performance of the no-borders/gradients build will take 3-4months. In the meantime we should look into simplifying our chrome to not feature as much expensive CSS.  
-  
-Longer term, Frank will look into reimplementing the tab bar in pure HTML  instead of XUL to maximize responsiveness.  
-  
-**CC/GC Pauses**  
-  
-Incremental GC should turned back on soon (bugs [750424](https://bugzilla.mozilla.org/show_bug.cgi?id=750424), [750416](https://bugzilla.mozilla.org/show_bug.cgi?id=750416)). Olli relanded bug [747675](https://bugzilla.mozilla.org/show_bug.cgi?id=747675) which should reduce CC times somewhat.  
-  
-Kyle's big memory leak [fix](http://blog.kylehuey.com/post/21892343371/fixing-the-memory-leak) from last week turned out to occasionally cause leaks where there were none before: see bug [751466](https://bugzilla.mozilla.org/show_bug.cgi?id=751466).  
-  
-**Frontend**  
-  
-Tim spent the week in a seemingly infinite r?/r- cycle attempting to prove that one handle clicks on tabs without setTimeout, bug [743877](https://bugzilla.mozilla.org/show_bug.cgi?id=743877). Tim also moved thumbnail storage away from network cache. This reduced cache contention (and browser freezes), bug [744388](https://bugzilla.mozilla.org/show_bug.cgi?id=744388). Paulo continued nuking sync favicon api usage, bug [728168](https://bugzilla.mozilla.org/show_bug.cgi?id=728168).
diff --git a/source/_posts/2012-05-14-snappy-may-10-suspending-activity-in-background-tabs.markdown b/source/_posts/2012-05-14-snappy-may-10-suspending-activity-in-background-tabs.markdown
deleted file mode 100644
index 9bdc172..0000000
--- a/source/_posts/2012-05-14-snappy-may-10-suspending-activity-in-background-tabs.markdown
+++ /dev/null
@@ -1,31 +0,0 @@
----
-comments: true
-date: 2012-05-14 10:06:52
-layout: post
-slug: snappy-may-10-suspending-activity-in-background-tabs
-title: 'Snappy, May 10: Suspending activity in background tabs'
-wordpress_id: 657
-categories:
-- mozilla
-- snappy
----
-
-Tim landed a fix to avoid setTimeout()s when handling tab clicks: bug [743877](https://bugzilla.mozilla.org/show_bug.cgi?id=743877). This should significantly improve our tab strip responsiveness.  
-  
-Incremental GC is making progress towards being turned on by default again: bugs [750959](https://bugzilla.mozilla.org/show_bug.cgi?id=750959), [752098](https://bugzilla.mozilla.org/show_bug.cgi?id=752098).  
-  
-There was also progress on cancellable SQL (bug [722243](https://bugzilla.mozilla.org/show_bug.cgi?id=722243)). This should result in faster shutdown.  
-  
-Progress was made towards fixing cache locking, bug [722034](http://bugzilla.mozilla.org/show_bug.cgi?id=722034).  
-  
-Lawrence posted a [summary](http://hacks.mozilla.org/2012/05/getting-snappy-performance-optimisations-in-firefox-13/) of snappy work that went into Firefox 13.  
-  
-**LagBlock Plus**  
-  
-Some of the lag in Firefox is caused by background tabs processing timeouts [willy-nilly](http://taras.glek.net/blog/2012/04/18/web-2-0-a-collection-of-settimeouts/). We are working on teaching Firefox to cope with overactive background tabs in bug [715376](https://bugzilla.mozilla.org/show_bug.cgi?id=715376). The plan is to allow Firefox to throttle/group background events, especially in tabs that are CPU hogs.  
-  
-To help us along, the author of Adblock Plus [released](http://adblockplus.org/blog/preventing-background-tabs-from-wasting-your-computer-s-resources) an experimental addon that freezes activity in background tabs. Since this addon halts all background tab activity, it is a useful gauge of baseline performance that we'll try to get asymptotically close to. It is also helpful for isolating responsiveness issues that are not caused by background tabs.  
-  
-  
-  
-
diff --git a/source/_posts/2012-05-21-snappy-may-17-physical-room-edition.markdown b/source/_posts/2012-05-21-snappy-may-17-physical-room-edition.markdown
deleted file mode 100644
index 1655da7..0000000
--- a/source/_posts/2012-05-21-snappy-may-17-physical-room-edition.markdown
+++ /dev/null
@@ -1,39 +0,0 @@
----
-comments: true
-date: 2012-05-21 11:10:23
-layout: post
-slug: snappy-may-17-physical-room-edition
-title: Snappy, May 17 - Physical Room Edition
-wordpress_id: 668
-categories:
-- mozilla
-- snappy
----
-
-**Misc**  
-  
-This was an unusual meeting for the Snappy project: everybody was in the same physical room (though someone dialed in 5min before the end). I love the distributed nature of Mozilla, but it's nice to have everybody in the same room for a change.  
-  
-Vlad did some super-slow-startup investigation. We have even more [evidence](http://blog.mozilla.org/vdjeric/2012/05/17/looking-at-my-own-abouttelemetry-data/) that loading pages before the UI is up is a bad idea: bug 715402.  
-  
-Jet sped up browser chrome by converting SVG masks to clip-paths: bug [752918](https://bugzilla.mozilla.org/show_bug.cgi?id=752918). With a name like that, how can he not work on performance bugs :)  
-  
-The necko team is looking for feedback on test builds that reduce cache-related pauses on the main thread. If you suffer from cache-related lag, give [these](https://ftp.mozilla.org/pub/mozilla.org/firefox/try-builds/bsmith@mozilla.com-10b6ced92518/) a spin: bug [722034](https://bugzilla.mozilla.org/show_bug.cgi?id=722034).  
-  
-Benoit made our profiling builds useful on Linux, Android (in addition to Windows, Mac64). Work is happening on extending our debug protocol with [profiling ](https://developer.mozilla.org/en/Performance/Profiling_with_the_Built-in_Profiler)abilities. Unfortunately I do not have bug #s to link to. The Windows symbol server is almost done with security review so it can be exposed to the web. For more profiler details see bugs: [753588](https://bugzilla.mozilla.org/show_bug.cgi?id=753588), [751355](https://bugzilla.mozilla.org/show_bug.cgi?id=751355), [751355](https://bugzilla.mozilla.org/show_bug.cgi?id=751355), [751034](https://bugzilla.mozilla.org/show_bug.cgi?id=751034), [751779](https://bugzilla.mozilla.org/show_bug.cgi?id=751779).  
-  
-Rafael is getting close to calling exit(0) in bug [662444](https://bugzilla.mozilla.org/show_bug.cgi?id=662444). Much work remains, it'll be the most significant change since we embarked on this project almost a year ago. Our current application shutdown situation is not pretty.  
-  
-**GC/CC**  
-  
-Bill landed incremental GC again, it promptly bounced out: bug [735099](https://bugzilla.mozilla.org/show_bug.cgi?id=735099).  
-  
-We now do compartmental GC more often: bug [716014](https://bugzilla.mozilla.org/show_bug.cgi?id=716014).  
-  
-Andrew is working on reducing CC overhead (by 80% in his benchmark) when closing tabs: bug [754495](https://bugzilla.mozilla.org/show_bug.cgi?id=754495).  
-  
-**LagBlock Plus**  
-  
-I've been running Wlad's [extension](https://addons.mozilla.org/en-US/firefox/addon/suspend-background-tabs/) for over a week now. The browser is so much more pleasant now. Background tabs used to make text-entry a painful process. Can't wait until we can approach a similar level of responsiveness by scheduling background tab events more intelligently.  
-  
-I feel that letting tabs run out of control is a serious misfeature in the current web 'architecture'. Modern OSes require background apps to suspend (ie Android, iOS). It is about time that browsers forced a similar behavior: ie bug [675539](https://bugzilla.mozilla.org/show_bug.cgi?id=675539). Web developers should be given a way to request to run background tasks and users should be able to veto that.
diff --git a/source/_posts/2012-05-21-snappy-workweek.markdown b/source/_posts/2012-05-21-snappy-workweek.markdown
deleted file mode 100644
index 8d23849..0000000
--- a/source/_posts/2012-05-21-snappy-workweek.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2012-05-21 09:53:14
-layout: post
-slug: snappy-workweek
-title: Snappy Workweek
-wordpress_id: 666
-categories:
-- mozilla
-- snappy
----
-
-**Workweek**  
-  
-The perf team + Lawrence held a snappy workweek at the Mozilla HQ last week. We spent most of the week meeting with various people involved with the Snappy project. I expect lots of good things to happen in the near future.  
-  
-The most immediate outcome of all of these meetings was the public unveiling of our telemetry dashboards. See Lawrence's [post](http://lawrencemandel.com/2012/05/16/sign-in-to-telemetry-with-persona/) on how to log in with your persona account. We started work on telemetry about a year ago, felt great to finally reach this milestone. Lots of work remains on UI polish, data validation, etc. Telemetry is our primary mechanism for gathering snappy performance data. Every telemetry infrastructure improvement leads to better snappy decisions.  
-  
-Additionally we discussed Australis theme work (how it should be faster than existing theme), dom event scheduling, main thread io work, feasibility of switching to an FTS backend for places, etc.  
-  
-Vlad wrote some good posts on analyzing [startup](http://blog.mozilla.org/vdjeric/2012/05/14/more-telemetry-from-super-slow-startups/) and [other data](http://blog.mozilla.org/vdjeric/2012/05/17/looking-at-my-own-abouttelemetry-data/) exposed by about:telemetry. [Planet Mozilla](http://planet.mozilla.org/) could use more technical posts like that.  
-  
-  
-  
-
diff --git a/source/_posts/2012-05-22-give-dxr-a-try.markdown b/source/_posts/2012-05-22-give-dxr-a-try.markdown
deleted file mode 100644
index 5792c06..0000000
--- a/source/_posts/2012-05-22-give-dxr-a-try.markdown
+++ /dev/null
@@ -1,21 +0,0 @@
----
-comments: true
-date: 2012-05-22 09:34:51
-layout: post
-slug: give-dxr-a-try
-title: Give DXR a try
-wordpress_id: 661
-categories:
-- mozilla
-- static-analysis
----
-
-At Mozilla we have a long history of using [MXR](http://mxr.mozilla.org/) for looking up and discussing source code. Unfortunately MXR is an unlovable mess of Perl and a crappy (in terms of performance and license) text indexing engine that is glimpse. It is dead because nobody wants to work on it.  
-  
-[DXR](https://wiki.mozilla.org/DXR) is a semantically-aware successor to MXR. Semantic information is extracted from LLVM during compilation. This makes it possible to do searches like [derived:nsIFile](http://dxr.lanedo.com/search.cgi?tree=mozilla-central&derived=nsIFile). DXR uses a modern Full Text Search engine for text searches, so it should be much faster than MXR. There is a test instance at [dxr.mozilla.org](http://dxr.lanedo.com/), please give it a try. The homepage lists sample searches you can do.  
-  
-DXR is written in Python. It uses an SQLite database + FTS index as a backend. Useful semantic information is extracted from the source via a Clang LLVM plugin. Checkout the [source code](https://github.com/mozilla/dxr/) at github.  
-  
-DXR should be getting close to feature parity with MXR. Give it a try and let me know of any bugs/missing features you encounter (or submit a patch!). I realize that people have gotten used to various MXR quirks and that it can be stressful to switch to a new code indexer while trying to get stuff done, but MXR IS DEAD. We need to move on. Mozilla is complex, finding relevant code can take quite a while, especially for new contributors. Using a smarter indexer should save time, reduce frustration and free up a few developer-years to make Firefox better.  
-  
-We have lots of ideas for DXR, but first we need to ensure it is a suitable replacement for MXR. Take DXR for a spin!
diff --git a/source/_posts/2012-05-29-snappy-may-24-meetingless.markdown b/source/_posts/2012-05-29-snappy-may-24-meetingless.markdown
deleted file mode 100644
index baeb5ee..0000000
--- a/source/_posts/2012-05-29-snappy-may-24-meetingless.markdown
+++ /dev/null
@@ -1,23 +0,0 @@
----
-comments: true
-date: 2012-05-29 10:31:59
-layout: post
-slug: snappy-may-24-meetingless
-title: Snappy, May 24 - meetingless
-wordpress_id: 677
-categories:
-- mozilla
-- snappy
----
-
-Frank and Jared are aiming to have the Australis theme up for review next week in [bug 732583](https://bugzilla.mozilla.org/show_bug.cgi?id=732583). There are no _computed_ borders or gradients in the redesign, so it will be faster.  The current theme generates new borders/gradients on every tab interaction, which is very inefficient. Bas is working on fixing our graphics backend to render borders/gradients more efficiently in bug [750871](https://bugzilla.mozilla.org/show_bug.cgi?id=750871).  
-  
-Wlad spotted some unintended bloat in the addon database in [bug 752868](https://bugzilla.mozilla.org/show_bug.cgi?id=752868). Blair fixed it, this should speed up startup and other addon manager interactions.  
-  
-Bill did some further IGC fixes: [bug 757483](https://bugzilla.mozilla.org/show_bug.cgi?id=757483), [bug 754588](https://bugzilla.mozilla.org/show_bug.cgi?id=754588), [bug 756732](https://bugzilla.mozilla.org/show_bug.cgi?id=756732), [bug 731423](https://bugzilla.mozilla.org/show_bug.cgi?id=731423).  
-  
-We started a new project to let Firefox diagnose common Windows/etc misconfiguration issues that severely impact Firefox performance. Our new intern, Nicholas, is working on this in bug [684646](https://bugzilla.mozilla.org/show_bug.cgi?id=684646). The immediate plan is to release an addon that detects when Firefox startup is unusually slow, checks for known Windows issues and pops up a link to a Mozilla [support](http://support.mozilla.com/) article on how to fix the problem. If this turns out to be successful, we'll integrate this functionality into Firefox.  
-  
-The gecko profiler is now ready for general consumption. See Benoit's [announcement](https://groups.google.com/forum/#!topic/mozilla.dev.platform/jOklwc7AdC8). This will allow users running  the [profiling ](http://groups.google.com/group/mozilla.dev.platform/browse_thread/thread/3389798e5ef9744b#)variant of Firefox nightly builds to capture/report performance problems in a way that developers can act on. I suspect that [Benoit ](http://benoitgirard.wordpress.com)will blog about this.  
-  
-**Update**: I originally linked the wrong bug for windows misconfiguration detection.
diff --git a/source/_posts/2012-06-04-snappy-may-31st-less-lag.markdown b/source/_posts/2012-06-04-snappy-may-31st-less-lag.markdown
deleted file mode 100644
index 1460bbc..0000000
--- a/source/_posts/2012-06-04-snappy-may-31st-less-lag.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2012-06-04 09:38:08
-layout: post
-slug: snappy-may-31st-less-lag
-title: Snappy, May 31st - Less lag
-wordpress_id: 687
-categories:
-- mozilla
-- snappy
----
-
-On Friday, the necko team finally landed a fix that makes cache less likely to freeze the UI thread during reads: [bug 722034](https://bugzilla.mozilla.org/show_bug.cgi?id=722034). Cache writes, other less common cache use-cases remain problematic (tracked by bug [717761](https://bugzilla.mozilla.org/show_bug.cgi?id=717761)). Poor cache/main-thread interactions are one of the main causes of UI lag tracked by the Snappy project, so this is very exciting. Barring the need to backout, this fix will appear in Firefox 15.  
-  
-**Help Wanted:** The necko team is looking for some help to determine the optimal disk cache size, please see [Nick's post](http://todesschaf.org/posts/2012/06/04/cache-usage-and-you.html). We need users to install an extension and submit detailed stats on our cache lifecycle.  
-  
-There are various Firefox frontend fixes in progress: improving session restore (working towards [669603](https://bugzilla.mozilla.org/show_bug.cgi?id=669603), [669034](https://bugzilla.mozilla.org/show_bug.cgi?id=669034)), FUEL (bug [750454](https://bugzilla.mozilla.org/show_bug.cgi?id=750454)),  search service (bug [722332](https://bugzilla.mozilla.org/show_bug.cgi?id=722332)) and the new theme (bug [732583](https://bugzilla.mozilla.org/show_bug.cgi?id=732583)). I will blog about these in more detail as they land.  
-  
-Bill landed turned on incremental GC again. Hopefully it will stay on in Firefox 15.  
-  
-Andrew is making progress on reducing CC pauses while closing tabs: bug [754495](https://bugzilla.mozilla.org/show_bug.cgi?id=754495).  
-  
-Brian has instrumented our event loop to measure the extent of Firefox lag when responding to user events, bug [759449](https://bugzilla.mozilla.org/show_bug.cgi?id=759449). This is different than measuring general event-loop lag in that it focuses on lag that the user would actually notice. Look for  the EVENTLOOP_UI_LAG_EXP_MS histogram in our [telemetry dashboard ](https://metrics.mozilla.com/data/)(yes, we are the only browser vendor to make this sort of data public). This should help us track progress as we tweak heuristics to delay background processing during user interaction (eg bug [712478](https://bugzilla.mozilla.org/show_bug.cgi?id=712478)).  
-  
-Brian also landed a way to bypass the windows prefetch service via our privileged silent update service, see [bug 692255](https://bugzilla.mozilla.org/show_bug.cgi?id=692255). In my testing prefetch is likely to prefetch too many files, slowing down startup for complex apps like Firefox. Hopefully we can do better with our own prefetch.
diff --git a/source/_posts/2012-06-11-snappy-june-7.markdown b/source/_posts/2012-06-11-snappy-june-7.markdown
deleted file mode 100644
index d7ad257..0000000
--- a/source/_posts/2012-06-11-snappy-june-7.markdown
+++ /dev/null
@@ -1,21 +0,0 @@
----
-comments: true
-date: 2012-06-11 16:13:36
-layout: post
-slug: snappy-june-7
-title: Snappy, June 7
-wordpress_id: 701
-categories:
-- mozilla
-- snappy
----
-
-[Notes](https://wiki.mozilla.org/Performance/Snappy/2012-06-07).  
-  
-Justin's FUEL fix will help add-ons avoid leaks and shutdown hangs: [bug 750454](https://bugzilla.mozilla.org/show_bug.cgi?id=750454).  
-  
-Jared plans to start landing Australis tab strip ([738491](https://bugzilla.mozilla.org/show_bug.cgi?id=738491)) on [UX branch](http://ftp.mozilla.org/pub/mozilla.org/firefox/nightly/latest-ux/) this week. Australis is our new, faster UI theme.  
-  
-We landed a cache locking fix recently ([722034](https://bugzilla.mozilla.org/show_bug.cgi?id=722034)), but telemetry is now showing a regression ([761736](https://bugzilla.mozilla.org/show_bug.cgi?id=761736)), so this will likely be backed out and reworked.  
-  
-Vladan [blogged](http://blog.mozilla.org/vdjeric/2012/06/08/cache-plugin-font-operations-most-common-in-chrome-hang-reports/) about first results from our non-destructive chromehang. Last year we briefly caused our nightly to crash if it hung for over 30seconds, which got us a lot of useful data (and some of the initial snappy bugs). This piggybacked on our crash-handling infrastructure so it was a very effective experiment (a bit brutal though). Vladan spent time this year working on plumbing to get the same sort of data non-destructively. As a result we are looking to [turn on frame pointers](https://groups.google.com/forum/?fromgroups#!topic/mozilla.dev.platform/UENmwUOFCkU) in nightly builds and dial down hang detection to 5 seconds (bug [763124](https://bugzilla.mozilla.org/show_bug.cgi?id=763124)).
diff --git a/source/_posts/2012-06-14-snappy-june-14th-telemetry-investigations.markdown b/source/_posts/2012-06-14-snappy-june-14th-telemetry-investigations.markdown
deleted file mode 100644
index 4b70d33..0000000
--- a/source/_posts/2012-06-14-snappy-june-14th-telemetry-investigations.markdown
+++ /dev/null
@@ -1,31 +0,0 @@
----
-comments: true
-date: 2012-06-14 14:51:24
-layout: post
-slug: snappy-june-14th-telemetry-investigations
-title: 'Snappy, June 14th: Telemetry Investigations'
-wordpress_id: 706
-categories:
-- mozilla
-- snappy
----
-
-There are no news from the Firefox frontend team this week.  
-  
-**Adventures in Measuring Changes**  
-  
-Necko team spent this week investigating why the recent big [cache fix](https://bugzilla.mozilla.org/show_bug.cgi?id=722034#c75) was not showing as a win in telemetry.  
-  
-[![](/assets/images/2012-06-14-snappy-june-14th-telemetry-investigations/cache_lock_mainthread_crap.jpg.png)](https://metrics.mozilla.com/data/content/pentaho-cdf-dd/Render?solution=metrics2&path=%2Ftelemetry&file=telemetryEvolution.wcdf&bookmarkState={\%22impl%22%3A%22client%22%2C%22params%22%3A{\%22appNameParameter%22%3A%22[Application].[Firefox]%22%2C%22channelParameter%22%3A%22[Channel].[nightly]%22%2C%22osParameter%22%3A%22[OS].[WINNT]%22%2C%22histogramParameter%22%3A%22[Histogram].[CACHE_SERVICE_LOCK_WAIT_MAINTHREAD]%22%2C%22referenceDate%22%3A%222012-06-14%22%2C%22histogramPopupTools%22%3A%22%22%2C%22duplicateHistogram%22%3A%22%23duplicateHistogram%22%2C%22medianButtonParam%22%3A0%2C%22scatterChart%22%3A%22%22}})  
-  
-We were on a verge of a big backout when Saptashi Guha's analysis in bug [762576](https://bugzilla.mozilla.org/show_bug.cgi?id=762576) suggested that we might actually be winning. It's frustrating to have data point us in different directions. However, it is better to try to make sense of data than have no data at all as was the case only a year ago. I'll have more on this next week.  
-  
-William McCloskey landed fix to turn on incremental GC for real (bug [761739](https://bugzilla.mozilla.org/show_bug.cgi?id=761739)). This might fix the mysterious recent user-responsiveness regression spotted by telemetry (bug [761722](https://bugzilla.mozilla.org/show_bug.cgi?id=761722)). He  also landed another GC speed up in [743396](https://bugzilla.mozilla.org/show_bug.cgi?id=743396).  
-  
-Mark Cote met with metrics analysts to discuss reporting peptest results robustly. The goal is avoid noise in reporting, so responsiveness regressions are acted upon  
-  
-**Interactivity Profiler**  
-  
-Benoit Girrard added added badges to mark known stacks in the profiler, see his [blog post](http://benoitgirard.wordpress.com/2012/06/08/making-profiling-easier-automated-profiler-diagnostics/). A few weeks ago Vladan [taught ](http://blog.mozilla.org/vdjeric/2012/05/30/profiling-with-the-built-in-gecko-profiler-and-local-symbols-on-windows/)the symbolication server to serve data from local .pdb files, allowing developers to use Benoit's profiler in own builds. Mike Conley added incomplete Thunderbird support to the profiler.  
-  
-
diff --git a/source/_posts/2012-06-18-40-60-of-startups-are-warm.markdown b/source/_posts/2012-06-18-40-60-of-startups-are-warm.markdown
deleted file mode 100644
index bc2dc4c..0000000
--- a/source/_posts/2012-06-18-40-60-of-startups-are-warm.markdown
+++ /dev/null
@@ -1,26 +0,0 @@
----
-comments: true
-date: 2012-06-18 14:00:34
-layout: post
-slug: 40-60-of-startups-are-warm
-title: 40-60% of startups are warm?
-wordpress_id: 715
-categories:
-- mozilla
----
-
-_Note: click on the images if they get clipped by other content. Cold startups are those where data has to be read in from disk, warm ones are subsequent startups where the OS already has Firefox files in memory. _ I'm really surprised by the amount of warm startups done by Firefox users. Somewhere between 40% to 60% of startups are warm. On Linux you can see that by watching whether pagefaults occur while loading the firefox binary via [EARLY_GLUE_STARTUP_HARD_FAULTS](https://metrics.mozilla.com/data/content/pentaho-cdf-dd/Render?solution=metrics2&path=%2Ftelemetry&file=telemetryHistogram.wcdf&bookmarkState={\%22impl%22%3A%22client%22%2C%22params%22%3A{\%22startDate%22%3A%222012-05-19%22%2C%22endDate%22%3A%222012-06-17%22%2C%22appVersion%22%3A%22%22%2C%22appName%22%3A%22firefox%22%2C%22arch%22%3A%22%22%2C%22OS%22%3A%22%22%2C%22version%22%3A%22%22%2C%22channel%22%3A%22%22%2C%22appBuildID%22%3A%22%22%2C%22fromPlatformBuildID%22%3A%22%22%2C%22toPlatformBuildID%22%3A%22%22%2C%22excludeParam%22%3A%22%22%2C%22measure%22%3A%22EARLY_GLUESTARTUP_HARD_FAULTS%22%2C%22histogramCompareParam%22%3A%22appVersion%22%2C%22histogramVariablesParam%22%3A%22%22%2C%22platformBuildIDMode%22%3A%22LATEST%22%2C%22platformBuildIDTopCount%22%3A%2230%22%2C%22conditionsStatistic%22%3A%22%23conditionsStatistic%22%2C%22submissionsParameter%22%3A[[5229518]]}}) histogram.  
-  
-[![](/assets/images/2012-06-18-40-60-of-startups-are-warm/glue.png)](/assets/images/2012-06-18-40-60-of-startups-are-warm/glue.png)  
-  
-On Windows we do not have a good metric  for distinguishing cold startups from warm ones. However can look at the distribution of [firstpaint histogram](https://metrics.mozilla.com/data/content/pentaho-cdf-dd/Render?solution=metrics2&path=%2Ftelemetry&file=telemetryHistogram.wcdf&bookmarkState={\%22impl%22%3A%22client%22%2C%22params%22%3A{\%22startDate%22%3A%222012-05-19%22%2C%22endDate%22%3A%222012-06-17%22%2C%22appVersion%22%3A%22%22%2C%22appName%22%3A%22firefox%22%2C%22arch%22%3A%22%22%2C%22OS%22%3A%22%22%2C%22version%22%3A%22%22%2C%22channel%22%3A%22%22%2C%22appBuildID%22%3A%22%22%2C%22fromPlatformBuildID%22%3A%22%22%2C%22toPlatformBuildID%22%3A%22%22%2C%22excludeParam%22%3A%22%22%2C%22measure%22%3A%22SIMPLE_MEASURES_FIRSTPAINT%22%2C%22histogramCompareParam%22%3A%22OS%22%2C%22histogramVariablesParam%22%3A%22darwin%2Clinux%2Cwinnt%22%2C%22platformBuildIDMode%22%3A%22LATEST%22%2C%22platformBuildIDTopCount%22%3A%2230%22%2C%22conditionsStatistic%22%3A%22%23conditionsStatistic%22%2C%22submissionsParameter%22%3A[[91510595]]}}) and see that faster startups are more common than slower ones. Only a small minority of machines should be able to cold start a browser in <3 seconds.  We have a lot of startups of various degrees of warmness.  
-  
-[![](/assets/images/2012-06-18-40-60-of-startups-are-warm/firstpaint.png)](/assets/images/2012-06-18-40-60-of-startups-are-warm/firstpaint.png)  
-  
-I have no explanation on why people restart Firefox so much. We know < 10% of our shutdowns are [unclean](https://metrics.mozilla.com/data/content/pentaho-cdf-dd/Render?solution=metrics2&path=%2Ftelemetry&file=telemetryHistogram.wcdf&bookmarkState={\%22impl%22%3A%22client%22%2C%22params%22%3A{\%22startDate%22%3A%222012-05-19%22%2C%22endDate%22%3A%222012-06-17%22%2C%22appVersion%22%3A%22%22%2C%22appName%22%3A%22firefox%22%2C%22arch%22%3A%22%22%2C%22OS%22%3A%22%22%2C%22version%22%3A%22%22%2C%22channel%22%3A%22%22%2C%22appBuildID%22%3A%22%22%2C%22fromPlatformBuildID%22%3A%22%22%2C%22toPlatformBuildID%22%3A%22%22%2C%22excludeParam%22%3A%22%22%2C%22measure%22%3A%22SHUTDOWN_OK%22%2C%22histogramCompareParam%22%3A%22OS%22%2C%22histogramVariablesParam%22%3A%22darwin%2Clinux%2Cwinnt%22%2C%22platformBuildIDMode%22%3A%22LATEST%22%2C%22platformBuildIDTopCount%22%3A%2230%22%2C%22conditionsStatistic%22%3A%22%23conditionsStatistic%22%2C%22submissionsParameter%22%3A[[91503292]]}}) (most of those appear to be due to OS shutdown not waiting on Firefox, ie us shutting down too [slowly](https://bugzilla.mozilla.org/show_bug.cgi?id=662444)) so users aren't crashing their browser and starting again. They are voluntarily closing the browser and then starting it soon after (ie OS doesn't get a chance to flush Firefox out of filesystem cache).  
-  
-[![](/assets/images/2012-06-18-40-60-of-startups-are-warm/shutdown_ok.png)](/assets/images/2012-06-18-40-60-of-startups-are-warm/shutdown_ok.png)  
-  
-These patterns are pretty consistent across all of the Firefox release channels I checked, so I can't blame warm startups on nightly users getting barraged with upgrade prompts. Can someone come up with a good theory(preferably with some evidence) for this?  
-  
-Note telemetry only collects data once a day and requires the browser to be open for a few minutes before submitting data, data could be skewed here.
diff --git a/source/_posts/2012-06-25-slow-startup-logging-help-wanted.markdown b/source/_posts/2012-06-25-slow-startup-logging-help-wanted.markdown
deleted file mode 100644
index c675aa9..0000000
--- a/source/_posts/2012-06-25-slow-startup-logging-help-wanted.markdown
+++ /dev/null
@@ -1,19 +0,0 @@
----
-comments: true
-date: 2012-06-25 10:07:06
-layout: post
-slug: slow-startup-logging-help-wanted
-title: 'Slow startup logging: help wanted'
-wordpress_id: 727
-categories:
-- mozilla
-- snappy
----
-
-We have an intern working on an analysis tool to analyze how other Windows applications/services affect Firefox startup.  
-  
-[![](http://media.tumblr.com/tumblr_m616xmP5m81qz73vw.png)](http://nchaim-moz2012.tumblr.com/post/25647745019/slow-startup-logging-add-on)  
-  
-If you run Windows and you experience slow startups, please see Nicolas' [blog post](http://nchaim-moz2012.tumblr.com/post/25647745019/slow-startup-logging-add-on) and submit data his addon gathers.  
-  
-ps. I will not have time to post a Snappy update for last week. The next update will cover 2 weeks.
diff --git a/source/_posts/2012-07-02-snappy-june-21-28.markdown b/source/_posts/2012-07-02-snappy-june-21-28.markdown
deleted file mode 100644
index fe2b34a..0000000
--- a/source/_posts/2012-07-02-snappy-june-21-28.markdown
+++ /dev/null
@@ -1,33 +0,0 @@
----
-comments: true
-date: 2012-07-02 14:06:24
-layout: post
-slug: snappy-june-21-28
-title: Snappy June 21, 28
-wordpress_id: 729
-categories:
-- mozilla
-- snappy
----
-
-Necko team is busy squashing main-thread waits, see [bug 765665](https://bugzilla.mozilla.org/show_bug.cgi?id=765665), [bug 766973](https://bugzilla.mozilla.org/show_bug.cgi?id=766973).  
-  
-Ehsan Akhgari turned on frame pointers on nightly channel: bug [764216](https://bugzilla.mozilla.org/show_bug.cgi?id=764216). This means that one can now use the [built-in profiler](https://developer.mozilla.org/en/Performance/Profiling_with_the_Built-in_Profiler#Running%20the%20profiler) on nightly builds. The main purpose behind the change was to collect more chromehang data(long Firefox UI stalls). Vlad Djeric lowered the chromehang reporting threshold to 5 seconds: [bug 763124](https://bugzilla.mozilla.org/show_bug.cgi?id=763124). We are waiting on metrics to separate out chromehang reporting from telemetry pings: [bug 763116](https://bugzilla.mozilla.org/show_bug.cgi?id=763116).  
-  
-Nathan Froyd is making heroic progress on teaching our events to queue so they can be prioritized: bug [715376](http://bugzilla.mozilla.org/show_bug.cgi?id=715376).  
-  
-Tim Taubert is working to reproduce a tab animation regression in [bug 752837](https://bugzilla.mozilla.org/show_bug.cgi?id=752837). He also taking over making Firefox themes less of a performance pig in** **[bug 650968](https://bugzilla.mozilla.org/show_bug.cgi?id=650968) .  
-  
-We had great success with eliciting data on slow startups in Nicholas Chaim's [blog post](http://nchaim-moz2012.tumblr.com/post/25647745019/slow-startup-logging-add-on).  We confirmed that external processes can affect Firefox startup (we had evidence for this) and that we can detect those situations (great work Nicholas!). It will be a hard slog before we can bolt a pretty UI to the extension + integrate system diagnostics into Firefox. In the meantime I recommend that [SUMO](http://support.mozilla.org/en-US/home) people start suggesting this extension to diagnose slow Firefox installs. Nicholas is working on a revision of the extension that records slow-IO-caused-startup situations on a server so we prioritize + turn these into detectable fingerprints.  
-  
-William McCloskey fixed a nasty GC regression which caused GCs to run too often: [bug 768282](https://bugzilla.mozilla.org/show_bug.cgi?id=768282). Andrew McCreight sped up cycle collection when closing tabs: [bug 754495](https://bugzilla.mozilla.org/show_bug.cgi?id=754495). Olli Pettay enabled freeing DOM nodes directly (bypassing cycle-collection) when setting .innerHtml of non-empty DOM elements see [bug 730639](https://bugzilla.mozilla.org/show_bug.cgi?id=730639).  
-  
-**PS**  
-  
-"The Performance of Open Source Applications" book is looking for [contributors](http://www.aosabook.org/blog/2012/06/the-performance-of-open-source-applications/). Would be cool if someone snuck some Mozilla wisdom in there.  
-  
-Sorry for skipping the snappy update last week. These posts take a lot more effort than is reasonable and I needed to direct it at my talk last week. You can see my [Velocity](http://velocityconf.com/velocity2012) slides [here](http://people.mozilla.com/~tglek/velocity2012/).  
-  
-At least one person objected to the strong language used in the presentation (ie "dom local storage sucks"). I chose this language to emphasize the fact this isn't a feature where one gets to weigh upsides vs downsides because the downsides are so severe. Most of the positive data on this is coming from what I believe to be unrepresentative benchmarks. I have not seen any other data points similar in quality to those reported by our [telemetry](https://metrics.mozilla.com/data/).  
-  
-Btw, Jan Varga is close to removing our IndexedDB prompt(bug [758357](https://bugzilla.mozilla.org/show_bug.cgi?id=758357)), opening up IndexedDB as an alternative to DOM Local Storage([which sucks](http://taras.glek.net/blog/2012/03/16/localstorage-pageload-perf/)).
diff --git a/source/_posts/2012-07-09-snappy-update-for-week-of-july-5th.markdown b/source/_posts/2012-07-09-snappy-update-for-week-of-july-5th.markdown
deleted file mode 100644
index b8b199b..0000000
--- a/source/_posts/2012-07-09-snappy-update-for-week-of-july-5th.markdown
+++ /dev/null
@@ -1,27 +0,0 @@
----
-comments: true
-date: 2012-07-09 14:49:31
-layout: post
-slug: snappy-update-for-week-of-july-5th
-title: Snappy update for week of July 5th
-wordpress_id: 737
-categories:
-- mozilla
-- snappy
----
-
-**Frontend**  
-  
-Jared Wein discovered that our about:home was surprisingly expensive to load. He sped up the page by an estimated 30% in bug [765411](https://bugzilla.mozilla.org/show_bug.cgi?id=765411#c11). Similarly, Tim Taubert is fixing our new tab page performance in bug [753448](https://bugzilla.mozilla.org/show_bug.cgi?id=753448).  
-  
-Tim is also bravely attacking (via bug [769634](https://bugzilla.mozilla.org/show_bug.cgi?id=769634)) horrid performance issues with Firefox themes tracked by bug [650968](https://bugzilla.mozilla.org/show_bug.cgi?id=650968).  
-  
-**Profiling**  
-  
-Alex Crichton added ability to profile JS in bug [761261](https://bugzilla.mozilla.org/show_bug.cgi?id=761261). Benoit Girard is adding labels to the profiler to expose JS profiling info in [bug 707308](https://bugzilla.mozilla.org/show_bug.cgi?id=707308).  Same functionality will also allow us to add URLs to the stacks. This means that in addition to seeing what Firefox is busy with, the profiler will now provide context on what caused the processing ([screenshot](http://people.mozilla.com/~tglek/velocity2012/css/profiler.png)). This is huge. Benoit also improved profiler timing data in [769989](https://bugzilla.mozilla.org/show_bug.cgi?id=769989).  
-  
-**Slow Startup Research**  
-  
-As I mentioned [before](http://taras.glek.net/blog/2012/06/25/slow-startup-logging-help-wanted/), Nicholas Chaim wrote an addon to track system IO usage while starting Firefox. He has since [updated ](http://nchaim-moz2012.tumblr.com/post/26653615162/slow-startup-logging-add-on-0-12)his addon to be hosted on [AMO](https://addons.mozilla.org/en-US/firefox/addon/slow-startup-logging/) and to submit that data for analysis. If you suffer from slow Firefox startups, please help us identify common IO hogs by installing his addon. Please encourage friends with slow startups to do the same.  
-  
-This addon lists names of processes and amount of IO they did. This is somewhat private information, we can't gather this data via telemetry.
diff --git a/source/_posts/2012-07-12-snappy-july-12-2012.markdown b/source/_posts/2012-07-12-snappy-july-12-2012.markdown
deleted file mode 100644
index e59b146..0000000
--- a/source/_posts/2012-07-12-snappy-july-12-2012.markdown
+++ /dev/null
@@ -1,39 +0,0 @@
----
-comments: true
-date: 2012-07-12 15:30:52
-layout: post
-slug: snappy-july-12-2012
-title: Snappy. July 12, 2012
-wordpress_id: 741
-categories:
-- mozilla
-- snappy
----
-
-**Testing**  
-  
-We discussed setting up [Eideticker](http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels), for desktop Firefox responsiveness testing.  
-  
-Andrew Halberstadt is making progress on a revised version of peptest. We are looking at loading talos pageset into individual tabs and tracking tab-switching  
-  
-We also discussed how QA can help in helping us confirm + narrow down regressions found by telemetry.  
-  
-**Necko**  
-  
-Necko guys are continuing to remove main thread DNS resolution, are integrating a custom DNS resolver. Last week they landed a bunch of [telemetry](https://metrics.mozilla.com/data/) to help them play cache-lock-whack-a-mole: bug [763342](https://bugzilla.mozilla.org/show_bug.cgi?id=763342), [767275](https://bugzilla.mozilla.org/show_bug.cgi?id=767275).  
-  
-**Profiler**  
-  
-Our [profiler ](https://developer.mozilla.org/en/Performance/Profiling_with_the_Built-in_Profiler)should grok JavaScript now. See tomorrow's nightly.  
-  
-**GC**  
-  
-Jon Coppeard put up a patch to do incremental sweeping. The cleanup phase of the GC is a major remaining continuous GC operation. This should help reduce remaining significant GC pauses.  
-  
-**Perf Team**  
-  
-Nicholas Chaim is almost done with setting a way to track main thread IO with XPerf in bug [770317](https://bugzilla.mozilla.org/show_bug.cgi?id=770317). We would like to track main thread network IO via xperf, but it's not clear if xperf can report what thread IO operations happen on.  
-  
-**Slow Startup**  
-  
-Turns out Firefox validates some signed extensions on startup: bug [726125](https://bugzilla.mozilla.org/show_bug.cgi?id=726125). I think we finally have a good explanation for some of the ridiculously slow startups we've been looking at. Yuck.
diff --git a/source/_posts/2012-07-23-snappy-july-19-telemetry-experiments.markdown b/source/_posts/2012-07-23-snappy-july-19-telemetry-experiments.markdown
deleted file mode 100644
index a4b6982..0000000
--- a/source/_posts/2012-07-23-snappy-july-19-telemetry-experiments.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2012-07-23 17:56:56
-layout: post
-slug: snappy-july-19-telemetry-experiments
-title: 'Snappy, July 19: Telemetry Experiments'
-wordpress_id: 748
-categories:
-- mozilla
-- snappy
----
-
-For the in-progress work and minor changes that landed see [non-meeting notes](https://wiki.mozilla.org/Performance/Snappy/2012-07-19) for this week.  
-  
-Jeff Muizelaar wrote an interesting [blog post](http://muizelaar.blogspot.ca/2012/07/what-happens-when-you-switch-to-gmail.html) work involved in a tab switch on Mac.  
-  
-**Windows Prefetch**:** Experimental Data vs Reality**  
-  
-I once discovered that [Windows Prefetch](http://en.wikipedia.org/wiki/Prefetcher) can adversely affect application startup times, bug [627591](https://bugzilla.mozilla.org/show_bug.cgi?id=627591). Certain machines were showing performance to be much better with Windows prefetch disabled and using my "manual" dll preload code to warm up the cache. Manual dll preload is a win for loading large applications because it causes xul.dll to be read in sequentially rather than randomly via page-in (see my [blog posts](http://taras.glek.net/blog/2010/) from 2010 for details of startup IO uglyness). Unfortunately Windows Prefetch + my preload code measured as a net regression. I found a weird API that seemed to return 0 when prefetch was broken and [guarded ](https://hg.mozilla.org/mozilla-central/rev/cc18551d5cc3#l1.19)preload on that.  
-  
-We have recently backed out above heuristic based on a telemetry study in bug [757215](https://bugzilla.mozilla.org/show_bug.cgi?id=757215). Perhaps this is why our startup numbers have started [getting better](https://metrics.mozilla.com/data/content/pentaho-cdf-dd/Render?solution=metrics2&path=%2Ftelemetry&file=telemetryEvolution.wcdf&bookmarkState={\%22impl%22%3A%22client%22%2C%22params%22%3A{\%22referenceDate%22%3A%222012-07-23%22%2C%22appNameParameter%22%3A%22[Application].[Firefox]%22%2C%22osParameter%22%3A%22[OS].[WINNT]%22%2C%22channelParameter%22%3A%22[Channel].[nightly]%22%2C%22reasonParameter%22%3A%22[Reason].[idle-daily]%22%2C%22histogramParameter%22%3A%22[Histogram].[SIMPLE_MEASURES_FIRSTPAINT]%22%2C%22histogramPopupTools%22%3A%22%22%2C%22duplicateHistogram%22%3A%22%23duplicateHistogram%22%2C%22medianButtonParam%22%3A0%2C%22scatterChart%22%3A%22%22}}) in Firefox 16?  
-  
-Brian Bondy setup a [telemetry startup trial](https://bugzilla.mozilla.org/show_bug.cgi?id=764905) to randomly delete prefetch, turn on dll preload. Last week Saptarshi Guha crunched some [telemetry](https://wiki.mozilla.org/Platform/Features/Telemetry) numbers, see this [bugzilla comment](https://bugzilla.mozilla.org/show_bug.cgi?id=771745#c9). Turned out Windows Prefetch is a huge win and dll preload is a tiny incremental improvement on top of that (rather than being a regression).  
-  
-Moral of the story is: _do not rely on manual performance testing for workloads involving large amounts of IO_. Simulating a "typical" Windows machine is extremely hard without getting noisy numbers. Effort is better spent on analyzing noisy real-world numbers and running experiments in the wild.
diff --git a/source/_posts/2012-07-25-telemetry-and-what-it-is-good-for-part-1-nuts-and-bolts.markdown b/source/_posts/2012-07-25-telemetry-and-what-it-is-good-for-part-1-nuts-and-bolts.markdown
deleted file mode 100644
index b707354..0000000
--- a/source/_posts/2012-07-25-telemetry-and-what-it-is-good-for-part-1-nuts-and-bolts.markdown
+++ /dev/null
@@ -1,42 +0,0 @@
----
-comments: true
-date: 2012-07-25 15:00:27
-layout: post
-slug: telemetry-and-what-it-is-good-for-part-1-nuts-and-bolts
-title: 'Telemetry and What It Is Good for: Part 1: Nuts and Bolts'
-wordpress_id: 750
-categories:
-- mozilla
----
-
-Telemetry has been in production for about year. However, it turns out that many Mozillians do not know what it is good for. I presented [about](http://people.mozilla.com/~tglek/fosdem2012/#/step-1) Telemetry at FOSDEM 2012, but have not had a chance to reach out to the core Mozilla developers because we haven't had a Mozilla All-Hands since Telemetry got useful.  
-  
-**Why Would One Use Telemetry?**  
-  
-Telemetry exists for a single purpose: matching developer expectations with real Firefox behavior. My experience working on startup lead me to believe that is unreasonably complex to try to model real-world behavior in a lab setting and that it was actually easier to just measure real world behavior.  
-  
-Anything that varies with IO, system configuration, user input, user workloads is easier to measure with Telemetry than to develop a useful finite benchmark for.  
-  
-**Nuts & Bolts**  
-  
-Telemetry consists of two parts: client-side collection code + serverside frontend.  
-  
-Client-side Telemetry currently records: 
-
-  * simple measures: discrete numbers such as amount of ram, various startup times, flash version, etc
-  * [histograms](http://mxr.mozilla.org/mozilla-central/source//ipc/chromium/src/base/histogram.h): efficient one-dimensional means of gathering a range of values such as memory usage, cycle collection times, types of events occurring, etc. These are all specified in [TelemetryHistograms.h](http://mxr.mozilla.org/mozilla-central/source/toolkit/components/telemetry/TelemetryHistograms.h). You can view your local histograms by enabling telemetry and installing [about:telemetry](https://addons.mozilla.org/en-US/firefox/addon/abouttelemetry/).
-  * slow sql statements: We record SQL statements that take over 100ms and whether they occur on main thread to prioritize [Snappy](https://wiki.mozilla.org/Performance/Snappy) SQL work.
-  * chromehangs: Nightly builds ship with frame-pointers so we can detect when Firefox pauses for over 5 seconds. Every time Firefox pauses, we record the backtrace. We started sending those a month ago, processing them on the serverside is a work-in-progress. These should be very handy for prioritizing work on making Firefox more responsive
-One current limitation is that histograms are on-dimensional, there is no way to relate cycle collection times to uptime, memory usage, etc. We also go to great lengths to avoid collecting any personal identifiers. As a result we have no user UIDs and no ability to track how a user's performance changes over time.  
-  
-Telemetry Frontend is a public dashboard that can be seen at [arewesnappyyet.com](http://arewesnappyyet.com/). Anyone can get a BrowserID login and look at our browser stats. Telemetry dashboard consists of two views: 
-
-  * Telemetry Histograms: this is basically the same data as displayed in about:telemetry, but aggregated from our userbase. This was our original view and is likely to get folded into evolution in the future.
-  * Telemetry Evolution: This view tracks how medians/percentiles gathered by histograms change over time. This is the view that most developers use.
-Telemetry is not a technology unique to Firefox. I borrowed a lot of code from the Chromium implementation to get caught up. Microsoft also collects similar metrics.  
-  
-There are two differences between us and other browser vendors: 
-
-  1. We do not assign a unique id to every user. This sucks from a developer perspective as it makes it a lot harder to track performance over time, but we believe the privacy benefits are worth it.
-  2. We made our dashboards public because we would like to have our community actively involved in helping us track Firefox performance.
-In part 2 I'll discuss how various people at Mozilla use Telemetry.
diff --git a/source/_posts/2012-07-25-telemetry-and-what-it-is-good-for-part-2-telemetry-achievements.markdown b/source/_posts/2012-07-25-telemetry-and-what-it-is-good-for-part-2-telemetry-achievements.markdown
deleted file mode 100644
index 5372ed5..0000000
--- a/source/_posts/2012-07-25-telemetry-and-what-it-is-good-for-part-2-telemetry-achievements.markdown
+++ /dev/null
@@ -1,24 +0,0 @@
----
-comments: true
-date: 2012-07-25 15:55:21
-layout: post
-slug: telemetry-and-what-it-is-good-for-part-2-telemetry-achievements
-title: ' Telemetry and What It Is Good for: Part 2: Telemetry Achievements '
-wordpress_id: 752
-categories:
-- mozilla
----
-
-An inquisitive mind sent me an email with a pointed question:  
-  
-"Is there an example of someone who's not you that had a burning question that would drive some sort of research or development activity and got it answered by telemetry?"  
-  
-I forwarded his email and got a pretty fun survey. See below for a slightly edited version of emails I got. In addition to positive experiences below, people had a lot of complains about the telemetry experience.  
-  
-_Justin Lebar_ Justin is probably the most vocal telemetry user who isn't me. He [blogged](http://jlebar.com/2012/5/30/A_ghost_story.html) about one of his more successful telemetry experiences. _Andrew McCreight_ One telemetry stat I added is [CYCLE_COLLECTOR_NEED_GC](https://metrics.mozilla.com/data/content/pentaho-cdf-dd/Render?solution=metrics2&path=%2Ftelemetry&file=telemetryHistogram.wcdf&bookmarkState={\%22impl%22%3A%22client%22%2C%22params%22%3A{\%22startDate%22%3A%222012-06-25%22%2C%22endDate%22%3A%222012-07-24%22%2C%22appVersion%22%3A%22%22%2C%22appName%22%3A%22Firefox%22%2C%22arch%22%3A%22%22%2C%22OS%22%3A%22%22%2C%22version%22%3A%22%22%2C%22channel%22%3A%22nightly%22%2C%22reason%22%3A%22idle-daily%22%2C%22appBuildID%22%3A%22%22%2C%22fromPlatformBuildID%22%3A%22%22%2C%22toPlatformBuildID%22%3A%22%22%2C%22excludeParam%22%3A%22%22%2C%22measure%22%3A%22CYCLE_COLLECTOR_NEED_GC%22%2C%22histogramCompareParam%22%3A%22appVersion%22%2C%22histogramVariablesParam%22%3A%22%22%2C%22platformBuildIDMode%22%3A%22LATEST%22%2C%22platformBuildIDTopCount%22%3A%2230%22%2C%22conditionsStatistic%22%3A%22%23conditionsStatistic%22%2C%22submissionsParameter%22%3A[[172394]]}}).  Sometimes a read barrier fails and we need to do a GC synchronously at the start of a CC, which is terrible for pause times.  Using telemetry, I confirmed my suspicion that this is very rare, and thus not worth trying to improve. Another state Olli added is [FORGET_SKIPPABLE_MAX](https://metrics.mozilla.com/data/content/pentaho-cdf-dd/Render?solution=metrics2&path=%2Ftelemetry&file=telemetryEvolution.wcdf&bookmarkState=%7B%22impl%22%3A%22client%22%2C%22params%22%3A%7B%22referenceDate%22%3A%222012-07-25%22%2C%22appNameParameter%22%3A%22%5BApplication%5D.%5BFirefox%5D%22%2C%22osParameter%22%3A%22%5BOS%5D.%5BWINNT%5D%22%2C%22channelParameter%22%3A%22%5BChannel%5D.%5Bnightly%5D%22%2C%22reasonParameter%22%3A%22%5BReason%5D.%5Bidle-daily%5D%22%2C%22histogramParameter%22%3A%22%5BHistogram%5D.%5BFORGET_SKIPPABLE_MAX%5D%22%2C%22histogramPopupTools%22%3A%22%22%2C%22duplicateHistogram%22%3A%22%23duplicateHistogram%22%2C%22medianButtonParam%22%3A0%2C%22scatterChart%22%3A%22%22%7D%7D), which tracks the length of the CC cleanup phases we run.  As we made the cleanup more and more thorough, the times of these got longer and longer.  I think eventually this led Olli to try to fix the worst case cleanup phases, in bug [747675](https://bugzilla.mozilla.org/show_bug.cgi?id=747675).  He had this comment in there: "Based on the initial telemetry data, the patch doesn't affect too much to the already low median times, but helps significantly with the worst 5%, so mean time decreases quite nicely." Also, back around Firefox 13, Olli was using telemetry to observe the results of various CC optimizations, to assess their effectiveness, which he then used to decide whether or not to nominate various patches for landing on Aurora 12.  Telemetry let us see the reward part of the risk vs. reward tradeoff, and get some pretty big improvements into 12. Locally, I use [about:telemetry](https://addons.mozilla.org/en-US/firefox/addon/abouttelemetry/) to get a sense of what the behavior on my local machine has been, but I suppose that doesn't really fall under "telemetry" per se.  But it was quite useful during the Cycle Collector Crisis to see what CC behavior people had been seeing on their machines.  
-  
-_Olli Pettay_ Thanks Andrew, very accurate summary of what I've been doing I tend to look at CC telemetry data daily. I very rarely use the histogram, since evolution is more interesting to me. Especially median time and also how P75 and P95 evolve. (The focus in this Q is to get lower bad times, so we should manage to drop P75 and P95) I use also [about:telemetry](about:telemetry) locally since I tend to run builds with some patch, and I want to see if they affect badly to CC or GC times.  
-  
-_Taras_ My blog is basically a collection of telemetry trivia :) I do not have testimonials from other people. However I heard that the silent-update team proved something about silent updates with telemetry, Necko team discovered that some optimizations were not, etc. I encourage other people who solved a problem with telemetry to either wrote a blog post or leave a comment.  
-  
-In part 3 I will cover flaws in the current Telemetry experience.
diff --git a/source/_posts/2012-07-26-snappy-july-26-go-try-the-gecko-profiler.markdown b/source/_posts/2012-07-26-snappy-july-26-go-try-the-gecko-profiler.markdown
deleted file mode 100644
index 61ab48c..0000000
--- a/source/_posts/2012-07-26-snappy-july-26-go-try-the-gecko-profiler.markdown
+++ /dev/null
@@ -1,41 +0,0 @@
----
-comments: true
-date: 2012-07-26 15:43:17
-layout: post
-slug: snappy-july-26-go-try-the-gecko-profiler
-title: 'Snappy, July 26: Go Try The Gecko Profiler!'
-wordpress_id: 755
-categories:
-- mozilla
-- snappy
----
-
-See raw [notes](https://wiki.mozilla.org/Performance/Snappy/2012-07-26) for details on mid-flight snappy work.  
-  
-**Checkout the SPS Profiler**!  
-  
-[SPS Gecko Profiler](https://developer.mozilla.org/en/Performance/Profiling_with_the_Built-in_Profiler) has gotten a lot of praise this week on #perf. If you ever wonder the hell Firefox is doing with your CPU, give the profiler a try. For the past couple of weeks it has been able to label stacks with JS, URLs and even favicons. It's likely that Mozilla may have shipped the world's first profiler to feature favicons.  
-  
-Having JS support is nice, it lead to the first 2 snappy addon bugs: [777266](https://bugzilla.mozilla.org/show_bug.cgi?id=777266), [777397](https://bugzilla.mozilla.org/show_bug.cgi?id=777397). I documented how to act on addon responsiveness issues in the [snappy wiki](https://wiki.mozilla.org/Performance/Snappy#Snappy_Addons).  
-  
-Whether you develop web pages, addons or are a core gecko hacker, the profiler may make the performance-analysis part of your life much more pleasant. Update: Benoit Girard [wrote](http://benoitgirard.wordpress.com/2012/07/27/javascript-profiling-with-the-gecko-profiler-and-js-anti-pattern/) about the new profiler features.  
-  
-**Things To Not Do On Startup **  
-  
-Blair McBride did some [digging](https://bugzilla.mozilla.org/show_bug.cgi?id=726125#c16), there may be 15million users with signed extensions which can cause Firefox to do network IO (ie stall for a long time) on startup.  
-  
-Brian Bondy landed a fix to lower IO priority of nuking our cache: [773518](https://bugzilla.mozilla.org/show_bug.cgi?id=773518). According to telemetry, 10-20% of startups feature cache nuking. It take a while to blow away 1GB of files on startup. Brian used telemetry to investigate causes for cache purges in bug [774146](https://bugzilla.mozilla.org/show_bug.cgi?id=774146). Based on this data, Brian will begin tackling what may be the oldest snappy bug so far: bug [105843](https://bugzilla.mozilla.org/show_bug.cgi?id=105843). For more details on our cache see Nick Hurley's [blog post](http://todesschaf.org/posts/2012/07/25/cache-usage-results.html) (also see his link to a similar blog post from a Chrome person).  
-  
-**More Responsive Tabs**  
-  
-Tim Taubert made our new tab animation more pleasant in bug [716108](https://bugzilla.mozilla.org/show_bug.cgi?id=716108). Tim also landed a fix to halve jank caused by thumbnail capture in bug [774811](https://bugzilla.mozilla.org/show_bug.cgi?id=774811), this should result in better tab-switching experience. Stay tuned for more developer attention in this area.  
-  
-**GC**  
-  
-Jon Coppeard enabled incremental sweeping: bug [729760](https://bugzilla.mozilla.org/show_bug.cgi?id=729760). This should result in slightly smaller GC pauses.  
-  
-  
-  
-  
-  
-
diff --git a/source/_posts/2012-08-06-snappy-aug-2.markdown b/source/_posts/2012-08-06-snappy-aug-2.markdown
deleted file mode 100644
index 0c4a9ec..0000000
--- a/source/_posts/2012-08-06-snappy-aug-2.markdown
+++ /dev/null
@@ -1,32 +0,0 @@
----
-comments: true
-date: 2012-08-06 16:27:10
-layout: post
-slug: snappy-aug-2
-title: Snappy, Aug 2
-wordpress_id: 761
-categories:
-- mozilla
-- snappy
----
-
-**Landed This Week**  
-  
-Neil Deakin joined the Snappy effort. He is working on eliminating pointless reflows in the tab strip. His fix for [bug 752486](https://bugzilla.mozilla.org/show_bug.cgi?id=752486) landed, [752376](https://bugzilla.mozilla.org/show_bug.cgi?id=752376), [752496](https://bugzilla.mozilla.org/show_bug.cgi?id=752496) are next.  
-  
-Brian Bondy landed removal of our prefetch-nuking code in bug [770911](https://bugzilla.mozilla.org/show_bug.cgi?id=770911). xul.dll preload is now always on based on our telemetry startup study in bug [765850](https://bugzilla.mozilla.org/show_bug.cgi?id=765850).  
-  
-Bill McCloskey landed the following improvements to reduce garbage collection pauses: 
-
-  * bug [777919 ](https://bugzilla.mozilla.org/show_bug.cgi?id=777919)- Free LifoAlloc chunks on background thread, instead of as part of the final IGC slice. This isn't a problem for most people, but for some people on OSX it can take anywhere from 50ms to 250ms or more.
-  * bug [ 778993 ](https://bugzilla.mozilla.org/show_bug.cgi?id=778993)- Separate runtime's gcMallocBytes from compartment's gcMallocBytes, so we trigger less non-incremental GCs with many tabs open
-  * bug [767209 ](https://bugzilla.mozilla.org/show_bug.cgi?id=767209)- Make GC slices longer when not painting to avoid non-incremental GCs.
-See Bill's comments in bug [767209](https://bugzilla.mozilla.org/show_bug.cgi?id=767209) for some insight into the complex heuristics that go into minimizing GC interruptions: [comment 1](https://bugzilla.mozilla.org/show_bug.cgi?id=767209#c3), [comment 2](https://bugzilla.mozilla.org/show_bug.cgi?id=767209#c8).  
-  
-**Coming Soon**  
-  
-In the coming week I expect to see some good optimizations land for page rendering, tab-switching behavior, more robust cache, etc.  
-  
-Some Snappy people will be attending [MozCamp.eu 2012](https://wiki.mozilla.org/MozCampEU2012) in Warsaw, Poland on September 8, 9. Expect to see lots of talk on profiling and other performance tools.  
-  
-I hope to have above 15-20 Performance/Snappy people in Warsaw for the following week. This is not yet finalized. At the moment we are looking to see if there is a coworking space or a company in Warsaw who could host us.
diff --git a/source/_posts/2012-08-14-snappy-for-aug-9.markdown b/source/_posts/2012-08-14-snappy-for-aug-9.markdown
deleted file mode 100644
index 94f196e..0000000
--- a/source/_posts/2012-08-14-snappy-for-aug-9.markdown
+++ /dev/null
@@ -1,15 +0,0 @@
----
-comments: true
-date: 2012-08-14 12:52:00
-layout: post
-slug: snappy-for-aug-9
-title: Snappy for Aug 9
-wordpress_id: 766
-categories:
-- mozilla
-- snappy
----
-
-Lawrence took excellent Snappy [meeting notes](https://wiki.mozilla.org/Performance/Snappy/2012-08-09) last week.  
-  
-
diff --git a/source/_posts/2012-08-15-dxr-is-back-at-dxr-mozilla-org.markdown b/source/_posts/2012-08-15-dxr-is-back-at-dxr-mozilla-org.markdown
deleted file mode 100644
index 2c94103..0000000
--- a/source/_posts/2012-08-15-dxr-is-back-at-dxr-mozilla-org.markdown
+++ /dev/null
@@ -1,14 +0,0 @@
----
-comments: true
-date: 2012-08-15 10:59:04
-layout: post
-slug: dxr-is-back-at-dxr-mozilla-org
-title: DXR is back at dxr.mozilla.org
-wordpress_id: 769
-categories:
-- mozilla
----
-
-For a while DXR lived on a [lanedo.com](http://dxr.lanedo.com/) server. Lanedo folks are now done with DXR development. DXR is once again deployed at dxr.mozilla.org. Our Perf intern, Jonas, is driving DXR development this summer. See his [progress report](http://jonasfj.dk/blog/2012/08/deploying-dxr-on-dxr-mozilla-org/). Be sure to subscribe to his blog. He may change how you use DXR as a result of his current work.  
-  
-_PS. Mozilla interns rule_
diff --git a/source/_posts/2012-08-16-snappy-36.markdown b/source/_posts/2012-08-16-snappy-36.markdown
deleted file mode 100644
index c182f3a..0000000
--- a/source/_posts/2012-08-16-snappy-36.markdown
+++ /dev/null
@@ -1,35 +0,0 @@
----
-comments: true
-date: 2012-08-16 14:24:19
-layout: post
-slug: snappy-36
-title: 'Snappy #36'
-wordpress_id: 772
-categories:
-- mozilla
-- snappy
----
-
-**Misc**  
-  
-I have been using dates to mark passage of time in the Snappy project. I think I'll switch to a simple counter instead. We are ~36 updates into this project.  
-  
-**Blogging**  
-  
-Ludovic Hirlimann [blogged](http://sietch-tabr.tumblr.com/post/29404692899/firefox-cache-and-spotlight) about how spotlight spends a lot of time indexing the Firefox network 'Cache' directory (known problem, bug [718910](https://bugzilla.mozilla.org/show_bug.cgi?id=718910)). If you experience this problem and would like to see it fixed, please comment in the bug if the [suggested remedy](https://bugzilla.mozilla.org/show_bug.cgi?id=718910#c13) helps.  
-  
-Tim Taubert [wrote](http://timtaubert.de/blog/2012/08/snappy-fixing-new-tab-page-performance-regressions/) about reducing new-tab jank. I mention Tim a lot in these updates. He takes on a lot of interesting bugs in Firefox frontend. Hopefully he'll make a habit out of blogging about his work.  
-  
-**Networking**  
-  
-Nick Hurley landed a change to reduce our maximum cache size to 350 megabytes. In order to avoid excessive disk IO traffic old cache size of 1 gigabyte remains in effect until the cache is reset. See bug [709297](https://bugzilla.mozilla.org/show_bug.cgi?id=709297) and Nick's [blog post](http://todesschaf.org/posts/2012/07/25/cache-usage-results.html) for more details. Progress is also being made on [bug 777328](https://bugzilla.mozilla.org/show_bug.cgi?id=777328) so we can move towards not blowing away our cache 10-20% of the time.  
-  
-Michal Novotny is proceeding with incrementally reducing cache-caused jank that's due to holding a lock on the main thread while doing IO on a background thread. He also removing a multitude of synchronous necko APIs, see [bug 695399](https://bugzilla.mozilla.org/show_bug.cgi?id=695399).  
-  
-Patrick McManus is removing synchronous proxy-related code, see [bug 766973](https://bugzilla.mozilla.org/show_bug.cgi?id=766973) for the DNS-related bit. Turns out our proxy code also does all kinds of synchronous operations when detecting proxy configuration, etc. This is being worked on, but hasn't been filed yet.  
-  
-I usually try to highlight work that has already landed, but in this case it is important to point out that the Necko team is working hard on addressing significant problems in the networking code. These problems are tricky and will take a while to fix. The team is relatively new and is still discovering hidden surprises in their codebase.  
-  
-**Profiler**  
-  
-Benoit Girard posted a [preview ](http://dl.dropbox.com/u/10523664/Screenshots/5p.png)of view-source in the profiler. This will be handy for figuring out where performance problems lay, especially in JS files that have been preprocessed (our JS preprocessor does not try to keep the line numbers sane).
diff --git a/source/_posts/2012-08-16-trilite-fast-string-matching-in-sqlite.markdown b/source/_posts/2012-08-16-trilite-fast-string-matching-in-sqlite.markdown
deleted file mode 100644
index 81886f4..0000000
--- a/source/_posts/2012-08-16-trilite-fast-string-matching-in-sqlite.markdown
+++ /dev/null
@@ -1,16 +0,0 @@
----
-comments: true
-date: 2012-08-16 16:51:20
-layout: post
-slug: trilite-fast-string-matching-in-sqlite
-title: TriLite, Fast String Matching in Sqlite
-wordpress_id: 776
-categories:
-- mozilla
----
-
-One of the limitations of the SQLite FTS is that it can't do regular expression or substring searches. Jonas is addressing this with [TriLite](http://jonasfj.dk/blog/2012/08/trilite-fast-string-matching-in-sqlite/). Be sure to subscribe to Jonas' blog for exciting DXR developments coming up within the final two weeks of his internship.  
-  
-  
-  
-Coming to our test [DXR instance](http://dxr.allizom.org/) soon...
diff --git a/source/_posts/2012-08-23-snappy-37.markdown b/source/_posts/2012-08-23-snappy-37.markdown
deleted file mode 100644
index 1355ed7..0000000
--- a/source/_posts/2012-08-23-snappy-37.markdown
+++ /dev/null
@@ -1,33 +0,0 @@
----
-comments: true
-date: 2012-08-23 16:10:49
-layout: post
-slug: snappy-37
-title: 'Snappy #37'
-wordpress_id: 780
-categories:
-- mozilla
-- snappy
----
-
-Highlights from [meeting note](https://wiki.mozilla.org/Performance/Snappy/2012-08-23#Incoming)s for today: 
-
-  * Tim Taubert worked on Firefox UI speedups
-  * Lots of improvements to the profiler from Benoit Girard
-  * More incremental GC work from Jon Coppeard
-  * Vladan Djeric got all of the security reviews and should be able to land Nicholas Chaim's fix for networked certificate validation:[ bug 726125](https://bugzilla.mozilla.org/show_bug.cgi?id=726125)
-We spent most of the meeting discussing bug [bug 784512](https://bugzilla.mozilla.org/show_bug.cgi?id=784512). According several data sources Firefox 15 Beta loads pages slower than 14. Occasionally problems squeeze past our performance testing + telemetry infrastructure, this looks like one of these times. Unfortunately, it's quite hard to reduce a few noisy signals to a concrete performance problem. If you can reproduce a performance regression to do with loading webpages/games/etc in FF15 vs FF14, please leave a comment.  
-  
-**Thanks!**  
-  
-Thanks for the great comments on my [previous ](http://taras.glek.net/blog/2012/08/16/snappy-36/)snappy updates. [Bug 783755](https://bugzilla.mozilla.org/show_bug.cgi?id=783755) should take care of the new cache size pref not sticking. [Bug 718910](https://bugzilla.mozilla.org/show_bug.cgi?id=718910) on hiding Cache directory from Spotlight is making progress too.  
-  
-Commenter, kumalos, reported a tab switching regression and posted a profile recorded with our [profiler ](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CCIQFjAA&url=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FPerformance%2FProfiling_with_the_Built-in_Profiler&ei=FLw2UKzMO4WXiQLSgoHwAQ&usg=AFQjCNEGPmI44wGwpjRbtR-WT36EdVv-ew)as evidence. This proved to be an example of bug [783748](https://bugzilla.mozilla.org/show_bug.cgi?id=783748), and lead us to identify a previously unknown issue in bug [784756](https://bugzilla.mozilla.org/show_bug.cgi?id=784756). Constructive feedback like this is one of the main reasons I blog.  
-  
-I highly encourage users interested in improving Firefox performance to use Nightly builds and report bugs with profiler traces attached.  
-  
-**Shutdown Times**  
-  
-I'll end with our latest Telemetry data point. This one took a while to get right, but we finally track our shutdown speed.  
-  
-[![](/assets/images/2012-08-23-snappy-37/shutdown-300x157.png)](http://taras.glek.net/blog/files/2012/08/shutdown.png)
diff --git a/source/_posts/2012-08-29-dxr-now-does-live-regexp-search-thanks-google-code.markdown b/source/_posts/2012-08-29-dxr-now-does-live-regexp-search-thanks-google-code.markdown
deleted file mode 100644
index db1bdee..0000000
--- a/source/_posts/2012-08-29-dxr-now-does-live-regexp-search-thanks-google-code.markdown
+++ /dev/null
@@ -1,22 +0,0 @@
----
-comments: true
-date: 2012-08-29 13:56:03
-layout: post
-slug: dxr-now-does-live-regexp-search-thanks-google-code
-title: DXR now does live regexp search, thanks Google Code
-wordpress_id: 783
-categories:
-- mozilla
----
-
-Google code was once the best code-search tool in the business. Then it got shut down, except for a few special instances like [chromium](http://code.google.com/p/chromium/source/search?q=Startup.BrowserMessageLoopStartTime&origq=Startup.BrowserMessageLoopStartTime&btnG=Search+Trunk).  
-  
-Our intern, Jonas Finnemann Jensen, took the re2 code that used to power google code search and integrated it into DXR (among other cleanups). See his blog [post ](http://jonasfj.dk/blog/2012/08/regular-expressions-on-dxr-allizom-org/)for more details.  
-  
-Regexps combined with the new instant search feature changed how I search Mozilla code. Instant search means that I'm constantly refining my search terms to narrow down my results to a minimum before I leave the search page. Digging through Mozilla code is pretty fun now. I believe our development instance* of [DXR](http://dxr.allizom.org/search?q=&tree=mozilla-central&redirect=true) is the most pleasant./efficient (even if a bit rough) code indexing solution atm. I no longer miss google code for searching Mozilla.  
-  
-Now that Mozilla can be searched in a pleasant way, something needs to fill the searching of masses of open source code usecase. Perhaps [github](https://github.com/) could plug the "google code"-sized gap in developer hearts?  
-  
-  
-  
-* we also need to stabilize the development version and move it to [dxr.mozilla.org](http://dxr.mozilla.org/).
diff --git a/source/_posts/2012-09-04-snappy-38.markdown b/source/_posts/2012-09-04-snappy-38.markdown
deleted file mode 100644
index 93f421b..0000000
--- a/source/_posts/2012-09-04-snappy-38.markdown
+++ /dev/null
@@ -1,35 +0,0 @@
----
-comments: true
-date: 2012-09-04 09:17:48
-layout: post
-slug: snappy-38
-title: 'Snappy #38: Responsiveness Fixes Galore'
-wordpress_id: 786
-categories:
-- mozilla
-- snappy
----
-
-End of summer is a tough time to make progress because a lot of people are on vacation. Surprisingly, Firefox got some good fixes in since the last update.  
-  
-**Less Slow Startups**  
-  
-[Bug 726125](https://bugzilla.mozilla.org/show_bug.cgi?id=726125): should get rid of a lot of super-slow startups. Due to an abstraction accident we ended up validating jars more eagerly than expected. Firefox would go on the net (on the main thread) to check the certificate every time a signed jar was opened. There are over 500 signed extensions on AMO with over 14million active users. See the following for background on the (now dead) feature that caused our jar code to go nuts: [signed scripts](http://www.mozilla.org/projects/security/components/signed-scripts.html) and [note on removal of signed script](https://developer.mozilla.org/en-US/docs/Bypassing_Security_Restrictions_and_Signing_Code) support. Thanks for Nicholas Chaim and Vladan Djeric for fixing this.  
-  
-**Less Proxy Lag (WIP)**  
-  
-[Bug 769764](https://bugzilla.mozilla.org/show_bug.cgi?id=769764#c5). We have received a lot of strange complaints about Firefox network performance that we could never reproduce. Turned out this was because none of us used proxies. Patrick McManus discovered a lot of synchronous proxy and DNS code in our network stack.  
-  
-Fix for this should also improve performance for people without proxies since proxy-autodetection code was also doing main thread IO. As a result all of us replacing sync APIs with async ones all of the existing proxy-related addons will have to be updated. Patrick is reaching out to addon authors to make sure addons are updated in time for the next release.  
-  
-**Less UI Repaint Lag**  
-  
-[Bug 786421](https://bugzilla.mozilla.org/show_bug.cgi?id=786421): Nightlies got unbearably slow for me recently. Turned out we ended continuously resizing + applying theme + redrawing invisible tooltips on every paint. Thanks for Timothy Nikkel for fixing this. This bug never affected anyone outside of the Nightly/Aurora testers, but it serves as yet another example of how the [Gecko Profiler](https://developer.mozilla.org/en-US/docs/Performance/Profiling_with_the_Built-in_Profiler) makes it easier than ever to diagnose weird performance problems. The single biggest contribution anyone can do at the moment is to provide instructions of how to reproduce lag with accompanying profiler traces.  
-  
-**Less Gradient Lag**  
-  
-[Bug 761393](https://bugzilla.mozilla.org/show_bug.cgi?id=761393): Paul Adenot implemented a gradient cache. This was landed as a Telemetry experiment so we can determine what the optimal cache retention strategy is. We'll be watching the relationship between GRADIENT_DURATION and GRADIENT_RETENTION_TIME in the coming weeks. Currently rendering gradients cause stalls in the GPU pipeline. In previous experiments we found out that most of the tab-switch rendering time in hardware-accelerated Firefox is spent rendering gradients :(. Gradients are hard to notice for casual users, but they are heavily used in our tab strip and on Google web properties.  
-  
-**MozCamp**  
-  
-I may not have a chance to post the next snappy update as I'll be hopping on the plane to Warsaw right after our meeting. If you are attending MozCamp come to our ['All About Performance' session](https://wiki.mozilla.org/index.php?title=MozCampEU2012/Schedule/Desktopandmobile/All-About-Performance). Our goal for the talk is to significantly expand the pool of people who can diagnose Firefox (and web) performance problems.
diff --git a/source/_posts/2012-09-18-moacamp-eu-in-warsaw.markdown b/source/_posts/2012-09-18-moacamp-eu-in-warsaw.markdown
deleted file mode 100644
index 0db6ef8..0000000
--- a/source/_posts/2012-09-18-moacamp-eu-in-warsaw.markdown
+++ /dev/null
@@ -1,17 +0,0 @@
----
-comments: true
-date: 2012-09-18 01:09:30
-layout: post
-slug: moacamp-eu-in-warsaw
-title: MozCamp.EU in Warsaw
-wordpress_id: 798
-categories:
-- mozilla
-- snappy
----
-
-Last week a few of us attended MozCamp.EU in Warsaw. Me, Benoit & Vlad presented a [talk ](https://wiki.mozilla.org/MozCampEU2012/Schedule/Desktopandmobile/All-About-Performance)on performance work. Primary aim of our talk was to inform our community about various performance tools that came to fruition of the past year and how to use them to investigate Firefox performance problems. Hopefully we'll see a spike in bug reports with detailed performance information (profiler traces, telemetry histogram+chromehang excepts, etc).  
-  
-My favourite part of MozCamp was finally meeting some a couple of the impressive community contributors in person. I finally had the pleasure of literally buying beer to thank someone for cleaning up some nasty code. I hope some day we can do a developer-oriented MozCamp-like conference.  
-  
-My favourite talk was Anant & Tim's presentation on WebRTC. There is something incredibly attractive about having an encrypted, cross-browser, firewall-punching p2p implementation (realtime open video conferencing is a nice bonus). See Anant's [blog post](http://kix.in/2012/09/16/mozcamp-eu-2012-mobilize-mozilla/) for more details.
diff --git a/source/_posts/2012-09-18-snappy-in-warsaw-pierogy-fueled-hackfest.markdown b/source/_posts/2012-09-18-snappy-in-warsaw-pierogy-fueled-hackfest.markdown
deleted file mode 100644
index d209616..0000000
--- a/source/_posts/2012-09-18-snappy-in-warsaw-pierogy-fueled-hackfest.markdown
+++ /dev/null
@@ -1,57 +0,0 @@
----
-comments: true
-date: 2012-09-18 03:06:15
-layout: post
-slug: snappy-in-warsaw-pierogy-fueled-hackfest
-title: 'Snappy in Warsaw: pierogy-fueled hackfest'
-wordpress_id: 799
-categories:
-- mozilla
-- snappy
----
-
-After MozCamp, we held a snappy meet-up at [NoaCowork](http://www.noacowork.pl/) in Warsaw. I believe this was one of the most productive weeks I had the pleasure of participating in since I started at Mozilla. My only regret I was not motivated to organize any memorable after-work activities while suffering the MozCamp.EU plague (Mozilla gatherings are great for exchanging global influenza strains).  
-  
-**Profiler**  
-  
-Benoit Girard went through existing and upcoming profiler features. We made sure that everyone in attendance knew how to use the profiler. We also discussed potential UX improvements. Markus Stange is a community contributor who originally designed and implemented the current profiler UI. He attended MozCamp and spent most of Monday with us planning future profiler improvements with Benoit.  
-  
-**Bas-tool: Azure Drawing Tracer**  
-  
-Bas Schouten presented his work-in-progress graphics tracing tool. Our graphics people have been using the Microsoft [PIX tool](http://www.google.com.ua/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CCEQFjAA&url=http%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPIX_(Microsoft)&ei=D0FYUM2yK4zasgat6IHoCQ&usg=AFQjCNFaEbWMtMB_UAvO0oOb0drynfX-qw) to debug accelerated drawing issues with Direct2D. I believe Bas got fed up with the buggyness and limitations of an otherwise excellent tool and wrote a similar Azure-specific tool with some special Bas-sauce.  
-  
-Bas-tool presents a graphics trace so one can see how Firefox draws on the screen. Seeing how something is drawn step-by-step helps us see when we not using efficient graphics primitives, are doing redundant invalidations, etc. The tool can also do tricks like bruteforce graphics operations to find redundant ones, etc.  
-  
-I expect Bas will present this tool + accompanying patches soon.  
-  
-**OMTC & Tab Strip**  
-  
-Current Firefox tab-strip implementation is crufty. It uses expensive graphics primitives, inefficient CSS transitions, implements scrolling/overflow animations in JS and does other non-performant things (tracked by [bug 593680](https://bugzilla.mozilla.org/show_bug.cgi?id=593680)). These things happen when one keeps adding features without having good profiling/tracing tools.  
-  
-Tim Taubert lead the effort to prototype a new tab strip that is implemented without JS animations and uses OMTC-friendly, efficient graphics primitives. Bas-tool was used heavily to see whether CSS transitions were animating efficiently. We sorely missed having a layout person around help diagnose layerizing issues, etc. Turns out CSS transition scheduling is very [jank-sensitive](https://bugzilla.mozilla.org/show_bug.cgi?id=753139#c10). We may also need come up + implement some new CSS transition to make an attractive tab strip. Good news is that any backend improvements we make in this area should make it easier to implement fluid, responsive web apps.  
-  
-Tim Taubert, Benoit Girard & Jared Wein cobbled together a desktop OMTC throbber demo where the tab throbber was implemented using CSS rotations which made it animate smoothly through content jank.  
-  
-**Chromehangs**  
-  
-Me, Josh Aas, Vladan Djeric, Lawrence Mandel went through our new non-destructive chromehang report. Chromehangs are multi-second browser stalls that we report via telemetry. See the complete list that we went through [here](https://etherpad.mozilla.org/chromehangs).  
-  
-Looks our recently-discovered synchronous proxy code and flash are to blame for most of our temporary hangs. Proxy stuff should disappear once bug [769764](https://bugzilla.mozilla.org/show_bug.cgi?id=769764) is fixed. [Click-to-play](http://www.google.com.ua/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CCQQFjAA&url=http%3A%2F%2Fmsujaws.wordpress.com%2F2012%2F04%2F11%2Fopting-in-to-plugins-in-firefox%2F&ei=DUhYUKGvA4eTswbZ94DYCw&usg=AFQjCNGkVdVAsE90oEm9Ycou1OrBheMdIg) will help with some of the plugin-caused hangs. We will be discussing how to deal with the rest of the plugin-jank in the coming weeks.  
-  
-My favourite chromehang was the one that pinpointed why downloads jank Firefox so much: bug [789932](https://bugzilla.mozilla.org/show_bug.cgi?id=789932). We tried to pin this on anti-virus scans, download manager sqlite activity, but the main reason turned out to be very simple. Turns out we do network traffic on a networking thread only to write out file contents to disk on main thread.  
-  
-**Other **  
-  
-Paulo Amadini, Lawrence Mandel, Gavin Sharp and me made plans to get rid of main thread SQL usage in download, addon manager.  
-  
-Vladan Djeric explained his plans to speed up & reduce jank caused by DOM Local Storage.  
-  
-Margaret Leibovic worked on removing synchronous cache API usage, added pageload telemetry. She also filed a bug that resulted in 20% faster link navigation in Fennec (bug [789889](https://bugzilla.mozilla.org/show_bug.cgi?id=789889)). Perhaps we should do the same on our Metro build?  
-  
-Olli Pettay & Felipe Gomes worked on making our social api features not leak memory.  
-  
-Julian Seward, Mike Hommey, Benoit Girard worked on improving our profiling infrastructure and making it work on Android, B2G, Linux.  
-  
-Josh Aas, Lawrence & me coordinated on Snappy priorities on necko team.  
-  
-I'm sure I missed a few projects, I hope other attendees blog about their work last week.
diff --git a/source/_posts/2012-10-04-snappy-39.markdown b/source/_posts/2012-10-04-snappy-39.markdown
deleted file mode 100644
index 4551e06..0000000
--- a/source/_posts/2012-10-04-snappy-39.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-comments: true
-date: 2012-10-04 16:24:57
-layout: post
-slug: snappy-39
-title: 'Snappy #39 '
-wordpress_id: 809
-categories:
-- mozilla
-- snappy
----
-
-We should no longer do proxy-related IO on the main thread now that Patrick McManus landed [bug 769764](https://bugzilla.mozilla.org/show_bug.cgi?id=769764). Synchronous proxy code resulted in a miserable user experience for people using proxies, but it also affected normal users during proxy-detection. This was one of the top intermittent freezes that we've seen.  
-  
-Tab switching should be much faster in Firefox 18 than before. Jared Wein got rid of an expensive regexp that was applied during a tab switch in [bug 781588](https://bugzilla.mozilla.org/show_bug.cgi?id=781588).  Jeff Muizelaar landed [bug 792199](https://bugzilla.mozilla.org/show_bug.cgi?id=792199) which should make switching to a image-heavy sites much faster. Jared's change is already on nightlies, Jeff's change should show up tomorrow if everything goes well.  
-  
-Matt Woodrow landed the huge change that is DLBI in [bug 539356](https://bugzilla.mozilla.org/show_bug.cgi?id=539356) (yet again). DLBI speeds up reflows, reduces repaints resulting in a more responsive browser. For more details see Robert O'Callahan's [announcement](https://groups.google.com/forum/#!topic/mozilla.dev.platform/UFndiSxW4rU).  
-  
-**Startup Regression **  
-  
-After working on improving startup for the last couple of releases we seem to have regressed it during the 18 cycle. I filed [bug 798130](https://bugzilla.mozilla.org/show_bug.cgi?id=798130) on this. I just noticed the regression a few hours ago. If anyone has ideas on what might've caused it, please comment.  
-  
-**Profiler**  
-  
-[Gecko profiler](https://addons.mozilla.org/en-us/firefox/addon/gecko-profiler/) now lives on AMO.
diff --git a/source/_posts/2012-10-18-snappy-41.markdown b/source/_posts/2012-10-18-snappy-41.markdown
deleted file mode 100644
index f191895..0000000
--- a/source/_posts/2012-10-18-snappy-41.markdown
+++ /dev/null
@@ -1,17 +0,0 @@
----
-comments: true
-date: 2012-10-18 15:53:19
-layout: post
-slug: snappy-41
-title: 'Snappy #41'
-wordpress_id: 819
-categories:
-- mozilla
-- snappy
----
-
-Jeff Muizelaar may not have cut tab switch times in half in my [last update](http://taras.glek.net/blog/2012/10/15/snappy-40-faster-tabswitching-startup-analysis/). The overhead moved to a later part of the process that we were not measuring before the change landed. We'll be able to tell the magnitude of the tab-switch improvement was by landing bug [800031](https://bugzilla.mozilla.org/show_bug.cgi?id=800031) on Aurora.  
-  
-Matt Woodrow reduced tab-close animation jank in [bug 750417](https://bugzilla.mozilla.org/show_bug.cgi?id=750417).  
-  
-
diff --git a/source/_posts/2012-10-26-snappy-42.markdown b/source/_posts/2012-10-26-snappy-42.markdown
deleted file mode 100644
index 68a9dd0..0000000
--- a/source/_posts/2012-10-26-snappy-42.markdown
+++ /dev/null
@@ -1,33 +0,0 @@
----
-comments: true
-date: 2012-10-26 15:01:40
-layout: post
-slug: snappy-42
-title: 'Snappy #42'
-wordpress_id: 823
-categories:
-- mozilla
-- snappy
----
-
-Vladan Djeric landed a probe to directly measure various DOM Local Storage overheads, bug [802920](https://bugzilla.mozilla.org/show_bug.cgi?id=802920), [telemetry data](http://is.gd/BYJQkE).  
-  
-**Frontend Speedups**  
-  
-I thought our frontend optimization people did not have spare cycles for snappy UI fixes due to other important projects atm, but they proved me wrong this week.  
-  
-Jared Wein landed bug [804968](https://bugzilla.mozilla.org/show_bug.cgi?id=804968) which fixes jank where our awesomebar popup would appear then disappear while typing in the location bar. We were flushing layout for the top and bottom result on each adjustment to the awesomebar results, those flushes weren't necessary for each time, they are now skipped after the first pass in the browser session. 
-
-Dão Gottwald landed [bug 752376](https://bugzilla.mozilla.org/show_bug.cgi?id=752376) which removes some expensive layout flushes when switching tabs if the user isn't overflowing their tabbar.
-
-Dão also landed bug[ 715402](https://bugzilla.mozilla.org/show_bug.cgi?id=715402) which corrects certain initialization code to run after the Firefox is drawn. Previously this code would get delayed, but due to some undeterministic event madness it would still be likely to get scheduled to run before Firefox is drawn on the screen. This should result in 10% faster perceived startups in some cases.
-
-**Profiler-assisted Bug Reporting**  
-  
-I looked at bug[ 642257](https://bugzilla.mozilla.org/show_bug.cgi?id=642257) and gave up figuring out what causes the problem because I could not reproduce it. I asked the reporter to try to record a profile of the problem with the [gecko profiler](https://developer.mozilla.org/en-US/docs/Performance/Profiling_with_the_Built-in_Profiler). Within 2.5 hours of the profile being posted in the bug, Timothy Nikkel identified the problem and posted a patch for it.  
-  
-I'm very excited about this because the reporter has never used a profiler and yet on the first try helped fix a hard to reproduce bug. Thanks to a dedicated bug reporter, keen layout hackers and our new profiling infrastructure Flash in background tabs will no longer slow down our layout calculations. For many types of bugs identifying the problem is the hardest part, this is very promising.  
-  
-**Moving Blogs Soon**  
-  
-I will be moving to a new blog location as soon as I decide on a better blog setup. I've been irritated by Wordpress since I started at Mozilla in 2006. The volume of comment spam has increased exponentially this year. After 6 years of suffering a terrible UI, spam, slowness, lossyness, I'm ready to move on to a blogging service elsewhere. If you have any suggestions for blog providers, ping me on [twitter](https://twitter.com/tarasglek) as I likely wont see your comment in the mountain of spam.
diff --git a/source/_posts/2012-11-16-snappy-44-fixing-tab-switching-in-vancouver.markdown b/source/_posts/2012-11-16-snappy-44-fixing-tab-switching-in-vancouver.markdown
deleted file mode 100644
index c9fef56..0000000
--- a/source/_posts/2012-11-16-snappy-44-fixing-tab-switching-in-vancouver.markdown
+++ /dev/null
@@ -1,23 +0,0 @@
----
-comments: true
-date: 2012-11-16 18:06:41
-layout: post
-slug: snappy-44-fixing-tab-switching-in-vancouver
-title: 'Snappy #44: Fixing tab switching in Vancouver'
-wordpress_id: 837
-categories:
-- mozilla
-- snappy
----
-
-I joined our GFX+Layout teams for a workweek in Vancouver. Since profiling is most effective on slow machines, I brought along my trusty Acer  Aspire 722(slow 1.3ghz  CPU+ fast GPU) as my primary laptop. This hardware is great because the combination of a weak CPU + decent GPU means that if we accelerate things right the browser can perform quite well and if we don't, things get really slow. (analogous situation exists when fast CPUs are matched with slow GPUs).  
-  
-In the beginning of the week I quickly demoed menu lag, slow gmail tab switching([811472](https://bugzilla.mozilla.org/show_bug.cgi?id=811472)). Later in the week we looked at problematic Facebook tab switch times ([811474](https://bugzilla.mozilla.org/show_bug.cgi?id=811474)), Australis(see Matt's [post](http://matthew.noorenberghe.com/blog/2012/11/australis-tabs-where-are-you)) performance. By the end of the week tab switching improved by over 2x for both facebook and gmail. I don't have exact figures because while we can measure general tab switch trends via telemetry, there isn't a convenient way to do it on individual browsers yet. _Help wanted:_ would be great if someone could do up a barebone addon to monitor tab switching in bug [812381](https://bugzilla.mozilla.org/show_bug.cgi?id=812381), we'll fill in the rest.  
-  
-Jeff Muizelaar started out by speeding up checkbox drawing in bug [809603](https://bugzilla.mozilla.org/show_bug.cgi?id=809603)**.** Matt Woodrow sped up gmail by tweaking how we use layers in bugs [811927](https://bugzilla.mozilla.org/show_bug.cgi?id=811927),  [811570](https://bugzilla.mozilla.org/show_bug.cgi?id=811570).  
-  
-Matt made sure that we no longer draw layers with opacity of 0 in bug [811831](https://bugzilla.mozilla.org/show_bug.cgi?id=811831). Turns rendering lots of invisible text can be expensive.  
-  
-Workweeks are a more about communication than getting code landed, so it is impressive that Jeff, Matt and their reviewers managed to diagnose, fix, review, land such significant optimizations in a couple of days. My laptop of pain feels much faster already.  
-  
-In the coming weeks expect to see smoother tab switching, smoother animations, lower profiling overhead as we work through issues discussed during the workweek.
diff --git a/source/_posts/2012-11-26-coping-with-flash-hangs.markdown b/source/_posts/2012-11-26-coping-with-flash-hangs.markdown
deleted file mode 100644
index 4ed11a4..0000000
--- a/source/_posts/2012-11-26-coping-with-flash-hangs.markdown
+++ /dev/null
@@ -1,13 +0,0 @@
----
-comments: true
-date: 2012-11-26 09:45:11
-layout: post
-slug: coping-with-flash-hangs
-title: Coping with Flash hangs
-wordpress_id: 842
-categories:
-- mozilla
-- snappy
----
-
-Blocking calls into the Flash plugin can temporarily hang Firefox. This is a problem because sometimes the user would be happy to kill the plugin to access their webpage and at other times it's the only way to get certain flash apps/games to load. If you suffer from flash-related hangs see Aaron's [blog post](http://dblohm7.ca/blog/2012/11/22/plugin-hang-user-interface-for-firefox/) for some builds to try. He is working a new [feature ](https://wiki.mozilla.org/Features/Firefox/Windows_Plugin_Hang_UI)to provide an option to kill hanging flash instances.
diff --git a/source/_posts/2012-12-17-hello-octopress.markdown b/source/_posts/2012-12-17-hello-octopress.markdown
deleted file mode 100644
index 2992633..0000000
--- a/source/_posts/2012-12-17-hello-octopress.markdown
+++ /dev/null
@@ -1,20 +0,0 @@
----
-layout: post
-title: "Hello Octopress"
-date: 2012-12-17 17:10
-comments: true
-categories: personal
----
-I'm off work until January. I took this opportunity to partake in chores such as fixing a toilet and switching away from wordpress.
-
-After suffering wordpress for half a decade I finally switched to a combination of Octopress + Disqus. 
-
-It took:
-
-* a few hours of tweaking the combination of [exitwp.py](https://github.com/thomasf/exitwp), html2text.py to convert my blog without busting links, images
-* a few hours of decyphering octopress/github documentation to setup a website
-* an hour to figure out where images should live (in *source/assets*)
-
-Thanks to everyone that suggested [Octopress](http://octopress.org/).
-
-Goodbye word-style wordpress bitchwork.
diff --git a/source/_posts/2012-12-21-interesting-bugzilla-activity.markdown b/source/_posts/2012-12-21-interesting-bugzilla-activity.markdown
deleted file mode 100644
index 6c9f25e..0000000
--- a/source/_posts/2012-12-21-interesting-bugzilla-activity.markdown
+++ /dev/null
@@ -1,20 +0,0 @@
----
-layout: post
-title: "Snappy #45: The view from home"
-date: 2012-12-21 12:09
-comments: true
-categories: 
-- mozilla
-- snappy
-published: true
----
-I'm out until January. However, I setup a [new blog](/blog/2012/12/17/hello-octopress/), so why not test it with a snappy update. 
-
-Benoit Girard sped up shutdown with:
-
-* not forcing startup cache flushes on shutdown: {%bug 816656%}. This speeds up exiting browser soon after startup.
-* {%bug 818296 summary%}. This may significantly reduce our shutdown times. We are waiting on more telemetry data to confirm.
-
-Aaron Klotz made startup slightly faster by speeding up reading of some urlclassifier files in {%bug 810101%}.
-
-Vladimir Vukicevic landed {%bug 731974%} which results in smoother browser animations and significantly improves the quality of tab-strip animations.
