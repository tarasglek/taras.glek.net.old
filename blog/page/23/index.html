
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>All About Performance</title>
  <meta name="author" content="Taras Glek">

  
  <meta name="description" content="It is always frustrating to see a compiler complain about something trivial. It is especially annoying since most of the trivial complaints are &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://taras.glek.net/blog/page/23/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="All About Performance" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">All RSS</a></li>
  
  <li><a href="/blog/categories/mozilla/atom.xml" rel="subscribe-rss" title="subscribe via RSS">Mozilla RSS</a></li>
</ul>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <header role="banner"><hgroup>
  <h1><a href="/">All About Performance</a></h1>
  
    <h2>and other stuff by Taras Glek</h2>
  
</hgroup>

</header>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/07/27/superity-complex-static-analysis/">Superity Complex & Static Analysis</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-07-27T07:57:23-07:00" pubdate data-updated="true">Jul 27<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>It is always frustrating to see a compiler complain about something trivial. It is especially annoying since most of the trivial complaints are trivial to fix automatically (eg. superfluous semicolon).</p>

<p>I think this is a bigger problem in the static analysis industry. Vendors/researchers ship their tools with a superiority complex built-in. Most of the error messages produced by error checking tools can be paraphrased as &#8220;Gee look, I found some trivial to fix bugs in your code, but I ain&#8217;t gonna do nothing about them! Neeener! Go worker-human!&#8221;</p>

<p>My policy is to make my tools more polite than that. Starting from prcheck, all of my tools will point out simple errors by suggesting patches (when possible). It is impossible to produce a correct patch every time, but I am not worried about that since developers are quite good at disregarding stupid suggestions.</p>

<p><strong>Automatic Whining</strong></p>

<p>Now I have a few extra scripts that lay the foundation for regular code inspection via static analysis. PRBool checks are my first step. Here is a sample email:
&#8220;`</p>

<p>&#8220;`</p>

<pre><code>Subject: Prbool violation in nsPlainTextSerializer.cpp

vidur@netscape.com introduced a new PRBool problem in revision 1.1 of nsPlainTextSerializer.cpp.

Commit message: branches:  1.1.2;  

Error: /content/base/src/nsPlainTextSerializer.cpp: 614:

-          PRInt32 semiOffset = style.Find("ch", widthOffset+6);
+          PRInt32 semiOffset = style.Find("ch", 0 != (widthOffset+6));
</code></pre>

<p><a href="http://bonsai.mozilla.org/cvsblame.cgi?file=mozilla/content/base/src/nsPlainTextSerializer.cpp&amp;rev=&amp;cvsroot=/cvsroot#614">http://bonsai.mozilla.org/cvsblame.cgi?file=mozilla/content/base/src/nsPlainTextSerializer.cpp&amp;rev=&amp;cvsroot=/cvsroot#614</a></p>

<p>This an example of an incorrect suggestion. The actual problem is due to the incorrect method overload being chosen.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/07/18/cpp-aware-c-rewriting-can-be-fun/">CPP-Aware C++ Rewriting Can Be Fun</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-07-18T07:29:16-07:00" pubdate data-updated="true">Jul 18<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Recently MCPP started working well enough to process all of Mozilla with the special macro-expansion undoing markup. Below is the most exciting patch line I have produced so far. A few months ago, I didn&#8217;t think was possible to rewrite macro parameters with elsa.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>-    ENCODE_SIMPLE_ARRAY(PRBool, Bool, (PRUint16) values[i]);
</span><span class='line'>+    ENCODE_SIMPLE_ARRAY(PRBool, Bool, 0 != ((PRUint16) values[i]));
</span></code></pre></td></tr></table></div></figure>


<p>To produce this:</p>

<ol>
<li>Elsa consumed the expanded .ii file</li>
<li>Boolean checker found the problematic subexpression</li>
<li>Original source position was calculated from the expansion log</li>
<li>Then prcheck figured out that only the macro parameter needs to be rewritten.</li>
<li>Original source was read in and enclosed within 0 != ()
<strong>Integrating Static Checks - PRBool check </strong></li>
</ol>


<p><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=266048">This bug</a> contains the rest of the rewriting results. Prcheck checks every assignment to a prbool and outputs a patch if the expression may evaluate to anything other than 0/1. A message is produced if a patch can not be generated because the expression is within a macro.</p>

<p>The goal is to have prcheck run on every commit(or every day) and send out an email or another form of a complaint when a new prbool violation is introduced. Since the current prbool misuses aren&#8217;t going to be fixed overnight, there should be a db kept somewhere with the old misuses to prevent the new ones from being introduced and old ones from being annoying. I&#8217;m thinking of associating misuse counts with a filename, so when the number goes up an error gets mailed out. Anyone get a better idea?</p>

<p><strong>Latest Recipe to Running Oink Tools </strong></p>

<ol>
<li>If you want to rewrite sources either wait for the next mcpp release or use my <a href="http://people.mozilla.org/~tglek/mcpp-post2.6.4.tar.gz">tarball</a>.</li>
<li>Install gcc 3.4.x. If using mcpp, configure mcpp with &#8211;enable-replace-system so it replaces the gcc preprocessor</li>
<li><a href="http://taras.glek.net/blog/2007/07/13/dehydra-prcheck-squash-in-mercurial/">Checkout</a> and build my oink version.</li>
<li>Build mozilla with -save-temps gcc option. If using mcpp set environment variables CC=&#8221;gcc -Wp,-K -Wp,-W0 -save-temps &#8221; and CXX=&#8221;g++ -Wp,-K -Wp,-W0 -save-temps &#8221; and do make -f client.mk build as usual. The extra gcc parameters tell it to save intermediate files to pass -K and -W0 to enable macro expansion annotation and silence warnings.</li>
<li>Run tools individual files</li>
<li>Produce a global patch with ./pork-barrel 4 /path/to/prcheck /tmp/input.txt where input.txt is a list of absolute filenames of all of the .i and .ii files produced by the build process</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/07/13/pondering-prepost-conditions-to-enforce-software-correctness/">Pondering Pre/Post Conditions to Enforce Software Correctness</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-07-13T02:12:55-07:00" pubdate data-updated="true">Jul 13<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>That other software company has a some brilliant people working on verifying their source code. Their approach is hardcore and seems quite good. Their recipe to robust C# (applying this to C is research-in-progress, C++ isn&#8217;t yet considered) code is:</p>

<ul>
<li>sprinkle pre/post-conditions for functions. Reduce annotation labour by additional rule inference</li>
<li>dataflow analysis to verify type-system stuff like not-null annotations</li>
<li>Abstract interpretation + model checker to enforce pre/post-conditions</li>
<li><a href="http://research.microsoft.com/research/pubs/view.aspx?type=Technical%20Report&amp;id=923">BoogiePL</a> intermediate language. Anything can be accomplished by an awesomely named intermediate language!
Resulting code runs fast has a lot fewer bugs than code without all this fancy machinery. Unfortunately, the benefits can only be reaped if a whole program gets annotated. Otherwise, the model checker gets frustrated. Essentially the language being checked is turned into another much safer (more boogie!) language. I&#8217;m looking forward to the day (that will never come) when all new C code is written this way.</li>
</ul>


<p>If adding these to source code makes you rewrite the whole program, wouldn&#8217;t it be easier to invent another low-level language that comes with safety by default?</p>

<p>I am guessing that the dehydra method of checking for a relatively small number of application specific bugs is the most practical approach available and it will get us 60% towards Boogieing. Now that elsa has support for preprocessor macros it should be possible to specify non-formal pre/post-conditions to check for common errors. It&#8217;s merely a complicated question of defining what should be checked for.</p>

<p>I don&#8217;t have the motivation to write/buy/adopt/integrate a formal tool like a model checker, but it seems that it&#8217;s possible to write application specific checks in JavaScript that can run circles around what most model checkers can do.</p>

<p>That other company isn&#8217;t the only vendor working on this stuff. There <a href="http://www.cs.princeton.edu/~appel/cminor/">brilliant people</a> taking a somewhat different (and open source) approach.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/07/13/dehydra-prcheck-squash-in-mercurial/">Dehydra, Prcheck, Squash - in Mercurial</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-07-13T01:54:08-07:00" pubdate data-updated="true">Jul 13<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>New Repository</strong></p>

<p>Since I do not yet have write access to oink svn, I have been doing all of my development in ad-hoc repositories within the svn checkout. This made it rather hard to collaborate with others. I finally got sick of the situation (and stumbled upon <a href="http://cheeseshop.python.org/pypi/hgsvn/">hgsvn</a>) and converted all 11 svn repositories to mercurial. To my surprise, mercurial even let me merge my repositories while preserving history (hg has yet to fail me!).</p>

<p>oink uses svn-externals to aggregate the repositories into a single checkout. hg doesn&#8217;t have anything similar, so to checkout all 11 repositories use a script:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[checkout.sh](http://people.mozilla.org/~tglek/checkout.sh) http://hg.mozilla.org
</span></code></pre></td></tr></table></div></figure>


<p><strong>Released Differences from Oink Mainline </strong></p>

<ul>
<li>New oink tool - <a href="http://taras.glek.net/blog/2007/06/26/status-report-recent-work/">prcheck</a>: ensures that bool-like integer typedefs behave like bools</li>
<li>New oink tool - <a href="http://wiki.mozilla.org/DeHydra">dehydra</a>: source query tool with queries specified in JavaScript</li>
<li>New oink tool - <a href="http://wiki.mozilla.org/Squash">squash</a>: source refactoring tool. This is now deprecated since most of the code in it dealt with working around elsa limitations to do with macro expansion &amp; lack of precise locations. The patching engine used in squash lives on to provide a simple refactoring API for use in other tools (like prcheck).</li>
<li>Minor grammar changes to parse more of Mozilla</li>
<li>Compilation fixes for OSX</li>
<li>Elsa fixes to parse OSX headers</li>
<li>make -j support for elsa</li>
<li>end-of-ast-node location support for elkhound &amp; elsa</li>
<li><p>preprocessor expansion markup support for elsa
<strong>Coming Soon</strong></p></li>
<li><p>Amazing new version of <a href="http://mcpp.sourceforge.net/">MCPP</a> capable of preprocessing mozilla while outputting refactoring-friendly annotations.</p></li>
<li>Web front-end for squash which will likely be refactored to be tool-agnostic.</li>
<li><p>Front-end to run patch-producing tools in parallel for multi-core machines
<strong>Near Future</strong></p></li>
<li><p>squash will be split up into a library with each major feature ripped out into a standalone tool. Two tools coming soon:outparam rewriter &amp; class member renamer.</p></li>
<li><p>RAD for static analysis: oink tool templates to make it trivial to write custom new tools with minimal amount of boilerplate
<strong>Some time in the Future</strong></p></li>
<li><p>Collaboration with the author of <a href="http://www.cs.ru.nl/~tews/olmar/">Olmar</a> to provide an OCaml API for Elsa. If everything goes as expected it will be possible to write analyses that are more powerful and more concise than DeHydra ones except they will perform at C/C++ speeds. Plus it should be possible to perform them from a native interactive OCaml toplevel. Most of this work already exists in bits and pieces. It&#8217;s a matter of adding some AST transformations, fixing a few issues and tying it all together.</p></li>
<li>MapReduce inspired front-end: generic framework for executing transformations/analyses in-parallel and Mozilla-wide without blowing the 32bit address space (as it typical when static analysis tools meet Mozilla).</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/06/26/status-report-recent-work/">Status Report: Recent Work</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-06-26T04:08:52-07:00" pubdate data-updated="true">Jun 26<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>New Tool: Prcheck - PRBool&#8217;s best friend </strong></p>

<p>Mozilla has a number boolean types and most of them are a form of an int. People expect them to behave like a bool, but since they can be assigned more than 1 value for true, this assumption can lead to bugs. Prcheck will mandate that prbools can only be assigned 1 or 0. Typically static checkers output errors, but prcheck outputs errors &amp; fixes for them in diff format so they can be fixed automatically. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=266048">this bug</a> for more info. I think the tool is almost complete. Hopefully, once the MCPP issues described below are addressed, I&#8217;ll have one giant patch to eliminate this problem.</p>

<p><strong>MCPP Teething Troubles</strong></p>

<p>Even in the open-source world there are some problems with vendor monoculture. For example we a single vendor providing the C++ compiler and one C preprocessor that is widely used. Even though MCPP is a portable preprocessor that can plug into multiple compilers, it still chokes on some GCCisms. Things are slowly changing and new open source compilers are on the horizon: I can&#8217;t wait.</p>

<p>Additionally, since Mozilla is one of the largest projects to be preprocessed with MCPP, we found some scalability bugs in MCPP. The MCPP maintainer addressed those.</p>

<p><strong>Elsa Backend Source Location Work - Works Well?</strong></p>

<p>I am amazed, but hack &amp; slash approach to adding end-of-ast-node info to elkhound still seems to work correctly! It mostly required consulting wikipedia on LR &amp; GLR parsing algorithms to understand how to modify the data structures used in elkhound. I love the combination of Wikipedia and pretty &amp; easy to modify source code.</p>

<p>The preprocessor undo-log appears to function exactly as intended too. That combined with the end-of-ast-node info means that I finally have the ability to easily cut&#8217;n&#8217;paste code to move it around programmatically. It basically makes the C/C++ pretty printer in oink obsolete for my purposes. This is cool because now I can output prettier source code AND rely on less oink C++ code to do so (ie no need to call the pretty printer[s]), so more refactoring tools could be written in higher level languages such as OCaml or JavaScript in the future.</p>

<p><strong>Publishing My Oink Mods</strong></p>

<p>I have been sending people tarballs on request, due to not being able to integrate my changes into the upstream svn repository. I tried a few svn2hg tools, but they didn&#8217;t work very well. <a href="http://cheeseshop.python.org/pypi/hgsvn/">hgsvn</a> is good enough to work for OpenJDK, so it might work for me. I&#8217;ll try to publish an hg repository of my work within the next week or two.</p>

<p>I&#8217;m sorry for not doing this earlier, but it&#8217;s extremely time consuming to switch gears from coding oink stuff to trying to package it, especially due to all of the politics involved. Hopefully once the repository is easier to work with I&#8217;ll have more people sharing the oink worldload with me. Now that dust settled and the major missing pieces are either implemented or decided upon, a lot of exciting possibilities opened up.</p>

<p><strong>libgcc</strong></p>

<p>Another day, another piece of preprocessor trivia. Turned out there was an alternative to MCPP that I could have used: gcc&#8217;s libcpp. It is common knowledge that gcc uses an integrated preprocessor. It is not so well known that the preprocessor is factored out into what appears to be a mostly standalone library inside of gcc called libgcc. Google barely knows about it and there are no docs or other webpages pointing to it, so i missed it in my search.</p>

<p>This could be a useful project, take libcpp turn it back into a standalone preprocessor and add the cpp undo log comments to it. The only downside of libgcc is that it is GPL which would normally be a pain for BSD-licensed projects, but by turning it back into a standalone tool there is no linking to to worry about.</p>

<p>So if anyone finds implementing the macro-undo log with libgcc interesting, please feel free to do so :)</p>

<p><strong>Random Rant on Parallels vs VMWare Fusion vs BootCamp vs 64bit Linux</strong></p>

<p>I installed 64bit ubuntu on my MBP. Compilers &amp; other tools are ridiculously fast when running linux natively on core2duo. Due to some performance bugs that I can&#8217;t track down (shark isn&#8217;t working for and recently OSX&#8217;s gdb stopped working too) oink runs much faster on the linux side of the MBP. If any mac people want to profile oink on OSX, that&#8217;d be awesome. However OSX has some nice things (such as a display driver that works well and good battery life). I wish ati wasn&#8217;t such a pain with releasing specs for their cards so linux could support them properly. I hope the recent reverse engineered driver work stabilizes soon. So I figured it would be nice to access &amp; work on the linux partition from within OSX.</p>

<p>I was pretty excited when I heard that Parallels 3 supports BootCamp. Problem was that nothing could see the bootcamp linux install. Turned the problem was caused because I used fdisk + refit to do the partitioning and turned on the bootable flag. To fix this I turned off the bootable flag on the linux partition using parted(which can sync the gpt partition table!) .</p>

<p>Then I realized that Parallels has very slow disk access AND doesn&#8217;t do 64bit and doesn&#8217;t appear to support SMP.</p>

<p>VMWare Fusion on the other hand supports bootcamp &amp; 64bit &amp; smp and appears to have much faster IO. However it lacks UI for accessing a linux bootcamp install or documentation. So here is the secret recipe to save time for others in my situation:</p>

<p>1) Create a vmware disk for the bootcamp partition using vmware-rawdiskCreator in /Library/Application Support/VMware Fusion.</p>

<p>2) Create a new machine, point at the file created in 1.</p>

<p>Fusion&#8217;s performance is remarkable. Oink runs almost as fast as it does natively. Plus VMWare support the VMI interface in Linux which combined with a tickless kernel should make the virtualizing overhead minimal. Too bad Linux doesn&#8217;t have these features yet for amd64.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/06/19/it-works/">It Works!</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-06-19T05:51:23-07:00" pubdate data-updated="true">Jun 19<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>Back to Real Life</strong></p>

<p>Just over a month ago I ran into <a href="http://taras.glek.net/blog/2007/05/11/cpp-strikes-back/">this problem</a>. Before last month I hoped to never have to work on the C preprocessor or a parser generator. So much for that plan. Now my head is full of CPP-expansion-related trivia.</p>

<p>After a month of design and implementing changes to mcpp, elsa, elkhound and oink I can finally move on. During the last week all of the pieces of the puzzle finally came together ( without any nasty surprises other than bugs). Now I can go back to solving real problems.</p>

<p><strong>Upcoming Features</strong></p>

<p>Benefits of having CPP support don&#8217;t stop at actually being able to rewrite code. Now that the Oink C++ parser is aware of the C preprocessor, it should be possible to refactor C++ almost as easily as Java. Here are some cool things that are possible now:</p>

<ul>
<li>Nicer UI. Exact source position info allows for eclipse-style context menus for renaming &amp; other refactorings in lxr (or other online code browsers).</li>
<li>Richer type system. It should be possible to detect macro constants. Tools will be able to tell the difference between a prnull and 0. Should also be able to detect and maintain NSRESULT and other macros used for declarations.</li>
<li>Macro refactoring. Now it&#8217;s possible to write a tool to automate the process of converting function-like macro calls to actual function calls. For example, PR_MAX could be converted into std::max calls with all of the accompanying casts to ensure that the resulting C++ is correct.</li>
<li>Other nasty tricks like rewriting code within macro declarations.
I&#8217;m not sure how much of these features I will work on, but they are relatively easy to implement now.</li>
</ul>


<p>I plan to write a minimalistic successor to squash and develop more aggressive refactorings than renames.</p>

<p>Additionally, I will continue pushing above changes upstream and trying to facilitate a more open oink development community.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/06/12/undoing-cpp-expansion-in-3-simple-steps-say-hello-to-easier-c-rewriting/">Undoing CPP Expansion in 3 Simple Steps. Say &#8220;Hello&#8221; to Easier C++ Rewriting.</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-06-12T03:26:01-07:00" pubdate data-updated="true">Jun 12<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This is incredibly exciting: I believe that I finally solved the messy and mind-numbingly boring CPP/C++ integration problem! Having code displaced or generated due to CPP-expansion should no longer be a fatal problem for <a href="http://wiki.mozilla.org/Squash">Squash</a>. I believe macro-expansion is (or was) the single biggest problem between me and large-scale automated refactoring of the Mozilla codebase.</p>

<p>What&#8217;s even more exciting is that I think my solution is both incredibly simple to implement and more general than prior work. Most other tools combine the CPP expansion &amp; C parsing into a single step and then integrate (or should I say violently shove?) CPP constructs into the AST. This results in complete lack of separation between preprocessing and program analysis. For example, due to this tight coupling existing solutions were useless to me because the fancy CPP logic could not be separated from the C parser. I would also have a hard time submitting a more convoluted C++ parser upstream to the Elsa maintainer.</p>

<p><strong>Design</strong></p>

<p>There are three parts to my solution:</p>

<ol>
<li><em>Critical component</em>. A CPP expansion undo-log injected during CPP-expansion by a modified C preprocessor (upcoming version of MCPP). The statements are wrapped in C comments such that the preprocessed result can be parsed by any C/C++/etc parser or compiler. Implementation-wise this is the hardest part since MCPP(as most other C proprocessors) was never designed it keep track of macro expansion info.</li>
<li>A small modification to the Elsa lexer to parse the undo-log and set it aside in a separate data structure.</li>
<li><em>Tricky</em>. A function that utilizes the cpp undo-log to map the preprocessed source locations to the unpreprocessed ones. This is a a ridiculously simple solution to a tricky design problem of how to efficiently advertise the fact that every AST node has at least 2 different source positions (pre expansion, post expansion &amp; a stack of positions resulting from expanding nested macros).
The MCPP maintainer is almost done with 1. I have a prototype implementation of 2 &amp; 3 weighing in at less than 500lines. Now that the design phase is complete, the amount of changes to Elsa is trivial, so I should be done with those real soon now.</li>
</ol>


<p><strong>Looking Ahead</strong></p>

<p>Now I need to modify Elsa to retain more precise source locations. This includes adding end-of-ast-node-location and adding positions to nodes(such as expressions) that don&#8217;t even have a start position at the moment. This combined with cpp-undo-log enhanced precise positions should allow for code rewrites to retain as much original source code as possible. This reduces the amount of ugly machine-generated code and results in better correctness (existing code is likely to work).</p>

<p><strong>CPP Undo-log Example</strong></p>

<p>The undo-log took a couple of tries to get right. Now macro-parameters have a notion of scope and sensible names. The following example features macro-induced column displacement and macro-expansion causing line shrinkage.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>#define NULL 0L
</span><span class='line'>#define FOO(a, b) a + b
</span><span class='line'>int i = NULL; int j;
</span><span class='line'>int k = FOO(
</span><span class='line'>FOO(NULL , 1),
</span><span class='line'>2);
</span></code></pre></td></tr></table></div></figure>


<p>Preprocessed version</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'># 1 "testcase4.c"
</span><span class='line'>/*mNULL 1:8-1:15*/
</span><span class='line'>/*mFOO 2:8-2:23*/</span></code></pre></td></tr></table></div></figure>


<p>int i = /<em><NULL 3:8-3:12*/0L/*></em>/; # 3 &#8220;testcase4.c&#8221; int j; int k = /<em><FOO 4:8-6:3*//*!FOO#0-0 5:0-5:13*//*!FOO#0-1 6:1-6:2*//*<FOO#0-0*//*<FOO*//*!FOO#1-0*//*!FOO#1-1*//*<FOO#1-0*//*<NULL*/0L/*></em>//<em>></em>/ + /<em>&lt;FOO#1-1</em>/1/<em>></em>//<em>></em>//<em>></em>/ + /<em>&lt;FOO#0-1</em>/2/<em>></em>//<em>></em>/;</p>

<p><strong>Conclusion</strong></p>

<p>It took a lot to arrive at such a simple solution. I expect that all of my work is likely to end up upstream in BSD-licensed projects: MCPP &amp; and Elsa/Oink. I sincerely hope that other people will be able to build on it for their CPP-infested analysis needs and avoid the unbearable mind-numbing discomfort associated with making CPP play along.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/05/29/cpp-integration-progress/">CPP Integration Progress</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-05-29T03:36:26-07:00" pubdate data-updated="true">May 29<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>Existing Work</strong></p>

<p>All of existing work is based on basic C parsers so it can&#8217;t be directly applied to C++.</p>

<p>I found out that someone did a PhD on refactoring C code resulting in the <a href="https://netfiles.uiuc.edu/garrido/www/CRefactory.html">CRefactory</a>(down atm) project. Looks like reversing the C preprocessor was by far the hardest task to address. Languages consisting of stacked lexical syntaxes (like OCaml &amp; camlp4) or preprocessorless ones like Java don&#8217;t even have this problem.</p>

<p>A way to tackle the problem is to violently shove the some of the preprocessor markup into the C AST. Unfortunately this is an incredibly hard task because CPP is purely lexical and works at the token level, whereas the C compilers works with higher level AST syntax trees. Combining the two can result in an ambiguous grammar which is useless for refactoring.</p>

<p>CRefactory integrates CPP into the AST where possible, it even handles some CPP conditionals. The author&#8217;s argument is that every CPP conditional represents a separate configuration and processing one configuration at a time will result in a combinatorial explosion of configurations to process thus conditionals must be integrated into the AST.</p>

<p>However, CPP-in-AST solution is error prone and has issues scaling to large projects. Besides I think processing every configuration within the AST is still potentially a combinatorial explosion, the major benefit being that one can eliminate unfeasible conditionals if they cause syntax errors. This conditional elimination would be incredibly slow for C++. I also don&#8217;t believe that this would be enough to solve Mozilla&#8217;s conditionals since most of the troublesome macros are platform specific and would have dependencies on the system headers. Having said that, I appreciate seeing people prove that with enough effort even seemingly impossible tasks can be accomplished.</p>

<p>A <a href="http://www.cs.berkeley.edu/~billm/astec-fse.pdf">paper</a> on ASTEC presents another solution which involves translating [lexical] CPP constructs into a CPP-like AST-based language. This works great in theory, but the translation process is only semi-automatic and requires a lot of hand-holding. I have mixed feeling about this approach. A simpler intermediate language is an excellent thing but as soon as it becomes &#8220;CPP sux, so I invented this better language: use it&#8221; the world gains yet another troublesome programming language.</p>

<p><strong>My Approach</strong></p>

<p>It took me a few weeks to figure out how to tackle the CPP problem in squash. I think I have a solution that will work real soon(TM).</p>

<p>I like to avoid solving unsolvable problems and stick with works-for-me approach. Thus I probably wont make squash aware of CPP conditionals. My existing approach of combining output of running squash on Mac/Linux(and Windows in the future) should take care of 99% of cases in Mozilla. The rest will be flagged by a compiler and will be trivial to fix by hand.</p>

<p><strong>Macro Expansion</strong></p>

<p>I also don&#8217;t see the benefit of a partially integrated CPP within the C++ AST. Instead I am modifying MCPP to log the macro expansions with special markup enclosed in comments. Afterwards I plan to modify elsa to parse the macro-expansion log and modify the position tags on AST nodes accordingly. Then I&#8217;ll be able to do cool things like &#8220;cut out the piece of code that was parsed as 0&#8221; which will reference the source locations, figure out that 0 was a result of macro expansion and return &#8220;NULL&#8221;. Or when I try to rewrite a member in PR_MAX(something->GetPresContext()->foo, 0), the code will know that the the two GetPresContext() calls in the AST correspond to the same code fragment.</p>

<p>Besides, isn&#8217;t this marked-up code pretty?</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>/*m__CONCAT,"testcase3.c",2,*/
</span><span class='line'>/*m__MATHDECL_1,"testcase3.c",5,*/
</span><span class='line'>/*m__MATH_PRECNAME,"testcase3.c",8,*/
</span><span class='line'># 10 "testcase3.c"
</span><span class='line'>/*!0x2adfbaa6e010 _*/
</span><span class='line'>/*!0x2adfbaa6e015 b*/
</span><span class='line'># 10 "testcase3.c"
</span><span class='line'>/*&lt;__CONCAT*/__boo/*&gt;*/
</span><span class='line'>/*!0x2adfbaa6e010 _*/
</span><span class='line'>/*!0x2adfbaa6e029 _*/
</span><span class='line'># 11 "testcase3.c"
</span><span class='line'># 11 "testcase3.c"
</span><span class='line'># 11 "testcase3.c"
</span><span class='line'>testcase3.c:11: error: Not a valid preprocessing token "//"
</span><span class='line'>macro "__CONCAT" defined as: #define __CONCAT(x,y) x ## y   /* testcase3.c:*
</span><span class='line'>/
</span><span class='line'>macro "__MATHDECL_1" defined as: #define __MATHDECL_1(function,suffix) __CON
</span><span class='line'>CAT(function,suffix)    /* testcase3.c:5        */
</span><span class='line'>from testcase3.c: 11:    int __MATHDECL_1( __CONCAT(__, lgamma),_r);
</span><span class='line'>int  /*&lt;__MATHDECL_1*/ /*&lt;__CONCAT*//*&lt;0x2adfbaa6e010*/ /*&lt;__CONCAT*/__lgamma/*&gt;
</span><span class='line'>*//*&gt;*// *&lt;0x2adfbaa6e029*/_r/*&gt;*//*&gt;*/ /*&gt;*/ ;
</span></code></pre></td></tr></table></div></figure>


<p>This is the original testcase:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>#define __CONCAT(x,y)   x ## y</span></code></pre></td></tr></table></div></figure>


<h1>define <strong>MATHDECL_1(function,suffix) \ </strong>CONCAT(function,suffix)</h1>

<h1>define <strong>MATH_PRECNAME(name,r) </strong>CONCAT(name,r)</h1>

<p><strong>CONCAT(</strong>, boo) int <strong>MATHDECL_1( </strong>CONCAT(<em>_, lgamma),</em>r); <strong>Code</strong></p>

<p>The MCPP maintainer is absolutely awesome work with. MCPP needs to be modified to preserve horizontal whitespace(which preprocessors don&#8217;t do) and to provide the above expansion info. He volunteered to do a lot of the MCPP modifications for me and has been a lot of help in guiding me through his code.</p>

<p>At this point looks like we&#8217;ll be able to integrate this work into the MCPP trunk. This is great news because to the best of my knowledge all of the other C refactoring tools either use a bitrotting fork of some C preprocessor or reimplement a yet another buggy version of CPP resulting in a lot of collectively wasted effort.</p>

<p>I hope to have this working in squash within two weeks so I can finish the outparam rewrite and hopefully rid squash of a large portion of code that details with the non-deterministic source positions due to macro expansion.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/05/17/undoing-cpp-deep-in-enemy-territory/">Undoing CPP - Deep in Enemy Territory</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-05-17T08:30:43-07:00" pubdate data-updated="true">May 17<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>Positive</strong></p>

<p>Since the last blog post, I have been investigating on how to teach elsa about the C preprocessor. Overall, I am really happy that <a href="http://mcpp.sourceforge.net/">MCPP</a> exists and is actively maintained. Preprocessed source code may not be invertible into the original form, but at least it can be undone enough for refactoring purposes.</p>

<p>Looks like I should be able to preprocess the source code, and while at it record macro expansion information and then have elsa fed with a somewhat xml-escue data structure.</p>

<p>The way I see it, a line of code like</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>foo = PR_MAX(boo(), nsnull)</span></code></pre></td></tr></table></div></figure>


<p>which expands into</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>foo =  boo() &gt; 0 ? boo() : 0;</span></code></pre></td></tr></table></div></figure>


<p>will get fed to elsa as something like</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;fragment&gt;foo = &lt;macro id=somemacro_instance&gt;PR_MAX(boo(), nsnull)&lt;/macro&gt;;&lt;/fragment&gt;
</span></code></pre></td></tr></table></div></figure>


<p>where somemacro_instance is defined as</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;fragment&gt;&lt;fragment ref=some_fragment/&gt; &gt; 0 ? &lt;fragment ref=some_fragment/&gt; : &lt;macro id=some_staticmacro&gt;0&lt;/macro&gt;&lt;/fragment&gt;
</span></code></pre></td></tr></table></div></figure>


<p>where some_staticmacro is defined as</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;fragment&gt;0&lt;/fragment&gt;</span></code></pre></td></tr></table></div></figure>


<p>I think this is a cute scheme because fragments are basically regions of source-code. This is exciting because once a macro is used in the code, the text fragment that defines the macro can be parsed as C++ and rewritten accordingly. Obviously, this wouldn&#8217;t be the default behavior.</p>

<p>If you see a fatal flow in the above model, let me know.</p>

<p><strong>Negative</strong></p>

<p>My main reason for adding preprocessor support to elsa is to obtain precise source locations from elsa. Ironically, MCPP &#8220;compresses&#8221; whitespace, so column information is basically thrown out of the window. Means I&#8217;ll have to do some extensive culling of the compression code (which is everywhere).</p>

<p>Another fun issue is that the general structure of MCPP encourages the &#8220;lots of global variables and defines&#8221; mode of programming. It also uses strings-as-a-data-structure pattern which may make me give up on the fancy onion-peel model I described above and instead have mcpp generate preprocessed code along with an &#8220;undo&#8221; type log.</p>

<p>MCPP is also a bit on the slow side compared to GCC, but I&#8217;ll trade a second or two slowdown per file for never having to cry due to CPP again.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/05/11/cpp-strikes-back/">CPP Strikes Back</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-05-11T09:07:26-07:00" pubdate data-updated="true">May 11<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I have gotten used to dodging CPP-expansion issues by fudging column &amp; line information until the position info in squash mostly matches the source positions in the original source code. That sufficed for rewriting declarations, but I have finally hit a brick wall.</p>

<p><strong>CPP Fun</strong></p>

<p>I got as far with call-site outparam rewriting as <a href="http://people.mozilla.org/~tglek/outparams.May11.diff">this patch</a>. It demonstrates an interesting flaw.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>@@ -8297,1 +8297,1 @@
</span><span class='line'>-  GetInsertionPoint(parentFrame, nsnull, &insertionPoint, &multiple);
</span><span class='line'>+  insertionPoint = GetInsertionPoint(parentFrame, &insertionPoint, &multiple);
</span><span class='line'>@@ -8346,1 +8346,1 @@
</span><span class='line'>-          GetInsertionPoint(parentFrame, child, &insertionPoint);
</span><span class='line'>+          insertionPoint = GetInsertionPoint(parentFrame, child);</span></code></pre></td></tr></table></div></figure>


<p>Due to macro expansion, nsnull contracts to 0 such that the .i file has &amp;insertionpoint positioned right in the middle of nsnull (in the .cpp file). So when squash trims the param including the surrounding commas, it ends up removing the wrong parameter.</p>

<p><strong>Elsa Limitation</strong></p>

<p>I have mentioned lack of end-of-ast-node position information in Elsa. It also lacks start-of-ast-node information for most expressions. This makes selectively rewriting source code rather difficult.</p>

<p><strong>Plan</strong></p>

<p>Instead of fighting an uphill fudging battle against CPP, I am going to have to suspend outparam rewriting yet again to work on better position information and integrating a preprocessor into elsa. This is unfortunate because I was looking forward to finally doing something more sophisticated than renames. Now my elsa fork is going to grow even bigger before I get commit access.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/24/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/22/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/12/24/making-pages-load-faster/">Making pages load faster</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/21/interesting-bugzilla-activity/">Snappy #45: The view from home</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/11/26/coping-with-flash-hangs/">Coping with Flash hangs</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/11/16/snappy-44-fixing-tab-switching-in-vancouver/">Snappy #44: Fixing tab switching in Vancouver</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/11/05/snappy-43-big-improvements-faster-startup-smoother-tabstrip/">Snappy #43: Big improvements: faster startup? Smoother tabstrip!</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("tarasglek", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/tarasglek" class="twitter-follow-button" data-show-count="false">Follow @tarasglek</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p><h6>
  Copyright &copy; 2012 - Taras Glek - content on this site is licensed under the
Creative Commons Attribution Share-Alike License v3.0 or any later version.

  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span></h6>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'allaboutperformance-tarasglek';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
