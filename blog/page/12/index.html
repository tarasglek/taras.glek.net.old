
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>All About Performance</title>
  <meta name="author" content="Taras Glek">

  
  <meta name="description" content="As I explained before, loading binaries from disk sucks. Aside from switching glibc to use madvise/fadvise, what can application developers do to &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://taras.glek.net/blog/page/12/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="All About Performance" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">All RSS</a></li>
  
  <li><a href="/blog/categories/mozilla/atom.xml" rel="subscribe-rss" title="subscribe via RSS">Mozilla RSS</a></li>
</ul>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <header role="banner"><hgroup>
  <h1><a href="/">All About Performance</a></h1>
  
    <h2>and other stuff by Taras Glek</h2>
  
</hgroup>

</header>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/04/05/linux-how-to-make-startup-suck-less-and-reduce-memory-usage/">Linux: How to Make Startup Suck Less (Also Reduce Memory Usage!)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-04-05T05:36:01-07:00" pubdate data-updated="true">Apr 5<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>As I explained before, loading binaries from disk <a href="http://taras.glek.net/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/">sucks</a>. Aside from <a href="http://taras.glek.net/blog/2010/03/25/madvise-prelink-update/">switching</a> glibc to use madvise/fadvise, what can application developers do to minimize this suckyness?</p>

<p>I am going to start with numbers to give an idea of the magnitudes involved here. I&#8217;m still using my 1.8ghz core2duo laptop with a 7200 200GB harddrive.</p>

<p>Time(ms)</p>

<h1>of libxul.so reads</h1>

<p>Typical Firefox build
2300
147</p>

<p>Prelinked Firefox
2130
139</p>

<p>Ordered Firefox
2500
131</p>

<p>Ordered+Prelinked
2065
124</p>

<p>Prelinked-Ordered Firefox
1860
72</p>

<p>Prelink-Ordered + Prelinked Firefox
1636
66
Additionally, proper binary reordering results in >2mb reduction in memory usage(out of 14mb that&#8217;s mapped in for code) since less random code gets paged in during readahead. This should be interesting for mobile where our binaries are RISC-bloated and there is less RAM is available.</p>

<p><strong>Analysis</strong></p>

<p>****A commonly-suggested linux adage is to <a href="http://en.wikipedia.org/wiki/Prelink">prelink</a> if your binaries are loading slowly. All of the good Linux distributions are doing using it. Unfortunately that alone gives pretty pathetic improvements. Beyond the weak 8.5% speed one has to do own tools to speed things up.</p>

<p>As I mentioned before, application binaries are laid out in a basically random order. This seemed like an obvious optimization so I embarked on a non-obvious quest to capture every single memory access and to use that info to order our binaries sensibly.</p>

<p><strong>Valgrind Adventures</strong></p>

<p>Due to disappointing results I had to change my strategies a few times. The happy numbers(easy 30% speedup) in the above table were produced after the 3rd rewrite of my valgrind plugin. Before I seemed perpetually stuck at 10%.</p>

<p>In the current revision of my valgrind plugin I produce a section listing by inferring section names from symbol names via a libelf-based program(unfortunately I do not know of a way get ld to retain function sections in the final binary). This turned out to be easier to get right than abusing Valgrind&#8217;s symbol-lookup APIs into figuring out what sections they came from.</p>

<p>Also in addition to reordering executable code in .text, the plugin now reorders the various .data sections. Turned out that even though data is a relatively small portion of the executable, it is located on the opposite end of the executable from code. This means that every page fault in the .data section kills continuous reading of the .text section.</p>

<p>I also switched to using gold with a section-ordering patch, it seems to produce binaries that are basically the same size as unordered ones(unlike ones produced by my linker script hack).</p>

<p><strong>What is a Prelink-Ordered binary?</strong></p>

<p>In the end, turned out prelink was the key to my problem. I realized that I am measuring memory accesses in valgrind on a non-prelinked binary causing the linker-induced memory accesses  to drive my binary layout. During symbol relocation, the dynamic linker rummages through the .text and .data sections (which I am trying to layout correctly) in order that does not correlate later execution of the program. Unfortunately I was using that data to order my binary even if the final result was meant to be prelinked.</p>

<p>Perhaps that explains why, in the above table, ordered non-prelinked firefox is actually slower than default non-prelinked firefox. Another explanation is that this could be to additional disk fragmentation or other factors. Cold startup numbers depend hard-drive&#8217;s luck at seeking + filesystem fragmentation, so the only reliably comparator is the number of reads/page-faults.</p>

<p>As of now my recipe to producing fast-starting binaries is:</p>

<ol>
<li>Build firefox</li>
<li>Switch to root, set LD_LIBRARY_PATH to /dist/bin/ in the object directory, run: prelink $LD_LIBRARY_PATH/firefox-bin $LD_LIBRARY_PATH/*.so</li>
<li>Run my libelf utility: elflog  &#8211;contents  dist/bin/libxul.so > dist/bin/libxul.so.sections</li>
<li>As a normal user run Firefox under my valgrind plugin. It will output a list of section names to dist/bin/libxul.so.log</li>
<li>Relink libxul.so with -Wl,&#8211;section-ordering-file,$HOME/builds/minefield.release/dist/bin/libxul.so.log</li>
<li>make dist, copy resulting binaries somewhere, prelink em</li>
<li>Enjoy faster startup
<strong>Conclusion</strong></li>
</ol>


<p>Using prelink incorrectly can cause massive performance variation.</p>

<p>My plugin does .data reordering now, but it would be very hard to do .data reordering as part of profile-guided optimization. Valgrind is the best tool for this job.</p>

<p>I will try to cleanup the code and release my plugin this week. Pretty much every significant application can benefit from this, might as well let this loose. I need to decide on a name: ldgrind? startupgrind? binarymaidgrind?</p>

<p>We need to develop a built-in diagnostic for detecting when the user isn&#8217;t using prelink (or has other startup misconfiguration issues).</p>

<p>Measuring startup times is highly machine-specific and varies even on individual machines. A much better metric is to measure the amount of io(ie number and size of pagefaults and non-cached reads) serviced by the kernel, that&#8217;s very consistent.</p>

<p><strong>Misc</strong></p>

<p>Prelink sure gets upset easily. The last (fastest) result in the table above causes:</p>

<p>prelink $LD_LIBRARY_PATH/firefox-bin prelink: /hd/startup.test/firefox//firefox-bin: section file offsets not monotonically increasing</p>

<p>What&#8217;s going on? I&#8217;m only modifying libxul inbetween prelink runs, why is prelink complaining about firefox-bin which stays constant?</p>

<p>prelink: /hd/startup.test/firefox.ordered.static/firefox-bin: DT_JMPREL tag not adjacent to DT_REL relocations</p>

<p>What does that mean?</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/31/how-to-get-reviews-fast-delete-code/">How to Get Reviews Fast: Delete Code!</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-31T13:17:48-07:00" pubdate data-updated="true">Mar 31<span>st</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>The fastest review I ever got was when I deleted a bunch of code from libjar. It was so riddled crud it was next to impossible to modify the code. That was a mere <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=505784">24KB patch</a> produced manually.</p>

<p><a href="http://ehren.wordpress.com/">Ehren</a> just put my personal records to shame with a <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=556446">94KB patch</a> that got r+ed at breakneck speed. Best part is that he generates these by plucking off dead parts of the Mozilla callgraph via static analysis. I bet if he tried he could land 90KB patches every day. Way to go Ehren!</p>

<p>I expect more good code deletions to make themselves known via this <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=457262">meta bug</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/29/linux-startup-inefficiency/">Linux Startup Inefficiency</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-29T06:11:02-07:00" pubdate data-updated="true">Mar 29<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There is a little bit of a disconnect between the kernel, the dynamic linker and compile-time linker. As I mentioned in my main &#8220;startup sucks&#8221; <a href="http://taras.glek.net/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/">post</a>: not-notifying the kernel of your patterns can kill performance, so can reading files backwards.</p>

<p>Turns out that if the compile-time linker lays out files without considering <em>exactly</em> how they are read by the runtime linker, binaries will load slower. I filed a <a href="http://sourceware.org/bugzilla/show_bug.cgi?id=11447">bug</a> on that.</p>

<p>Currently, SuSE appears to be leading in startup performance by shipping their glibc with the fadvise() patch (to load binaries from disk in bigger chunks). A <a href="http://sourceware.org/bugzilla/show_bug.cgi?id=11431">bug</a> is filed for this to get fixed in glibc, but in the meantime distributions should consider including SuSE&#8217;s patch (glibc-2.3.90-ld.so-madvise.diff) in their libc.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/25/madvise-prelink-update/">Madvise, Prelink Update</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-25T04:09:25-07:00" pubdate data-updated="true">Mar 25<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Got some helpful comments on my <a href="http://taras.glek.net/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/">previous post</a>.</p>

<p><strong>madvise(WILLNEED) in ld.so</strong></p>

<p>Frank Ch. Eigler pointed out that other people have <a href="http://www.google.com/search?q=ld.so%20madvise">noticed</a> the madvise/mmap deficiency in the dynamic linker. Unfortunately those unfortunate people did not have the ability to flush caches or to measure page faults exactly. Linux has gotten a lot nicer for diagnosing this. Frank also filed a <a href="http://sourceware.org/bugzilla/show_bug.cgi?id=11431">glibc bug</a>. SuSE already ships with a madvise()ed dynamic linker.</p>

<p><strong>Prelink saga</strong></p>

<p>Both Bradley Baetz and Frank pointed me at the FIPS-caused <a href="https://bugzilla.redhat.com/show_bug.cgi?id=504949">bug</a> which causes prelink to get angry at Firefox. This isn&#8217;t the first time that practically-useless FIPS has gotten in the way of a higher performing Firefox.</p>

<p>The most common response to people who complain about run-time linker issue is &#8220;are you using prelink?&#8221;. So I did my best to assume that prelink would erase a bunch of the overhead I saw in the previous bug.</p>

<p>I got rid of the offending nss rule in the prelink configuration as the bug instructed; prelink started working on Firefox (according to LD_DEBUG=statistics). Unfortunately the IO pattern was identical to what I was seeing before.</p>

<p>Frank suggested that I try prelink -u to undo any prelinking. This caused a bunch more runtime-linker IO from which one can conclude that the overhead I am seeing is not solved by prelink. The is still a lot of IO that happens before any application code is executed, so the runtime linker is still my primary suspect.</p>

<p>Going to spend some quality time with SystemTap to try to figure out what the linker is doing.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/">Linux: Why Loading Binaries From Disk Sucks</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-24T08:47:28-07:00" pubdate data-updated="true">Mar 24<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>Note: I am doing my measurements and experiments on Fedora 12, once I feel that I understand and can solve the problems on Linux, other operating systems will follow. The aim of this post is to document what I have learned about the mysterious process of loading programs from the filesystem perspective.</em></p>

<p>A binary is broken up into segments. There are about half dozen different segments in an executable, but only two that matter here:</p>

<ol>
<li>A segment that mostly contains function-bodies and some const data. It&#8217;s mapped in read+execute mode</li>
<li>A segment that contains variable initializers, GOT, PLT, lists of constructors/destructors, etc
The compile-time linker composes segments out of sections that contain variable data, function bodies, etc. The run-time linker maps the segments into memory via <a href="http://en.wikipedia.org/wiki/Mmap">mmap</a>. It resolves references to data and code in dynamic libraries (eg relocation) via COW. IO happens when the program (on behalf of the run-time linker) is trying to access memory that hasn&#8217;t been read from disk yet. These interruptions are called page faults. They cause the kernel to interrupt the program to read in some multiple of pages (4096byte chunks) from disk. On my system, page faults trigger ﻿﻿131072byte (32 pages) reads.</li>
</ol>


<p>For a detailed explanation of how linkers work check out the guides written by experts. Out of the scant <a href="http://lambda-the-ultimate.org/node/3474">list</a> of literature on the subject, my &#8220;favourite&#8221; is Ulrich Drepper&#8217;s &#8220;How to Write Shared Libraries&#8221;. It actually explains things in terms of file offsets, not just virtual addresses.</p>

<p>A common misconception is that mmap()-caused IO is free (because you don&#8217;t issue any explicit read() statements). IO via page faults is just another &#8220;API&#8221; for file-access, there is no reason for it to be free. Another misconception is that one has no control over IO-patterns triggered by mmap(). On Linux-like OSes one can use madvise(). (Windows is more limited, afaik one can only set io-pattern-flags on the filehandles).</p>

<p><strong>Prelinking Fail </strong></p>

<p>Having the run-time linker fix up the binary causes a huge amount of IO even before any application code gets executed. These faults are visible in the second graph in my <a href="http://taras.glek.net/blog/2010/03/23/when-in-trouble-draw-a-picture/">previous post</a>. The linker&#8217;s faults (pun intended) are the small green rectangles above the big ones. The graph clearly shows the huge relative cost of inefficient run-time linker memory prodding.</p>

<p>Supposedly, this problem is largely solved by <a href="http://en.wikipedia.org/wiki/Prelink">prelinking</a>. I can&#8217;t confirm that as prelink does not work on Firefox on the systems that I can measure IO with SystemTap. This non-determinism is frustrating; we should figure out a way to warn to the user that the OS infrastructure failed them. ****</p>

<p><strong>Post-linker Fail</strong></p>

<p>Above IO patterns can be blamed on careless run-time linker behavior. IO after that can be attributed to lack of organization in the output of the compiler and the compile-time linker. Turns out that the layout of the .text section (where all of the function bodies lie) and to a smaller degree .data[, .bss, etc] sections(ie variable initializers) is completely unhelpful. For a good laugh look at how the official nightly libxul.so is read mostly through backwards io (<a href="http://people.mozilla.com/~tglek/startup/systemtap_graphs/visualize.html?#stock.io.html">graph link</a>).</p>

<p><em><aside>The libxul.so graphs in the previous post did not exhibit this kind of insanity. I did my best to order functions based on chronological order of access (courtesy of my </em><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=549749"><em>valgrind hack</em></a><em>). Unfortunately, the chronological log is not deterministic. Someone suggested that statistical fudging via </em><a href="http://en.wikipedia.org/wiki/Markov_chain"><em>markov chains</em></a><em> will help. From the io patterns in the graph I&#8217;m guessing that io patterns detected by valgrind and those that actually happen diverge due to threading differences. Linux users that are interested in fast startup should pray to the GCC Santas to reorder binaries as part of Profile-Guided-Optimization.</aside></em> ****</p>

<p><strong>Are Large Programs Screwed Out of Fast Startup?</strong></p>

<p>Yes, but it doesn&#8217;t have to be this way. Turns out this utter disaster is caused by naive use of mmap() in the dynamic-linker. The second graph (previous post) shows, that even a late madvise call (delightfully nasty <a href="https://bugzilla.mozilla.org/attachment.cgi?id=434721&amp;action=edit">patch</a>) can significantly improve the situation. Specifying madvise(MADV_WILLNEED) causes individual faults to read in 2097152bytes (512 pages,  16x larger reads than default),  3x(10x if one counts only ones after madvise()) reduction in the number of total faults, saves about 1 second of startup.</p>

<p>The basic trick is outlined as &#8220;approach c&#8221; in this <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=554421">bug</a>. My current thinking is to:</p>

<ol>
<li>use Jim Blandy&#8217;s executable-parsing library from breakpad(which is already in our build) to parse our binaries</li>
<li>calculate what the dynamic linker will mmap() at runtime.</li>
<li>have some firefox.sh-like native frontend mmap()/madvise() it with appropriate flags
In the longer term some fixes for madvise() should land in both runtime and compile-time linkers.</li>
</ol>


<p><strong>Conclusion</strong></p>

<p>It took me a long time to produce the above story from my runtime linker observations. As recently as December I had no idea what a runtime linker was or what linker segments, sections, etc were. I&#8217;d like to thank Valgrind authors, kind folks on #gcc and numerous individuals who helped me connect the pieces. The above is written to the best of my still-incomplete understanding; I will appreciate any corrections.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/23/when-in-trouble-draw-a-picture/">When in Trouble, Draw a Picture</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-23T08:12:52-07:00" pubdate data-updated="true">Mar 23<span>rd</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>Graphs</strong></p>

<p><em>Note: the following graphs broke on the nightlies this week. I would appreciate help with reducing this to a proper testcase. They work fine on older nightlies and released versions of Firefox. Non-spidermonkey JS engines wont work as they don&#8217;t support <a href="https://developer.mozilla.org/en/New_in_JavaScript_1.7#Destructuring_assignment">destructuring assignment</a> and other goodies.</em></p>

<p>Once I graphed my file-access logs, most of my problems became clear. Here is the <a href="http://people.mozilla.org/~tglek/startup/systemtap_graphs/visualize.html#original.data.html">first</a> graph(<a href="http://people.mozilla.org/~tglek/startup/systemtap_graphs/orig.png">screenshot</a>). The y-axis is time; once you click on a square, x-axis is the file offset. One can clearly see that libxul (4th rectangle) is a big chunk of our io. It&#8217;s also clear that initially the file is being accessed in the begining and near the end. One can also see that there is a some &#8220;backwards&#8221; io. It&#8217;s ugly stuff.</p>

<p>I first saw this picture on Friday evening, I spent the last 2 days trying to make libxul.so load less stupidly. <a href="http://people.mozilla.org/~tglek/startup/systemtap_graphs/visualize.html?#madvise.hack.html">Here</a> is a graph(<a href="http://people.mozilla.org/~tglek/startup/systemtap_graphs/madvise1.png">screenshot</a>) from a hack I tried this morning (approach b in the <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=554421">bug</a>) . The top is still stupid, but near the bottom, libxul is being read in a much more efficient manner (>50% less io).</p>

<p>This <a href="http://people.mozilla.org/~tglek/startup/systemtap_graphs/visualize.html??#madvise_ahead.html">graph</a> is from a lunch-time hack(approach c). IO is being spread across two processes so it&#8217;s evading my systemtap script for  now. Fortunately, &#8220;approach c&#8221; also shaved off a second of my startup time, so I know the libxul graph would&#8217;ve been real pretty.</p>

<p>What follows is a story of how I ended up graphing stuff; more on lessons learned later&#8230;</p>

<p><strong>Story</strong></p>

<p>Last week I was about to give up and live with a <a href="http://taras.glek.net/blog/2010/03/05/mirror-mirror-on-the-wall-why-is-my-binary-slow/">meager</a> 10% win on libxul.so cold startup. I just couldn&#8217;t squeeze any more useful ideas out of my timing and io logs. I reached out to Jim Blandy, who confirmed that things seemed to be working as expected (unlike me, Jim actually knows this stuff).</p>

<p>Upon hearing of my quest, surprising number of people strongly suggested that I chat with <a href="http://people.gnome.org/~michael/blog/">Michael Meeks</a>. He was digging around in the binary cesspool for OpenOffice recently and asked many of the same questions. We had a fun conversation, where Michael proved me wrong. I said I couldn&#8217;t imagine a useful way to graph the file io logs. In response Michel, dug up this <a href="http://people.gnome.org/~michael/blog/">beauty</a>. He built it with a <a href="http://live.gnome.org/iogrind">fun</a> mix of valgrind + c#.</p>

<p>Feeling massive diagram envy, I decided that I had to get an interactive graph of my <a href="http://taras.glek.net/blog/2009/10/23/studying-library-io-systemtap-style/">SystemTap</a> data. A brief Google search revealed that <a href="http://raphaeljs.com/">RaphaelJS</a> would be awesome for my needs (the most <a href="http://www.youtube.com/watch?v=4pXfHLUlZf4">j***worthy</a> vector gfx library ever). After many happy hours of messing with with pretty graphics and colours, the ugly truth emerged (hint: it&#8217;s about the linker/kernel relationship). More on that soon.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/11/extensions-startup/">Extensions & Startup</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-11T03:20:35-08:00" pubdate data-updated="true">Mar 11<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Dietrich <a href="http://autonome.wordpress.com/2010/03/10/firefox-extensions-and-performance/">blogged</a> a &#8220;wake up and smell the startup&#8221; executive overview of startup issues caused by our extension practices. This post is a &#8220;numbers&#8221; followup. For this experiment I installed a brand-spankin-new copy of Linux Firefox 3.6. Firefox is installed on a 7200 hard drive, the rest of my system lives on an SSD. The CPU is core2duo, keep in mind these numbers will be significantly worse for people running on netbooks and other common hardware. The numbers vary +/- 150ms, but the general picture is pretty clear.</p>

<p><strong>Results</strong></p>

<p><strong>Startup Time</strong></p>

<p>Firefox 3.6 with no extensions:
2240ms</p>

<p>+<a href="https://addons.mozilla.org/en-US/firefox/addon/1865">Adblock Plus</a> (no subscriptions)
2538ms</p>

<p>+<a href="https://addons.mozilla.org/en-US/firefox/addon/3006">Video Download Helper</a>
2727ms</p>

<p>+<a href="https://addons.mozilla.org/en-US/firefox/addon/10900">Personas</a>
3220ms</p>

<p>+<a href="https://addons.mozilla.org/en-US/firefox/addon/748">Greasemonkey</a>
3300ms</p>

<p>+EasyList subscription for adblock
4044ms
I just doubled cold startup time for Firefox by merely adding 4 extensions. It takes weeks or even months of developer time to shave off every 100ms off Firefox startup, but mere seconds to undo any of those gains by installing extensions. These are just the top-4 extensions in the list (presumably they are higher quality too), I&#8217;m sure there are lots of other extensions with more drastic performance hits.</p>

<p>Dietrich&#8217;s <a href="http://autonome.wordpress.com/2010/03/10/firefox-extensions-and-performance/">post</a> details some of the remedies that should reduce the startup cost of extensions. For the inquisitive minds: I used <a href="http://taras.glek.net/blog/2009/10/23/studying-library-io-systemtap-style/">SystemTap</a> to produce a <a href="http://people.mozilla.com/~tglek/startup/extensions_report.txt">report</a> of files read by Firefox on startup ordered by their startup cost.</p>

<p><strong>Update:</strong> Dietrich asked me to summarize warm startup too:</p>

<ul>
<li>Without extensions: 550ms</li>
<li>With above Extensions: 1800ms
Note that this is a developer blog, so by &#8220;remedies&#8221; I meant &#8220;things developers can do to&#8221;. There is little normal users can do short of complaining to the extension authors.</li>
</ul>


<p>This post isn&#8217;t meant to shame specific extension authors into speeding up their extensions. The aim is to show that a measurable percentage of startup is due to extensions and that we need to:</p>

<ol>
<li>Educate extension developers about it</li>
<li>Provide better tools to measure slowdowns caused by extensions</li>
<li>Make sure that the Firefox side of extension handling is sufficiently efficient</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/05/mirror-mirror-on-the-wall-why-is-my-binary-slow/">Mirror, Mirror on the Wall, Why Is My Binary Slow?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-05T09:48:25-08:00" pubdate data-updated="true">Mar 5<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In an <a href="http://taras.glek.net/blog/2010/02/19/teaching-ld-to-optimize-binaries-for-startup/">earlier</a> post I described my Fiji hack: how to use some nasty instrumentation to spit out ld scripts to speed up cold startup. This week I tried to extract more data out of the binary to lay it out even better. Trouble is that even if one lays out functions perfectly, they load data for things like variable initializers which will cause more IO.</p>

<p>A very clever friend suggested that I can write a valgrind plugin that can detect data accesses and function access and write the linker input files in one step. So with much hand-holding I hacked a sample valgrind plugin to do what I <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=549749">want</a>. Unfortunately, my binaries ended up not being significantly faster(if at all) than the Fiji ones. They also ended up 20% bigger.</p>

<p>Fortunately, the GCC devs were able to point out my linker mistakes and pointed me at a <a href="http://sourceware.org/ml/binutils/2010-03/msg00050.html">linker patch</a> that does what I want without linker scripts(and has less binary-bloating side-effects). Unfortunately, that just confirmed that the speedup I was looking for wasn&#8217;t hiding behind data symbols. So I am going to have to sit down with my <a href="http://taras.glek.net/blog/2009/10/23/studying-library-io-systemtap-style/">io tracing script </a>and study what the heck is going on.</p>

<p><strong>Cool Things I Learned</strong></p>

<p>In the process of helping me, GCC people namedropped some compiler flags that may prove very helpful:</p>

<ul>
<li>-freorder-blocks-and-partition: Apparently this breaks up functions into hot/cold parts and gives them different section names so they can be moved around at link time.</li>
<li>-fno-common, -fno-zero-initialized-in-bss should go well with my favourites: -ffunction-sections -fdata-sections
Additionally, it may be possible to benefit from linking with large page support. I have some doubts about that.</li>
</ul>


<p>I did learn about some cool GNU Gold flags:</p>

<ul>
<li>&#8211;compress-debug-sections=zlib: Most of the overhead of linking a development libxul.so is writing out a near gig of debug data</li>
<li>&#8211;icf: Identical code folding, I think that matches the deduplication feature found in the ms linker. Saves 5% on my libxul.so</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/02/26/updated-dehydra-installation-instructions/">Updated Dehydra Installation Instructions</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-26T03:02:46-08:00" pubdate data-updated="true">Feb 26<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>The <a href="https://developer.mozilla.org/En/Dehydra/Installing_Dehydra">Dehydra installation instructions</a> got to the point where they were more confusing than helpful. I spent this morning cutting out irrelevant crud, please let me know if there are any further cleanups that need to be done.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/02/19/teaching-ld-to-optimize-binaries-for-startup/">Teaching Ld to Optimize Binaries for Startup</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-19T03:28:51-08:00" pubdate data-updated="true">Feb 19<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I have been told that it should be possible to control the way the GNU linker lays out binaries. Unfortunately until recently I couldn&#8217;t figure out the right incantations to convince ld to do my bidding. Turns out what I needed was to be stranded on a beach in Fiji with nothing better to do than to reread the ld info page a few times.</p>

<p>Recipe:</p>

<ol>
<li>Produce 2 mozilla builds: A tracing build with -finstrument-functions in CXXFLAGS/CFLAGS A release build with -ffunction-sections and -fdata-sections CXXFLAGS/CFLAGS to allow the linker to move stuff at function or static data(mostly variables) granularity</li>
<li>Link my <a href="http://people.mozilla.com/~tglek/startup/ld/profile.cpp">profile.cpp</a> into libxul in the tracing build (without -finstrument-functions flag)</li>
<li>Run the tracing build, capturing the spew from profile.cpp into a log file</li>
<li>Feed the log file to <a href="http://people.mozilla.com/~tglek/startup/ld/generate_sections_ff.py">my script</a> to produce a linker script. This will produce library.so.script files for all of Mozilla libraries.</li>
<li>Rebuild relevant libraries in the release build with -T library.so.script linker flag</li>
<li>Enjoy faster startup
This results in 200ms faster startup my 7200rpm laptop harddrive which is about a 10% of my startup. I think that&#8217;s pretty good for a proof of concept. Unfortunately there isn&#8217;t a measurable win on the SSD (not surprising) nor a reduction in memory usage (I expected one due to not having to page in code that isn&#8217;t needed for firefox startup).</li>
</ol>


<p>I suspect the problem is that data sections need to be laid out adjacent to functions that refer to them. I started sketching out a treehydra <a href="http://people.mozilla.com/~tglek/startup/ld/map_functions_and_symbols.js">script</a> to extract that info.</p>

<p>I posted the relevant testcase and scripts. Do hg clone <a href="http://people.mozilla.com/~tglek/startup/ld/">http://people.mozilla.com/~tglek/startup/ld</a> to see the simple testcase and various WIP firefox scripts.</p>

<p><strong>Long-term Expectations</strong></p>

<p>The majority of Firefox startup overhead (prior to rendering of web pages) comes from frustrating areas such inefficient libraries (eg fontconfig, gtk) and the mess caused by crappy layout of binaries and overuse of dynamic libraries. This post describes one small step towards fixing the crappy layout of our binaries.</p>

<p>I would like to end up in a world where our binaries are static and laid out such that they are read sequentially on startup (such that we can use the massive sequential read speeds provided by modern storage media). Laying out code/data properly should result in memory usage reductions which should be especially welcome on Fennec (especially on Windows Mobile).</p>

<p>I am hoping to see 30-50% startup time improvements from this work if everything goes according to plan.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/13/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/11/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/12/21/interesting-bugzilla-activity/">Snappy #45: The view from home</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/17/hello-octopress/">Hello Octopress</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/11/26/coping-with-flash-hangs/">Coping with Flash hangs</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/11/16/snappy-44-fixing-tab-switching-in-vancouver/">Snappy #44: Fixing tab switching in Vancouver</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/11/05/snappy-43-big-improvements-faster-startup-smoother-tabstrip/">Snappy #43: Big improvements: faster startup? Smoother tabstrip!</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("tarasglek", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/tarasglek" class="twitter-follow-button" data-show-count="false">Follow @tarasglek</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p><h6>
  Copyright &copy; 2012 - Taras Glek - content on this site is licensed under the
Creative Commons Attribution Share-Alike License v3.0 or any later version.

  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span></h6>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'allaboutperformance-tarasglek';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
