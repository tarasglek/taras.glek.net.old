
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>All About Performance</title>
  <meta name="author" content="Taras Glek">

  
  <meta name="description" content="Last week I learned about how Windows handles page faults backed by files (specifically xul.dll). I already knew that Linux was suboptimal in this &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://taras.glek.net/blog/page/13/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  
  <link href="/atom.xml" rel="alternate" title="All About Performance" type="application/atom+xml">
  
  

</head>

<body   >
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" title="subscribe via RSS">All RSS</a></li>
  
  <li><a href="/mozilla.xml" title="subscribe via RSS">Mozilla RSS</a></li>
</ul>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

<script>
if (!window.requestAnimationFrame) {
  window.requestAnimationFrame = window.mozRequestAnimationFrame
    || window.webkitRequestAnimationFrame
    || window.msRequestAnimationFrame;

  window.cancelAnimationFrame = window.mozCancelAnimationFrame
    || window.webkitCancelAnimationFrame
    || window.msCancelAnimationFrame;

}

window._refreshLog = []
function refreshLogCounter() {
  window._refreshLog.push(Date.now())
  window._refreshLogCounter = requestAnimationFrame(refreshLogCounter);
}

if (requestAnimationFrame)
  window._refreshLogCounter = requestAnimationFrame(refreshLogCounter);
</script>

</nav>
  <header role="banner"><hgroup>
  <h1><a href="/">All About Performance</a></h1>
  
    <h2>and other stuff by Taras Glek</h2>
  
</hgroup>

</header>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/04/19/windows-sucks-at-memory-mapped-io-during-startup/">Windows Sucks at Memory-Mapped IO During Startup</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-04-19T07:00:00-07:00" pubdate data-updated="true">Apr 19<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Last week I learned about how Windows handles page faults backed by files (specifically xul.dll). I already knew that Linux was <a href="http://taras.glek.net/blog/2010/04/12/squeezing-every-last-bit-of-performance-out-of-the-linux-toolchain/">suboptimal</a> in this area, perhaps the clever people at Redmond did better.</p>

<p>Shaver pointed me at <a href="https://developer.mozilla.org/En/Profiling_with_Xperf">xperf</a>, which is sort of like the new Linux perf tools. Xperf rocks in that it can capture the relevant data and it can export it as .csv.</p>

<p>Even with profile-guided-optimization Windows causes 3x as much IO in xul.dll than linux does on libxul.so. That&#8217;s especially interesting given that xul.dll is one-third smaller on Windows. Here is the <a href="http://people.mozilla.com/~tglek/startup/systemtap_graphs/visualize.html?#../win7/noprefetch.csv.html">graph</a>. PGO isn&#8217;t helping on Windows as much as it can help on Linux because MSVC PGO doesn&#8217;t do the equivalent of GCC&#8217;s -freorder-blocks-and-partition (unless I missed something in the docs).</p>

<p>With the Windows <a href="http://en.wikipedia.org/wiki/Prefetcher">prefetcher</a>, there were 4x less xul.dll IOs (graph <a href="http://people.mozilla.com/~tglek/startup/systemtap_graphs/visualize.html?#../win7/prefetch.csv.html">here</a>). Unfortunately, the prefetcher can&#8217;t figure out that the whole xul.dll should be paged in and we still end up with an excess of random IO.</p>

<p><strong>Why?</strong></p>

<p>When a page fault occurs, Windows goes to read the page from the file and reads a little extra (just like any other sane OS) assuming that there will be more IO nearby. Unfortunately the gods of virtual memory at Microsoft decided that for every page fault, only 7 extra pages should read. So reads occur in 32K chunks (vs 128K in Linux, which is still too small). To make matters worse, segments mapped in as data only read in 3 extra pages (ie 16K chunks).</p>

<p>This is funny in a sad way. Reading in 32K chunks is supposed to minimize ram usage (which makes no bloody sense when Win7 officially requires 1GB of RAM). As a result of being so thrifty on easy-to-evict file cache, windows ends up doing 4x as much file IO as Linux. The 16K reads are particularly funny as one can see the result of that misoptimization in the string of puny reads on the top right of the graphs.</p>

<p><strong>Surely There is an API like madvise()</strong> On Posix systems madvise() can be used to influence the caching behavior of the OS. fadvise() is another such call for IO based on filehandles. For example, Firefox fastload files are now madvise()ed such that they are read in a single 2mb chunk on startup. Unfortunately, it appears that Windows has no such APIs so one is stuck with pathetically small reads.</p>

<p>At first, I thought that, passing FILE_FLAG_SEQUENTIAL_SCAN when opening the file handle will work like a crappy fadvise()-equivalent. Turns out that mmaping files completely bypasses the Windows Cache Manager, so that flag just gets ignored.</p>

<p>So as far as I can tell the only way to convince Windows to not read stuff in stupidly small chunks is to mmap() everything we care about using large pages. Unfortunately that comes with some significant costs.</p>

<p>We are going to try to <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=553721">order</a> the binaries better which should halve the amount of page faults.</p>

<p><strong>Can Windows Do Anything Better?</strong></p>

<p>Yes. The &#8220;Unix way&#8221; of breaking up everything into a billion libraries and configuration files results in 10x more files being read on startup on Linux vs Windows. Just because Linux can read individual libraries 4x faster, doesn&#8217;t mean that IO becomes free.</p>

<p>Presently, in ideal conditions, Firefox starts up 30-50% faster on Windows. The Windows Prefetcher hack sweeps a lot of Windows suck under the carpet, but Microsoft has a lot of room for improvement.</p>

<p><strong>Update:</strong><br/>
People seem to prefer to comment on <a href="http://www.reddit.com/r/programming/comments/bu2do/windows_sucks_at_memorymapped_io_during_startup/">reddit</a>. If you want me to not miss your comment, make sure you comment here.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/04/12/squeezing-every-last-bit-of-performance-out-of-the-linux-toolchain/">Squeezing Every Last Bit of Performance Out of the Linux Toolchain</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-04-12T08:16:08-07:00" pubdate data-updated="true">Apr 12<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>Magic of GCC PGO</strong></p>

<p>On Friday I finally got gold to produce a prelinkable static binary(<a href="http://sourceware.org/bugzilla/show_bug.cgi?id=11483">bug</a>). I also got around to trying out GCC <a href="https://developer.mozilla.org/en/Building_with_Profile-Guided_Optimization">profile-guided-optimization</a> with the debloatifying -freorder-blocks-and-partition option. This option breaks up every profiled function into cold and hot &#8220;functions&#8221;. It then lumps all of the hot functions together.</p>

<p>PGO performance is amazingly close to that of binaries produced by <a href="http://taras.glek.net/blog/2010/04/07/icegrind-valgrind-plugin-for-optimizing-cold-startup/">icegrind </a>(within 10% based on page-counts).</p>

<p><strong>Startup Time</strong>
<strong>RSS (KB)</strong></p>

<p>firefox.stock
2515ms
49452</p>

<p>firefox.ordered
1919ms
45344</p>

<p>firefox.static
2321ms
49616</p>

<p>firefox.static.ordered
1577ms
37072</p>

<p>firefox.static.pgo
1619ms
38436
In above table, ordered means application of <a href="http://taras.glek.net/blog/2010/04/07/icegrind-valgrind-plugin-for-optimizing-cold-startup/">icegrind</a>, <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=525013">static</a> means a fat firefox-bin. To generate the PGO profile I just started and closed Firefox. So it&#8217;s not too surprising that the results are similar to those of an explicitly ordered binary. RSS refers to how much memory is mmap()ed into the process(lower RSS usage means we are paging in less junk). I was not able to control the layout of PGO builds; will need some linker hackery to deal with split functions.</p>

<p>I think the numbers speak for themselves. Isn&#8217;t it scary how wasteful binaries are by default? It amazes me that Firefox can shrug off a significant amount of resource bloat without changing a single line of code. I think this is a good demonstration on why application developers should a) expect more out of their toolchain (Linux, GCC, Binutils) b) contribute to their toolchain.</p>

<p>I think my next step is to tackle PGO Firefox builds(<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=418866">bug</a>). From there I would like to teach icegrind to play together with PGO.</p>

<p><strong>Pieces of The Startup Puzzle</strong></p>

<p>It took a long time since I <a href="http://taras.glek.net/blog/2009/10/20/large-apps-just-have-to-start-slow/">first noticed</a> the suckyness of library io. After much digging, help by smart people on #gcc + <a href="http://thread.gmane.org/gmane.linux.kernel/970483/focus=970920">LKML discussion</a>, I think I finally have a pretty clear list of the remaining/inprogress things needed for Linux applications to start faster.</p>

<ol>
<li>Wu Fengguang is making headway on <a href="http://lwn.net/Articles/372384/">smarter readahead</a> that makes better use of available RAM + disk bandwidth. Firefox could be read in 512kb chunks instead of 128 (4x page-fault reduction). Distributions should be aggressively testing this patch.</li>
<li>Better agreement on binary organization between the compile-time <a href="http://sourceware.org/bugzilla/show_bug.cgi?id=11447">linker</a>, run-time <a href="http://sourceware.org/bugzilla/show_bug.cgi?id=11431">linker</a> and the kernel (see LKML discussion). Can shave off a handful of unneeded page-faults per file this way.</li>
<li>A linker flag to specify how much of a particular library should be read-in via madvise(). For example any xulrunner apps will know ahead of time that they need large parts of libxul.so - might as well let the OS know.</li>
<li>Transparent read-only per-file ext4 compression (<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=514083">like OSX</a>). Ted Tso indicated that this would be easy to add to ext4, but as far as I know nobody has jumped on this.
I think with all of the above combined, we could load apps like Firefox at near-warm (0.5 second) speeds. Most of these are easy. #1 is hard, but it&#8217;s already being worked on. I&#8217;ll be happy to point someone at how to solve items 2-4 while I work on the Firefox side of things. The end result of all this should be a more instant gratification for all Linux users.</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/04/07/icegrind-valgrind-plugin-for-optimizing-cold-startup/">Icegrind - Valgrind Plugin for Optimizing Cold Startup</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-04-07T08:03:24-07:00" pubdate data-updated="true">Apr 7<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Most program binaries are laid out with little to no regard to how programs get loaded from disk. This disconnect between compile-time and runtime behaviour of binaries imposes a significant performance penalty to on large applications such as browsers, office suites, etc.</p>

<p>It is incredibly difficult to observe both the cause (ie calling a random function) of binary-induced IO and the effect (the program gets suspended during startup while parts being loaded from disk), so this area doesn&#8217;t get as much optimization love as it deserves.</p>

<p>My estimate is that around 50% of Firefox startup time is wasted on subobtimal binary layout. My previous <a href="http://taras.glek.net/blog/2010/04/05/linux-how-to-make-startup-suck-less-and-reduce-memory-usage/">post</a> demonstrated the kind of difference a better binary layout can make. Note that reordering executables isn&#8217;t the only solution, eliminating dead code should also speed things up (deleting <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=457262">dead code</a> is a <a href="http://ehren.wordpress.com/">hard</a>).</p>

<p><strong>Optimizing Binary Layout</strong><em> Disclaimer:I just finished my 3rd rewrite of icegrind a few hours ago, be gentle.</em></p>

<p>Ingredients: <a href="http://valgrind.org/">Valgrind</a> SVN trunk + <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=549749">icegrind patch</a>, GNU Gold + <a href="http://sourceware.org/ml/binutils/2010-03/msg00050.html">section-ordering-file patch</a>, a way to describe contents of binaries.</p>

<p><em>Step 1a: Produce a build </em>Since I am interested in reorganizing program binaries, I build mozilla with &#8220;-ffunction-sections -fdata-sections&#8221; in CFLAGS/CXXFLAGS</p>

<p>I also prelink the binaries in dist/bin such that my binaries better correspond to how they will be used: prelink $LD_LIBRARY_PATH/firefox-bin $LD_LIBRARY_PATH/*.so</p>

<p><em>Step 1b: Produce a description of interesting files </em>I use my <a href="http://hg.mozilla.org/users/tglek_mozilla.com/startup/file/6453ad2a7906/elflog.cpp">elflog</a> utility to produce a .sections description of files I&#8217;m interested in. Elflog looks at the symbol table and tries to infer section names (produced by -ffunction-sections -fdata-sections) from symbol names/locations(see also &#8211;print-map option for ld).</p>

<p>elflog  &#8211;contents  libxul.so >  libxul.so.sections elflog currently emits non-existent .comment.* sections because it gets confused by 0-length sections such as .bss. Note, one can also build tools to describe other kinds of files, such as jar or sqlite files. The only limitation is that Icegrind currently only tracks mmap()-caused disk IO, it would be trivial to extend it to deal with open/seek/read kind of disk IO.</p>

<p><em>Step 2: Produce a log with icegrind! </em>Apply my icegrind <a href="https://bugzilla.mozilla.org/attachment.cgi?id=437664&amp;action=edit">patch</a>, build+install valgrind. Run Firefox valgrind &#8211;tool=icegrind firefox-bin -profile /tmp/ff -no-remote This will produce a .log file for every mmap()ed file with a .sections description. This log chronologically lists sections in the order of access.</p>

<p><em>Step 3: Tell gold to link using the above log</em> Build/install binutils (I use a CVS checkout from a month ago) with the <a href="http://sourceware.org/ml/binutils/2010-03/msg00050.html">section ordering patch</a>, specify &#8211;enable-gold. To reorder the binary, I just add -Wl,&#8211;section-ordering-file,libxul.so.log to my linker commandline. Note there are still some teething issues with using this patch, it exhibits N<sup>2</sup> behavior (ie takes 10min to link libxul.so with it) and occasionally swaps order for .rela.plt and .rela.dyn, which makes prelink upset. But unlike my <a href="http://taras.glek.net/blog/2010/02/19/teaching-ld-to-optimize-binaries-for-startup/">earlier attempt</a> with linker scripts, it does not affect the binary size.</p>

<p>Step 4: Enjoy! Now strip, install, prelink your binaries and enjoy faster startup.</p>

<p><strong>Plans</strong></p>

<p>I would like to see the gold patch fixed up and landed. Once that is done I&#8217;d like to turn this on for our Linux and mobile linux builds.</p>

<p>I am hoping that some sort of sensible ordering of binaries will become commonplace in the future.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/04/05/linux-how-to-make-startup-suck-less-and-reduce-memory-usage/">Linux: How to Make Startup Suck Less (Also Reduce Memory Usage!)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-04-05T05:36:01-07:00" pubdate data-updated="true">Apr 5<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>As I explained before, loading binaries from disk <a href="http://taras.glek.net/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/">sucks</a>. Aside from <a href="http://taras.glek.net/blog/2010/03/25/madvise-prelink-update/">switching</a> glibc to use madvise/fadvise, what can application developers do to minimize this suckyness?</p>

<p>I am going to start with numbers to give an idea of the magnitudes involved here. I&#8217;m still using my 1.8ghz core2duo laptop with a 7200 200GB harddrive.</p>

<p>Time(ms)</p>

<h1>of libxul.so reads</h1>

<p>Typical Firefox build
2300
147</p>

<p>Prelinked Firefox
2130
139</p>

<p>Ordered Firefox
2500
131</p>

<p>Ordered+Prelinked
2065
124</p>

<p>Prelinked-Ordered Firefox
1860
72</p>

<p>Prelink-Ordered + Prelinked Firefox
1636
66
Additionally, proper binary reordering results in >2mb reduction in memory usage(out of 14mb that&#8217;s mapped in for code) since less random code gets paged in during readahead. This should be interesting for mobile where our binaries are RISC-bloated and there is less RAM is available.</p>

<p><strong>Analysis</strong></p>

<p>****A commonly-suggested linux adage is to <a href="http://en.wikipedia.org/wiki/Prelink">prelink</a> if your binaries are loading slowly. All of the good Linux distributions are doing using it. Unfortunately that alone gives pretty pathetic improvements. Beyond the weak 8.5% speed one has to do own tools to speed things up.</p>

<p>As I mentioned before, application binaries are laid out in a basically random order. This seemed like an obvious optimization so I embarked on a non-obvious quest to capture every single memory access and to use that info to order our binaries sensibly.</p>

<p><strong>Valgrind Adventures</strong></p>

<p>Due to disappointing results I had to change my strategies a few times. The happy numbers(easy 30% speedup) in the above table were produced after the 3rd rewrite of my valgrind plugin. Before I seemed perpetually stuck at 10%.</p>

<p>In the current revision of my valgrind plugin I produce a section listing by inferring section names from symbol names via a libelf-based program(unfortunately I do not know of a way get ld to retain function sections in the final binary). This turned out to be easier to get right than abusing Valgrind&#8217;s symbol-lookup APIs into figuring out what sections they came from.</p>

<p>Also in addition to reordering executable code in .text, the plugin now reorders the various .data sections. Turned out that even though data is a relatively small portion of the executable, it is located on the opposite end of the executable from code. This means that every page fault in the .data section kills continuous reading of the .text section.</p>

<p>I also switched to using gold with a section-ordering patch, it seems to produce binaries that are basically the same size as unordered ones(unlike ones produced by my linker script hack).</p>

<p><strong>What is a Prelink-Ordered binary?</strong></p>

<p>In the end, turned out prelink was the key to my problem. I realized that I am measuring memory accesses in valgrind on a non-prelinked binary causing the linker-induced memory accesses  to drive my binary layout. During symbol relocation, the dynamic linker rummages through the .text and .data sections (which I am trying to layout correctly) in order that does not correlate later execution of the program. Unfortunately I was using that data to order my binary even if the final result was meant to be prelinked.</p>

<p>Perhaps that explains why, in the above table, ordered non-prelinked firefox is actually slower than default non-prelinked firefox. Another explanation is that this could be to additional disk fragmentation or other factors. Cold startup numbers depend hard-drive&#8217;s luck at seeking + filesystem fragmentation, so the only reliably comparator is the number of reads/page-faults.</p>

<p>As of now my recipe to producing fast-starting binaries is:</p>

<ol>
<li>Build firefox</li>
<li>Switch to root, set LD_LIBRARY_PATH to /dist/bin/ in the object directory, run: prelink $LD_LIBRARY_PATH/firefox-bin $LD_LIBRARY_PATH/*.so</li>
<li>Run my libelf utility: elflog  &#8211;contents  dist/bin/libxul.so > dist/bin/libxul.so.sections</li>
<li>As a normal user run Firefox under my valgrind plugin. It will output a list of section names to dist/bin/libxul.so.log</li>
<li>Relink libxul.so with -Wl,&#8211;section-ordering-file,$HOME/builds/minefield.release/dist/bin/libxul.so.log</li>
<li>make dist, copy resulting binaries somewhere, prelink em</li>
<li>Enjoy faster startup
<strong>Conclusion</strong></li>
</ol>


<p>Using prelink incorrectly can cause massive performance variation.</p>

<p>My plugin does .data reordering now, but it would be very hard to do .data reordering as part of profile-guided optimization. Valgrind is the best tool for this job.</p>

<p>I will try to cleanup the code and release my plugin this week. Pretty much every significant application can benefit from this, might as well let this loose. I need to decide on a name: ldgrind? startupgrind? binarymaidgrind?</p>

<p>We need to develop a built-in diagnostic for detecting when the user isn&#8217;t using prelink (or has other startup misconfiguration issues).</p>

<p>Measuring startup times is highly machine-specific and varies even on individual machines. A much better metric is to measure the amount of io(ie number and size of pagefaults and non-cached reads) serviced by the kernel, that&#8217;s very consistent.</p>

<p><strong>Misc</strong></p>

<p>Prelink sure gets upset easily. The last (fastest) result in the table above causes:</p>

<p>prelink $LD_LIBRARY_PATH/firefox-bin prelink: /hd/startup.test/firefox//firefox-bin: section file offsets not monotonically increasing</p>

<p>What&#8217;s going on? I&#8217;m only modifying libxul inbetween prelink runs, why is prelink complaining about firefox-bin which stays constant?</p>

<p>prelink: /hd/startup.test/firefox.ordered.static/firefox-bin: DT_JMPREL tag not adjacent to DT_REL relocations</p>

<p>What does that mean?</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/31/how-to-get-reviews-fast-delete-code/">How to Get Reviews Fast: Delete Code!</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-31T13:17:48-07:00" pubdate data-updated="true">Mar 31<span>st</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>The fastest review I ever got was when I deleted a bunch of code from libjar. It was so riddled crud it was next to impossible to modify the code. That was a mere <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=505784">24KB patch</a> produced manually.</p>

<p><a href="http://ehren.wordpress.com/">Ehren</a> just put my personal records to shame with a <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=556446">94KB patch</a> that got r+ed at breakneck speed. Best part is that he generates these by plucking off dead parts of the Mozilla callgraph via static analysis. I bet if he tried he could land 90KB patches every day. Way to go Ehren!</p>

<p>I expect more good code deletions to make themselves known via this <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=457262">meta bug</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/29/linux-startup-inefficiency/">Linux Startup Inefficiency</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-29T06:11:02-07:00" pubdate data-updated="true">Mar 29<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There is a little bit of a disconnect between the kernel, the dynamic linker and compile-time linker. As I mentioned in my main &#8220;startup sucks&#8221; <a href="http://taras.glek.net/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/">post</a>: not-notifying the kernel of your patterns can kill performance, so can reading files backwards.</p>

<p>Turns out that if the compile-time linker lays out files without considering <em>exactly</em> how they are read by the runtime linker, binaries will load slower. I filed a <a href="http://sourceware.org/bugzilla/show_bug.cgi?id=11447">bug</a> on that.</p>

<p>Currently, SuSE appears to be leading in startup performance by shipping their glibc with the fadvise() patch (to load binaries from disk in bigger chunks). A <a href="http://sourceware.org/bugzilla/show_bug.cgi?id=11431">bug</a> is filed for this to get fixed in glibc, but in the meantime distributions should consider including SuSE&#8217;s patch (glibc-2.3.90-ld.so-madvise.diff) in their libc.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/25/madvise-prelink-update/">Madvise, Prelink Update</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-25T04:09:25-07:00" pubdate data-updated="true">Mar 25<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Got some helpful comments on my <a href="http://taras.glek.net/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/">previous post</a>.</p>

<p><strong>madvise(WILLNEED) in ld.so</strong></p>

<p>Frank Ch. Eigler pointed out that other people have <a href="http://www.google.com/search?q=ld.so%20madvise">noticed</a> the madvise/mmap deficiency in the dynamic linker. Unfortunately those unfortunate people did not have the ability to flush caches or to measure page faults exactly. Linux has gotten a lot nicer for diagnosing this. Frank also filed a <a href="http://sourceware.org/bugzilla/show_bug.cgi?id=11431">glibc bug</a>. SuSE already ships with a madvise()ed dynamic linker.</p>

<p><strong>Prelink saga</strong></p>

<p>Both Bradley Baetz and Frank pointed me at the FIPS-caused <a href="https://bugzilla.redhat.com/show_bug.cgi?id=504949">bug</a> which causes prelink to get angry at Firefox. This isn&#8217;t the first time that practically-useless FIPS has gotten in the way of a higher performing Firefox.</p>

<p>The most common response to people who complain about run-time linker issue is &#8220;are you using prelink?&#8221;. So I did my best to assume that prelink would erase a bunch of the overhead I saw in the previous bug.</p>

<p>I got rid of the offending nss rule in the prelink configuration as the bug instructed; prelink started working on Firefox (according to LD_DEBUG=statistics). Unfortunately the IO pattern was identical to what I was seeing before.</p>

<p>Frank suggested that I try prelink -u to undo any prelinking. This caused a bunch more runtime-linker IO from which one can conclude that the overhead I am seeing is not solved by prelink. The is still a lot of IO that happens before any application code is executed, so the runtime linker is still my primary suspect.</p>

<p>Going to spend some quality time with SystemTap to try to figure out what the linker is doing.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/24/linux-why-loading-binaries-from-disk-sucks/">Linux: Why Loading Binaries From Disk Sucks</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-24T08:47:28-07:00" pubdate data-updated="true">Mar 24<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>Note: I am doing my measurements and experiments on Fedora 12, once I feel that I understand and can solve the problems on Linux, other operating systems will follow. The aim of this post is to document what I have learned about the mysterious process of loading programs from the filesystem perspective.</em></p>

<p>A binary is broken up into segments. There are about half dozen different segments in an executable, but only two that matter here:</p>

<ol>
<li>A segment that mostly contains function-bodies and some const data. It&#8217;s mapped in read+execute mode</li>
<li>A segment that contains variable initializers, GOT, PLT, lists of constructors/destructors, etc
The compile-time linker composes segments out of sections that contain variable data, function bodies, etc. The run-time linker maps the segments into memory via <a href="http://en.wikipedia.org/wiki/Mmap">mmap</a>. It resolves references to data and code in dynamic libraries (eg relocation) via COW. IO happens when the program (on behalf of the run-time linker) is trying to access memory that hasn&#8217;t been read from disk yet. These interruptions are called page faults. They cause the kernel to interrupt the program to read in some multiple of pages (4096byte chunks) from disk. On my system, page faults trigger ﻿﻿131072byte (32 pages) reads.</li>
</ol>


<p>For a detailed explanation of how linkers work check out the guides written by experts. Out of the scant <a href="http://lambda-the-ultimate.org/node/3474">list</a> of literature on the subject, my &#8220;favourite&#8221; is Ulrich Drepper&#8217;s &#8220;How to Write Shared Libraries&#8221;. It actually explains things in terms of file offsets, not just virtual addresses.</p>

<p>A common misconception is that mmap()-caused IO is free (because you don&#8217;t issue any explicit read() statements). IO via page faults is just another &#8220;API&#8221; for file-access, there is no reason for it to be free. Another misconception is that one has no control over IO-patterns triggered by mmap(). On Linux-like OSes one can use madvise(). (Windows is more limited, afaik one can only set io-pattern-flags on the filehandles).</p>

<p><strong>Prelinking Fail </strong></p>

<p>Having the run-time linker fix up the binary causes a huge amount of IO even before any application code gets executed. These faults are visible in the second graph in my <a href="http://taras.glek.net/blog/2010/03/23/when-in-trouble-draw-a-picture/">previous post</a>. The linker&#8217;s faults (pun intended) are the small green rectangles above the big ones. The graph clearly shows the huge relative cost of inefficient run-time linker memory prodding.</p>

<p>Supposedly, this problem is largely solved by <a href="http://en.wikipedia.org/wiki/Prelink">prelinking</a>. I can&#8217;t confirm that as prelink does not work on Firefox on the systems that I can measure IO with SystemTap. This non-determinism is frustrating; we should figure out a way to warn to the user that the OS infrastructure failed them. ****</p>

<p><strong>Post-linker Fail</strong></p>

<p>Above IO patterns can be blamed on careless run-time linker behavior. IO after that can be attributed to lack of organization in the output of the compiler and the compile-time linker. Turns out that the layout of the .text section (where all of the function bodies lie) and to a smaller degree .data[, .bss, etc] sections(ie variable initializers) is completely unhelpful. For a good laugh look at how the official nightly libxul.so is read mostly through backwards io (<a href="http://people.mozilla.com/~tglek/startup/systemtap_graphs/visualize.html?#stock.io.html">graph link</a>).</p>

<p><em><aside>The libxul.so graphs in the previous post did not exhibit this kind of insanity. I did my best to order functions based on chronological order of access (courtesy of my </em><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=549749"><em>valgrind hack</em></a><em>). Unfortunately, the chronological log is not deterministic. Someone suggested that statistical fudging via </em><a href="http://en.wikipedia.org/wiki/Markov_chain"><em>markov chains</em></a><em> will help. From the io patterns in the graph I&#8217;m guessing that io patterns detected by valgrind and those that actually happen diverge due to threading differences. Linux users that are interested in fast startup should pray to the GCC Santas to reorder binaries as part of Profile-Guided-Optimization.</aside></em> ****</p>

<p><strong>Are Large Programs Screwed Out of Fast Startup?</strong></p>

<p>Yes, but it doesn&#8217;t have to be this way. Turns out this utter disaster is caused by naive use of mmap() in the dynamic-linker. The second graph (previous post) shows, that even a late madvise call (delightfully nasty <a href="https://bugzilla.mozilla.org/attachment.cgi?id=434721&amp;action=edit">patch</a>) can significantly improve the situation. Specifying madvise(MADV_WILLNEED) causes individual faults to read in 2097152bytes (512 pages,  16x larger reads than default),  3x(10x if one counts only ones after madvise()) reduction in the number of total faults, saves about 1 second of startup.</p>

<p>The basic trick is outlined as &#8220;approach c&#8221; in this <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=554421">bug</a>. My current thinking is to:</p>

<ol>
<li>use Jim Blandy&#8217;s executable-parsing library from breakpad(which is already in our build) to parse our binaries</li>
<li>calculate what the dynamic linker will mmap() at runtime.</li>
<li>have some firefox.sh-like native frontend mmap()/madvise() it with appropriate flags
In the longer term some fixes for madvise() should land in both runtime and compile-time linkers.</li>
</ol>


<p><strong>Conclusion</strong></p>

<p>It took me a long time to produce the above story from my runtime linker observations. As recently as December I had no idea what a runtime linker was or what linker segments, sections, etc were. I&#8217;d like to thank Valgrind authors, kind folks on #gcc and numerous individuals who helped me connect the pieces. The above is written to the best of my still-incomplete understanding; I will appreciate any corrections.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/23/when-in-trouble-draw-a-picture/">When in Trouble, Draw a Picture</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-23T08:12:52-07:00" pubdate data-updated="true">Mar 23<span>rd</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>Graphs</strong></p>

<p><em>Note: the following graphs broke on the nightlies this week. I would appreciate help with reducing this to a proper testcase. They work fine on older nightlies and released versions of Firefox. Non-spidermonkey JS engines wont work as they don&#8217;t support <a href="https://developer.mozilla.org/en/New_in_JavaScript_1.7#Destructuring_assignment">destructuring assignment</a> and other goodies.</em></p>

<p>Once I graphed my file-access logs, most of my problems became clear. Here is the <a href="http://people.mozilla.org/~tglek/startup/systemtap_graphs/visualize.html#original.data.html">first</a> graph(<a href="http://people.mozilla.org/~tglek/startup/systemtap_graphs/orig.png">screenshot</a>). The y-axis is time; once you click on a square, x-axis is the file offset. One can clearly see that libxul (4th rectangle) is a big chunk of our io. It&#8217;s also clear that initially the file is being accessed in the begining and near the end. One can also see that there is a some &#8220;backwards&#8221; io. It&#8217;s ugly stuff.</p>

<p>I first saw this picture on Friday evening, I spent the last 2 days trying to make libxul.so load less stupidly. <a href="http://people.mozilla.org/~tglek/startup/systemtap_graphs/visualize.html?#madvise.hack.html">Here</a> is a graph(<a href="http://people.mozilla.org/~tglek/startup/systemtap_graphs/madvise1.png">screenshot</a>) from a hack I tried this morning (approach b in the <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=554421">bug</a>) . The top is still stupid, but near the bottom, libxul is being read in a much more efficient manner (>50% less io).</p>

<p>This <a href="http://people.mozilla.org/~tglek/startup/systemtap_graphs/visualize.html??#madvise_ahead.html">graph</a> is from a lunch-time hack(approach c). IO is being spread across two processes so it&#8217;s evading my systemtap script for  now. Fortunately, &#8220;approach c&#8221; also shaved off a second of my startup time, so I know the libxul graph would&#8217;ve been real pretty.</p>

<p>What follows is a story of how I ended up graphing stuff; more on lessons learned later&#8230;</p>

<p><strong>Story</strong></p>

<p>Last week I was about to give up and live with a <a href="http://taras.glek.net/blog/2010/03/05/mirror-mirror-on-the-wall-why-is-my-binary-slow/">meager</a> 10% win on libxul.so cold startup. I just couldn&#8217;t squeeze any more useful ideas out of my timing and io logs. I reached out to Jim Blandy, who confirmed that things seemed to be working as expected (unlike me, Jim actually knows this stuff).</p>

<p>Upon hearing of my quest, surprising number of people strongly suggested that I chat with <a href="http://people.gnome.org/~michael/blog/">Michael Meeks</a>. He was digging around in the binary cesspool for OpenOffice recently and asked many of the same questions. We had a fun conversation, where Michael proved me wrong. I said I couldn&#8217;t imagine a useful way to graph the file io logs. In response Michel, dug up this <a href="http://people.gnome.org/~michael/blog/">beauty</a>. He built it with a <a href="http://live.gnome.org/iogrind">fun</a> mix of valgrind + c#.</p>

<p>Feeling massive diagram envy, I decided that I had to get an interactive graph of my <a href="http://taras.glek.net/blog/2009/10/23/studying-library-io-systemtap-style/">SystemTap</a> data. A brief Google search revealed that <a href="http://raphaeljs.com/">RaphaelJS</a> would be awesome for my needs (the most <a href="http://www.youtube.com/watch?v=4pXfHLUlZf4">j***worthy</a> vector gfx library ever). After many happy hours of messing with with pretty graphics and colours, the ugly truth emerged (hint: it&#8217;s about the linker/kernel relationship). More on that soon.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2010/03/11/extensions-startup/">Extensions & Startup</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-11T03:20:35-08:00" pubdate data-updated="true">Mar 11<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Dietrich <a href="http://autonome.wordpress.com/2010/03/10/firefox-extensions-and-performance/">blogged</a> a &#8220;wake up and smell the startup&#8221; executive overview of startup issues caused by our extension practices. This post is a &#8220;numbers&#8221; followup. For this experiment I installed a brand-spankin-new copy of Linux Firefox 3.6. Firefox is installed on a 7200 hard drive, the rest of my system lives on an SSD. The CPU is core2duo, keep in mind these numbers will be significantly worse for people running on netbooks and other common hardware. The numbers vary +/- 150ms, but the general picture is pretty clear.</p>

<p><strong>Results</strong></p>

<p><strong>Startup Time</strong></p>

<p>Firefox 3.6 with no extensions:
2240ms</p>

<p>+<a href="https://addons.mozilla.org/en-US/firefox/addon/1865">Adblock Plus</a> (no subscriptions)
2538ms</p>

<p>+<a href="https://addons.mozilla.org/en-US/firefox/addon/3006">Video Download Helper</a>
2727ms</p>

<p>+<a href="https://addons.mozilla.org/en-US/firefox/addon/10900">Personas</a>
3220ms</p>

<p>+<a href="https://addons.mozilla.org/en-US/firefox/addon/748">Greasemonkey</a>
3300ms</p>

<p>+EasyList subscription for adblock
4044ms
I just doubled cold startup time for Firefox by merely adding 4 extensions. It takes weeks or even months of developer time to shave off every 100ms off Firefox startup, but mere seconds to undo any of those gains by installing extensions. These are just the top-4 extensions in the list (presumably they are higher quality too), I&#8217;m sure there are lots of other extensions with more drastic performance hits.</p>

<p>Dietrich&#8217;s <a href="http://autonome.wordpress.com/2010/03/10/firefox-extensions-and-performance/">post</a> details some of the remedies that should reduce the startup cost of extensions. For the inquisitive minds: I used <a href="http://taras.glek.net/blog/2009/10/23/studying-library-io-systemtap-style/">SystemTap</a> to produce a <a href="http://people.mozilla.com/~tglek/startup/extensions_report.txt">report</a> of files read by Firefox on startup ordered by their startup cost.</p>

<p><strong>Update:</strong> Dietrich asked me to summarize warm startup too:</p>

<ul>
<li>Without extensions: 550ms</li>
<li>With above Extensions: 1800ms
Note that this is a developer blog, so by &#8220;remedies&#8221; I meant &#8220;things developers can do to&#8221;. There is little normal users can do short of complaining to the extension authors.</li>
</ul>


<p>This post isn&#8217;t meant to shame specific extension authors into speeding up their extensions. The aim is to show that a measurable percentage of startup is due to extensions and that we need to:</p>

<ol>
<li>Educate extension developers about it</li>
<li>Provide better tools to measure slowdowns caused by extensions</li>
<li>Make sure that the Firefox side of extension handling is sufficiently efficient</li>
</ol>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/14/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/12/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/01/10/snappy-number-48-now-with-faster-shutdown/">Snappy #48: Now With Faster Shutdown</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/01/04/snappy-2012-summary/">Snappy: 2012 Summary</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/24/making-pages-load-faster/">Making pages load faster</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/21/interesting-bugzilla-activity/">Snappy #45: The view from home</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/17/hello-octopress/">Hello Octopress</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
<script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>

  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("tarasglek", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/tarasglek" class="twitter-follow-button" data-show-count="false">Follow @tarasglek</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p><h6>
  Copyright &copy; 2013 - Taras Glek - content on this site is licensed under the
Creative Commons Attribution Share-Alike License v3.0 or any later version.

  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span></h6>
</p>
<script>
//indicate that content has been loaded
window._monitorContentLoaded = Date.now()
</script>
<script src="http://monitor-taras-glek-net.appspot.com/static/monitor.js">
</script>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'allaboutperformance-tarasglek';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
