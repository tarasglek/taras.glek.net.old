<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: mozilla | All About Performance]]></title>
  <link href="http://taras.glek.net/blog/categories/mozilla/atom.xml" rel="self"/>
  <link href="http://taras.glek.net/"/>
  <updated>2014-01-12T16:11:35-08:00</updated>
  <id>http://taras.glek.net/</id>
  <author>
    <name><![CDATA[Taras Glek]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[New Role: Developer Productivity]]></title>
    <link href="http://taras.glek.net/blog/2013/11/20/new-role-developer-productivity/"/>
    <updated>2013-11-20T13:44:00-08:00</updated>
    <id>http://taras.glek.net/blog/2013/11/20/new-role-developer-productivity</id>
    <content type="html"><![CDATA[New Role
--------
The performance part of my team is now lead by [Vladan](http://blog.mozilla.org/vdjeric/). They are doing usual performancy things with a focus on improving our 'internal' benchmarks such as talos, TART + some upcoming power testing. 

I got a new task recently: developer productivity. I'm prioritizing tasks based on developer unproductivity. I have the following new stuff on my radar:

* slow build system for local builds
* long build/test times on our release automation
* bugzilla improvements (eg tracking review times, lack of pull reqs, etc)

Expect to hear less Gecko and more web dev stuff out of me for the foreseable future. Note, this is a collaborative project. My team would not be able to accomplish any of the new goals as we are already above capacity. I'm mainly working on improving coordination and collaboration on existing projects. Let me know if you have ideas related to this dev productivity stuff.


Cost-Oriented Architecture
---------------------------
My main project for the remainder of this year is to maximize throughput per dollar spent on our release automation infrastructure. I'm focusing on computation that happens on Amazon EC2(because it's easier than pricing out our own infrastructure). My goal is to be able to say "making improvement x will pay for itself in y time". This is mainly management technique to make it easier to justify working on infrastructure.

John posted some initial costing [figures](http://oduinn.com/blog/2013/11/20/the-financial-cost-of-a-checkin-part-1/). Rail is working on switching us over to Amazon Spot instances in <a title="Prepare infra to handle spot instances" href="https://bugzilla.mozilla.org/show_bug.cgi?id=935533">bug 935533</a>. I expect a 2-5x reduction in our AWS costs once Rail is done.

I'd like to have a receipt attached to every job that executes on our build infrastructure. I hope this encourages devs to look into build/test inefficiencies. 

Keeping an eye on costs means we'll be able to better reason about moving more workloads into the cloud. Cloud stuff is attractive because it allows us to give developers keys to AWS. They can deploy(in a low-friction manner) whatever they need to make their job easier while cost-monitoring ensures that things don't get crazy.

Open Architecture
------------------
In theory, open source is about scratching own needs. In practice service owners (usually inadvertently) put up walls to contribution by depending on licensing requirements, poor documentation, vpns, obscure infrastructure, weird version control, etc. This then snowballs into something equivalent to closed source where 'clients' have to ask for 'features' from 'owners'. This usually results in unhappy customers and overworked owners. This happened to Telemetry (see previous post) and is happening to a few of our tools. Expect improvements in this area.

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Telemetry Reboot]]></title>
    <link href="http://taras.glek.net/blog/2013/08/28/telemetry-reboot/"/>
    <updated>2013-08-28T15:54:00-07:00</updated>
    <id>http://taras.glek.net/blog/2013/08/28/telemetry-reboot</id>
    <content type="html"><![CDATA[A year ago I wrote 2 blog posts describing telemetry ([post1](/blog/2012/07/25/telemetry-and-what-it-is-good-for-part-2-telemetry-achievements/), [post2](/blog/2012/07/25/telemetry-and-what-it-is-good-for-part-1-nuts-and-bolts/)).

What sucks about telemetry?
---------------------------
The following aspects of performance made us unhappy with telemetry as deployed now: dashboard performance, effort required to add new dashboards/visualizations, data-gathering latency and slow ad-hoc queries on hadoop. Telemetry dashboards keep timing out, infrastructure keeps failing, this can't be the way to drive Firefox performance improvements.

Telemetry Reboot
-----------------
After a few months of soul-searching we ended up with a small group of people working on a replacement for current telemetry serverside. The goals are to minimize latency in the following dimensions:

* Serverside should be fast and robust. Slow dashboards are a good way to discourage their use. 
* We should have extensive monitoring and alerting to notify us when data isn't coming in (eg due to a bug in Firefox client code).
* Everything should be open source and easy to hack on. Outgoing telemetry infrastructure has an overly complicated software stack and code isn't open source. This was a mistake.
* Fast ad-hoc queries
* Minimal submission->graphing latency. Currently it takes about 3 days between landing a piece of telemetry code and having that data show up in a dashboard. Takes about 7 to gather a useful amount of data. My goal is to eventually do live-histogram-aggregation so the data can be graphed as soon as it hits the server. This means we should be able to gather a useful amount of telemetry data within 3 days of landing a probe. Should we choose to switch to shipping hourly nightlies, telemetry would come back even faster :)

ETA
---
I expect to shut down old dashboards and cut over to the new server + dashboards on Oct 1. See the wiki for our next set of [milestones](https://wiki.mozilla.org/Telemetry/Reboot).

We'll be deploying the new telemetry backend on Amazon AWS. I'll write a blog post about switching from a private cluster to AWS once we go live.

[Mark](http://mreid-moz.github.io/) is working on our serverside. Mark started implementing the server in Python/Django, but Node.js turned out to be a much more potent platform in terms of amount of work needed to squeeze out good performance. You can find the current node [code](https://github.com/mreid-moz/telemetry-server/blob/master/server/server.js) on github. I suspect we'll be switching to a C/C++ HTTP receiver in the future to get another 2-3x increase in req/s performance. In the past we've run into servers having difficulty coping with increases in telemetry volume (submissions went up 10-fold when we added saved-session telemetry).

At the moment we are looking at squeezing out the maximum possible requests per second out of node. If you have a background of that sort of thing feel free to try improving our code.

I spent a lot of time thinking about how to write the fastest(+robustest) possible telemetry dashboard. I ended up writing a [dashboard](http://telemetry-dash.mozilla.org/) ([code](https://github.com/mozilla/telemetry-dashboard/)) based on static JSON. This approach is fast and should make dashboards easy to contribute to. [Chris](http://xor.lonnen.com/) is working on making my prototype useful and usable. The dashboard is going to be going through a lot of refactoring in the near future. At the moment we use [jydoop](https://github.com/mozilla/jydoop) to generate the dashboard JSON from hadoop (was easier to write a new query tool for hadoop than do a complex map/reduce in Java).

Summary
-------
We will be cutting over to brand new telemetry infrastructure on Oct 1. There will be pain. If you have any questions or are interested in helping out ping us on IRC in `#telemetry`.
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[New Performance People, Telemetry News]]></title>
    <link href="http://taras.glek.net/blog/2013/06/28/new-performance-people/"/>
    <updated>2013-06-28T16:52:00-07:00</updated>
    <id>http://taras.glek.net/blog/2013/06/28/new-performance-people</id>
    <content type="html"><![CDATA[reddit/[MozillaTech](http://www.reddit.com/r/MozillaTech/)
--------------------------------
I like our make-planet-techy subreddit. Seems like articles that get rated as one would expect. I happily switched to reddit as my primary way to consume planet mozilla. Redditors, keep up the good work!

Telemetry Dashboard
-------------------------------
Our new telemetry [dashboard](http://telemetry-dash.mozilla.org/) went live yesterday. It's missing features, data, UX. However it is public, fast and hackable. It should evolve quickly.
New Blood
---------------
[Mark Reid](http://mreid-moz.github.io/) is our first server-side dev. His primary task is switching telemetry backend from hadoop to a custom telemetry server. New server infrastructure will enable a live dashboard (3-day delay atm) + ability to run queries in minutes rather than in hours.

[Dhaval Giani](http://randomkernels.wordpress.com), "the intern", is our first kernel hacker. He's working on helping land [volatile memory](https://lwn.net/Articles/522135/) in the kernel. This feature will let Firefox safely consume more memory when memory is plentiful and use less in limited scenarios. Hopefully he'll also add read-only file compression to ext4.

Blogs linked above are in the please-add-to-planet queue. Expect them to spend a few weeks there. Please subscribe to their RSS feeds in meantime.
 
Investigating SQLite Performance via Telemetry
----------------------------------------------------------------------
Years ago I tweaked our SQLite clients to use a larger page size. In my testing this seemed to achieve a speedup of 0.2-2x, see <a title="Suboptimal SQLite page size" href="https://bugzilla.mozilla.org/show_bug.cgi?id=416330">bug 416330</a>. Unfortunately, ~30% of our users are still on the old page size (<a title="Fix page_size of WAL databases" href="https://bugzilla.mozilla.org/show_bug.cgi?id=634374">bug 634374</a>). We used a [jydoop](https://github.com/mozilla/jydoop) query to figure out if it's worth developing a feature to convert these users over using two different (time spent [reading](https://github.com/mozilla/jydoop/blob/master/scripts/places4k.py) & time spent [executing](https://github.com/mozilla/jydoop/blob/master/scripts/places4k-slowsql.py) a query) ways to measure performance differences. According to both methods there is a 4x reduction in sqlite IO waits with the larger page size, so we'll be adding code to convert people over more aggressively.

This was a cool investigation because it highlighted how much more confidence we have when making performance decisions now (due to telemetry) vs a few years ago.
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mozilla Tech on Reddit]]></title>
    <link href="http://taras.glek.net/blog/2013/04/05/mozilla-tech-on-reddit/"/>
    <updated>2013-04-05T20:02:00-07:00</updated>
    <id>http://taras.glek.net/blog/2013/04/05/mozilla-tech-on-reddit</id>
    <content type="html"><![CDATA[I posted earlier about [planet mozilla being obsolete](/blog/2013/02/15/is-planet-mozilla-obsolete/). To move forward, we need to experiment with some alternatives. Mozilla contributor, [@djco](https://twitter.com/djco), setup a [reddit feed](http://www.reddit.com/r/MozillaTech/) so we can up-vote technical content and down-vote the rest.

I know a number of good people who stopped reading and posting on planet because of irrelevant, offensive, etc content. Please give the reddit feed a try. Maybe once we get enough people moderating, we'll encourage more quality content.

I am not suggesting that people stop posting pictures of their cats, dictionary entries on planet. I only want to filter that out so I can have a satisfying technical feed.

Please try out the [reddit feed](http://www.reddit.com/r/MozillaTech/) and let [me](https://twitter.com/tarasglek) and [Dirkjan](https://twitter.com/djco) know if it works for you. We are open to other suggestions too.
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Snappy #55: Snappy Evolution]]></title>
    <link href="http://taras.glek.net/blog/2013/03/27/snappy-number-55-snappy-evolution/"/>
    <updated>2013-03-27T03:56:00-07:00</updated>
    <id>http://taras.glek.net/blog/2013/03/27/snappy-number-55-snappy-evolution</id>
    <content type="html"><![CDATA[The Snappy name will be retired in favor of Performance: we will be expanding our meta scope beyond desktop Firefox responsiveness.

I think as a result of Snappy, Firefox is in a much happier performance place now. There are a big wins remaining, but we have tools and ideas on how to get there. We've come a long way from "how to make Firefox feel fast?" discussions in late 2011.

Snappy has been a tricky meta-project because work has to happen across teams. While my Performance team has an exclusive commitment to performance, other teams have to context-switch between feature-work, platform-work, performance, etc. There are also team culture differences on internal vs external communication, planning, etc.

Some of the projects are quite hard and require specialized expertise. This meant that we'd make a bunch of progress on a project (eg breakpad profiler backend) only to realize that we are blocked on someone we didn't loop into the project right away (eg Ted). Ideally we will minimize chances of surprises like this in the future.

Until recently my solution was to deal with this as a manager. I'd sync up with relevant managers about Snappy needs and try to get some Snappy bugs onto relevant team's todo. This has worked out ok, but there were a few too many instances of unexpected delays due to shifting team priorities, miscommunication, general lag. My conclusion is that at a developer-driven organization like Mozilla heavy manager involvement on Snappy-type projects is a sign that we are doing it wrong. Developers should be adding performance goals to their team's agenda.

Last week we came up with a more developer-centric way to do performance work. I'll still be around making sure things are moving forward, but from now one I'd like to see developers drive planning & coordination on a per-project basis. I'll introduce individual projects + their respective blogs as they start in the next couple of weeks.

Irving Reid (addon-manager startup performance lead) summed up key mechanics of the new approach in an email. Thanks, Irving.

###Irving's Summary

Coming out of the Snappy work week, we decided to try and make performance projects a little more structured than they have been in the past; see [Lawrence's post](http://lawrencemandel.com/2013/03/21/no-more-snappy-meetings-and-other-changes-from-the-snappy-team/) for a summary.

While not mentioned in Lawrence's blog, one of the things Taras (if I recall correctly) suggested was to have a project kick-off meeting to get rough agreement on scope, responsibilities, and how we're going to track progress. If everyone is happy with settling those questions over email, we can; I think we lose a little by not getting a chance to see and hear each other directly, but it is rather painful to get that scheduled in the current circumstances.

In any case I wasn't planning on delaying work until after the meeting could happen; it's more about getting things as clear as we can, as early as we can.

The current plan is for Felipe and I to do the patches, with me handling coordination and progress tracking as well. Everybody else is involved to make sure we're going in the right direction, and help us over roadblocks.

The progress tracking technique the Snappy team settled on last week was a combination of daily one-line updates using the [status bot](http://teamstat.us/#browse/irc.mozilla.org/perf) in the #perf channel, and a blog post every two weeks summarizing overall progress. I'll do the [blog posts](http://www.controlledflight.ca/category/mozilla/); depending on how things go I may do them weekly instead of biweekly.
]]></content>
  </entry>
  
</feed>
